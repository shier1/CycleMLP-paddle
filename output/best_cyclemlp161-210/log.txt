2022-01-18 13:00:35,497 
AMP: False
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 256
  BATCH_SIZE_EVAL: 8
  CROP_PCT: 0.9
  DATASET: imagenet2012
  DATA_PATH: /root/paddlejob/workspace/train_data/datasets/Light_ILSVRC2012
  IMAGE_SIZE: 224
  NUM_WORKERS: 16
EVAL: False
LOCAL_RANK: 0
MODEL:
  MIXER:
    EMBED_DIMS: [64, 128, 320, 512]
    LAYERS: [2, 2, 4, 2]
    MLP_RATIOS: [4, 4, 4, 4]
    TRANSITIONS: [True, True, True, True]
  NAME: cyclemlp_b1
  NUM_CLASSES: 1000
  PRETRAINED: None
  RESUME: CycleMLP-Epoch-160-Loss-3.3763265611259743
  TYPE: CycleMLP
NGPUS: 4
REPORT_FREQ: 50
SAVE: /root/paddlejob/workspace/output//train
SAVE_FREQ: 50
SEED: 0
TAG: default
TRAIN:
  ACCUM_ITER: 1
  AUTO_AUGMENT: True
  BASE_LR: 0.0005
  COLOR_JITTER: 0.4
  CUTMIX_ALPHA: 1.0
  CUTMIX_MINMAX: None
  END_LR: 5e-06
  GRAD_CLIP: 5.0
  LAST_EPOCH: 160
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    MILESTONES: 30, 60, 90
    NAME: warmupcosine
  MIXUP_ALPHA: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  NUM_EPOCHS: 300
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: AdamW
  RANDOM_ERASE_COUNT: 1
  RANDOM_ERASE_MODE: pixel
  RANDOM_ERASE_PROB: 0.25
  RANDOM_ERASE_SPLIT: False
  SMOOTHING: 0.1
  WARMUP_EPOCHS: 20
  WARMUP_START_LR: 5e-07
  WEIGHT_DECAY: 0.05
VALIDATE_FREQ: 2
VALIDATION:
  REQUIREMENTS: 0.789
2022-01-18 13:00:35,497 ----- world_size = 4, local_rank = 0
2022-01-18 13:00:36,274 ----- Total # of train batch (single gpu): 1252
2022-01-18 13:00:36,274 ----- Total # of val batch (single gpu): 1563
2022-01-18 13:00:38,311 ----- Resume Training: Load model and optmizer from CycleMLP-Epoch-160-Loss-3.3763265611259743
2022-01-18 13:00:38,311 Start training from epoch 161.
2022-01-18 13:00:38,311 Now training epoch 161. LR=0.000499
2022-01-18 13:02:33,498 Epoch[161/300], Step[0000/1252], Avg Loss: 3.4233, Avg Acc: 0.2480
2022-01-18 13:04:02,341 Epoch[161/300], Step[0050/1252], Avg Loss: 3.4318, Avg Acc: 0.3860
2022-01-18 13:05:30,174 Epoch[161/300], Step[0100/1252], Avg Loss: 3.4260, Avg Acc: 0.3992
2022-01-18 13:06:57,583 Epoch[161/300], Step[0150/1252], Avg Loss: 3.4091, Avg Acc: 0.3980
2022-01-18 13:08:25,512 Epoch[161/300], Step[0200/1252], Avg Loss: 3.3892, Avg Acc: 0.3993
2022-01-18 13:09:54,244 Epoch[161/300], Step[0250/1252], Avg Loss: 3.3732, Avg Acc: 0.4027
2022-01-18 13:11:21,753 Epoch[161/300], Step[0300/1252], Avg Loss: 3.3600, Avg Acc: 0.4084
2022-01-18 13:12:50,386 Epoch[161/300], Step[0350/1252], Avg Loss: 3.3781, Avg Acc: 0.4101
2022-01-18 13:14:18,952 Epoch[161/300], Step[0400/1252], Avg Loss: 3.3759, Avg Acc: 0.4084
2022-01-18 13:15:46,246 Epoch[161/300], Step[0450/1252], Avg Loss: 3.3830, Avg Acc: 0.4059
2022-01-18 13:17:12,171 Epoch[161/300], Step[0500/1252], Avg Loss: 3.3815, Avg Acc: 0.4070
2022-01-18 13:18:37,071 Epoch[161/300], Step[0550/1252], Avg Loss: 3.3739, Avg Acc: 0.4085
2022-01-18 13:20:03,894 Epoch[161/300], Step[0600/1252], Avg Loss: 3.3774, Avg Acc: 0.4096
2022-01-18 13:21:30,670 Epoch[161/300], Step[0650/1252], Avg Loss: 3.3817, Avg Acc: 0.4075
2022-01-18 13:22:57,247 Epoch[161/300], Step[0700/1252], Avg Loss: 3.3807, Avg Acc: 0.4088
2022-01-18 13:24:25,730 Epoch[161/300], Step[0750/1252], Avg Loss: 3.3804, Avg Acc: 0.4104
2022-01-18 13:25:52,536 Epoch[161/300], Step[0800/1252], Avg Loss: 3.3821, Avg Acc: 0.4098
2022-01-18 13:27:19,957 Epoch[161/300], Step[0850/1252], Avg Loss: 3.3783, Avg Acc: 0.4089
2022-01-18 13:28:47,407 Epoch[161/300], Step[0900/1252], Avg Loss: 3.3791, Avg Acc: 0.4093
2022-01-18 13:30:14,749 Epoch[161/300], Step[0950/1252], Avg Loss: 3.3781, Avg Acc: 0.4100
2022-01-18 13:31:41,174 Epoch[161/300], Step[1000/1252], Avg Loss: 3.3788, Avg Acc: 0.4090
2022-01-18 13:33:07,750 Epoch[161/300], Step[1050/1252], Avg Loss: 3.3797, Avg Acc: 0.4068
2022-01-18 13:34:34,893 Epoch[161/300], Step[1100/1252], Avg Loss: 3.3798, Avg Acc: 0.4061
2022-01-18 13:36:01,471 Epoch[161/300], Step[1150/1252], Avg Loss: 3.3816, Avg Acc: 0.4054
2022-01-18 13:37:29,548 Epoch[161/300], Step[1200/1252], Avg Loss: 3.3825, Avg Acc: 0.4050
2022-01-18 13:38:56,953 Epoch[161/300], Step[1250/1252], Avg Loss: 3.3830, Avg Acc: 0.4044
2022-01-18 13:39:04,017 ----- Epoch[161/300], Train Loss: 3.3829, Train Acc: 0.4044, time: 2305.70
2022-01-18 13:39:04,017 Now training epoch 162. LR=0.000494
2022-01-18 13:40:54,264 Epoch[162/300], Step[0000/1252], Avg Loss: 3.5038, Avg Acc: 0.2402
2022-01-18 13:42:21,581 Epoch[162/300], Step[0050/1252], Avg Loss: 3.4605, Avg Acc: 0.3975
2022-01-18 13:43:47,601 Epoch[162/300], Step[0100/1252], Avg Loss: 3.4145, Avg Acc: 0.3947
2022-01-18 13:45:13,029 Epoch[162/300], Step[0150/1252], Avg Loss: 3.4179, Avg Acc: 0.3984
2022-01-18 13:46:39,748 Epoch[162/300], Step[0200/1252], Avg Loss: 3.4038, Avg Acc: 0.4036
2022-01-18 13:48:06,605 Epoch[162/300], Step[0250/1252], Avg Loss: 3.3944, Avg Acc: 0.4076
2022-01-18 13:49:31,520 Epoch[162/300], Step[0300/1252], Avg Loss: 3.3927, Avg Acc: 0.4106
2022-01-18 13:50:58,512 Epoch[162/300], Step[0350/1252], Avg Loss: 3.3956, Avg Acc: 0.4085
2022-01-18 13:52:25,302 Epoch[162/300], Step[0400/1252], Avg Loss: 3.3927, Avg Acc: 0.4092
2022-01-18 13:53:51,600 Epoch[162/300], Step[0450/1252], Avg Loss: 3.3923, Avg Acc: 0.4080
2022-01-18 13:55:17,877 Epoch[162/300], Step[0500/1252], Avg Loss: 3.3898, Avg Acc: 0.4057
2022-01-18 13:56:43,569 Epoch[162/300], Step[0550/1252], Avg Loss: 3.3886, Avg Acc: 0.4061
2022-01-18 13:58:09,181 Epoch[162/300], Step[0600/1252], Avg Loss: 3.3858, Avg Acc: 0.4087
2022-01-18 13:59:36,560 Epoch[162/300], Step[0650/1252], Avg Loss: 3.3808, Avg Acc: 0.4069
2022-01-18 14:01:01,338 Epoch[162/300], Step[0700/1252], Avg Loss: 3.3721, Avg Acc: 0.4083
2022-01-18 14:02:27,716 Epoch[162/300], Step[0750/1252], Avg Loss: 3.3698, Avg Acc: 0.4098
2022-01-18 14:03:53,106 Epoch[162/300], Step[0800/1252], Avg Loss: 3.3734, Avg Acc: 0.4077
2022-01-18 14:05:20,226 Epoch[162/300], Step[0850/1252], Avg Loss: 3.3736, Avg Acc: 0.4063
2022-01-18 14:06:45,880 Epoch[162/300], Step[0900/1252], Avg Loss: 3.3774, Avg Acc: 0.4062
2022-01-18 14:08:10,973 Epoch[162/300], Step[0950/1252], Avg Loss: 3.3804, Avg Acc: 0.4059
2022-01-18 14:09:36,981 Epoch[162/300], Step[1000/1252], Avg Loss: 3.3819, Avg Acc: 0.4050
2022-01-18 14:11:03,919 Epoch[162/300], Step[1050/1252], Avg Loss: 3.3815, Avg Acc: 0.4034
2022-01-18 14:12:30,469 Epoch[162/300], Step[1100/1252], Avg Loss: 3.3846, Avg Acc: 0.4033
2022-01-18 14:13:56,740 Epoch[162/300], Step[1150/1252], Avg Loss: 3.3845, Avg Acc: 0.4028
2022-01-18 14:15:23,589 Epoch[162/300], Step[1200/1252], Avg Loss: 3.3855, Avg Acc: 0.4041
2022-01-18 14:16:48,691 Epoch[162/300], Step[1250/1252], Avg Loss: 3.3867, Avg Acc: 0.4049
2022-01-18 14:16:55,712 ----- Epoch[162/300], Train Loss: 3.3867, Train Acc: 0.4049, time: 2271.69
2022-01-18 14:16:55,712 ----- Validation after Epoch: 162
2022-01-18 14:18:10,390 Val Step[0000/1563], Avg Loss: 0.9971, Avg Acc@1: 0.6875, Avg Acc@5: 0.9375
2022-01-18 14:18:12,339 Val Step[0050/1563], Avg Loss: 1.1948, Avg Acc@1: 0.7273, Avg Acc@5: 0.9136
2022-01-18 14:18:14,185 Val Step[0100/1563], Avg Loss: 1.2033, Avg Acc@1: 0.7283, Avg Acc@5: 0.9152
2022-01-18 14:18:16,017 Val Step[0150/1563], Avg Loss: 1.2005, Avg Acc@1: 0.7301, Avg Acc@5: 0.9120
2022-01-18 14:18:17,839 Val Step[0200/1563], Avg Loss: 1.1969, Avg Acc@1: 0.7326, Avg Acc@5: 0.9145
2022-01-18 14:18:19,684 Val Step[0250/1563], Avg Loss: 1.1880, Avg Acc@1: 0.7326, Avg Acc@5: 0.9147
2022-01-18 14:18:21,546 Val Step[0300/1563], Avg Loss: 1.1898, Avg Acc@1: 0.7322, Avg Acc@5: 0.9138
2022-01-18 14:18:23,393 Val Step[0350/1563], Avg Loss: 1.1933, Avg Acc@1: 0.7313, Avg Acc@5: 0.9131
2022-01-18 14:18:25,294 Val Step[0400/1563], Avg Loss: 1.1924, Avg Acc@1: 0.7304, Avg Acc@5: 0.9133
2022-01-18 14:18:27,123 Val Step[0450/1563], Avg Loss: 1.1984, Avg Acc@1: 0.7277, Avg Acc@5: 0.9127
2022-01-18 14:18:28,935 Val Step[0500/1563], Avg Loss: 1.2007, Avg Acc@1: 0.7272, Avg Acc@5: 0.9127
2022-01-18 14:18:30,735 Val Step[0550/1563], Avg Loss: 1.2001, Avg Acc@1: 0.7273, Avg Acc@5: 0.9127
2022-01-18 14:18:32,536 Val Step[0600/1563], Avg Loss: 1.2003, Avg Acc@1: 0.7273, Avg Acc@5: 0.9133
2022-01-18 14:18:34,333 Val Step[0650/1563], Avg Loss: 1.1997, Avg Acc@1: 0.7282, Avg Acc@5: 0.9135
2022-01-18 14:18:36,170 Val Step[0700/1563], Avg Loss: 1.1959, Avg Acc@1: 0.7291, Avg Acc@5: 0.9146
2022-01-18 14:18:37,993 Val Step[0750/1563], Avg Loss: 1.2017, Avg Acc@1: 0.7274, Avg Acc@5: 0.9142
2022-01-18 14:18:39,824 Val Step[0800/1563], Avg Loss: 1.2006, Avg Acc@1: 0.7283, Avg Acc@5: 0.9143
2022-01-18 14:18:41,648 Val Step[0850/1563], Avg Loss: 1.2031, Avg Acc@1: 0.7279, Avg Acc@5: 0.9137
2022-01-18 14:18:43,585 Val Step[0900/1563], Avg Loss: 1.1997, Avg Acc@1: 0.7284, Avg Acc@5: 0.9141
2022-01-18 14:18:45,532 Val Step[0950/1563], Avg Loss: 1.2001, Avg Acc@1: 0.7287, Avg Acc@5: 0.9140
2022-01-18 14:18:47,397 Val Step[1000/1563], Avg Loss: 1.2005, Avg Acc@1: 0.7287, Avg Acc@5: 0.9137
2022-01-18 14:18:49,309 Val Step[1050/1563], Avg Loss: 1.2026, Avg Acc@1: 0.7273, Avg Acc@5: 0.9134
2022-01-18 14:18:51,105 Val Step[1100/1563], Avg Loss: 1.2020, Avg Acc@1: 0.7272, Avg Acc@5: 0.9135
2022-01-18 14:18:52,906 Val Step[1150/1563], Avg Loss: 1.2002, Avg Acc@1: 0.7276, Avg Acc@5: 0.9139
2022-01-18 14:18:54,873 Val Step[1200/1563], Avg Loss: 1.1982, Avg Acc@1: 0.7285, Avg Acc@5: 0.9139
2022-01-18 14:18:56,716 Val Step[1250/1563], Avg Loss: 1.1972, Avg Acc@1: 0.7285, Avg Acc@5: 0.9140
2022-01-18 14:18:58,530 Val Step[1300/1563], Avg Loss: 1.1998, Avg Acc@1: 0.7284, Avg Acc@5: 0.9136
2022-01-18 14:19:00,428 Val Step[1350/1563], Avg Loss: 1.1999, Avg Acc@1: 0.7280, Avg Acc@5: 0.9136
2022-01-18 14:19:02,471 Val Step[1400/1563], Avg Loss: 1.1991, Avg Acc@1: 0.7276, Avg Acc@5: 0.9139
2022-01-18 14:19:04,525 Val Step[1450/1563], Avg Loss: 1.1991, Avg Acc@1: 0.7279, Avg Acc@5: 0.9140
2022-01-18 14:19:06,653 Val Step[1500/1563], Avg Loss: 1.1984, Avg Acc@1: 0.7280, Avg Acc@5: 0.9141
2022-01-18 14:19:08,679 Val Step[1550/1563], Avg Loss: 1.1998, Avg Acc@1: 0.7278, Avg Acc@5: 0.9138
2022-01-18 14:19:10,594 ----- Epoch[162/300], Validation Loss: 1.1997, Validation Acc@1: 0.7277, Validation Acc@5: 0.9139, time: 134.88
2022-01-18 14:19:11,072 the pre best model acc:0.0000, at epoch 0
2022-01-18 14:19:11,073 current best model acc:0.7277, at epoch 162
2022-01-18 14:19:11,073 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 14:19:11,073 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 14:19:11,073 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 14:19:11,073 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 14:19:11,073 Now training epoch 163. LR=0.000488
2022-01-18 14:21:07,639 Epoch[163/300], Step[0000/1252], Avg Loss: 3.2457, Avg Acc: 0.4932
2022-01-18 14:22:36,448 Epoch[163/300], Step[0050/1252], Avg Loss: 3.3303, Avg Acc: 0.4367
2022-01-18 14:24:03,876 Epoch[163/300], Step[0100/1252], Avg Loss: 3.3453, Avg Acc: 0.4374
2022-01-18 14:25:30,853 Epoch[163/300], Step[0150/1252], Avg Loss: 3.3491, Avg Acc: 0.4234
2022-01-18 14:26:57,677 Epoch[163/300], Step[0200/1252], Avg Loss: 3.3615, Avg Acc: 0.4218
2022-01-18 14:28:25,944 Epoch[163/300], Step[0250/1252], Avg Loss: 3.3649, Avg Acc: 0.4226
2022-01-18 14:29:54,407 Epoch[163/300], Step[0300/1252], Avg Loss: 3.3601, Avg Acc: 0.4221
2022-01-18 14:31:22,098 Epoch[163/300], Step[0350/1252], Avg Loss: 3.3649, Avg Acc: 0.4213
2022-01-18 14:32:48,692 Epoch[163/300], Step[0400/1252], Avg Loss: 3.3653, Avg Acc: 0.4210
2022-01-18 14:34:15,855 Epoch[163/300], Step[0450/1252], Avg Loss: 3.3627, Avg Acc: 0.4183
2022-01-18 14:35:42,973 Epoch[163/300], Step[0500/1252], Avg Loss: 3.3622, Avg Acc: 0.4152
2022-01-18 14:37:09,989 Epoch[163/300], Step[0550/1252], Avg Loss: 3.3698, Avg Acc: 0.4140
2022-01-18 14:38:37,142 Epoch[163/300], Step[0600/1252], Avg Loss: 3.3703, Avg Acc: 0.4148
2022-01-18 14:40:04,559 Epoch[163/300], Step[0650/1252], Avg Loss: 3.3697, Avg Acc: 0.4148
2022-01-18 14:41:30,907 Epoch[163/300], Step[0700/1252], Avg Loss: 3.3723, Avg Acc: 0.4121
2022-01-18 14:42:57,966 Epoch[163/300], Step[0750/1252], Avg Loss: 3.3764, Avg Acc: 0.4105
2022-01-18 14:44:24,613 Epoch[163/300], Step[0800/1252], Avg Loss: 3.3790, Avg Acc: 0.4115
2022-01-18 14:45:50,586 Epoch[163/300], Step[0850/1252], Avg Loss: 3.3796, Avg Acc: 0.4107
2022-01-18 14:47:17,276 Epoch[163/300], Step[0900/1252], Avg Loss: 3.3817, Avg Acc: 0.4080
2022-01-18 14:48:43,786 Epoch[163/300], Step[0950/1252], Avg Loss: 3.3791, Avg Acc: 0.4081
2022-01-18 14:50:10,625 Epoch[163/300], Step[1000/1252], Avg Loss: 3.3789, Avg Acc: 0.4087
2022-01-18 14:51:38,272 Epoch[163/300], Step[1050/1252], Avg Loss: 3.3784, Avg Acc: 0.4078
2022-01-18 14:53:05,425 Epoch[163/300], Step[1100/1252], Avg Loss: 3.3788, Avg Acc: 0.4074
2022-01-18 14:54:31,953 Epoch[163/300], Step[1150/1252], Avg Loss: 3.3820, Avg Acc: 0.4072
2022-01-18 14:55:58,909 Epoch[163/300], Step[1200/1252], Avg Loss: 3.3801, Avg Acc: 0.4073
2022-01-18 14:57:26,749 Epoch[163/300], Step[1250/1252], Avg Loss: 3.3837, Avg Acc: 0.4057
2022-01-18 14:57:33,846 ----- Epoch[163/300], Train Loss: 3.3837, Train Acc: 0.4057, time: 2302.77, Best Val(epoch162) Acc@1: 0.7277
2022-01-18 14:57:33,846 Now training epoch 164. LR=0.000483
2022-01-18 14:59:19,256 Epoch[164/300], Step[0000/1252], Avg Loss: 2.5861, Avg Acc: 0.5410
2022-01-18 15:00:46,162 Epoch[164/300], Step[0050/1252], Avg Loss: 3.3942, Avg Acc: 0.4169
2022-01-18 15:02:12,928 Epoch[164/300], Step[0100/1252], Avg Loss: 3.3841, Avg Acc: 0.4153
2022-01-18 15:03:40,052 Epoch[164/300], Step[0150/1252], Avg Loss: 3.3673, Avg Acc: 0.4274
2022-01-18 15:05:07,223 Epoch[164/300], Step[0200/1252], Avg Loss: 3.3703, Avg Acc: 0.4171
2022-01-18 15:06:34,325 Epoch[164/300], Step[0250/1252], Avg Loss: 3.3626, Avg Acc: 0.4097
2022-01-18 15:08:01,700 Epoch[164/300], Step[0300/1252], Avg Loss: 3.3701, Avg Acc: 0.4134
2022-01-18 15:09:28,795 Epoch[164/300], Step[0350/1252], Avg Loss: 3.3608, Avg Acc: 0.4156
2022-01-18 15:10:56,392 Epoch[164/300], Step[0400/1252], Avg Loss: 3.3595, Avg Acc: 0.4160
2022-01-18 15:12:23,536 Epoch[164/300], Step[0450/1252], Avg Loss: 3.3630, Avg Acc: 0.4147
2022-01-18 15:13:51,125 Epoch[164/300], Step[0500/1252], Avg Loss: 3.3692, Avg Acc: 0.4142
2022-01-18 15:15:19,080 Epoch[164/300], Step[0550/1252], Avg Loss: 3.3658, Avg Acc: 0.4155
2022-01-18 15:16:47,633 Epoch[164/300], Step[0600/1252], Avg Loss: 3.3685, Avg Acc: 0.4150
2022-01-18 15:18:14,390 Epoch[164/300], Step[0650/1252], Avg Loss: 3.3697, Avg Acc: 0.4137
2022-01-18 15:19:43,025 Epoch[164/300], Step[0700/1252], Avg Loss: 3.3744, Avg Acc: 0.4121
2022-01-18 15:21:11,042 Epoch[164/300], Step[0750/1252], Avg Loss: 3.3774, Avg Acc: 0.4107
2022-01-18 15:22:39,366 Epoch[164/300], Step[0800/1252], Avg Loss: 3.3822, Avg Acc: 0.4082
2022-01-18 15:24:06,915 Epoch[164/300], Step[0850/1252], Avg Loss: 3.3863, Avg Acc: 0.4068
2022-01-18 15:25:35,136 Epoch[164/300], Step[0900/1252], Avg Loss: 3.3874, Avg Acc: 0.4071
2022-01-18 15:27:03,255 Epoch[164/300], Step[0950/1252], Avg Loss: 3.3891, Avg Acc: 0.4069
2022-01-18 15:28:29,428 Epoch[164/300], Step[1000/1252], Avg Loss: 3.3866, Avg Acc: 0.4070
2022-01-18 15:29:56,489 Epoch[164/300], Step[1050/1252], Avg Loss: 3.3862, Avg Acc: 0.4081
2022-01-18 15:31:24,096 Epoch[164/300], Step[1100/1252], Avg Loss: 3.3856, Avg Acc: 0.4083
2022-01-18 15:32:50,222 Epoch[164/300], Step[1150/1252], Avg Loss: 3.3833, Avg Acc: 0.4091
2022-01-18 15:34:18,070 Epoch[164/300], Step[1200/1252], Avg Loss: 3.3840, Avg Acc: 0.4096
2022-01-18 15:35:46,148 Epoch[164/300], Step[1250/1252], Avg Loss: 3.3857, Avg Acc: 0.4088
2022-01-18 15:35:53,276 ----- Epoch[164/300], Train Loss: 3.3857, Train Acc: 0.4088, time: 2299.42, Best Val(epoch162) Acc@1: 0.7277
2022-01-18 15:35:53,276 ----- Validation after Epoch: 164
2022-01-18 15:37:09,702 Val Step[0000/1563], Avg Loss: 1.0748, Avg Acc@1: 0.6875, Avg Acc@5: 0.9375
2022-01-18 15:37:11,803 Val Step[0050/1563], Avg Loss: 1.2090, Avg Acc@1: 0.7286, Avg Acc@5: 0.9277
2022-01-18 15:37:13,723 Val Step[0100/1563], Avg Loss: 1.2260, Avg Acc@1: 0.7262, Avg Acc@5: 0.9226
2022-01-18 15:37:15,575 Val Step[0150/1563], Avg Loss: 1.2241, Avg Acc@1: 0.7270, Avg Acc@5: 0.9187
2022-01-18 15:37:17,420 Val Step[0200/1563], Avg Loss: 1.2281, Avg Acc@1: 0.7295, Avg Acc@5: 0.9176
2022-01-18 15:37:19,258 Val Step[0250/1563], Avg Loss: 1.2204, Avg Acc@1: 0.7301, Avg Acc@5: 0.9167
2022-01-18 15:37:21,093 Val Step[0300/1563], Avg Loss: 1.2278, Avg Acc@1: 0.7301, Avg Acc@5: 0.9147
2022-01-18 15:37:23,023 Val Step[0350/1563], Avg Loss: 1.2308, Avg Acc@1: 0.7291, Avg Acc@5: 0.9137
2022-01-18 15:37:24,959 Val Step[0400/1563], Avg Loss: 1.2296, Avg Acc@1: 0.7304, Avg Acc@5: 0.9140
2022-01-18 15:37:26,898 Val Step[0450/1563], Avg Loss: 1.2357, Avg Acc@1: 0.7274, Avg Acc@5: 0.9137
2022-01-18 15:37:28,800 Val Step[0500/1563], Avg Loss: 1.2408, Avg Acc@1: 0.7265, Avg Acc@5: 0.9141
2022-01-18 15:37:30,611 Val Step[0550/1563], Avg Loss: 1.2418, Avg Acc@1: 0.7246, Avg Acc@5: 0.9142
2022-01-18 15:37:32,419 Val Step[0600/1563], Avg Loss: 1.2408, Avg Acc@1: 0.7245, Avg Acc@5: 0.9144
2022-01-18 15:37:34,302 Val Step[0650/1563], Avg Loss: 1.2414, Avg Acc@1: 0.7246, Avg Acc@5: 0.9143
2022-01-18 15:37:36,256 Val Step[0700/1563], Avg Loss: 1.2381, Avg Acc@1: 0.7251, Avg Acc@5: 0.9149
2022-01-18 15:37:38,179 Val Step[0750/1563], Avg Loss: 1.2432, Avg Acc@1: 0.7237, Avg Acc@5: 0.9143
2022-01-18 15:37:40,098 Val Step[0800/1563], Avg Loss: 1.2424, Avg Acc@1: 0.7250, Avg Acc@5: 0.9142
2022-01-18 15:37:42,001 Val Step[0850/1563], Avg Loss: 1.2435, Avg Acc@1: 0.7246, Avg Acc@5: 0.9141
2022-01-18 15:37:43,816 Val Step[0900/1563], Avg Loss: 1.2399, Avg Acc@1: 0.7247, Avg Acc@5: 0.9145
2022-01-18 15:37:45,664 Val Step[0950/1563], Avg Loss: 1.2408, Avg Acc@1: 0.7251, Avg Acc@5: 0.9144
2022-01-18 15:37:47,514 Val Step[1000/1563], Avg Loss: 1.2419, Avg Acc@1: 0.7249, Avg Acc@5: 0.9138
2022-01-18 15:37:49,436 Val Step[1050/1563], Avg Loss: 1.2433, Avg Acc@1: 0.7239, Avg Acc@5: 0.9134
2022-01-18 15:37:51,410 Val Step[1100/1563], Avg Loss: 1.2431, Avg Acc@1: 0.7235, Avg Acc@5: 0.9131
2022-01-18 15:37:53,392 Val Step[1150/1563], Avg Loss: 1.2415, Avg Acc@1: 0.7236, Avg Acc@5: 0.9134
2022-01-18 15:37:55,380 Val Step[1200/1563], Avg Loss: 1.2408, Avg Acc@1: 0.7240, Avg Acc@5: 0.9132
2022-01-18 15:37:57,324 Val Step[1250/1563], Avg Loss: 1.2400, Avg Acc@1: 0.7238, Avg Acc@5: 0.9133
2022-01-18 15:37:59,354 Val Step[1300/1563], Avg Loss: 1.2427, Avg Acc@1: 0.7235, Avg Acc@5: 0.9129
2022-01-18 15:38:01,380 Val Step[1350/1563], Avg Loss: 1.2434, Avg Acc@1: 0.7229, Avg Acc@5: 0.9124
2022-01-18 15:38:03,442 Val Step[1400/1563], Avg Loss: 1.2422, Avg Acc@1: 0.7233, Avg Acc@5: 0.9126
2022-01-18 15:38:05,472 Val Step[1450/1563], Avg Loss: 1.2425, Avg Acc@1: 0.7234, Avg Acc@5: 0.9126
2022-01-18 15:38:07,505 Val Step[1500/1563], Avg Loss: 1.2422, Avg Acc@1: 0.7234, Avg Acc@5: 0.9129
2022-01-18 15:38:09,333 Val Step[1550/1563], Avg Loss: 1.2425, Avg Acc@1: 0.7234, Avg Acc@5: 0.9126
2022-01-18 15:38:11,162 ----- Epoch[164/300], Validation Loss: 1.2423, Validation Acc@1: 0.7233, Validation Acc@5: 0.9127, time: 137.88
2022-01-18 15:38:11,162 Now training epoch 165. LR=0.000477
2022-01-18 15:39:56,935 Epoch[165/300], Step[0000/1252], Avg Loss: 2.8319, Avg Acc: 0.6377
2022-01-18 15:41:24,080 Epoch[165/300], Step[0050/1252], Avg Loss: 3.3929, Avg Acc: 0.3904
2022-01-18 15:42:49,042 Epoch[165/300], Step[0100/1252], Avg Loss: 3.3674, Avg Acc: 0.4287
2022-01-18 15:44:16,290 Epoch[165/300], Step[0150/1252], Avg Loss: 3.3464, Avg Acc: 0.4326
2022-01-18 15:45:42,952 Epoch[165/300], Step[0200/1252], Avg Loss: 3.3484, Avg Acc: 0.4232
2022-01-18 15:47:10,055 Epoch[165/300], Step[0250/1252], Avg Loss: 3.3574, Avg Acc: 0.4216
2022-01-18 15:48:38,080 Epoch[165/300], Step[0300/1252], Avg Loss: 3.3607, Avg Acc: 0.4193
2022-01-18 15:50:05,412 Epoch[165/300], Step[0350/1252], Avg Loss: 3.3596, Avg Acc: 0.4170
2022-01-18 15:51:32,847 Epoch[165/300], Step[0400/1252], Avg Loss: 3.3669, Avg Acc: 0.4191
2022-01-18 15:53:00,644 Epoch[165/300], Step[0450/1252], Avg Loss: 3.3700, Avg Acc: 0.4177
2022-01-18 15:54:26,796 Epoch[165/300], Step[0500/1252], Avg Loss: 3.3664, Avg Acc: 0.4173
2022-01-18 15:55:52,972 Epoch[165/300], Step[0550/1252], Avg Loss: 3.3647, Avg Acc: 0.4162
2022-01-18 15:57:21,139 Epoch[165/300], Step[0600/1252], Avg Loss: 3.3692, Avg Acc: 0.4142
2022-01-18 15:58:46,997 Epoch[165/300], Step[0650/1252], Avg Loss: 3.3691, Avg Acc: 0.4108
2022-01-18 16:00:14,148 Epoch[165/300], Step[0700/1252], Avg Loss: 3.3705, Avg Acc: 0.4102
2022-01-18 16:01:40,523 Epoch[165/300], Step[0750/1252], Avg Loss: 3.3688, Avg Acc: 0.4109
2022-01-18 16:03:07,052 Epoch[165/300], Step[0800/1252], Avg Loss: 3.3661, Avg Acc: 0.4112
2022-01-18 16:04:34,263 Epoch[165/300], Step[0850/1252], Avg Loss: 3.3669, Avg Acc: 0.4112
2022-01-18 16:06:00,656 Epoch[165/300], Step[0900/1252], Avg Loss: 3.3705, Avg Acc: 0.4109
2022-01-18 16:07:27,176 Epoch[165/300], Step[0950/1252], Avg Loss: 3.3713, Avg Acc: 0.4115
2022-01-18 16:08:53,702 Epoch[165/300], Step[1000/1252], Avg Loss: 3.3749, Avg Acc: 0.4107
2022-01-18 16:10:20,495 Epoch[165/300], Step[1050/1252], Avg Loss: 3.3713, Avg Acc: 0.4114
2022-01-18 16:11:48,014 Epoch[165/300], Step[1100/1252], Avg Loss: 3.3716, Avg Acc: 0.4118
2022-01-18 16:13:15,177 Epoch[165/300], Step[1150/1252], Avg Loss: 3.3714, Avg Acc: 0.4116
2022-01-18 16:14:42,989 Epoch[165/300], Step[1200/1252], Avg Loss: 3.3718, Avg Acc: 0.4112
2022-01-18 16:16:11,990 Epoch[165/300], Step[1250/1252], Avg Loss: 3.3743, Avg Acc: 0.4102
2022-01-18 16:16:19,006 ----- Epoch[165/300], Train Loss: 3.3743, Train Acc: 0.4102, time: 2287.84, Best Val(epoch162) Acc@1: 0.7277
2022-01-18 16:16:19,007 Now training epoch 166. LR=0.000472
2022-01-18 16:18:13,616 Epoch[166/300], Step[0000/1252], Avg Loss: 3.6325, Avg Acc: 0.1484
2022-01-18 16:19:41,562 Epoch[166/300], Step[0050/1252], Avg Loss: 3.4606, Avg Acc: 0.3997
2022-01-18 16:21:08,675 Epoch[166/300], Step[0100/1252], Avg Loss: 3.4202, Avg Acc: 0.4115
2022-01-18 16:22:36,054 Epoch[166/300], Step[0150/1252], Avg Loss: 3.4230, Avg Acc: 0.4102
2022-01-18 16:24:03,040 Epoch[166/300], Step[0200/1252], Avg Loss: 3.4171, Avg Acc: 0.4003
2022-01-18 16:25:30,986 Epoch[166/300], Step[0250/1252], Avg Loss: 3.4031, Avg Acc: 0.4032
2022-01-18 16:26:58,451 Epoch[166/300], Step[0300/1252], Avg Loss: 3.4111, Avg Acc: 0.4037
2022-01-18 16:28:25,580 Epoch[166/300], Step[0350/1252], Avg Loss: 3.4038, Avg Acc: 0.4036
2022-01-18 16:29:52,148 Epoch[166/300], Step[0400/1252], Avg Loss: 3.3993, Avg Acc: 0.4051
2022-01-18 16:31:19,479 Epoch[166/300], Step[0450/1252], Avg Loss: 3.3885, Avg Acc: 0.4106
2022-01-18 16:32:47,648 Epoch[166/300], Step[0500/1252], Avg Loss: 3.3862, Avg Acc: 0.4091
2022-01-18 16:34:14,998 Epoch[166/300], Step[0550/1252], Avg Loss: 3.3867, Avg Acc: 0.4083
2022-01-18 16:35:42,386 Epoch[166/300], Step[0600/1252], Avg Loss: 3.3805, Avg Acc: 0.4069
2022-01-18 16:37:09,360 Epoch[166/300], Step[0650/1252], Avg Loss: 3.3797, Avg Acc: 0.4061
2022-01-18 16:38:37,115 Epoch[166/300], Step[0700/1252], Avg Loss: 3.3804, Avg Acc: 0.4070
2022-01-18 16:40:03,960 Epoch[166/300], Step[0750/1252], Avg Loss: 3.3774, Avg Acc: 0.4075
2022-01-18 16:41:28,280 Epoch[166/300], Step[0800/1252], Avg Loss: 3.3771, Avg Acc: 0.4092
2022-01-18 16:42:54,623 Epoch[166/300], Step[0850/1252], Avg Loss: 3.3770, Avg Acc: 0.4096
2022-01-18 16:44:22,134 Epoch[166/300], Step[0900/1252], Avg Loss: 3.3790, Avg Acc: 0.4094
2022-01-18 16:45:50,029 Epoch[166/300], Step[0950/1252], Avg Loss: 3.3755, Avg Acc: 0.4090
2022-01-18 16:47:17,592 Epoch[166/300], Step[1000/1252], Avg Loss: 3.3763, Avg Acc: 0.4079
2022-01-18 16:48:45,535 Epoch[166/300], Step[1050/1252], Avg Loss: 3.3765, Avg Acc: 0.4059
2022-01-18 16:50:13,467 Epoch[166/300], Step[1100/1252], Avg Loss: 3.3747, Avg Acc: 0.4061
2022-01-18 16:51:40,103 Epoch[166/300], Step[1150/1252], Avg Loss: 3.3738, Avg Acc: 0.4061
2022-01-18 16:53:07,964 Epoch[166/300], Step[1200/1252], Avg Loss: 3.3738, Avg Acc: 0.4067
2022-01-18 16:54:35,796 Epoch[166/300], Step[1250/1252], Avg Loss: 3.3773, Avg Acc: 0.4080
2022-01-18 16:54:42,881 ----- Epoch[166/300], Train Loss: 3.3773, Train Acc: 0.4080, time: 2303.87, Best Val(epoch162) Acc@1: 0.7277
2022-01-18 16:54:42,881 ----- Validation after Epoch: 166
2022-01-18 16:55:57,918 Val Step[0000/1563], Avg Loss: 1.1602, Avg Acc@1: 0.7500, Avg Acc@5: 0.9062
2022-01-18 16:55:59,772 Val Step[0050/1563], Avg Loss: 1.1912, Avg Acc@1: 0.7237, Avg Acc@5: 0.9087
2022-01-18 16:56:01,622 Val Step[0100/1563], Avg Loss: 1.1975, Avg Acc@1: 0.7271, Avg Acc@5: 0.9158
2022-01-18 16:56:03,565 Val Step[0150/1563], Avg Loss: 1.1946, Avg Acc@1: 0.7334, Avg Acc@5: 0.9158
2022-01-18 16:56:05,459 Val Step[0200/1563], Avg Loss: 1.1928, Avg Acc@1: 0.7335, Avg Acc@5: 0.9165
2022-01-18 16:56:07,390 Val Step[0250/1563], Avg Loss: 1.1849, Avg Acc@1: 0.7356, Avg Acc@5: 0.9167
2022-01-18 16:56:09,298 Val Step[0300/1563], Avg Loss: 1.1859, Avg Acc@1: 0.7362, Avg Acc@5: 0.9165
2022-01-18 16:56:11,083 Val Step[0350/1563], Avg Loss: 1.1928, Avg Acc@1: 0.7350, Avg Acc@5: 0.9159
2022-01-18 16:56:12,903 Val Step[0400/1563], Avg Loss: 1.1936, Avg Acc@1: 0.7355, Avg Acc@5: 0.9160
2022-01-18 16:56:14,753 Val Step[0450/1563], Avg Loss: 1.2005, Avg Acc@1: 0.7326, Avg Acc@5: 0.9151
2022-01-18 16:56:16,553 Val Step[0500/1563], Avg Loss: 1.2018, Avg Acc@1: 0.7317, Avg Acc@5: 0.9153
2022-01-18 16:56:18,346 Val Step[0550/1563], Avg Loss: 1.2034, Avg Acc@1: 0.7315, Avg Acc@5: 0.9153
2022-01-18 16:56:20,230 Val Step[0600/1563], Avg Loss: 1.2012, Avg Acc@1: 0.7314, Avg Acc@5: 0.9162
2022-01-18 16:56:22,135 Val Step[0650/1563], Avg Loss: 1.2007, Avg Acc@1: 0.7317, Avg Acc@5: 0.9166
2022-01-18 16:56:24,030 Val Step[0700/1563], Avg Loss: 1.1984, Avg Acc@1: 0.7323, Avg Acc@5: 0.9174
2022-01-18 16:56:25,937 Val Step[0750/1563], Avg Loss: 1.2049, Avg Acc@1: 0.7304, Avg Acc@5: 0.9166
2022-01-18 16:56:27,928 Val Step[0800/1563], Avg Loss: 1.2052, Avg Acc@1: 0.7309, Avg Acc@5: 0.9164
2022-01-18 16:56:30,006 Val Step[0850/1563], Avg Loss: 1.2067, Avg Acc@1: 0.7301, Avg Acc@5: 0.9160
2022-01-18 16:56:32,082 Val Step[0900/1563], Avg Loss: 1.2043, Avg Acc@1: 0.7304, Avg Acc@5: 0.9162
2022-01-18 16:56:34,186 Val Step[0950/1563], Avg Loss: 1.2041, Avg Acc@1: 0.7308, Avg Acc@5: 0.9165
2022-01-18 16:56:36,042 Val Step[1000/1563], Avg Loss: 1.2041, Avg Acc@1: 0.7312, Avg Acc@5: 0.9163
2022-01-18 16:56:37,851 Val Step[1050/1563], Avg Loss: 1.2065, Avg Acc@1: 0.7299, Avg Acc@5: 0.9160
2022-01-18 16:56:39,685 Val Step[1100/1563], Avg Loss: 1.2066, Avg Acc@1: 0.7292, Avg Acc@5: 0.9163
2022-01-18 16:56:41,655 Val Step[1150/1563], Avg Loss: 1.2060, Avg Acc@1: 0.7296, Avg Acc@5: 0.9165
2022-01-18 16:56:43,594 Val Step[1200/1563], Avg Loss: 1.2051, Avg Acc@1: 0.7300, Avg Acc@5: 0.9166
2022-01-18 16:56:45,511 Val Step[1250/1563], Avg Loss: 1.2039, Avg Acc@1: 0.7300, Avg Acc@5: 0.9169
2022-01-18 16:56:47,356 Val Step[1300/1563], Avg Loss: 1.2073, Avg Acc@1: 0.7296, Avg Acc@5: 0.9164
2022-01-18 16:56:49,169 Val Step[1350/1563], Avg Loss: 1.2074, Avg Acc@1: 0.7295, Avg Acc@5: 0.9163
2022-01-18 16:56:51,081 Val Step[1400/1563], Avg Loss: 1.2064, Avg Acc@1: 0.7297, Avg Acc@5: 0.9162
2022-01-18 16:56:53,059 Val Step[1450/1563], Avg Loss: 1.2065, Avg Acc@1: 0.7298, Avg Acc@5: 0.9161
2022-01-18 16:56:55,048 Val Step[1500/1563], Avg Loss: 1.2062, Avg Acc@1: 0.7297, Avg Acc@5: 0.9165
2022-01-18 16:56:56,874 Val Step[1550/1563], Avg Loss: 1.2063, Avg Acc@1: 0.7297, Avg Acc@5: 0.9164
2022-01-18 16:56:58,732 ----- Epoch[166/300], Validation Loss: 1.2061, Validation Acc@1: 0.7296, Validation Acc@5: 0.9166, time: 135.85
2022-01-18 16:57:00,162 the pre best model acc:0.7277, at epoch 162
2022-01-18 16:57:00,447 current best model acc:0.7296, at epoch 166
2022-01-18 16:57:00,447 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 16:57:00,447 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 16:57:00,447 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 16:57:00,448 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 16:57:00,448 Now training epoch 167. LR=0.000466
2022-01-18 16:58:44,503 Epoch[167/300], Step[0000/1252], Avg Loss: 2.8913, Avg Acc: 0.3330
2022-01-18 17:00:11,605 Epoch[167/300], Step[0050/1252], Avg Loss: 3.3906, Avg Acc: 0.4071
2022-01-18 17:01:38,099 Epoch[167/300], Step[0100/1252], Avg Loss: 3.3706, Avg Acc: 0.4063
2022-01-18 17:03:05,084 Epoch[167/300], Step[0150/1252], Avg Loss: 3.3615, Avg Acc: 0.4044
2022-01-18 17:04:32,795 Epoch[167/300], Step[0200/1252], Avg Loss: 3.3521, Avg Acc: 0.4115
2022-01-18 17:06:00,288 Epoch[167/300], Step[0250/1252], Avg Loss: 3.3518, Avg Acc: 0.4131
2022-01-18 17:07:28,472 Epoch[167/300], Step[0300/1252], Avg Loss: 3.3517, Avg Acc: 0.4113
2022-01-18 17:08:55,582 Epoch[167/300], Step[0350/1252], Avg Loss: 3.3505, Avg Acc: 0.4113
2022-01-18 17:10:22,067 Epoch[167/300], Step[0400/1252], Avg Loss: 3.3630, Avg Acc: 0.4106
2022-01-18 17:11:49,016 Epoch[167/300], Step[0450/1252], Avg Loss: 3.3611, Avg Acc: 0.4113
2022-01-18 17:13:15,965 Epoch[167/300], Step[0500/1252], Avg Loss: 3.3577, Avg Acc: 0.4129
2022-01-18 17:14:41,875 Epoch[167/300], Step[0550/1252], Avg Loss: 3.3571, Avg Acc: 0.4123
2022-01-18 17:16:08,966 Epoch[167/300], Step[0600/1252], Avg Loss: 3.3592, Avg Acc: 0.4135
2022-01-18 17:17:36,502 Epoch[167/300], Step[0650/1252], Avg Loss: 3.3557, Avg Acc: 0.4155
2022-01-18 17:19:03,605 Epoch[167/300], Step[0700/1252], Avg Loss: 3.3577, Avg Acc: 0.4145
2022-01-18 17:20:31,142 Epoch[167/300], Step[0750/1252], Avg Loss: 3.3594, Avg Acc: 0.4147
2022-01-18 17:21:59,152 Epoch[167/300], Step[0800/1252], Avg Loss: 3.3622, Avg Acc: 0.4143
2022-01-18 17:23:27,498 Epoch[167/300], Step[0850/1252], Avg Loss: 3.3651, Avg Acc: 0.4142
2022-01-18 17:24:54,240 Epoch[167/300], Step[0900/1252], Avg Loss: 3.3639, Avg Acc: 0.4135
2022-01-18 17:26:22,957 Epoch[167/300], Step[0950/1252], Avg Loss: 3.3638, Avg Acc: 0.4133
2022-01-18 17:27:49,051 Epoch[167/300], Step[1000/1252], Avg Loss: 3.3634, Avg Acc: 0.4143
2022-01-18 17:29:16,674 Epoch[167/300], Step[1050/1252], Avg Loss: 3.3647, Avg Acc: 0.4144
2022-01-18 17:30:43,172 Epoch[167/300], Step[1100/1252], Avg Loss: 3.3676, Avg Acc: 0.4138
2022-01-18 17:32:11,195 Epoch[167/300], Step[1150/1252], Avg Loss: 3.3703, Avg Acc: 0.4132
2022-01-18 17:33:37,740 Epoch[167/300], Step[1200/1252], Avg Loss: 3.3693, Avg Acc: 0.4137
2022-01-18 17:35:06,089 Epoch[167/300], Step[1250/1252], Avg Loss: 3.3698, Avg Acc: 0.4138
2022-01-18 17:35:12,984 ----- Epoch[167/300], Train Loss: 3.3698, Train Acc: 0.4138, time: 2292.53, Best Val(epoch166) Acc@1: 0.7296
2022-01-18 17:35:12,984 Now training epoch 168. LR=0.000461
2022-01-18 17:37:00,100 Epoch[168/300], Step[0000/1252], Avg Loss: 3.0589, Avg Acc: 0.3594
2022-01-18 17:38:26,290 Epoch[168/300], Step[0050/1252], Avg Loss: 3.3354, Avg Acc: 0.4602
2022-01-18 17:39:54,540 Epoch[168/300], Step[0100/1252], Avg Loss: 3.3662, Avg Acc: 0.4240
2022-01-18 17:41:22,185 Epoch[168/300], Step[0150/1252], Avg Loss: 3.3548, Avg Acc: 0.4151
2022-01-18 17:42:49,804 Epoch[168/300], Step[0200/1252], Avg Loss: 3.3477, Avg Acc: 0.4128
2022-01-18 17:44:17,774 Epoch[168/300], Step[0250/1252], Avg Loss: 3.3387, Avg Acc: 0.4143
2022-01-18 17:45:45,623 Epoch[168/300], Step[0300/1252], Avg Loss: 3.3371, Avg Acc: 0.4168
2022-01-18 17:47:13,338 Epoch[168/300], Step[0350/1252], Avg Loss: 3.3372, Avg Acc: 0.4166
2022-01-18 17:48:41,229 Epoch[168/300], Step[0400/1252], Avg Loss: 3.3425, Avg Acc: 0.4188
2022-01-18 17:50:08,623 Epoch[168/300], Step[0450/1252], Avg Loss: 3.3424, Avg Acc: 0.4217
2022-01-18 17:51:35,716 Epoch[168/300], Step[0500/1252], Avg Loss: 3.3419, Avg Acc: 0.4217
2022-01-18 17:53:03,645 Epoch[168/300], Step[0550/1252], Avg Loss: 3.3427, Avg Acc: 0.4169
2022-01-18 17:54:30,365 Epoch[168/300], Step[0600/1252], Avg Loss: 3.3443, Avg Acc: 0.4200
2022-01-18 17:55:58,014 Epoch[168/300], Step[0650/1252], Avg Loss: 3.3503, Avg Acc: 0.4204
2022-01-18 17:57:25,436 Epoch[168/300], Step[0700/1252], Avg Loss: 3.3530, Avg Acc: 0.4201
2022-01-18 17:58:52,365 Epoch[168/300], Step[0750/1252], Avg Loss: 3.3543, Avg Acc: 0.4202
2022-01-18 18:00:19,020 Epoch[168/300], Step[0800/1252], Avg Loss: 3.3515, Avg Acc: 0.4206
2022-01-18 18:01:46,234 Epoch[168/300], Step[0850/1252], Avg Loss: 3.3519, Avg Acc: 0.4207
2022-01-18 18:03:13,182 Epoch[168/300], Step[0900/1252], Avg Loss: 3.3527, Avg Acc: 0.4198
2022-01-18 18:04:41,170 Epoch[168/300], Step[0950/1252], Avg Loss: 3.3555, Avg Acc: 0.4183
2022-01-18 18:06:07,625 Epoch[168/300], Step[1000/1252], Avg Loss: 3.3583, Avg Acc: 0.4172
2022-01-18 18:07:34,801 Epoch[168/300], Step[1050/1252], Avg Loss: 3.3598, Avg Acc: 0.4157
2022-01-18 18:09:01,825 Epoch[168/300], Step[1100/1252], Avg Loss: 3.3587, Avg Acc: 0.4173
2022-01-18 18:10:28,915 Epoch[168/300], Step[1150/1252], Avg Loss: 3.3585, Avg Acc: 0.4169
2022-01-18 18:11:56,297 Epoch[168/300], Step[1200/1252], Avg Loss: 3.3563, Avg Acc: 0.4161
2022-01-18 18:13:23,895 Epoch[168/300], Step[1250/1252], Avg Loss: 3.3542, Avg Acc: 0.4173
2022-01-18 18:13:30,916 ----- Epoch[168/300], Train Loss: 3.3542, Train Acc: 0.4173, time: 2297.93, Best Val(epoch166) Acc@1: 0.7296
2022-01-18 18:13:30,916 ----- Validation after Epoch: 168
2022-01-18 18:14:40,581 Val Step[0000/1563], Avg Loss: 1.3096, Avg Acc@1: 0.7188, Avg Acc@5: 0.8750
2022-01-18 18:14:42,500 Val Step[0050/1563], Avg Loss: 1.2193, Avg Acc@1: 0.7237, Avg Acc@5: 0.9130
2022-01-18 18:14:44,333 Val Step[0100/1563], Avg Loss: 1.2270, Avg Acc@1: 0.7265, Avg Acc@5: 0.9158
2022-01-18 18:14:46,395 Val Step[0150/1563], Avg Loss: 1.2259, Avg Acc@1: 0.7318, Avg Acc@5: 0.9139
2022-01-18 18:14:48,434 Val Step[0200/1563], Avg Loss: 1.2220, Avg Acc@1: 0.7321, Avg Acc@5: 0.9150
2022-01-18 18:14:50,475 Val Step[0250/1563], Avg Loss: 1.2105, Avg Acc@1: 0.7348, Avg Acc@5: 0.9151
2022-01-18 18:14:52,506 Val Step[0300/1563], Avg Loss: 1.2158, Avg Acc@1: 0.7342, Avg Acc@5: 0.9136
2022-01-18 18:14:54,583 Val Step[0350/1563], Avg Loss: 1.2225, Avg Acc@1: 0.7331, Avg Acc@5: 0.9127
2022-01-18 18:14:56,639 Val Step[0400/1563], Avg Loss: 1.2195, Avg Acc@1: 0.7330, Avg Acc@5: 0.9132
2022-01-18 18:14:58,730 Val Step[0450/1563], Avg Loss: 1.2243, Avg Acc@1: 0.7312, Avg Acc@5: 0.9130
2022-01-18 18:15:00,854 Val Step[0500/1563], Avg Loss: 1.2291, Avg Acc@1: 0.7301, Avg Acc@5: 0.9130
2022-01-18 18:15:02,949 Val Step[0550/1563], Avg Loss: 1.2295, Avg Acc@1: 0.7284, Avg Acc@5: 0.9136
2022-01-18 18:15:05,002 Val Step[0600/1563], Avg Loss: 1.2286, Avg Acc@1: 0.7289, Avg Acc@5: 0.9140
2022-01-18 18:15:07,109 Val Step[0650/1563], Avg Loss: 1.2290, Avg Acc@1: 0.7291, Avg Acc@5: 0.9140
2022-01-18 18:15:09,220 Val Step[0700/1563], Avg Loss: 1.2264, Avg Acc@1: 0.7293, Avg Acc@5: 0.9147
2022-01-18 18:15:11,290 Val Step[0750/1563], Avg Loss: 1.2324, Avg Acc@1: 0.7279, Avg Acc@5: 0.9144
2022-01-18 18:15:13,360 Val Step[0800/1563], Avg Loss: 1.2308, Avg Acc@1: 0.7284, Avg Acc@5: 0.9147
2022-01-18 18:15:15,441 Val Step[0850/1563], Avg Loss: 1.2327, Avg Acc@1: 0.7279, Avg Acc@5: 0.9141
2022-01-18 18:15:17,520 Val Step[0900/1563], Avg Loss: 1.2282, Avg Acc@1: 0.7285, Avg Acc@5: 0.9147
2022-01-18 18:15:19,615 Val Step[0950/1563], Avg Loss: 1.2278, Avg Acc@1: 0.7288, Avg Acc@5: 0.9149
2022-01-18 18:15:21,699 Val Step[1000/1563], Avg Loss: 1.2285, Avg Acc@1: 0.7296, Avg Acc@5: 0.9149
2022-01-18 18:15:23,794 Val Step[1050/1563], Avg Loss: 1.2306, Avg Acc@1: 0.7285, Avg Acc@5: 0.9141
2022-01-18 18:15:25,887 Val Step[1100/1563], Avg Loss: 1.2305, Avg Acc@1: 0.7281, Avg Acc@5: 0.9141
2022-01-18 18:15:27,929 Val Step[1150/1563], Avg Loss: 1.2288, Avg Acc@1: 0.7285, Avg Acc@5: 0.9142
2022-01-18 18:15:29,961 Val Step[1200/1563], Avg Loss: 1.2282, Avg Acc@1: 0.7289, Avg Acc@5: 0.9139
2022-01-18 18:15:32,039 Val Step[1250/1563], Avg Loss: 1.2278, Avg Acc@1: 0.7287, Avg Acc@5: 0.9140
2022-01-18 18:15:34,091 Val Step[1300/1563], Avg Loss: 1.2310, Avg Acc@1: 0.7284, Avg Acc@5: 0.9135
2022-01-18 18:15:36,155 Val Step[1350/1563], Avg Loss: 1.2319, Avg Acc@1: 0.7280, Avg Acc@5: 0.9135
2022-01-18 18:15:38,226 Val Step[1400/1563], Avg Loss: 1.2319, Avg Acc@1: 0.7278, Avg Acc@5: 0.9133
2022-01-18 18:15:40,284 Val Step[1450/1563], Avg Loss: 1.2315, Avg Acc@1: 0.7282, Avg Acc@5: 0.9133
2022-01-18 18:15:42,349 Val Step[1500/1563], Avg Loss: 1.2311, Avg Acc@1: 0.7283, Avg Acc@5: 0.9137
2022-01-18 18:15:44,366 Val Step[1550/1563], Avg Loss: 1.2319, Avg Acc@1: 0.7281, Avg Acc@5: 0.9134
2022-01-18 18:15:46,282 ----- Epoch[168/300], Validation Loss: 1.2320, Validation Acc@1: 0.7279, Validation Acc@5: 0.9135, time: 135.36
2022-01-18 18:15:46,283 Now training epoch 169. LR=0.000455
2022-01-18 18:17:25,595 Epoch[169/300], Step[0000/1252], Avg Loss: 3.6310, Avg Acc: 0.2676
2022-01-18 18:18:50,722 Epoch[169/300], Step[0050/1252], Avg Loss: 3.4203, Avg Acc: 0.4116
2022-01-18 18:20:15,971 Epoch[169/300], Step[0100/1252], Avg Loss: 3.3872, Avg Acc: 0.4182
2022-01-18 18:21:41,472 Epoch[169/300], Step[0150/1252], Avg Loss: 3.3621, Avg Acc: 0.4225
2022-01-18 18:23:05,423 Epoch[169/300], Step[0200/1252], Avg Loss: 3.3620, Avg Acc: 0.4173
2022-01-18 18:24:31,662 Epoch[169/300], Step[0250/1252], Avg Loss: 3.3577, Avg Acc: 0.4151
2022-01-18 18:25:57,780 Epoch[169/300], Step[0300/1252], Avg Loss: 3.3574, Avg Acc: 0.4181
2022-01-18 18:27:25,649 Epoch[169/300], Step[0350/1252], Avg Loss: 3.3643, Avg Acc: 0.4160
2022-01-18 18:28:53,346 Epoch[169/300], Step[0400/1252], Avg Loss: 3.3687, Avg Acc: 0.4139
2022-01-18 18:30:20,790 Epoch[169/300], Step[0450/1252], Avg Loss: 3.3620, Avg Acc: 0.4146
2022-01-18 18:31:47,202 Epoch[169/300], Step[0500/1252], Avg Loss: 3.3614, Avg Acc: 0.4131
2022-01-18 18:33:14,404 Epoch[169/300], Step[0550/1252], Avg Loss: 3.3584, Avg Acc: 0.4145
2022-01-18 18:34:41,208 Epoch[169/300], Step[0600/1252], Avg Loss: 3.3597, Avg Acc: 0.4168
2022-01-18 18:36:09,191 Epoch[169/300], Step[0650/1252], Avg Loss: 3.3613, Avg Acc: 0.4137
2022-01-18 18:37:36,687 Epoch[169/300], Step[0700/1252], Avg Loss: 3.3642, Avg Acc: 0.4125
2022-01-18 18:39:03,905 Epoch[169/300], Step[0750/1252], Avg Loss: 3.3640, Avg Acc: 0.4142
2022-01-18 18:40:30,071 Epoch[169/300], Step[0800/1252], Avg Loss: 3.3650, Avg Acc: 0.4165
2022-01-18 18:41:56,675 Epoch[169/300], Step[0850/1252], Avg Loss: 3.3672, Avg Acc: 0.4169
2022-01-18 18:43:23,698 Epoch[169/300], Step[0900/1252], Avg Loss: 3.3660, Avg Acc: 0.4185
2022-01-18 18:44:51,233 Epoch[169/300], Step[0950/1252], Avg Loss: 3.3637, Avg Acc: 0.4192
2022-01-18 18:46:18,730 Epoch[169/300], Step[1000/1252], Avg Loss: 3.3656, Avg Acc: 0.4180
2022-01-18 18:47:46,130 Epoch[169/300], Step[1050/1252], Avg Loss: 3.3638, Avg Acc: 0.4191
2022-01-18 18:49:13,447 Epoch[169/300], Step[1100/1252], Avg Loss: 3.3630, Avg Acc: 0.4189
2022-01-18 18:50:40,774 Epoch[169/300], Step[1150/1252], Avg Loss: 3.3629, Avg Acc: 0.4184
2022-01-18 18:52:07,165 Epoch[169/300], Step[1200/1252], Avg Loss: 3.3616, Avg Acc: 0.4179
2022-01-18 18:53:35,593 Epoch[169/300], Step[1250/1252], Avg Loss: 3.3597, Avg Acc: 0.4190
2022-01-18 18:53:42,650 ----- Epoch[169/300], Train Loss: 3.3597, Train Acc: 0.4190, time: 2276.36, Best Val(epoch166) Acc@1: 0.7296
2022-01-18 18:53:42,651 Now training epoch 170. LR=0.000450
2022-01-18 18:55:34,430 Epoch[170/300], Step[0000/1252], Avg Loss: 3.6265, Avg Acc: 0.5801
2022-01-18 18:56:58,866 Epoch[170/300], Step[0050/1252], Avg Loss: 3.4034, Avg Acc: 0.3950
2022-01-18 18:58:25,629 Epoch[170/300], Step[0100/1252], Avg Loss: 3.3963, Avg Acc: 0.4081
2022-01-18 18:59:54,011 Epoch[170/300], Step[0150/1252], Avg Loss: 3.3787, Avg Acc: 0.4100
2022-01-18 19:01:21,958 Epoch[170/300], Step[0200/1252], Avg Loss: 3.3892, Avg Acc: 0.4023
2022-01-18 19:02:48,987 Epoch[170/300], Step[0250/1252], Avg Loss: 3.3849, Avg Acc: 0.4071
2022-01-18 19:04:17,685 Epoch[170/300], Step[0300/1252], Avg Loss: 3.3812, Avg Acc: 0.4047
2022-01-18 19:05:47,304 Epoch[170/300], Step[0350/1252], Avg Loss: 3.3767, Avg Acc: 0.4085
2022-01-18 19:07:16,600 Epoch[170/300], Step[0400/1252], Avg Loss: 3.3752, Avg Acc: 0.4084
2022-01-18 19:08:45,474 Epoch[170/300], Step[0450/1252], Avg Loss: 3.3736, Avg Acc: 0.4111
2022-01-18 19:10:13,635 Epoch[170/300], Step[0500/1252], Avg Loss: 3.3694, Avg Acc: 0.4139
2022-01-18 19:11:41,262 Epoch[170/300], Step[0550/1252], Avg Loss: 3.3691, Avg Acc: 0.4157
2022-01-18 19:13:10,303 Epoch[170/300], Step[0600/1252], Avg Loss: 3.3692, Avg Acc: 0.4153
2022-01-18 19:14:39,384 Epoch[170/300], Step[0650/1252], Avg Loss: 3.3736, Avg Acc: 0.4130
2022-01-18 19:16:08,309 Epoch[170/300], Step[0700/1252], Avg Loss: 3.3755, Avg Acc: 0.4127
2022-01-18 19:17:37,338 Epoch[170/300], Step[0750/1252], Avg Loss: 3.3702, Avg Acc: 0.4104
2022-01-18 19:19:05,096 Epoch[170/300], Step[0800/1252], Avg Loss: 3.3700, Avg Acc: 0.4124
2022-01-18 19:20:32,146 Epoch[170/300], Step[0850/1252], Avg Loss: 3.3676, Avg Acc: 0.4132
2022-01-18 19:22:00,867 Epoch[170/300], Step[0900/1252], Avg Loss: 3.3667, Avg Acc: 0.4146
2022-01-18 19:23:30,456 Epoch[170/300], Step[0950/1252], Avg Loss: 3.3664, Avg Acc: 0.4139
2022-01-18 19:24:59,774 Epoch[170/300], Step[1000/1252], Avg Loss: 3.3671, Avg Acc: 0.4115
2022-01-18 19:26:28,612 Epoch[170/300], Step[1050/1252], Avg Loss: 3.3669, Avg Acc: 0.4108
2022-01-18 19:27:57,535 Epoch[170/300], Step[1100/1252], Avg Loss: 3.3666, Avg Acc: 0.4109
2022-01-18 19:29:26,258 Epoch[170/300], Step[1150/1252], Avg Loss: 3.3659, Avg Acc: 0.4108
2022-01-18 19:30:54,330 Epoch[170/300], Step[1200/1252], Avg Loss: 3.3673, Avg Acc: 0.4116
2022-01-18 19:32:23,069 Epoch[170/300], Step[1250/1252], Avg Loss: 3.3687, Avg Acc: 0.4116
2022-01-18 19:32:30,768 ----- Epoch[170/300], Train Loss: 3.3687, Train Acc: 0.4116, time: 2328.11, Best Val(epoch166) Acc@1: 0.7296
2022-01-18 19:32:30,768 ----- Validation after Epoch: 170
2022-01-18 19:33:56,007 Val Step[0000/1563], Avg Loss: 0.9940, Avg Acc@1: 0.7188, Avg Acc@5: 0.9688
2022-01-18 19:33:58,338 Val Step[0050/1563], Avg Loss: 1.1686, Avg Acc@1: 0.7426, Avg Acc@5: 0.9210
2022-01-18 19:34:00,227 Val Step[0100/1563], Avg Loss: 1.1939, Avg Acc@1: 0.7382, Avg Acc@5: 0.9202
2022-01-18 19:34:02,279 Val Step[0150/1563], Avg Loss: 1.2016, Avg Acc@1: 0.7349, Avg Acc@5: 0.9195
2022-01-18 19:34:04,175 Val Step[0200/1563], Avg Loss: 1.2019, Avg Acc@1: 0.7352, Avg Acc@5: 0.9188
2022-01-18 19:34:06,105 Val Step[0250/1563], Avg Loss: 1.1916, Avg Acc@1: 0.7359, Avg Acc@5: 0.9188
2022-01-18 19:34:08,237 Val Step[0300/1563], Avg Loss: 1.1957, Avg Acc@1: 0.7357, Avg Acc@5: 0.9174
2022-01-18 19:34:10,185 Val Step[0350/1563], Avg Loss: 1.1987, Avg Acc@1: 0.7364, Avg Acc@5: 0.9176
2022-01-18 19:34:12,063 Val Step[0400/1563], Avg Loss: 1.1963, Avg Acc@1: 0.7371, Avg Acc@5: 0.9168
2022-01-18 19:34:13,912 Val Step[0450/1563], Avg Loss: 1.2015, Avg Acc@1: 0.7339, Avg Acc@5: 0.9161
2022-01-18 19:34:15,820 Val Step[0500/1563], Avg Loss: 1.2046, Avg Acc@1: 0.7337, Avg Acc@5: 0.9154
2022-01-18 19:34:17,638 Val Step[0550/1563], Avg Loss: 1.2056, Avg Acc@1: 0.7330, Avg Acc@5: 0.9156
2022-01-18 19:34:19,431 Val Step[0600/1563], Avg Loss: 1.2073, Avg Acc@1: 0.7325, Avg Acc@5: 0.9155
2022-01-18 19:34:21,239 Val Step[0650/1563], Avg Loss: 1.2073, Avg Acc@1: 0.7331, Avg Acc@5: 0.9158
2022-01-18 19:34:23,017 Val Step[0700/1563], Avg Loss: 1.2050, Avg Acc@1: 0.7344, Avg Acc@5: 0.9166
2022-01-18 19:34:24,826 Val Step[0750/1563], Avg Loss: 1.2094, Avg Acc@1: 0.7330, Avg Acc@5: 0.9163
2022-01-18 19:34:26,599 Val Step[0800/1563], Avg Loss: 1.2085, Avg Acc@1: 0.7335, Avg Acc@5: 0.9162
2022-01-18 19:34:28,386 Val Step[0850/1563], Avg Loss: 1.2112, Avg Acc@1: 0.7323, Avg Acc@5: 0.9156
2022-01-18 19:34:30,163 Val Step[0900/1563], Avg Loss: 1.2084, Avg Acc@1: 0.7324, Avg Acc@5: 0.9158
2022-01-18 19:34:31,942 Val Step[0950/1563], Avg Loss: 1.2079, Avg Acc@1: 0.7326, Avg Acc@5: 0.9161
2022-01-18 19:34:33,795 Val Step[1000/1563], Avg Loss: 1.2084, Avg Acc@1: 0.7327, Avg Acc@5: 0.9159
2022-01-18 19:34:35,839 Val Step[1050/1563], Avg Loss: 1.2097, Avg Acc@1: 0.7322, Avg Acc@5: 0.9155
2022-01-18 19:34:37,878 Val Step[1100/1563], Avg Loss: 1.2090, Avg Acc@1: 0.7321, Avg Acc@5: 0.9157
2022-01-18 19:34:39,935 Val Step[1150/1563], Avg Loss: 1.2069, Avg Acc@1: 0.7328, Avg Acc@5: 0.9154
2022-01-18 19:34:41,980 Val Step[1200/1563], Avg Loss: 1.2066, Avg Acc@1: 0.7328, Avg Acc@5: 0.9153
2022-01-18 19:34:44,119 Val Step[1250/1563], Avg Loss: 1.2058, Avg Acc@1: 0.7324, Avg Acc@5: 0.9157
2022-01-18 19:34:46,171 Val Step[1300/1563], Avg Loss: 1.2089, Avg Acc@1: 0.7319, Avg Acc@5: 0.9155
2022-01-18 19:34:48,190 Val Step[1350/1563], Avg Loss: 1.2098, Avg Acc@1: 0.7312, Avg Acc@5: 0.9155
2022-01-18 19:34:50,285 Val Step[1400/1563], Avg Loss: 1.2096, Avg Acc@1: 0.7310, Avg Acc@5: 0.9154
2022-01-18 19:34:52,300 Val Step[1450/1563], Avg Loss: 1.2097, Avg Acc@1: 0.7311, Avg Acc@5: 0.9152
2022-01-18 19:34:54,321 Val Step[1500/1563], Avg Loss: 1.2095, Avg Acc@1: 0.7310, Avg Acc@5: 0.9154
2022-01-18 19:34:56,329 Val Step[1550/1563], Avg Loss: 1.2104, Avg Acc@1: 0.7310, Avg Acc@5: 0.9152
2022-01-18 19:34:58,366 ----- Epoch[170/300], Validation Loss: 1.2103, Validation Acc@1: 0.7310, Validation Acc@5: 0.9153, time: 147.60
2022-01-18 19:34:59,529 the pre best model acc:0.7296, at epoch 166
2022-01-18 19:34:59,529 current best model acc:0.7310, at epoch 170
2022-01-18 19:34:59,529 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 19:34:59,529 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 19:34:59,529 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 19:34:59,530 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 19:34:59,530 Now training epoch 171. LR=0.000444
2022-01-18 19:36:51,559 Epoch[171/300], Step[0000/1252], Avg Loss: 3.4968, Avg Acc: 0.5342
2022-01-18 19:38:20,920 Epoch[171/300], Step[0050/1252], Avg Loss: 3.3548, Avg Acc: 0.4215
2022-01-18 19:39:49,621 Epoch[171/300], Step[0100/1252], Avg Loss: 3.3676, Avg Acc: 0.4053
2022-01-18 19:41:18,411 Epoch[171/300], Step[0150/1252], Avg Loss: 3.3690, Avg Acc: 0.4005
2022-01-18 19:42:46,824 Epoch[171/300], Step[0200/1252], Avg Loss: 3.3775, Avg Acc: 0.4063
2022-01-18 19:44:15,577 Epoch[171/300], Step[0250/1252], Avg Loss: 3.3660, Avg Acc: 0.4058
2022-01-18 19:45:43,338 Epoch[171/300], Step[0300/1252], Avg Loss: 3.3625, Avg Acc: 0.4058
2022-01-18 19:47:11,543 Epoch[171/300], Step[0350/1252], Avg Loss: 3.3549, Avg Acc: 0.4080
2022-01-18 19:48:39,796 Epoch[171/300], Step[0400/1252], Avg Loss: 3.3624, Avg Acc: 0.4089
2022-01-18 19:50:08,315 Epoch[171/300], Step[0450/1252], Avg Loss: 3.3569, Avg Acc: 0.4128
2022-01-18 19:51:37,625 Epoch[171/300], Step[0500/1252], Avg Loss: 3.3555, Avg Acc: 0.4133
2022-01-18 19:53:05,665 Epoch[171/300], Step[0550/1252], Avg Loss: 3.3542, Avg Acc: 0.4150
2022-01-18 19:54:35,640 Epoch[171/300], Step[0600/1252], Avg Loss: 3.3551, Avg Acc: 0.4143
2022-01-18 19:56:04,832 Epoch[171/300], Step[0650/1252], Avg Loss: 3.3541, Avg Acc: 0.4127
2022-01-18 19:57:33,585 Epoch[171/300], Step[0700/1252], Avg Loss: 3.3549, Avg Acc: 0.4142
2022-01-18 19:59:02,456 Epoch[171/300], Step[0750/1252], Avg Loss: 3.3607, Avg Acc: 0.4127
2022-01-18 20:00:31,021 Epoch[171/300], Step[0800/1252], Avg Loss: 3.3566, Avg Acc: 0.4143
2022-01-18 20:02:00,700 Epoch[171/300], Step[0850/1252], Avg Loss: 3.3586, Avg Acc: 0.4138
2022-01-18 20:03:30,087 Epoch[171/300], Step[0900/1252], Avg Loss: 3.3573, Avg Acc: 0.4139
2022-01-18 20:04:59,204 Epoch[171/300], Step[0950/1252], Avg Loss: 3.3602, Avg Acc: 0.4121
2022-01-18 20:06:27,793 Epoch[171/300], Step[1000/1252], Avg Loss: 3.3576, Avg Acc: 0.4139
2022-01-18 20:07:56,390 Epoch[171/300], Step[1050/1252], Avg Loss: 3.3538, Avg Acc: 0.4149
2022-01-18 20:09:25,971 Epoch[171/300], Step[1100/1252], Avg Loss: 3.3510, Avg Acc: 0.4161
2022-01-18 20:10:53,356 Epoch[171/300], Step[1150/1252], Avg Loss: 3.3488, Avg Acc: 0.4170
2022-01-18 20:12:23,030 Epoch[171/300], Step[1200/1252], Avg Loss: 3.3500, Avg Acc: 0.4169
2022-01-18 20:13:51,569 Epoch[171/300], Step[1250/1252], Avg Loss: 3.3512, Avg Acc: 0.4183
2022-01-18 20:13:58,763 ----- Epoch[171/300], Train Loss: 3.3512, Train Acc: 0.4183, time: 2339.23, Best Val(epoch170) Acc@1: 0.7310
2022-01-18 20:13:58,764 Now training epoch 172. LR=0.000439
2022-01-18 20:15:49,402 Epoch[172/300], Step[0000/1252], Avg Loss: 3.0165, Avg Acc: 0.2617
2022-01-18 20:17:18,038 Epoch[172/300], Step[0050/1252], Avg Loss: 3.3009, Avg Acc: 0.4211
2022-01-18 20:18:46,433 Epoch[172/300], Step[0100/1252], Avg Loss: 3.3105, Avg Acc: 0.4320
2022-01-18 20:20:15,518 Epoch[172/300], Step[0150/1252], Avg Loss: 3.3101, Avg Acc: 0.4250
2022-01-18 20:21:44,794 Epoch[172/300], Step[0200/1252], Avg Loss: 3.3094, Avg Acc: 0.4229
2022-01-18 20:23:13,603 Epoch[172/300], Step[0250/1252], Avg Loss: 3.3122, Avg Acc: 0.4212
2022-01-18 20:24:41,435 Epoch[172/300], Step[0300/1252], Avg Loss: 3.3089, Avg Acc: 0.4240
2022-01-18 20:26:10,308 Epoch[172/300], Step[0350/1252], Avg Loss: 3.3169, Avg Acc: 0.4224
2022-01-18 20:27:38,873 Epoch[172/300], Step[0400/1252], Avg Loss: 3.3232, Avg Acc: 0.4209
2022-01-18 20:29:07,914 Epoch[172/300], Step[0450/1252], Avg Loss: 3.3296, Avg Acc: 0.4187
2022-01-18 20:30:36,150 Epoch[172/300], Step[0500/1252], Avg Loss: 3.3272, Avg Acc: 0.4182
2022-01-18 20:32:04,723 Epoch[172/300], Step[0550/1252], Avg Loss: 3.3225, Avg Acc: 0.4188
2022-01-18 20:33:33,809 Epoch[172/300], Step[0600/1252], Avg Loss: 3.3258, Avg Acc: 0.4205
2022-01-18 20:35:02,527 Epoch[172/300], Step[0650/1252], Avg Loss: 3.3282, Avg Acc: 0.4215
2022-01-18 20:36:31,973 Epoch[172/300], Step[0700/1252], Avg Loss: 3.3326, Avg Acc: 0.4201
2022-01-18 20:38:01,087 Epoch[172/300], Step[0750/1252], Avg Loss: 3.3366, Avg Acc: 0.4179
2022-01-18 20:39:29,675 Epoch[172/300], Step[0800/1252], Avg Loss: 3.3373, Avg Acc: 0.4171
2022-01-18 20:40:57,767 Epoch[172/300], Step[0850/1252], Avg Loss: 3.3397, Avg Acc: 0.4166
2022-01-18 20:42:25,654 Epoch[172/300], Step[0900/1252], Avg Loss: 3.3391, Avg Acc: 0.4169
2022-01-18 20:43:54,041 Epoch[172/300], Step[0950/1252], Avg Loss: 3.3348, Avg Acc: 0.4170
2022-01-18 20:45:23,659 Epoch[172/300], Step[1000/1252], Avg Loss: 3.3381, Avg Acc: 0.4172
2022-01-18 20:46:52,355 Epoch[172/300], Step[1050/1252], Avg Loss: 3.3375, Avg Acc: 0.4176
2022-01-18 20:48:22,151 Epoch[172/300], Step[1100/1252], Avg Loss: 3.3402, Avg Acc: 0.4166
2022-01-18 20:49:51,662 Epoch[172/300], Step[1150/1252], Avg Loss: 3.3412, Avg Acc: 0.4157
2022-01-18 20:51:20,451 Epoch[172/300], Step[1200/1252], Avg Loss: 3.3387, Avg Acc: 0.4162
2022-01-18 20:52:49,335 Epoch[172/300], Step[1250/1252], Avg Loss: 3.3406, Avg Acc: 0.4164
2022-01-18 20:52:56,513 ----- Epoch[172/300], Train Loss: 3.3406, Train Acc: 0.4164, time: 2337.75, Best Val(epoch170) Acc@1: 0.7310
2022-01-18 20:52:56,513 ----- Validation after Epoch: 172
2022-01-18 20:54:19,190 Val Step[0000/1563], Avg Loss: 0.9805, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-18 20:54:21,128 Val Step[0050/1563], Avg Loss: 1.1927, Avg Acc@1: 0.7335, Avg Acc@5: 0.9222
2022-01-18 20:54:23,069 Val Step[0100/1563], Avg Loss: 1.2105, Avg Acc@1: 0.7342, Avg Acc@5: 0.9230
2022-01-18 20:54:24,958 Val Step[0150/1563], Avg Loss: 1.2085, Avg Acc@1: 0.7388, Avg Acc@5: 0.9180
2022-01-18 20:54:26,812 Val Step[0200/1563], Avg Loss: 1.2110, Avg Acc@1: 0.7368, Avg Acc@5: 0.9173
2022-01-18 20:54:28,616 Val Step[0250/1563], Avg Loss: 1.1954, Avg Acc@1: 0.7399, Avg Acc@5: 0.9178
2022-01-18 20:54:30,487 Val Step[0300/1563], Avg Loss: 1.1970, Avg Acc@1: 0.7409, Avg Acc@5: 0.9167
2022-01-18 20:54:32,331 Val Step[0350/1563], Avg Loss: 1.2034, Avg Acc@1: 0.7392, Avg Acc@5: 0.9167
2022-01-18 20:54:34,174 Val Step[0400/1563], Avg Loss: 1.2015, Avg Acc@1: 0.7391, Avg Acc@5: 0.9165
2022-01-18 20:54:36,073 Val Step[0450/1563], Avg Loss: 1.2080, Avg Acc@1: 0.7363, Avg Acc@5: 0.9154
2022-01-18 20:54:37,991 Val Step[0500/1563], Avg Loss: 1.2108, Avg Acc@1: 0.7353, Avg Acc@5: 0.9156
2022-01-18 20:54:39,943 Val Step[0550/1563], Avg Loss: 1.2100, Avg Acc@1: 0.7345, Avg Acc@5: 0.9156
2022-01-18 20:54:41,860 Val Step[0600/1563], Avg Loss: 1.2113, Avg Acc@1: 0.7339, Avg Acc@5: 0.9156
2022-01-18 20:54:43,639 Val Step[0650/1563], Avg Loss: 1.2093, Avg Acc@1: 0.7341, Avg Acc@5: 0.9163
2022-01-18 20:54:45,436 Val Step[0700/1563], Avg Loss: 1.2067, Avg Acc@1: 0.7344, Avg Acc@5: 0.9170
2022-01-18 20:54:47,231 Val Step[0750/1563], Avg Loss: 1.2129, Avg Acc@1: 0.7330, Avg Acc@5: 0.9162
2022-01-18 20:54:49,011 Val Step[0800/1563], Avg Loss: 1.2131, Avg Acc@1: 0.7335, Avg Acc@5: 0.9158
2022-01-18 20:54:50,885 Val Step[0850/1563], Avg Loss: 1.2143, Avg Acc@1: 0.7333, Avg Acc@5: 0.9157
2022-01-18 20:54:52,659 Val Step[0900/1563], Avg Loss: 1.2110, Avg Acc@1: 0.7338, Avg Acc@5: 0.9160
2022-01-18 20:54:54,456 Val Step[0950/1563], Avg Loss: 1.2104, Avg Acc@1: 0.7346, Avg Acc@5: 0.9163
2022-01-18 20:54:56,268 Val Step[1000/1563], Avg Loss: 1.2115, Avg Acc@1: 0.7346, Avg Acc@5: 0.9160
2022-01-18 20:54:58,096 Val Step[1050/1563], Avg Loss: 1.2138, Avg Acc@1: 0.7335, Avg Acc@5: 0.9156
2022-01-18 20:55:00,102 Val Step[1100/1563], Avg Loss: 1.2151, Avg Acc@1: 0.7330, Avg Acc@5: 0.9154
2022-01-18 20:55:02,212 Val Step[1150/1563], Avg Loss: 1.2135, Avg Acc@1: 0.7332, Avg Acc@5: 0.9155
2022-01-18 20:55:04,296 Val Step[1200/1563], Avg Loss: 1.2129, Avg Acc@1: 0.7335, Avg Acc@5: 0.9155
2022-01-18 20:55:06,372 Val Step[1250/1563], Avg Loss: 1.2123, Avg Acc@1: 0.7333, Avg Acc@5: 0.9156
2022-01-18 20:55:08,459 Val Step[1300/1563], Avg Loss: 1.2148, Avg Acc@1: 0.7329, Avg Acc@5: 0.9152
2022-01-18 20:55:10,527 Val Step[1350/1563], Avg Loss: 1.2152, Avg Acc@1: 0.7326, Avg Acc@5: 0.9151
2022-01-18 20:55:12,689 Val Step[1400/1563], Avg Loss: 1.2146, Avg Acc@1: 0.7328, Avg Acc@5: 0.9150
2022-01-18 20:55:14,810 Val Step[1450/1563], Avg Loss: 1.2146, Avg Acc@1: 0.7327, Avg Acc@5: 0.9148
2022-01-18 20:55:16,830 Val Step[1500/1563], Avg Loss: 1.2140, Avg Acc@1: 0.7330, Avg Acc@5: 0.9149
2022-01-18 20:55:18,568 Val Step[1550/1563], Avg Loss: 1.2141, Avg Acc@1: 0.7326, Avg Acc@5: 0.9147
2022-01-18 20:55:20,374 ----- Epoch[172/300], Validation Loss: 1.2140, Validation Acc@1: 0.7326, Validation Acc@5: 0.9148, time: 143.86
2022-01-18 20:55:21,510 the pre best model acc:0.7310, at epoch 170
2022-01-18 20:55:21,511 current best model acc:0.7326, at epoch 172
2022-01-18 20:55:21,511 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 20:55:21,511 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 20:55:21,511 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-18 20:55:21,511 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-18 20:55:21,511 Now training epoch 173. LR=0.000433
2022-01-18 20:57:18,408 Epoch[173/300], Step[0000/1252], Avg Loss: 3.3356, Avg Acc: 0.4170
2022-01-18 20:58:46,992 Epoch[173/300], Step[0050/1252], Avg Loss: 3.3179, Avg Acc: 0.4508
2022-01-18 21:00:16,549 Epoch[173/300], Step[0100/1252], Avg Loss: 3.3557, Avg Acc: 0.4043
2022-01-18 21:01:45,047 Epoch[173/300], Step[0150/1252], Avg Loss: 3.3542, Avg Acc: 0.4106
2022-01-18 21:03:13,361 Epoch[173/300], Step[0200/1252], Avg Loss: 3.3473, Avg Acc: 0.4138
2022-01-18 21:04:41,496 Epoch[173/300], Step[0250/1252], Avg Loss: 3.3588, Avg Acc: 0.4096
2022-01-18 21:06:10,750 Epoch[173/300], Step[0300/1252], Avg Loss: 3.3587, Avg Acc: 0.4070
2022-01-18 21:07:38,739 Epoch[173/300], Step[0350/1252], Avg Loss: 3.3637, Avg Acc: 0.4078
2022-01-18 21:09:07,103 Epoch[173/300], Step[0400/1252], Avg Loss: 3.3576, Avg Acc: 0.4103
2022-01-18 21:10:34,653 Epoch[173/300], Step[0450/1252], Avg Loss: 3.3491, Avg Acc: 0.4127
2022-01-18 21:12:01,453 Epoch[173/300], Step[0500/1252], Avg Loss: 3.3461, Avg Acc: 0.4158
2022-01-18 21:13:29,166 Epoch[173/300], Step[0550/1252], Avg Loss: 3.3542, Avg Acc: 0.4125
2022-01-18 21:14:57,842 Epoch[173/300], Step[0600/1252], Avg Loss: 3.3540, Avg Acc: 0.4099
2022-01-18 21:16:25,478 Epoch[173/300], Step[0650/1252], Avg Loss: 3.3555, Avg Acc: 0.4089
2022-01-18 21:17:52,573 Epoch[173/300], Step[0700/1252], Avg Loss: 3.3539, Avg Acc: 0.4093
2022-01-18 21:19:18,827 Epoch[173/300], Step[0750/1252], Avg Loss: 3.3577, Avg Acc: 0.4103
2022-01-18 21:20:46,247 Epoch[173/300], Step[0800/1252], Avg Loss: 3.3545, Avg Acc: 0.4122
2022-01-18 21:22:13,619 Epoch[173/300], Step[0850/1252], Avg Loss: 3.3533, Avg Acc: 0.4125
2022-01-18 21:23:41,391 Epoch[173/300], Step[0900/1252], Avg Loss: 3.3546, Avg Acc: 0.4111
2022-01-18 21:25:09,570 Epoch[173/300], Step[0950/1252], Avg Loss: 3.3535, Avg Acc: 0.4104
2022-01-18 21:26:36,772 Epoch[173/300], Step[1000/1252], Avg Loss: 3.3537, Avg Acc: 0.4119
2022-01-18 21:28:04,560 Epoch[173/300], Step[1050/1252], Avg Loss: 3.3553, Avg Acc: 0.4109
2022-01-18 21:29:30,817 Epoch[173/300], Step[1100/1252], Avg Loss: 3.3563, Avg Acc: 0.4103
2022-01-18 21:30:58,475 Epoch[173/300], Step[1150/1252], Avg Loss: 3.3570, Avg Acc: 0.4110
2022-01-18 21:32:26,975 Epoch[173/300], Step[1200/1252], Avg Loss: 3.3584, Avg Acc: 0.4105
2022-01-18 21:33:53,662 Epoch[173/300], Step[1250/1252], Avg Loss: 3.3569, Avg Acc: 0.4107
2022-01-18 21:34:01,968 ----- Epoch[173/300], Train Loss: 3.3569, Train Acc: 0.4107, time: 2320.45, Best Val(epoch172) Acc@1: 0.7326
2022-01-18 21:34:01,968 Now training epoch 174. LR=0.000428
2022-01-18 21:35:54,343 Epoch[174/300], Step[0000/1252], Avg Loss: 3.6506, Avg Acc: 0.4062
2022-01-18 21:37:22,550 Epoch[174/300], Step[0050/1252], Avg Loss: 3.2941, Avg Acc: 0.4210
2022-01-18 21:38:49,972 Epoch[174/300], Step[0100/1252], Avg Loss: 3.3079, Avg Acc: 0.4154
2022-01-18 21:40:16,340 Epoch[174/300], Step[0150/1252], Avg Loss: 3.2959, Avg Acc: 0.4063
2022-01-18 21:41:44,035 Epoch[174/300], Step[0200/1252], Avg Loss: 3.3088, Avg Acc: 0.4149
2022-01-18 21:43:11,406 Epoch[174/300], Step[0250/1252], Avg Loss: 3.3148, Avg Acc: 0.4129
2022-01-18 21:44:38,645 Epoch[174/300], Step[0300/1252], Avg Loss: 3.3162, Avg Acc: 0.4109
2022-01-18 21:46:07,458 Epoch[174/300], Step[0350/1252], Avg Loss: 3.3220, Avg Acc: 0.4097
2022-01-18 21:47:35,508 Epoch[174/300], Step[0400/1252], Avg Loss: 3.3234, Avg Acc: 0.4149
2022-01-18 21:49:03,713 Epoch[174/300], Step[0450/1252], Avg Loss: 3.3283, Avg Acc: 0.4148
2022-01-18 21:50:31,155 Epoch[174/300], Step[0500/1252], Avg Loss: 3.3319, Avg Acc: 0.4154
2022-01-18 21:51:58,371 Epoch[174/300], Step[0550/1252], Avg Loss: 3.3329, Avg Acc: 0.4171
2022-01-18 21:53:25,734 Epoch[174/300], Step[0600/1252], Avg Loss: 3.3408, Avg Acc: 0.4169
2022-01-18 21:54:52,419 Epoch[174/300], Step[0650/1252], Avg Loss: 3.3357, Avg Acc: 0.4167
2022-01-18 21:56:20,455 Epoch[174/300], Step[0700/1252], Avg Loss: 3.3395, Avg Acc: 0.4157
2022-01-18 21:57:46,189 Epoch[174/300], Step[0750/1252], Avg Loss: 3.3396, Avg Acc: 0.4166
2022-01-18 21:59:12,128 Epoch[174/300], Step[0800/1252], Avg Loss: 3.3423, Avg Acc: 0.4147
2022-01-18 22:00:38,458 Epoch[174/300], Step[0850/1252], Avg Loss: 3.3383, Avg Acc: 0.4133
2022-01-18 22:02:04,820 Epoch[174/300], Step[0900/1252], Avg Loss: 3.3413, Avg Acc: 0.4122
2022-01-18 22:03:31,818 Epoch[174/300], Step[0950/1252], Avg Loss: 3.3391, Avg Acc: 0.4117
2022-01-18 22:04:59,537 Epoch[174/300], Step[1000/1252], Avg Loss: 3.3383, Avg Acc: 0.4118
2022-01-18 22:06:26,599 Epoch[174/300], Step[1050/1252], Avg Loss: 3.3398, Avg Acc: 0.4113
2022-01-18 22:07:52,075 Epoch[174/300], Step[1100/1252], Avg Loss: 3.3391, Avg Acc: 0.4112
2022-01-18 22:09:19,017 Epoch[174/300], Step[1150/1252], Avg Loss: 3.3370, Avg Acc: 0.4122
2022-01-18 22:10:45,584 Epoch[174/300], Step[1200/1252], Avg Loss: 3.3359, Avg Acc: 0.4124
2022-01-18 22:12:12,316 Epoch[174/300], Step[1250/1252], Avg Loss: 3.3346, Avg Acc: 0.4133
2022-01-18 22:12:19,313 ----- Epoch[174/300], Train Loss: 3.3345, Train Acc: 0.4133, time: 2297.34, Best Val(epoch172) Acc@1: 0.7326
2022-01-18 22:12:19,313 ----- Validation after Epoch: 174
2022-01-18 22:13:34,858 Val Step[0000/1563], Avg Loss: 0.9459, Avg Acc@1: 0.7188, Avg Acc@5: 0.9688
2022-01-18 22:13:36,950 Val Step[0050/1563], Avg Loss: 1.1434, Avg Acc@1: 0.7390, Avg Acc@5: 0.9167
2022-01-18 22:13:39,038 Val Step[0100/1563], Avg Loss: 1.1607, Avg Acc@1: 0.7348, Avg Acc@5: 0.9196
2022-01-18 22:13:41,109 Val Step[0150/1563], Avg Loss: 1.1633, Avg Acc@1: 0.7345, Avg Acc@5: 0.9145
2022-01-18 22:13:43,181 Val Step[0200/1563], Avg Loss: 1.1647, Avg Acc@1: 0.7359, Avg Acc@5: 0.9148
2022-01-18 22:13:45,252 Val Step[0250/1563], Avg Loss: 1.1536, Avg Acc@1: 0.7387, Avg Acc@5: 0.9157
2022-01-18 22:13:47,312 Val Step[0300/1563], Avg Loss: 1.1571, Avg Acc@1: 0.7371, Avg Acc@5: 0.9140
2022-01-18 22:13:49,358 Val Step[0350/1563], Avg Loss: 1.1644, Avg Acc@1: 0.7361, Avg Acc@5: 0.9144
2022-01-18 22:13:51,353 Val Step[0400/1563], Avg Loss: 1.1622, Avg Acc@1: 0.7366, Avg Acc@5: 0.9150
2022-01-18 22:13:53,191 Val Step[0450/1563], Avg Loss: 1.1678, Avg Acc@1: 0.7341, Avg Acc@5: 0.9142
2022-01-18 22:13:55,227 Val Step[0500/1563], Avg Loss: 1.1705, Avg Acc@1: 0.7333, Avg Acc@5: 0.9144
2022-01-18 22:13:57,203 Val Step[0550/1563], Avg Loss: 1.1705, Avg Acc@1: 0.7325, Avg Acc@5: 0.9151
2022-01-18 22:13:59,201 Val Step[0600/1563], Avg Loss: 1.1676, Avg Acc@1: 0.7329, Avg Acc@5: 0.9157
2022-01-18 22:14:01,163 Val Step[0650/1563], Avg Loss: 1.1683, Avg Acc@1: 0.7328, Avg Acc@5: 0.9155
2022-01-18 22:14:02,990 Val Step[0700/1563], Avg Loss: 1.1652, Avg Acc@1: 0.7339, Avg Acc@5: 0.9164
2022-01-18 22:14:04,855 Val Step[0750/1563], Avg Loss: 1.1706, Avg Acc@1: 0.7322, Avg Acc@5: 0.9161
2022-01-18 22:14:06,918 Val Step[0800/1563], Avg Loss: 1.1710, Avg Acc@1: 0.7328, Avg Acc@5: 0.9162
2022-01-18 22:14:08,978 Val Step[0850/1563], Avg Loss: 1.1738, Avg Acc@1: 0.7323, Avg Acc@5: 0.9157
2022-01-18 22:14:11,023 Val Step[0900/1563], Avg Loss: 1.1700, Avg Acc@1: 0.7324, Avg Acc@5: 0.9162
2022-01-18 22:14:13,075 Val Step[0950/1563], Avg Loss: 1.1694, Avg Acc@1: 0.7327, Avg Acc@5: 0.9165
2022-01-18 22:14:15,129 Val Step[1000/1563], Avg Loss: 1.1711, Avg Acc@1: 0.7325, Avg Acc@5: 0.9163
2022-01-18 22:14:17,195 Val Step[1050/1563], Avg Loss: 1.1723, Avg Acc@1: 0.7318, Avg Acc@5: 0.9161
2022-01-18 22:14:19,300 Val Step[1100/1563], Avg Loss: 1.1725, Avg Acc@1: 0.7317, Avg Acc@5: 0.9160
2022-01-18 22:14:21,405 Val Step[1150/1563], Avg Loss: 1.1714, Avg Acc@1: 0.7321, Avg Acc@5: 0.9161
2022-01-18 22:14:23,550 Val Step[1200/1563], Avg Loss: 1.1702, Avg Acc@1: 0.7323, Avg Acc@5: 0.9162
2022-01-18 22:14:25,704 Val Step[1250/1563], Avg Loss: 1.1693, Avg Acc@1: 0.7322, Avg Acc@5: 0.9165
2022-01-18 22:14:27,848 Val Step[1300/1563], Avg Loss: 1.1712, Avg Acc@1: 0.7322, Avg Acc@5: 0.9162
2022-01-18 22:14:29,699 Val Step[1350/1563], Avg Loss: 1.1724, Avg Acc@1: 0.7316, Avg Acc@5: 0.9158
2022-01-18 22:14:31,500 Val Step[1400/1563], Avg Loss: 1.1718, Avg Acc@1: 0.7316, Avg Acc@5: 0.9156
2022-01-18 22:14:33,326 Val Step[1450/1563], Avg Loss: 1.1717, Avg Acc@1: 0.7316, Avg Acc@5: 0.9157
2022-01-18 22:14:35,181 Val Step[1500/1563], Avg Loss: 1.1711, Avg Acc@1: 0.7318, Avg Acc@5: 0.9160
2022-01-18 22:14:37,012 Val Step[1550/1563], Avg Loss: 1.1713, Avg Acc@1: 0.7317, Avg Acc@5: 0.9162
2022-01-18 22:14:38,904 ----- Epoch[174/300], Validation Loss: 1.1711, Validation Acc@1: 0.7317, Validation Acc@5: 0.9163, time: 139.59
2022-01-18 22:14:38,904 Now training epoch 175. LR=0.000422
2022-01-18 22:16:28,317 Epoch[175/300], Step[0000/1252], Avg Loss: 2.7190, Avg Acc: 0.6533
2022-01-18 22:17:57,086 Epoch[175/300], Step[0050/1252], Avg Loss: 3.2755, Avg Acc: 0.4151
2022-01-18 22:19:25,563 Epoch[175/300], Step[0100/1252], Avg Loss: 3.2667, Avg Acc: 0.4101
2022-01-18 22:20:53,503 Epoch[175/300], Step[0150/1252], Avg Loss: 3.2853, Avg Acc: 0.4144
2022-01-18 22:22:22,816 Epoch[175/300], Step[0200/1252], Avg Loss: 3.2899, Avg Acc: 0.4157
2022-01-18 22:23:51,926 Epoch[175/300], Step[0250/1252], Avg Loss: 3.2977, Avg Acc: 0.4150
2022-01-18 22:25:20,420 Epoch[175/300], Step[0300/1252], Avg Loss: 3.2953, Avg Acc: 0.4180
2022-01-18 22:26:48,530 Epoch[175/300], Step[0350/1252], Avg Loss: 3.3032, Avg Acc: 0.4212
2022-01-18 22:28:17,257 Epoch[175/300], Step[0400/1252], Avg Loss: 3.3080, Avg Acc: 0.4204
2022-01-18 22:29:44,370 Epoch[175/300], Step[0450/1252], Avg Loss: 3.3086, Avg Acc: 0.4205
2022-01-18 22:31:11,976 Epoch[175/300], Step[0500/1252], Avg Loss: 3.3032, Avg Acc: 0.4208
2022-01-18 22:32:40,799 Epoch[175/300], Step[0550/1252], Avg Loss: 3.3118, Avg Acc: 0.4178
2022-01-18 22:34:09,607 Epoch[175/300], Step[0600/1252], Avg Loss: 3.3169, Avg Acc: 0.4180
2022-01-18 22:35:37,980 Epoch[175/300], Step[0650/1252], Avg Loss: 3.3214, Avg Acc: 0.4185
2022-01-18 22:37:04,732 Epoch[175/300], Step[0700/1252], Avg Loss: 3.3252, Avg Acc: 0.4175
2022-01-18 22:38:32,388 Epoch[175/300], Step[0750/1252], Avg Loss: 3.3272, Avg Acc: 0.4164
2022-01-18 22:40:00,490 Epoch[175/300], Step[0800/1252], Avg Loss: 3.3279, Avg Acc: 0.4163
2022-01-18 22:41:28,731 Epoch[175/300], Step[0850/1252], Avg Loss: 3.3290, Avg Acc: 0.4164
2022-01-18 22:42:55,415 Epoch[175/300], Step[0900/1252], Avg Loss: 3.3321, Avg Acc: 0.4176
2022-01-18 22:44:25,130 Epoch[175/300], Step[0950/1252], Avg Loss: 3.3330, Avg Acc: 0.4181
2022-01-18 22:45:54,282 Epoch[175/300], Step[1000/1252], Avg Loss: 3.3316, Avg Acc: 0.4187
2022-01-18 22:47:23,383 Epoch[175/300], Step[1050/1252], Avg Loss: 3.3325, Avg Acc: 0.4187
2022-01-18 22:48:52,105 Epoch[175/300], Step[1100/1252], Avg Loss: 3.3315, Avg Acc: 0.4188
2022-01-18 22:50:21,200 Epoch[175/300], Step[1150/1252], Avg Loss: 3.3306, Avg Acc: 0.4189
2022-01-18 22:51:49,197 Epoch[175/300], Step[1200/1252], Avg Loss: 3.3310, Avg Acc: 0.4201
2022-01-18 22:53:14,210 Epoch[175/300], Step[1250/1252], Avg Loss: 3.3335, Avg Acc: 0.4187
2022-01-18 22:53:21,219 ----- Epoch[175/300], Train Loss: 3.3335, Train Acc: 0.4187, time: 2322.31, Best Val(epoch172) Acc@1: 0.7326
2022-01-18 22:53:21,219 Now training epoch 176. LR=0.000417
2022-01-18 22:55:13,187 Epoch[176/300], Step[0000/1252], Avg Loss: 3.5750, Avg Acc: 0.2373
2022-01-18 22:56:42,167 Epoch[176/300], Step[0050/1252], Avg Loss: 3.2787, Avg Acc: 0.4448
2022-01-18 22:58:11,038 Epoch[176/300], Step[0100/1252], Avg Loss: 3.2734, Avg Acc: 0.4429
2022-01-18 22:59:40,519 Epoch[176/300], Step[0150/1252], Avg Loss: 3.2951, Avg Acc: 0.4366
2022-01-18 23:01:09,195 Epoch[176/300], Step[0200/1252], Avg Loss: 3.2973, Avg Acc: 0.4327
2022-01-18 23:02:37,329 Epoch[176/300], Step[0250/1252], Avg Loss: 3.3074, Avg Acc: 0.4321
2022-01-18 23:04:06,708 Epoch[176/300], Step[0300/1252], Avg Loss: 3.3067, Avg Acc: 0.4251
2022-01-18 23:05:35,784 Epoch[176/300], Step[0350/1252], Avg Loss: 3.3116, Avg Acc: 0.4259
2022-01-18 23:07:05,672 Epoch[176/300], Step[0400/1252], Avg Loss: 3.3082, Avg Acc: 0.4193
2022-01-18 23:08:33,274 Epoch[176/300], Step[0450/1252], Avg Loss: 3.3159, Avg Acc: 0.4193
2022-01-18 23:10:02,377 Epoch[176/300], Step[0500/1252], Avg Loss: 3.3179, Avg Acc: 0.4205
2022-01-18 23:11:31,652 Epoch[176/300], Step[0550/1252], Avg Loss: 3.3171, Avg Acc: 0.4188
2022-01-18 23:13:00,077 Epoch[176/300], Step[0600/1252], Avg Loss: 3.3192, Avg Acc: 0.4205
2022-01-18 23:14:27,678 Epoch[176/300], Step[0650/1252], Avg Loss: 3.3213, Avg Acc: 0.4214
2022-01-18 23:15:55,485 Epoch[176/300], Step[0700/1252], Avg Loss: 3.3235, Avg Acc: 0.4201
2022-01-18 23:17:24,063 Epoch[176/300], Step[0750/1252], Avg Loss: 3.3242, Avg Acc: 0.4234
2022-01-18 23:18:52,556 Epoch[176/300], Step[0800/1252], Avg Loss: 3.3247, Avg Acc: 0.4232
2022-01-18 23:20:22,324 Epoch[176/300], Step[0850/1252], Avg Loss: 3.3253, Avg Acc: 0.4226
2022-01-18 23:21:51,084 Epoch[176/300], Step[0900/1252], Avg Loss: 3.3212, Avg Acc: 0.4226
2022-01-18 23:23:19,201 Epoch[176/300], Step[0950/1252], Avg Loss: 3.3241, Avg Acc: 0.4224
2022-01-18 23:24:47,344 Epoch[176/300], Step[1000/1252], Avg Loss: 3.3223, Avg Acc: 0.4238
2022-01-18 23:26:14,376 Epoch[176/300], Step[1050/1252], Avg Loss: 3.3218, Avg Acc: 0.4224
2022-01-18 23:27:41,355 Epoch[176/300], Step[1100/1252], Avg Loss: 3.3217, Avg Acc: 0.4222
2022-01-18 23:29:10,025 Epoch[176/300], Step[1150/1252], Avg Loss: 3.3226, Avg Acc: 0.4231
2022-01-18 23:30:37,350 Epoch[176/300], Step[1200/1252], Avg Loss: 3.3233, Avg Acc: 0.4233
2022-01-18 23:32:03,638 Epoch[176/300], Step[1250/1252], Avg Loss: 3.3247, Avg Acc: 0.4226
2022-01-18 23:32:10,543 ----- Epoch[176/300], Train Loss: 3.3248, Train Acc: 0.4226, time: 2329.32, Best Val(epoch172) Acc@1: 0.7326
2022-01-18 23:32:10,544 ----- Validation after Epoch: 176
2022-01-18 23:33:27,856 Val Step[0000/1563], Avg Loss: 1.0116, Avg Acc@1: 0.7812, Avg Acc@5: 0.9375
2022-01-18 23:33:29,963 Val Step[0050/1563], Avg Loss: 1.1685, Avg Acc@1: 0.7408, Avg Acc@5: 0.9210
2022-01-18 23:33:31,898 Val Step[0100/1563], Avg Loss: 1.1819, Avg Acc@1: 0.7398, Avg Acc@5: 0.9199
2022-01-18 23:33:33,691 Val Step[0150/1563], Avg Loss: 1.1841, Avg Acc@1: 0.7378, Avg Acc@5: 0.9203
2022-01-18 23:33:35,528 Val Step[0200/1563], Avg Loss: 1.1889, Avg Acc@1: 0.7368, Avg Acc@5: 0.9198
2022-01-18 23:33:37,322 Val Step[0250/1563], Avg Loss: 1.1810, Avg Acc@1: 0.7379, Avg Acc@5: 0.9198
2022-01-18 23:33:39,116 Val Step[0300/1563], Avg Loss: 1.1831, Avg Acc@1: 0.7367, Avg Acc@5: 0.9182
2022-01-18 23:33:41,062 Val Step[0350/1563], Avg Loss: 1.1928, Avg Acc@1: 0.7350, Avg Acc@5: 0.9170
2022-01-18 23:33:42,926 Val Step[0400/1563], Avg Loss: 1.1915, Avg Acc@1: 0.7337, Avg Acc@5: 0.9176
2022-01-18 23:33:44,718 Val Step[0450/1563], Avg Loss: 1.1968, Avg Acc@1: 0.7314, Avg Acc@5: 0.9173
2022-01-18 23:33:46,521 Val Step[0500/1563], Avg Loss: 1.1997, Avg Acc@1: 0.7304, Avg Acc@5: 0.9170
2022-01-18 23:33:48,315 Val Step[0550/1563], Avg Loss: 1.2014, Avg Acc@1: 0.7289, Avg Acc@5: 0.9173
2022-01-18 23:33:50,225 Val Step[0600/1563], Avg Loss: 1.2008, Avg Acc@1: 0.7295, Avg Acc@5: 0.9171
2022-01-18 23:33:52,266 Val Step[0650/1563], Avg Loss: 1.2009, Avg Acc@1: 0.7294, Avg Acc@5: 0.9167
2022-01-18 23:33:54,311 Val Step[0700/1563], Avg Loss: 1.1992, Avg Acc@1: 0.7298, Avg Acc@5: 0.9178
2022-01-18 23:33:56,433 Val Step[0750/1563], Avg Loss: 1.2037, Avg Acc@1: 0.7291, Avg Acc@5: 0.9175
2022-01-18 23:33:58,513 Val Step[0800/1563], Avg Loss: 1.2045, Avg Acc@1: 0.7297, Avg Acc@5: 0.9176
2022-01-18 23:34:00,566 Val Step[0850/1563], Avg Loss: 1.2056, Avg Acc@1: 0.7293, Avg Acc@5: 0.9176
2022-01-18 23:34:02,658 Val Step[0900/1563], Avg Loss: 1.2025, Avg Acc@1: 0.7304, Avg Acc@5: 0.9176
2022-01-18 23:34:04,709 Val Step[0950/1563], Avg Loss: 1.2020, Avg Acc@1: 0.7310, Avg Acc@5: 0.9181
2022-01-18 23:34:06,767 Val Step[1000/1563], Avg Loss: 1.2035, Avg Acc@1: 0.7311, Avg Acc@5: 0.9182
2022-01-18 23:34:08,809 Val Step[1050/1563], Avg Loss: 1.2042, Avg Acc@1: 0.7305, Avg Acc@5: 0.9180
2022-01-18 23:34:10,849 Val Step[1100/1563], Avg Loss: 1.2042, Avg Acc@1: 0.7303, Avg Acc@5: 0.9180
2022-01-18 23:34:12,911 Val Step[1150/1563], Avg Loss: 1.2035, Avg Acc@1: 0.7305, Avg Acc@5: 0.9182
2022-01-18 23:34:14,966 Val Step[1200/1563], Avg Loss: 1.2029, Avg Acc@1: 0.7308, Avg Acc@5: 0.9181
2022-01-18 23:34:16,979 Val Step[1250/1563], Avg Loss: 1.2022, Avg Acc@1: 0.7310, Avg Acc@5: 0.9181
2022-01-18 23:34:18,973 Val Step[1300/1563], Avg Loss: 1.2046, Avg Acc@1: 0.7309, Avg Acc@5: 0.9178
2022-01-18 23:34:20,803 Val Step[1350/1563], Avg Loss: 1.2051, Avg Acc@1: 0.7307, Avg Acc@5: 0.9177
2022-01-18 23:34:22,695 Val Step[1400/1563], Avg Loss: 1.2046, Avg Acc@1: 0.7306, Avg Acc@5: 0.9176
2022-01-18 23:34:24,588 Val Step[1450/1563], Avg Loss: 1.2036, Avg Acc@1: 0.7309, Avg Acc@5: 0.9174
2022-01-18 23:34:26,480 Val Step[1500/1563], Avg Loss: 1.2035, Avg Acc@1: 0.7313, Avg Acc@5: 0.9174
2022-01-18 23:34:28,248 Val Step[1550/1563], Avg Loss: 1.2041, Avg Acc@1: 0.7309, Avg Acc@5: 0.9173
2022-01-18 23:34:31,310 ----- Epoch[176/300], Validation Loss: 1.2042, Validation Acc@1: 0.7309, Validation Acc@5: 0.9173, time: 140.76
2022-01-18 23:34:31,311 Now training epoch 177. LR=0.000411
2022-01-18 23:36:21,839 Epoch[177/300], Step[0000/1252], Avg Loss: 3.5678, Avg Acc: 0.3838
2022-01-18 23:37:51,100 Epoch[177/300], Step[0050/1252], Avg Loss: 3.3595, Avg Acc: 0.4398
2022-01-18 23:39:19,749 Epoch[177/300], Step[0100/1252], Avg Loss: 3.3282, Avg Acc: 0.4437
2022-01-18 23:40:46,956 Epoch[177/300], Step[0150/1252], Avg Loss: 3.2814, Avg Acc: 0.4471
2022-01-18 23:42:16,737 Epoch[177/300], Step[0200/1252], Avg Loss: 3.2828, Avg Acc: 0.4412
2022-01-18 23:43:46,538 Epoch[177/300], Step[0250/1252], Avg Loss: 3.2940, Avg Acc: 0.4389
2022-01-18 23:45:13,054 Epoch[177/300], Step[0300/1252], Avg Loss: 3.2908, Avg Acc: 0.4421
2022-01-18 23:46:40,262 Epoch[177/300], Step[0350/1252], Avg Loss: 3.2982, Avg Acc: 0.4397
2022-01-18 23:48:08,313 Epoch[177/300], Step[0400/1252], Avg Loss: 3.2993, Avg Acc: 0.4382
2022-01-18 23:49:35,219 Epoch[177/300], Step[0450/1252], Avg Loss: 3.3119, Avg Acc: 0.4346
2022-01-18 23:51:03,623 Epoch[177/300], Step[0500/1252], Avg Loss: 3.3178, Avg Acc: 0.4342
2022-01-18 23:52:31,937 Epoch[177/300], Step[0550/1252], Avg Loss: 3.3132, Avg Acc: 0.4356
2022-01-18 23:53:58,647 Epoch[177/300], Step[0600/1252], Avg Loss: 3.3130, Avg Acc: 0.4332
2022-01-18 23:55:26,382 Epoch[177/300], Step[0650/1252], Avg Loss: 3.3190, Avg Acc: 0.4312
2022-01-18 23:56:54,010 Epoch[177/300], Step[0700/1252], Avg Loss: 3.3190, Avg Acc: 0.4284
2022-01-18 23:58:22,116 Epoch[177/300], Step[0750/1252], Avg Loss: 3.3217, Avg Acc: 0.4268
2022-01-18 23:59:51,399 Epoch[177/300], Step[0800/1252], Avg Loss: 3.3219, Avg Acc: 0.4266
2022-01-19 00:01:20,570 Epoch[177/300], Step[0850/1252], Avg Loss: 3.3196, Avg Acc: 0.4255
2022-01-19 00:02:50,043 Epoch[177/300], Step[0900/1252], Avg Loss: 3.3244, Avg Acc: 0.4252
2022-01-19 00:04:18,248 Epoch[177/300], Step[0950/1252], Avg Loss: 3.3212, Avg Acc: 0.4251
2022-01-19 00:05:46,685 Epoch[177/300], Step[1000/1252], Avg Loss: 3.3227, Avg Acc: 0.4245
2022-01-19 00:07:15,117 Epoch[177/300], Step[1050/1252], Avg Loss: 3.3212, Avg Acc: 0.4234
2022-01-19 00:08:42,613 Epoch[177/300], Step[1100/1252], Avg Loss: 3.3222, Avg Acc: 0.4229
2022-01-19 00:10:10,332 Epoch[177/300], Step[1150/1252], Avg Loss: 3.3223, Avg Acc: 0.4239
2022-01-19 00:11:38,618 Epoch[177/300], Step[1200/1252], Avg Loss: 3.3243, Avg Acc: 0.4241
2022-01-19 00:13:04,951 Epoch[177/300], Step[1250/1252], Avg Loss: 3.3273, Avg Acc: 0.4236
2022-01-19 00:13:12,037 ----- Epoch[177/300], Train Loss: 3.3273, Train Acc: 0.4236, time: 2320.72, Best Val(epoch172) Acc@1: 0.7326
2022-01-19 00:13:12,037 Now training epoch 178. LR=0.000406
2022-01-19 00:15:02,067 Epoch[178/300], Step[0000/1252], Avg Loss: 2.8847, Avg Acc: 0.5410
2022-01-19 00:16:30,385 Epoch[178/300], Step[0050/1252], Avg Loss: 3.2924, Avg Acc: 0.3756
2022-01-19 00:17:58,501 Epoch[178/300], Step[0100/1252], Avg Loss: 3.3094, Avg Acc: 0.3986
2022-01-19 00:19:27,067 Epoch[178/300], Step[0150/1252], Avg Loss: 3.3076, Avg Acc: 0.4073
2022-01-19 00:20:56,540 Epoch[178/300], Step[0200/1252], Avg Loss: 3.3090, Avg Acc: 0.4096
2022-01-19 00:22:24,927 Epoch[178/300], Step[0250/1252], Avg Loss: 3.3047, Avg Acc: 0.4185
2022-01-19 00:23:53,274 Epoch[178/300], Step[0300/1252], Avg Loss: 3.3012, Avg Acc: 0.4206
2022-01-19 00:25:21,272 Epoch[178/300], Step[0350/1252], Avg Loss: 3.3076, Avg Acc: 0.4194
2022-01-19 00:26:49,713 Epoch[178/300], Step[0400/1252], Avg Loss: 3.3076, Avg Acc: 0.4187
2022-01-19 00:28:17,193 Epoch[178/300], Step[0450/1252], Avg Loss: 3.3097, Avg Acc: 0.4189
2022-01-19 00:29:46,561 Epoch[178/300], Step[0500/1252], Avg Loss: 3.3096, Avg Acc: 0.4179
2022-01-19 00:31:15,266 Epoch[178/300], Step[0550/1252], Avg Loss: 3.3129, Avg Acc: 0.4186
2022-01-19 00:32:45,230 Epoch[178/300], Step[0600/1252], Avg Loss: 3.3110, Avg Acc: 0.4189
2022-01-19 00:34:14,372 Epoch[178/300], Step[0650/1252], Avg Loss: 3.3192, Avg Acc: 0.4183
2022-01-19 00:35:43,219 Epoch[178/300], Step[0700/1252], Avg Loss: 3.3162, Avg Acc: 0.4202
2022-01-19 00:37:12,175 Epoch[178/300], Step[0750/1252], Avg Loss: 3.3156, Avg Acc: 0.4196
2022-01-19 00:38:41,341 Epoch[178/300], Step[0800/1252], Avg Loss: 3.3174, Avg Acc: 0.4189
2022-01-19 00:40:10,040 Epoch[178/300], Step[0850/1252], Avg Loss: 3.3187, Avg Acc: 0.4180
2022-01-19 00:41:39,370 Epoch[178/300], Step[0900/1252], Avg Loss: 3.3211, Avg Acc: 0.4163
2022-01-19 00:43:07,742 Epoch[178/300], Step[0950/1252], Avg Loss: 3.3262, Avg Acc: 0.4149
2022-01-19 00:44:36,729 Epoch[178/300], Step[1000/1252], Avg Loss: 3.3296, Avg Acc: 0.4146
2022-01-19 00:46:05,111 Epoch[178/300], Step[1050/1252], Avg Loss: 3.3312, Avg Acc: 0.4141
2022-01-19 00:47:33,678 Epoch[178/300], Step[1100/1252], Avg Loss: 3.3312, Avg Acc: 0.4143
2022-01-19 00:49:03,132 Epoch[178/300], Step[1150/1252], Avg Loss: 3.3308, Avg Acc: 0.4137
2022-01-19 00:50:31,279 Epoch[178/300], Step[1200/1252], Avg Loss: 3.3323, Avg Acc: 0.4144
2022-01-19 00:51:59,071 Epoch[178/300], Step[1250/1252], Avg Loss: 3.3325, Avg Acc: 0.4148
2022-01-19 00:52:06,035 ----- Epoch[178/300], Train Loss: 3.3325, Train Acc: 0.4148, time: 2333.99, Best Val(epoch172) Acc@1: 0.7326
2022-01-19 00:52:06,035 ----- Validation after Epoch: 178
2022-01-19 00:53:14,752 Val Step[0000/1563], Avg Loss: 0.9972, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-19 00:53:16,658 Val Step[0050/1563], Avg Loss: 1.1839, Avg Acc@1: 0.7359, Avg Acc@5: 0.9222
2022-01-19 00:53:18,717 Val Step[0100/1563], Avg Loss: 1.1946, Avg Acc@1: 0.7287, Avg Acc@5: 0.9230
2022-01-19 00:53:20,790 Val Step[0150/1563], Avg Loss: 1.1943, Avg Acc@1: 0.7345, Avg Acc@5: 0.9199
2022-01-19 00:53:22,833 Val Step[0200/1563], Avg Loss: 1.1875, Avg Acc@1: 0.7376, Avg Acc@5: 0.9216
2022-01-19 00:53:24,729 Val Step[0250/1563], Avg Loss: 1.1791, Avg Acc@1: 0.7392, Avg Acc@5: 0.9208
2022-01-19 00:53:26,645 Val Step[0300/1563], Avg Loss: 1.1783, Avg Acc@1: 0.7404, Avg Acc@5: 0.9204
2022-01-19 00:53:28,592 Val Step[0350/1563], Avg Loss: 1.1829, Avg Acc@1: 0.7375, Avg Acc@5: 0.9196
2022-01-19 00:53:30,499 Val Step[0400/1563], Avg Loss: 1.1831, Avg Acc@1: 0.7368, Avg Acc@5: 0.9190
2022-01-19 00:53:32,348 Val Step[0450/1563], Avg Loss: 1.1895, Avg Acc@1: 0.7340, Avg Acc@5: 0.9181
2022-01-19 00:53:34,151 Val Step[0500/1563], Avg Loss: 1.1924, Avg Acc@1: 0.7334, Avg Acc@5: 0.9177
2022-01-19 00:53:35,969 Val Step[0550/1563], Avg Loss: 1.1938, Avg Acc@1: 0.7329, Avg Acc@5: 0.9182
2022-01-19 00:53:37,786 Val Step[0600/1563], Avg Loss: 1.1956, Avg Acc@1: 0.7319, Avg Acc@5: 0.9178
2022-01-19 00:53:39,639 Val Step[0650/1563], Avg Loss: 1.1962, Avg Acc@1: 0.7320, Avg Acc@5: 0.9180
2022-01-19 00:53:41,535 Val Step[0700/1563], Avg Loss: 1.1927, Avg Acc@1: 0.7329, Avg Acc@5: 0.9187
2022-01-19 00:53:43,357 Val Step[0750/1563], Avg Loss: 1.1988, Avg Acc@1: 0.7317, Avg Acc@5: 0.9177
2022-01-19 00:53:45,167 Val Step[0800/1563], Avg Loss: 1.1998, Avg Acc@1: 0.7324, Avg Acc@5: 0.9173
2022-01-19 00:53:47,061 Val Step[0850/1563], Avg Loss: 1.2005, Avg Acc@1: 0.7319, Avg Acc@5: 0.9172
2022-01-19 00:53:48,884 Val Step[0900/1563], Avg Loss: 1.1979, Avg Acc@1: 0.7319, Avg Acc@5: 0.9175
2022-01-19 00:53:50,758 Val Step[0950/1563], Avg Loss: 1.1985, Avg Acc@1: 0.7323, Avg Acc@5: 0.9176
2022-01-19 00:53:52,821 Val Step[1000/1563], Avg Loss: 1.2001, Avg Acc@1: 0.7325, Avg Acc@5: 0.9173
2022-01-19 00:53:54,980 Val Step[1050/1563], Avg Loss: 1.2023, Avg Acc@1: 0.7315, Avg Acc@5: 0.9170
2022-01-19 00:53:57,087 Val Step[1100/1563], Avg Loss: 1.2019, Avg Acc@1: 0.7314, Avg Acc@5: 0.9173
2022-01-19 00:53:59,182 Val Step[1150/1563], Avg Loss: 1.2013, Avg Acc@1: 0.7313, Avg Acc@5: 0.9172
2022-01-19 00:54:01,273 Val Step[1200/1563], Avg Loss: 1.2001, Avg Acc@1: 0.7314, Avg Acc@5: 0.9174
2022-01-19 00:54:03,344 Val Step[1250/1563], Avg Loss: 1.1997, Avg Acc@1: 0.7312, Avg Acc@5: 0.9177
2022-01-19 00:54:05,550 Val Step[1300/1563], Avg Loss: 1.2024, Avg Acc@1: 0.7312, Avg Acc@5: 0.9175
2022-01-19 00:54:07,703 Val Step[1350/1563], Avg Loss: 1.2021, Avg Acc@1: 0.7312, Avg Acc@5: 0.9173
2022-01-19 00:54:09,715 Val Step[1400/1563], Avg Loss: 1.2017, Avg Acc@1: 0.7312, Avg Acc@5: 0.9171
2022-01-19 00:54:11,751 Val Step[1450/1563], Avg Loss: 1.2009, Avg Acc@1: 0.7316, Avg Acc@5: 0.9170
2022-01-19 00:54:13,798 Val Step[1500/1563], Avg Loss: 1.2014, Avg Acc@1: 0.7320, Avg Acc@5: 0.9169
2022-01-19 00:54:15,824 Val Step[1550/1563], Avg Loss: 1.2017, Avg Acc@1: 0.7317, Avg Acc@5: 0.9167
2022-01-19 00:54:17,829 ----- Epoch[178/300], Validation Loss: 1.2015, Validation Acc@1: 0.7317, Validation Acc@5: 0.9169, time: 131.79
2022-01-19 00:54:17,830 Now training epoch 179. LR=0.000400
2022-01-19 00:56:04,685 Epoch[179/300], Step[0000/1252], Avg Loss: 3.3721, Avg Acc: 0.3193
2022-01-19 00:57:33,290 Epoch[179/300], Step[0050/1252], Avg Loss: 3.3441, Avg Acc: 0.4358
2022-01-19 00:59:02,512 Epoch[179/300], Step[0100/1252], Avg Loss: 3.2910, Avg Acc: 0.4280
2022-01-19 01:00:31,121 Epoch[179/300], Step[0150/1252], Avg Loss: 3.2801, Avg Acc: 0.4296
2022-01-19 01:01:57,778 Epoch[179/300], Step[0200/1252], Avg Loss: 3.2942, Avg Acc: 0.4348
2022-01-19 01:03:26,351 Epoch[179/300], Step[0250/1252], Avg Loss: 3.3035, Avg Acc: 0.4283
2022-01-19 01:04:53,487 Epoch[179/300], Step[0300/1252], Avg Loss: 3.3010, Avg Acc: 0.4294
2022-01-19 01:06:21,269 Epoch[179/300], Step[0350/1252], Avg Loss: 3.2956, Avg Acc: 0.4289
2022-01-19 01:07:47,247 Epoch[179/300], Step[0400/1252], Avg Loss: 3.2989, Avg Acc: 0.4283
2022-01-19 01:09:14,687 Epoch[179/300], Step[0450/1252], Avg Loss: 3.2994, Avg Acc: 0.4262
2022-01-19 01:10:41,367 Epoch[179/300], Step[0500/1252], Avg Loss: 3.3056, Avg Acc: 0.4282
2022-01-19 01:12:09,787 Epoch[179/300], Step[0550/1252], Avg Loss: 3.3050, Avg Acc: 0.4280
2022-01-19 01:13:38,100 Epoch[179/300], Step[0600/1252], Avg Loss: 3.3051, Avg Acc: 0.4270
2022-01-19 01:15:06,323 Epoch[179/300], Step[0650/1252], Avg Loss: 3.3079, Avg Acc: 0.4270
2022-01-19 01:16:34,466 Epoch[179/300], Step[0700/1252], Avg Loss: 3.3091, Avg Acc: 0.4266
2022-01-19 01:18:01,081 Epoch[179/300], Step[0750/1252], Avg Loss: 3.3114, Avg Acc: 0.4263
2022-01-19 01:19:29,279 Epoch[179/300], Step[0800/1252], Avg Loss: 3.3132, Avg Acc: 0.4242
2022-01-19 01:20:56,977 Epoch[179/300], Step[0850/1252], Avg Loss: 3.3096, Avg Acc: 0.4227
2022-01-19 01:22:25,344 Epoch[179/300], Step[0900/1252], Avg Loss: 3.3078, Avg Acc: 0.4224
2022-01-19 01:23:52,604 Epoch[179/300], Step[0950/1252], Avg Loss: 3.3082, Avg Acc: 0.4221
2022-01-19 01:25:20,835 Epoch[179/300], Step[1000/1252], Avg Loss: 3.3100, Avg Acc: 0.4205
2022-01-19 01:26:48,429 Epoch[179/300], Step[1050/1252], Avg Loss: 3.3115, Avg Acc: 0.4210
2022-01-19 01:28:16,719 Epoch[179/300], Step[1100/1252], Avg Loss: 3.3160, Avg Acc: 0.4205
2022-01-19 01:29:46,260 Epoch[179/300], Step[1150/1252], Avg Loss: 3.3150, Avg Acc: 0.4204
2022-01-19 01:31:14,526 Epoch[179/300], Step[1200/1252], Avg Loss: 3.3169, Avg Acc: 0.4202
2022-01-19 01:32:42,968 Epoch[179/300], Step[1250/1252], Avg Loss: 3.3181, Avg Acc: 0.4199
2022-01-19 01:32:49,959 ----- Epoch[179/300], Train Loss: 3.3181, Train Acc: 0.4199, time: 2312.12, Best Val(epoch172) Acc@1: 0.7326
2022-01-19 01:32:49,959 Now training epoch 180. LR=0.000395
2022-01-19 01:34:41,549 Epoch[180/300], Step[0000/1252], Avg Loss: 3.2719, Avg Acc: 0.3281
2022-01-19 01:36:09,644 Epoch[180/300], Step[0050/1252], Avg Loss: 3.3136, Avg Acc: 0.4201
2022-01-19 01:37:37,922 Epoch[180/300], Step[0100/1252], Avg Loss: 3.3296, Avg Acc: 0.4139
2022-01-19 01:39:06,119 Epoch[180/300], Step[0150/1252], Avg Loss: 3.3212, Avg Acc: 0.4204
2022-01-19 01:40:34,696 Epoch[180/300], Step[0200/1252], Avg Loss: 3.3243, Avg Acc: 0.4268
2022-01-19 01:42:03,591 Epoch[180/300], Step[0250/1252], Avg Loss: 3.3100, Avg Acc: 0.4294
2022-01-19 01:43:31,034 Epoch[180/300], Step[0300/1252], Avg Loss: 3.3068, Avg Acc: 0.4291
2022-01-19 01:44:58,092 Epoch[180/300], Step[0350/1252], Avg Loss: 3.3123, Avg Acc: 0.4247
2022-01-19 01:46:26,433 Epoch[180/300], Step[0400/1252], Avg Loss: 3.3180, Avg Acc: 0.4238
2022-01-19 01:47:55,510 Epoch[180/300], Step[0450/1252], Avg Loss: 3.3144, Avg Acc: 0.4228
2022-01-19 01:49:24,499 Epoch[180/300], Step[0500/1252], Avg Loss: 3.3206, Avg Acc: 0.4214
2022-01-19 01:50:51,851 Epoch[180/300], Step[0550/1252], Avg Loss: 3.3226, Avg Acc: 0.4216
2022-01-19 01:52:20,015 Epoch[180/300], Step[0600/1252], Avg Loss: 3.3222, Avg Acc: 0.4220
2022-01-19 01:53:49,257 Epoch[180/300], Step[0650/1252], Avg Loss: 3.3199, Avg Acc: 0.4198
2022-01-19 01:55:17,609 Epoch[180/300], Step[0700/1252], Avg Loss: 3.3152, Avg Acc: 0.4193
2022-01-19 01:56:47,059 Epoch[180/300], Step[0750/1252], Avg Loss: 3.3165, Avg Acc: 0.4167
2022-01-19 01:58:15,922 Epoch[180/300], Step[0800/1252], Avg Loss: 3.3162, Avg Acc: 0.4171
2022-01-19 01:59:45,516 Epoch[180/300], Step[0850/1252], Avg Loss: 3.3178, Avg Acc: 0.4181
2022-01-19 02:01:14,927 Epoch[180/300], Step[0900/1252], Avg Loss: 3.3156, Avg Acc: 0.4185
2022-01-19 02:02:43,398 Epoch[180/300], Step[0950/1252], Avg Loss: 3.3191, Avg Acc: 0.4167
2022-01-19 02:04:12,913 Epoch[180/300], Step[1000/1252], Avg Loss: 3.3180, Avg Acc: 0.4175
2022-01-19 02:05:42,994 Epoch[180/300], Step[1050/1252], Avg Loss: 3.3189, Avg Acc: 0.4167
2022-01-19 02:07:12,349 Epoch[180/300], Step[1100/1252], Avg Loss: 3.3170, Avg Acc: 0.4173
2022-01-19 02:08:41,365 Epoch[180/300], Step[1150/1252], Avg Loss: 3.3161, Avg Acc: 0.4187
2022-01-19 02:10:11,016 Epoch[180/300], Step[1200/1252], Avg Loss: 3.3174, Avg Acc: 0.4182
2022-01-19 02:11:39,299 Epoch[180/300], Step[1250/1252], Avg Loss: 3.3168, Avg Acc: 0.4183
2022-01-19 02:11:46,336 ----- Epoch[180/300], Train Loss: 3.3169, Train Acc: 0.4183, time: 2336.37, Best Val(epoch172) Acc@1: 0.7326
2022-01-19 02:11:46,336 ----- Validation after Epoch: 180
2022-01-19 02:13:10,081 Val Step[0000/1563], Avg Loss: 0.9216, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-19 02:13:12,179 Val Step[0050/1563], Avg Loss: 1.1684, Avg Acc@1: 0.7445, Avg Acc@5: 0.9142
2022-01-19 02:13:14,220 Val Step[0100/1563], Avg Loss: 1.1713, Avg Acc@1: 0.7389, Avg Acc@5: 0.9202
2022-01-19 02:13:16,290 Val Step[0150/1563], Avg Loss: 1.1741, Avg Acc@1: 0.7405, Avg Acc@5: 0.9189
2022-01-19 02:13:18,358 Val Step[0200/1563], Avg Loss: 1.1758, Avg Acc@1: 0.7404, Avg Acc@5: 0.9195
2022-01-19 02:13:20,404 Val Step[0250/1563], Avg Loss: 1.1568, Avg Acc@1: 0.7427, Avg Acc@5: 0.9207
2022-01-19 02:13:22,425 Val Step[0300/1563], Avg Loss: 1.1569, Avg Acc@1: 0.7438, Avg Acc@5: 0.9193
2022-01-19 02:13:24,452 Val Step[0350/1563], Avg Loss: 1.1635, Avg Acc@1: 0.7427, Avg Acc@5: 0.9186
2022-01-19 02:13:26,560 Val Step[0400/1563], Avg Loss: 1.1637, Avg Acc@1: 0.7420, Avg Acc@5: 0.9183
2022-01-19 02:13:28,589 Val Step[0450/1563], Avg Loss: 1.1667, Avg Acc@1: 0.7404, Avg Acc@5: 0.9178
2022-01-19 02:13:30,612 Val Step[0500/1563], Avg Loss: 1.1693, Avg Acc@1: 0.7398, Avg Acc@5: 0.9179
2022-01-19 02:13:32,628 Val Step[0550/1563], Avg Loss: 1.1707, Avg Acc@1: 0.7386, Avg Acc@5: 0.9179
2022-01-19 02:13:34,695 Val Step[0600/1563], Avg Loss: 1.1711, Avg Acc@1: 0.7380, Avg Acc@5: 0.9180
2022-01-19 02:13:36,759 Val Step[0650/1563], Avg Loss: 1.1713, Avg Acc@1: 0.7380, Avg Acc@5: 0.9180
2022-01-19 02:13:38,797 Val Step[0700/1563], Avg Loss: 1.1694, Avg Acc@1: 0.7379, Avg Acc@5: 0.9186
2022-01-19 02:13:40,819 Val Step[0750/1563], Avg Loss: 1.1732, Avg Acc@1: 0.7372, Avg Acc@5: 0.9180
2022-01-19 02:13:42,859 Val Step[0800/1563], Avg Loss: 1.1739, Avg Acc@1: 0.7374, Avg Acc@5: 0.9179
2022-01-19 02:13:44,901 Val Step[0850/1563], Avg Loss: 1.1755, Avg Acc@1: 0.7375, Avg Acc@5: 0.9176
2022-01-19 02:13:46,983 Val Step[0900/1563], Avg Loss: 1.1724, Avg Acc@1: 0.7379, Avg Acc@5: 0.9182
2022-01-19 02:13:49,046 Val Step[0950/1563], Avg Loss: 1.1719, Avg Acc@1: 0.7387, Avg Acc@5: 0.9185
2022-01-19 02:13:51,118 Val Step[1000/1563], Avg Loss: 1.1741, Avg Acc@1: 0.7381, Avg Acc@5: 0.9181
2022-01-19 02:13:53,178 Val Step[1050/1563], Avg Loss: 1.1746, Avg Acc@1: 0.7378, Avg Acc@5: 0.9181
2022-01-19 02:13:55,350 Val Step[1100/1563], Avg Loss: 1.1744, Avg Acc@1: 0.7375, Avg Acc@5: 0.9182
2022-01-19 02:13:57,452 Val Step[1150/1563], Avg Loss: 1.1731, Avg Acc@1: 0.7378, Avg Acc@5: 0.9183
2022-01-19 02:13:59,533 Val Step[1200/1563], Avg Loss: 1.1728, Avg Acc@1: 0.7377, Avg Acc@5: 0.9184
2022-01-19 02:14:01,586 Val Step[1250/1563], Avg Loss: 1.1725, Avg Acc@1: 0.7378, Avg Acc@5: 0.9185
2022-01-19 02:14:03,639 Val Step[1300/1563], Avg Loss: 1.1750, Avg Acc@1: 0.7376, Avg Acc@5: 0.9185
2022-01-19 02:14:05,686 Val Step[1350/1563], Avg Loss: 1.1760, Avg Acc@1: 0.7370, Avg Acc@5: 0.9183
2022-01-19 02:14:07,746 Val Step[1400/1563], Avg Loss: 1.1750, Avg Acc@1: 0.7370, Avg Acc@5: 0.9181
2022-01-19 02:14:09,788 Val Step[1450/1563], Avg Loss: 1.1748, Avg Acc@1: 0.7371, Avg Acc@5: 0.9181
2022-01-19 02:14:11,910 Val Step[1500/1563], Avg Loss: 1.1740, Avg Acc@1: 0.7376, Avg Acc@5: 0.9184
2022-01-19 02:14:13,939 Val Step[1550/1563], Avg Loss: 1.1745, Avg Acc@1: 0.7371, Avg Acc@5: 0.9185
2022-01-19 02:14:15,895 ----- Epoch[180/300], Validation Loss: 1.1743, Validation Acc@1: 0.7371, Validation Acc@5: 0.9186, time: 149.56
2022-01-19 02:14:17,093 the pre best model acc:0.7326, at epoch 172
2022-01-19 02:14:17,094 current best model acc:0.7371, at epoch 180
2022-01-19 02:14:17,094 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 02:14:17,094 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 02:14:17,094 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 02:14:17,094 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 02:14:17,094 Now training epoch 181. LR=0.000389
2022-01-19 02:16:11,403 Epoch[181/300], Step[0000/1252], Avg Loss: 3.2411, Avg Acc: 0.6055
2022-01-19 02:17:39,132 Epoch[181/300], Step[0050/1252], Avg Loss: 3.2976, Avg Acc: 0.4055
2022-01-19 02:19:06,748 Epoch[181/300], Step[0100/1252], Avg Loss: 3.2853, Avg Acc: 0.4352
2022-01-19 02:20:34,774 Epoch[181/300], Step[0150/1252], Avg Loss: 3.2867, Avg Acc: 0.4310
2022-01-19 02:22:02,084 Epoch[181/300], Step[0200/1252], Avg Loss: 3.3199, Avg Acc: 0.4273
2022-01-19 02:23:30,548 Epoch[181/300], Step[0250/1252], Avg Loss: 3.3204, Avg Acc: 0.4320
2022-01-19 02:24:57,977 Epoch[181/300], Step[0300/1252], Avg Loss: 3.3224, Avg Acc: 0.4349
2022-01-19 02:26:24,487 Epoch[181/300], Step[0350/1252], Avg Loss: 3.3149, Avg Acc: 0.4348
2022-01-19 02:27:52,675 Epoch[181/300], Step[0400/1252], Avg Loss: 3.3174, Avg Acc: 0.4368
2022-01-19 02:29:20,281 Epoch[181/300], Step[0450/1252], Avg Loss: 3.3164, Avg Acc: 0.4347
2022-01-19 02:30:47,159 Epoch[181/300], Step[0500/1252], Avg Loss: 3.3089, Avg Acc: 0.4335
2022-01-19 02:32:13,961 Epoch[181/300], Step[0550/1252], Avg Loss: 3.3075, Avg Acc: 0.4344
2022-01-19 02:33:42,355 Epoch[181/300], Step[0600/1252], Avg Loss: 3.3036, Avg Acc: 0.4333
2022-01-19 02:35:10,495 Epoch[181/300], Step[0650/1252], Avg Loss: 3.3067, Avg Acc: 0.4320
2022-01-19 02:36:38,958 Epoch[181/300], Step[0700/1252], Avg Loss: 3.3055, Avg Acc: 0.4312
2022-01-19 02:38:07,316 Epoch[181/300], Step[0750/1252], Avg Loss: 3.3090, Avg Acc: 0.4311
2022-01-19 02:39:36,110 Epoch[181/300], Step[0800/1252], Avg Loss: 3.3102, Avg Acc: 0.4315
2022-01-19 02:41:04,814 Epoch[181/300], Step[0850/1252], Avg Loss: 3.3078, Avg Acc: 0.4319
2022-01-19 02:42:33,017 Epoch[181/300], Step[0900/1252], Avg Loss: 3.3074, Avg Acc: 0.4306
2022-01-19 02:43:58,991 Epoch[181/300], Step[0950/1252], Avg Loss: 3.3075, Avg Acc: 0.4310
2022-01-19 02:45:27,792 Epoch[181/300], Step[1000/1252], Avg Loss: 3.3081, Avg Acc: 0.4297
2022-01-19 02:46:56,728 Epoch[181/300], Step[1050/1252], Avg Loss: 3.3102, Avg Acc: 0.4295
2022-01-19 02:48:26,756 Epoch[181/300], Step[1100/1252], Avg Loss: 3.3116, Avg Acc: 0.4289
2022-01-19 02:49:55,483 Epoch[181/300], Step[1150/1252], Avg Loss: 3.3134, Avg Acc: 0.4281
2022-01-19 02:51:24,828 Epoch[181/300], Step[1200/1252], Avg Loss: 3.3102, Avg Acc: 0.4278
2022-01-19 02:52:53,205 Epoch[181/300], Step[1250/1252], Avg Loss: 3.3093, Avg Acc: 0.4266
2022-01-19 02:53:00,570 ----- Epoch[181/300], Train Loss: 3.3093, Train Acc: 0.4266, time: 2323.47, Best Val(epoch180) Acc@1: 0.7371
2022-01-19 02:53:00,570 Now training epoch 182. LR=0.000384
2022-01-19 02:54:50,329 Epoch[182/300], Step[0000/1252], Avg Loss: 2.9103, Avg Acc: 0.5947
2022-01-19 02:56:16,469 Epoch[182/300], Step[0050/1252], Avg Loss: 3.2496, Avg Acc: 0.4319
2022-01-19 02:57:43,843 Epoch[182/300], Step[0100/1252], Avg Loss: 3.2815, Avg Acc: 0.4443
2022-01-19 02:59:13,563 Epoch[182/300], Step[0150/1252], Avg Loss: 3.2785, Avg Acc: 0.4323
2022-01-19 03:00:42,851 Epoch[182/300], Step[0200/1252], Avg Loss: 3.2835, Avg Acc: 0.4328
2022-01-19 03:02:11,320 Epoch[182/300], Step[0250/1252], Avg Loss: 3.2966, Avg Acc: 0.4316
2022-01-19 03:03:39,045 Epoch[182/300], Step[0300/1252], Avg Loss: 3.2991, Avg Acc: 0.4354
2022-01-19 03:05:08,438 Epoch[182/300], Step[0350/1252], Avg Loss: 3.2975, Avg Acc: 0.4334
2022-01-19 03:06:36,772 Epoch[182/300], Step[0400/1252], Avg Loss: 3.3099, Avg Acc: 0.4301
2022-01-19 03:08:05,076 Epoch[182/300], Step[0450/1252], Avg Loss: 3.3127, Avg Acc: 0.4301
2022-01-19 03:09:33,813 Epoch[182/300], Step[0500/1252], Avg Loss: 3.3096, Avg Acc: 0.4296
2022-01-19 03:11:02,839 Epoch[182/300], Step[0550/1252], Avg Loss: 3.3152, Avg Acc: 0.4292
2022-01-19 03:12:30,954 Epoch[182/300], Step[0600/1252], Avg Loss: 3.3141, Avg Acc: 0.4270
2022-01-19 03:14:00,514 Epoch[182/300], Step[0650/1252], Avg Loss: 3.3151, Avg Acc: 0.4271
2022-01-19 03:15:29,706 Epoch[182/300], Step[0700/1252], Avg Loss: 3.3084, Avg Acc: 0.4267
2022-01-19 03:16:56,193 Epoch[182/300], Step[0750/1252], Avg Loss: 3.3088, Avg Acc: 0.4258
2022-01-19 03:18:24,650 Epoch[182/300], Step[0800/1252], Avg Loss: 3.3060, Avg Acc: 0.4257
2022-01-19 03:19:54,798 Epoch[182/300], Step[0850/1252], Avg Loss: 3.3081, Avg Acc: 0.4248
2022-01-19 03:21:24,020 Epoch[182/300], Step[0900/1252], Avg Loss: 3.3106, Avg Acc: 0.4240
2022-01-19 03:22:54,023 Epoch[182/300], Step[0950/1252], Avg Loss: 3.3095, Avg Acc: 0.4241
2022-01-19 03:24:22,036 Epoch[182/300], Step[1000/1252], Avg Loss: 3.3106, Avg Acc: 0.4227
2022-01-19 03:25:50,375 Epoch[182/300], Step[1050/1252], Avg Loss: 3.3111, Avg Acc: 0.4230
2022-01-19 03:27:19,872 Epoch[182/300], Step[1100/1252], Avg Loss: 3.3110, Avg Acc: 0.4240
2022-01-19 03:28:48,328 Epoch[182/300], Step[1150/1252], Avg Loss: 3.3085, Avg Acc: 0.4244
2022-01-19 03:30:16,900 Epoch[182/300], Step[1200/1252], Avg Loss: 3.3081, Avg Acc: 0.4244
2022-01-19 03:31:45,724 Epoch[182/300], Step[1250/1252], Avg Loss: 3.3109, Avg Acc: 0.4240
2022-01-19 03:31:52,732 ----- Epoch[182/300], Train Loss: 3.3109, Train Acc: 0.4240, time: 2332.16, Best Val(epoch180) Acc@1: 0.7371
2022-01-19 03:31:52,732 ----- Validation after Epoch: 182
2022-01-19 03:33:10,006 Val Step[0000/1563], Avg Loss: 0.7630, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-19 03:33:12,069 Val Step[0050/1563], Avg Loss: 1.1363, Avg Acc@1: 0.7512, Avg Acc@5: 0.9283
2022-01-19 03:33:14,199 Val Step[0100/1563], Avg Loss: 1.1502, Avg Acc@1: 0.7488, Avg Acc@5: 0.9245
2022-01-19 03:33:16,070 Val Step[0150/1563], Avg Loss: 1.1560, Avg Acc@1: 0.7465, Avg Acc@5: 0.9230
2022-01-19 03:33:17,913 Val Step[0200/1563], Avg Loss: 1.1580, Avg Acc@1: 0.7447, Avg Acc@5: 0.9235
2022-01-19 03:33:19,816 Val Step[0250/1563], Avg Loss: 1.1440, Avg Acc@1: 0.7466, Avg Acc@5: 0.9253
2022-01-19 03:33:21,673 Val Step[0300/1563], Avg Loss: 1.1480, Avg Acc@1: 0.7456, Avg Acc@5: 0.9239
2022-01-19 03:33:23,579 Val Step[0350/1563], Avg Loss: 1.1572, Avg Acc@1: 0.7430, Avg Acc@5: 0.9232
2022-01-19 03:33:25,525 Val Step[0400/1563], Avg Loss: 1.1590, Avg Acc@1: 0.7427, Avg Acc@5: 0.9222
2022-01-19 03:33:27,431 Val Step[0450/1563], Avg Loss: 1.1652, Avg Acc@1: 0.7404, Avg Acc@5: 0.9217
2022-01-19 03:33:29,329 Val Step[0500/1563], Avg Loss: 1.1685, Avg Acc@1: 0.7388, Avg Acc@5: 0.9208
2022-01-19 03:33:31,202 Val Step[0550/1563], Avg Loss: 1.1696, Avg Acc@1: 0.7377, Avg Acc@5: 0.9208
2022-01-19 03:33:32,988 Val Step[0600/1563], Avg Loss: 1.1687, Avg Acc@1: 0.7380, Avg Acc@5: 0.9207
2022-01-19 03:33:34,788 Val Step[0650/1563], Avg Loss: 1.1695, Avg Acc@1: 0.7376, Avg Acc@5: 0.9205
2022-01-19 03:33:36,614 Val Step[0700/1563], Avg Loss: 1.1672, Avg Acc@1: 0.7385, Avg Acc@5: 0.9213
2022-01-19 03:33:38,385 Val Step[0750/1563], Avg Loss: 1.1737, Avg Acc@1: 0.7368, Avg Acc@5: 0.9205
2022-01-19 03:33:40,174 Val Step[0800/1563], Avg Loss: 1.1746, Avg Acc@1: 0.7372, Avg Acc@5: 0.9204
2022-01-19 03:33:42,004 Val Step[0850/1563], Avg Loss: 1.1766, Avg Acc@1: 0.7365, Avg Acc@5: 0.9201
2022-01-19 03:33:43,910 Val Step[0900/1563], Avg Loss: 1.1727, Avg Acc@1: 0.7368, Avg Acc@5: 0.9204
2022-01-19 03:33:45,798 Val Step[0950/1563], Avg Loss: 1.1711, Avg Acc@1: 0.7378, Avg Acc@5: 0.9209
2022-01-19 03:33:47,752 Val Step[1000/1563], Avg Loss: 1.1726, Avg Acc@1: 0.7375, Avg Acc@5: 0.9205
2022-01-19 03:33:49,726 Val Step[1050/1563], Avg Loss: 1.1734, Avg Acc@1: 0.7369, Avg Acc@5: 0.9202
2022-01-19 03:33:51,766 Val Step[1100/1563], Avg Loss: 1.1748, Avg Acc@1: 0.7365, Avg Acc@5: 0.9202
2022-01-19 03:33:53,795 Val Step[1150/1563], Avg Loss: 1.1735, Avg Acc@1: 0.7369, Avg Acc@5: 0.9203
2022-01-19 03:33:55,998 Val Step[1200/1563], Avg Loss: 1.1724, Avg Acc@1: 0.7375, Avg Acc@5: 0.9204
2022-01-19 03:33:58,085 Val Step[1250/1563], Avg Loss: 1.1718, Avg Acc@1: 0.7376, Avg Acc@5: 0.9203
2022-01-19 03:34:00,165 Val Step[1300/1563], Avg Loss: 1.1746, Avg Acc@1: 0.7373, Avg Acc@5: 0.9200
2022-01-19 03:34:02,231 Val Step[1350/1563], Avg Loss: 1.1757, Avg Acc@1: 0.7372, Avg Acc@5: 0.9194
2022-01-19 03:34:04,327 Val Step[1400/1563], Avg Loss: 1.1755, Avg Acc@1: 0.7371, Avg Acc@5: 0.9192
2022-01-19 03:34:06,434 Val Step[1450/1563], Avg Loss: 1.1748, Avg Acc@1: 0.7377, Avg Acc@5: 0.9192
2022-01-19 03:34:08,568 Val Step[1500/1563], Avg Loss: 1.1732, Avg Acc@1: 0.7381, Avg Acc@5: 0.9195
2022-01-19 03:34:10,601 Val Step[1550/1563], Avg Loss: 1.1736, Avg Acc@1: 0.7377, Avg Acc@5: 0.9195
2022-01-19 03:34:12,493 ----- Epoch[182/300], Validation Loss: 1.1736, Validation Acc@1: 0.7377, Validation Acc@5: 0.9195, time: 139.76
2022-01-19 03:34:13,628 the pre best model acc:0.7371, at epoch 180
2022-01-19 03:34:13,629 current best model acc:0.7377, at epoch 182
2022-01-19 03:34:13,629 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 03:34:13,629 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 03:34:13,629 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 03:34:13,629 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 03:34:13,629 Now training epoch 183. LR=0.000379
2022-01-19 03:36:00,439 Epoch[183/300], Step[0000/1252], Avg Loss: 3.0276, Avg Acc: 0.5771
2022-01-19 03:37:29,246 Epoch[183/300], Step[0050/1252], Avg Loss: 3.2506, Avg Acc: 0.4174
2022-01-19 03:38:57,037 Epoch[183/300], Step[0100/1252], Avg Loss: 3.2851, Avg Acc: 0.4152
2022-01-19 03:40:25,900 Epoch[183/300], Step[0150/1252], Avg Loss: 3.2696, Avg Acc: 0.4188
2022-01-19 03:41:54,637 Epoch[183/300], Step[0200/1252], Avg Loss: 3.2812, Avg Acc: 0.4203
2022-01-19 03:43:24,460 Epoch[183/300], Step[0250/1252], Avg Loss: 3.2815, Avg Acc: 0.4183
2022-01-19 03:44:53,061 Epoch[183/300], Step[0300/1252], Avg Loss: 3.2935, Avg Acc: 0.4195
2022-01-19 03:46:22,733 Epoch[183/300], Step[0350/1252], Avg Loss: 3.2894, Avg Acc: 0.4189
2022-01-19 03:47:51,630 Epoch[183/300], Step[0400/1252], Avg Loss: 3.2853, Avg Acc: 0.4195
2022-01-19 03:49:21,229 Epoch[183/300], Step[0450/1252], Avg Loss: 3.2872, Avg Acc: 0.4192
2022-01-19 03:50:50,342 Epoch[183/300], Step[0500/1252], Avg Loss: 3.2937, Avg Acc: 0.4218
2022-01-19 03:52:18,353 Epoch[183/300], Step[0550/1252], Avg Loss: 3.2963, Avg Acc: 0.4241
2022-01-19 03:53:47,545 Epoch[183/300], Step[0600/1252], Avg Loss: 3.2939, Avg Acc: 0.4219
2022-01-19 03:55:16,834 Epoch[183/300], Step[0650/1252], Avg Loss: 3.2963, Avg Acc: 0.4208
2022-01-19 03:56:45,750 Epoch[183/300], Step[0700/1252], Avg Loss: 3.2951, Avg Acc: 0.4230
2022-01-19 03:58:13,704 Epoch[183/300], Step[0750/1252], Avg Loss: 3.2936, Avg Acc: 0.4242
2022-01-19 03:59:41,417 Epoch[183/300], Step[0800/1252], Avg Loss: 3.2955, Avg Acc: 0.4242
2022-01-19 04:01:09,067 Epoch[183/300], Step[0850/1252], Avg Loss: 3.2944, Avg Acc: 0.4254
2022-01-19 04:02:37,975 Epoch[183/300], Step[0900/1252], Avg Loss: 3.2908, Avg Acc: 0.4269
2022-01-19 04:04:06,968 Epoch[183/300], Step[0950/1252], Avg Loss: 3.2911, Avg Acc: 0.4263
2022-01-19 04:05:36,620 Epoch[183/300], Step[1000/1252], Avg Loss: 3.2919, Avg Acc: 0.4256
2022-01-19 04:07:05,986 Epoch[183/300], Step[1050/1252], Avg Loss: 3.2939, Avg Acc: 0.4238
2022-01-19 04:08:34,561 Epoch[183/300], Step[1100/1252], Avg Loss: 3.2967, Avg Acc: 0.4221
2022-01-19 04:10:03,045 Epoch[183/300], Step[1150/1252], Avg Loss: 3.3005, Avg Acc: 0.4216
2022-01-19 04:11:32,692 Epoch[183/300], Step[1200/1252], Avg Loss: 3.3019, Avg Acc: 0.4216
2022-01-19 04:13:01,900 Epoch[183/300], Step[1250/1252], Avg Loss: 3.3036, Avg Acc: 0.4211
2022-01-19 04:13:08,902 ----- Epoch[183/300], Train Loss: 3.3036, Train Acc: 0.4210, time: 2335.27, Best Val(epoch182) Acc@1: 0.7377
2022-01-19 04:13:08,902 Now training epoch 184. LR=0.000373
2022-01-19 04:14:57,704 Epoch[184/300], Step[0000/1252], Avg Loss: 2.7337, Avg Acc: 0.1328
2022-01-19 04:16:26,741 Epoch[184/300], Step[0050/1252], Avg Loss: 3.3050, Avg Acc: 0.4296
2022-01-19 04:17:55,288 Epoch[184/300], Step[0100/1252], Avg Loss: 3.2908, Avg Acc: 0.4161
2022-01-19 04:19:23,665 Epoch[184/300], Step[0150/1252], Avg Loss: 3.2787, Avg Acc: 0.4304
2022-01-19 04:20:51,276 Epoch[184/300], Step[0200/1252], Avg Loss: 3.2693, Avg Acc: 0.4317
2022-01-19 04:22:19,792 Epoch[184/300], Step[0250/1252], Avg Loss: 3.2705, Avg Acc: 0.4207
2022-01-19 04:23:48,297 Epoch[184/300], Step[0300/1252], Avg Loss: 3.2825, Avg Acc: 0.4197
2022-01-19 04:25:16,139 Epoch[184/300], Step[0350/1252], Avg Loss: 3.2751, Avg Acc: 0.4255
2022-01-19 04:26:45,095 Epoch[184/300], Step[0400/1252], Avg Loss: 3.2744, Avg Acc: 0.4294
2022-01-19 04:28:14,208 Epoch[184/300], Step[0450/1252], Avg Loss: 3.2789, Avg Acc: 0.4279
2022-01-19 04:29:41,432 Epoch[184/300], Step[0500/1252], Avg Loss: 3.2839, Avg Acc: 0.4265
2022-01-19 04:31:09,728 Epoch[184/300], Step[0550/1252], Avg Loss: 3.2854, Avg Acc: 0.4273
2022-01-19 04:32:37,804 Epoch[184/300], Step[0600/1252], Avg Loss: 3.2841, Avg Acc: 0.4281
2022-01-19 04:34:06,150 Epoch[184/300], Step[0650/1252], Avg Loss: 3.2822, Avg Acc: 0.4269
2022-01-19 04:35:34,879 Epoch[184/300], Step[0700/1252], Avg Loss: 3.2845, Avg Acc: 0.4278
2022-01-19 04:37:04,088 Epoch[184/300], Step[0750/1252], Avg Loss: 3.2825, Avg Acc: 0.4279
2022-01-19 04:38:31,986 Epoch[184/300], Step[0800/1252], Avg Loss: 3.2821, Avg Acc: 0.4258
2022-01-19 04:40:00,196 Epoch[184/300], Step[0850/1252], Avg Loss: 3.2823, Avg Acc: 0.4262
2022-01-19 04:41:28,033 Epoch[184/300], Step[0900/1252], Avg Loss: 3.2857, Avg Acc: 0.4234
2022-01-19 04:42:56,059 Epoch[184/300], Step[0950/1252], Avg Loss: 3.2880, Avg Acc: 0.4233
2022-01-19 04:44:24,503 Epoch[184/300], Step[1000/1252], Avg Loss: 3.2855, Avg Acc: 0.4234
2022-01-19 04:45:52,845 Epoch[184/300], Step[1050/1252], Avg Loss: 3.2882, Avg Acc: 0.4213
2022-01-19 04:47:22,338 Epoch[184/300], Step[1100/1252], Avg Loss: 3.2867, Avg Acc: 0.4240
2022-01-19 04:48:49,056 Epoch[184/300], Step[1150/1252], Avg Loss: 3.2877, Avg Acc: 0.4252
2022-01-19 04:50:17,362 Epoch[184/300], Step[1200/1252], Avg Loss: 3.2908, Avg Acc: 0.4239
2022-01-19 04:51:45,621 Epoch[184/300], Step[1250/1252], Avg Loss: 3.2939, Avg Acc: 0.4241
2022-01-19 04:51:52,581 ----- Epoch[184/300], Train Loss: 3.2940, Train Acc: 0.4241, time: 2323.67, Best Val(epoch182) Acc@1: 0.7377
2022-01-19 04:51:52,581 ----- Validation after Epoch: 184
2022-01-19 04:53:10,581 Val Step[0000/1563], Avg Loss: 1.0299, Avg Acc@1: 0.7812, Avg Acc@5: 0.9375
2022-01-19 04:53:12,410 Val Step[0050/1563], Avg Loss: 1.1584, Avg Acc@1: 0.7457, Avg Acc@5: 0.9161
2022-01-19 04:53:14,213 Val Step[0100/1563], Avg Loss: 1.1608, Avg Acc@1: 0.7429, Avg Acc@5: 0.9196
2022-01-19 04:53:16,210 Val Step[0150/1563], Avg Loss: 1.1640, Avg Acc@1: 0.7475, Avg Acc@5: 0.9193
2022-01-19 04:53:18,103 Val Step[0200/1563], Avg Loss: 1.1690, Avg Acc@1: 0.7447, Avg Acc@5: 0.9190
2022-01-19 04:53:19,981 Val Step[0250/1563], Avg Loss: 1.1603, Avg Acc@1: 0.7459, Avg Acc@5: 0.9194
2022-01-19 04:53:21,919 Val Step[0300/1563], Avg Loss: 1.1602, Avg Acc@1: 0.7457, Avg Acc@5: 0.9199
2022-01-19 04:53:23,782 Val Step[0350/1563], Avg Loss: 1.1669, Avg Acc@1: 0.7444, Avg Acc@5: 0.9196
2022-01-19 04:53:25,680 Val Step[0400/1563], Avg Loss: 1.1656, Avg Acc@1: 0.7445, Avg Acc@5: 0.9200
2022-01-19 04:53:27,539 Val Step[0450/1563], Avg Loss: 1.1706, Avg Acc@1: 0.7429, Avg Acc@5: 0.9202
2022-01-19 04:53:29,390 Val Step[0500/1563], Avg Loss: 1.1721, Avg Acc@1: 0.7422, Avg Acc@5: 0.9207
2022-01-19 04:53:31,202 Val Step[0550/1563], Avg Loss: 1.1744, Avg Acc@1: 0.7410, Avg Acc@5: 0.9210
2022-01-19 04:53:33,090 Val Step[0600/1563], Avg Loss: 1.1736, Avg Acc@1: 0.7410, Avg Acc@5: 0.9213
2022-01-19 04:53:34,981 Val Step[0650/1563], Avg Loss: 1.1761, Avg Acc@1: 0.7402, Avg Acc@5: 0.9214
2022-01-19 04:53:36,795 Val Step[0700/1563], Avg Loss: 1.1748, Avg Acc@1: 0.7407, Avg Acc@5: 0.9221
2022-01-19 04:53:38,644 Val Step[0750/1563], Avg Loss: 1.1809, Avg Acc@1: 0.7386, Avg Acc@5: 0.9214
2022-01-19 04:53:40,476 Val Step[0800/1563], Avg Loss: 1.1807, Avg Acc@1: 0.7398, Avg Acc@5: 0.9216
2022-01-19 04:53:42,330 Val Step[0850/1563], Avg Loss: 1.1835, Avg Acc@1: 0.7388, Avg Acc@5: 0.9209
2022-01-19 04:53:44,126 Val Step[0900/1563], Avg Loss: 1.1808, Avg Acc@1: 0.7393, Avg Acc@5: 0.9209
2022-01-19 04:53:45,934 Val Step[0950/1563], Avg Loss: 1.1796, Avg Acc@1: 0.7399, Avg Acc@5: 0.9210
2022-01-19 04:53:47,728 Val Step[1000/1563], Avg Loss: 1.1812, Avg Acc@1: 0.7395, Avg Acc@5: 0.9208
2022-01-19 04:53:49,526 Val Step[1050/1563], Avg Loss: 1.1819, Avg Acc@1: 0.7391, Avg Acc@5: 0.9206
2022-01-19 04:53:51,321 Val Step[1100/1563], Avg Loss: 1.1832, Avg Acc@1: 0.7388, Avg Acc@5: 0.9204
2022-01-19 04:53:53,158 Val Step[1150/1563], Avg Loss: 1.1819, Avg Acc@1: 0.7389, Avg Acc@5: 0.9210
2022-01-19 04:53:55,011 Val Step[1200/1563], Avg Loss: 1.1815, Avg Acc@1: 0.7393, Avg Acc@5: 0.9209
2022-01-19 04:53:56,867 Val Step[1250/1563], Avg Loss: 1.1814, Avg Acc@1: 0.7391, Avg Acc@5: 0.9210
2022-01-19 04:53:58,696 Val Step[1300/1563], Avg Loss: 1.1828, Avg Acc@1: 0.7391, Avg Acc@5: 0.9210
2022-01-19 04:54:00,507 Val Step[1350/1563], Avg Loss: 1.1837, Avg Acc@1: 0.7390, Avg Acc@5: 0.9207
2022-01-19 04:54:02,375 Val Step[1400/1563], Avg Loss: 1.1831, Avg Acc@1: 0.7388, Avg Acc@5: 0.9206
2022-01-19 04:54:04,311 Val Step[1450/1563], Avg Loss: 1.1837, Avg Acc@1: 0.7386, Avg Acc@5: 0.9203
2022-01-19 04:54:06,140 Val Step[1500/1563], Avg Loss: 1.1832, Avg Acc@1: 0.7388, Avg Acc@5: 0.9207
2022-01-19 04:54:07,901 Val Step[1550/1563], Avg Loss: 1.1840, Avg Acc@1: 0.7387, Avg Acc@5: 0.9206
2022-01-19 04:54:09,886 ----- Epoch[184/300], Validation Loss: 1.1839, Validation Acc@1: 0.7387, Validation Acc@5: 0.9207, time: 137.30
2022-01-19 04:54:11,028 the pre best model acc:0.7377, at epoch 182
2022-01-19 04:54:11,028 current best model acc:0.7387, at epoch 184
2022-01-19 04:54:11,028 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 04:54:11,029 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 04:54:11,029 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 04:54:11,029 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 04:54:11,029 Now training epoch 185. LR=0.000368
2022-01-19 04:55:57,235 Epoch[185/300], Step[0000/1252], Avg Loss: 3.4190, Avg Acc: 0.3984
2022-01-19 04:57:23,693 Epoch[185/300], Step[0050/1252], Avg Loss: 3.2669, Avg Acc: 0.4158
2022-01-19 04:58:50,222 Epoch[185/300], Step[0100/1252], Avg Loss: 3.3065, Avg Acc: 0.4138
2022-01-19 05:00:18,707 Epoch[185/300], Step[0150/1252], Avg Loss: 3.3194, Avg Acc: 0.4178
2022-01-19 05:01:44,514 Epoch[185/300], Step[0200/1252], Avg Loss: 3.3184, Avg Acc: 0.4205
2022-01-19 05:03:11,837 Epoch[185/300], Step[0250/1252], Avg Loss: 3.3196, Avg Acc: 0.4181
2022-01-19 05:04:40,537 Epoch[185/300], Step[0300/1252], Avg Loss: 3.3123, Avg Acc: 0.4184
2022-01-19 05:06:08,331 Epoch[185/300], Step[0350/1252], Avg Loss: 3.3118, Avg Acc: 0.4191
2022-01-19 05:07:36,485 Epoch[185/300], Step[0400/1252], Avg Loss: 3.3154, Avg Acc: 0.4221
2022-01-19 05:09:05,167 Epoch[185/300], Step[0450/1252], Avg Loss: 3.3188, Avg Acc: 0.4241
2022-01-19 05:10:34,507 Epoch[185/300], Step[0500/1252], Avg Loss: 3.3129, Avg Acc: 0.4221
2022-01-19 05:12:03,101 Epoch[185/300], Step[0550/1252], Avg Loss: 3.3044, Avg Acc: 0.4235
2022-01-19 05:13:30,959 Epoch[185/300], Step[0600/1252], Avg Loss: 3.3024, Avg Acc: 0.4233
2022-01-19 05:14:59,463 Epoch[185/300], Step[0650/1252], Avg Loss: 3.3006, Avg Acc: 0.4226
2022-01-19 05:16:26,742 Epoch[185/300], Step[0700/1252], Avg Loss: 3.3007, Avg Acc: 0.4205
2022-01-19 05:17:54,637 Epoch[185/300], Step[0750/1252], Avg Loss: 3.3002, Avg Acc: 0.4201
2022-01-19 05:19:20,825 Epoch[185/300], Step[0800/1252], Avg Loss: 3.3063, Avg Acc: 0.4198
2022-01-19 05:20:47,935 Epoch[185/300], Step[0850/1252], Avg Loss: 3.3102, Avg Acc: 0.4190
2022-01-19 05:22:15,280 Epoch[185/300], Step[0900/1252], Avg Loss: 3.3088, Avg Acc: 0.4196
2022-01-19 05:23:43,074 Epoch[185/300], Step[0950/1252], Avg Loss: 3.3073, Avg Acc: 0.4196
2022-01-19 05:25:10,399 Epoch[185/300], Step[1000/1252], Avg Loss: 3.3060, Avg Acc: 0.4200
2022-01-19 05:26:37,503 Epoch[185/300], Step[1050/1252], Avg Loss: 3.3048, Avg Acc: 0.4201
2022-01-19 05:28:04,410 Epoch[185/300], Step[1100/1252], Avg Loss: 3.3086, Avg Acc: 0.4192
2022-01-19 05:29:30,916 Epoch[185/300], Step[1150/1252], Avg Loss: 3.3102, Avg Acc: 0.4201
2022-01-19 05:30:58,290 Epoch[185/300], Step[1200/1252], Avg Loss: 3.3096, Avg Acc: 0.4198
2022-01-19 05:32:25,180 Epoch[185/300], Step[1250/1252], Avg Loss: 3.3119, Avg Acc: 0.4200
2022-01-19 05:32:32,131 ----- Epoch[185/300], Train Loss: 3.3118, Train Acc: 0.4199, time: 2301.10, Best Val(epoch184) Acc@1: 0.7387
2022-01-19 05:32:32,131 Now training epoch 186. LR=0.000363
2022-01-19 05:34:23,966 Epoch[186/300], Step[0000/1252], Avg Loss: 3.7867, Avg Acc: 0.4404
2022-01-19 05:35:51,103 Epoch[186/300], Step[0050/1252], Avg Loss: 3.3129, Avg Acc: 0.4325
2022-01-19 05:37:17,026 Epoch[186/300], Step[0100/1252], Avg Loss: 3.2826, Avg Acc: 0.4339
2022-01-19 05:38:44,409 Epoch[186/300], Step[0150/1252], Avg Loss: 3.2847, Avg Acc: 0.4212
2022-01-19 05:40:13,162 Epoch[186/300], Step[0200/1252], Avg Loss: 3.2814, Avg Acc: 0.4194
2022-01-19 05:41:40,884 Epoch[186/300], Step[0250/1252], Avg Loss: 3.2695, Avg Acc: 0.4217
2022-01-19 05:43:09,841 Epoch[186/300], Step[0300/1252], Avg Loss: 3.2712, Avg Acc: 0.4227
2022-01-19 05:44:38,639 Epoch[186/300], Step[0350/1252], Avg Loss: 3.2690, Avg Acc: 0.4249
2022-01-19 05:46:07,163 Epoch[186/300], Step[0400/1252], Avg Loss: 3.2814, Avg Acc: 0.4229
2022-01-19 05:47:35,657 Epoch[186/300], Step[0450/1252], Avg Loss: 3.2866, Avg Acc: 0.4208
2022-01-19 05:49:05,242 Epoch[186/300], Step[0500/1252], Avg Loss: 3.2904, Avg Acc: 0.4171
2022-01-19 05:50:32,916 Epoch[186/300], Step[0550/1252], Avg Loss: 3.2907, Avg Acc: 0.4190
2022-01-19 05:52:01,903 Epoch[186/300], Step[0600/1252], Avg Loss: 3.2924, Avg Acc: 0.4174
2022-01-19 05:53:30,880 Epoch[186/300], Step[0650/1252], Avg Loss: 3.2910, Avg Acc: 0.4161
2022-01-19 05:54:59,256 Epoch[186/300], Step[0700/1252], Avg Loss: 3.2899, Avg Acc: 0.4172
2022-01-19 05:56:28,384 Epoch[186/300], Step[0750/1252], Avg Loss: 3.2887, Avg Acc: 0.4185
2022-01-19 05:57:55,908 Epoch[186/300], Step[0800/1252], Avg Loss: 3.2914, Avg Acc: 0.4198
2022-01-19 05:59:24,942 Epoch[186/300], Step[0850/1252], Avg Loss: 3.2931, Avg Acc: 0.4192
2022-01-19 06:00:53,654 Epoch[186/300], Step[0900/1252], Avg Loss: 3.2977, Avg Acc: 0.4190
2022-01-19 06:02:22,708 Epoch[186/300], Step[0950/1252], Avg Loss: 3.2972, Avg Acc: 0.4173
2022-01-19 06:03:51,492 Epoch[186/300], Step[1000/1252], Avg Loss: 3.2991, Avg Acc: 0.4163
2022-01-19 06:05:21,400 Epoch[186/300], Step[1050/1252], Avg Loss: 3.3002, Avg Acc: 0.4161
2022-01-19 06:06:51,256 Epoch[186/300], Step[1100/1252], Avg Loss: 3.3016, Avg Acc: 0.4162
2022-01-19 06:08:20,324 Epoch[186/300], Step[1150/1252], Avg Loss: 3.3008, Avg Acc: 0.4171
2022-01-19 06:09:48,548 Epoch[186/300], Step[1200/1252], Avg Loss: 3.2979, Avg Acc: 0.4185
2022-01-19 06:11:16,966 Epoch[186/300], Step[1250/1252], Avg Loss: 3.2977, Avg Acc: 0.4195
2022-01-19 06:11:24,094 ----- Epoch[186/300], Train Loss: 3.2977, Train Acc: 0.4195, time: 2331.96, Best Val(epoch184) Acc@1: 0.7387
2022-01-19 06:11:24,094 ----- Validation after Epoch: 186
2022-01-19 06:12:45,634 Val Step[0000/1563], Avg Loss: 0.8424, Avg Acc@1: 0.7812, Avg Acc@5: 0.9375
2022-01-19 06:12:47,565 Val Step[0050/1563], Avg Loss: 1.1282, Avg Acc@1: 0.7414, Avg Acc@5: 0.9161
2022-01-19 06:12:49,474 Val Step[0100/1563], Avg Loss: 1.1393, Avg Acc@1: 0.7410, Avg Acc@5: 0.9211
2022-01-19 06:12:51,285 Val Step[0150/1563], Avg Loss: 1.1490, Avg Acc@1: 0.7399, Avg Acc@5: 0.9212
2022-01-19 06:12:53,132 Val Step[0200/1563], Avg Loss: 1.1508, Avg Acc@1: 0.7397, Avg Acc@5: 0.9206
2022-01-19 06:12:55,088 Val Step[0250/1563], Avg Loss: 1.1391, Avg Acc@1: 0.7407, Avg Acc@5: 0.9207
2022-01-19 06:12:56,945 Val Step[0300/1563], Avg Loss: 1.1445, Avg Acc@1: 0.7415, Avg Acc@5: 0.9190
2022-01-19 06:12:58,786 Val Step[0350/1563], Avg Loss: 1.1517, Avg Acc@1: 0.7400, Avg Acc@5: 0.9188
2022-01-19 06:13:00,588 Val Step[0400/1563], Avg Loss: 1.1500, Avg Acc@1: 0.7395, Avg Acc@5: 0.9197
2022-01-19 06:13:02,373 Val Step[0450/1563], Avg Loss: 1.1544, Avg Acc@1: 0.7373, Avg Acc@5: 0.9196
2022-01-19 06:13:04,141 Val Step[0500/1563], Avg Loss: 1.1567, Avg Acc@1: 0.7358, Avg Acc@5: 0.9200
2022-01-19 06:13:05,983 Val Step[0550/1563], Avg Loss: 1.1553, Avg Acc@1: 0.7355, Avg Acc@5: 0.9203
2022-01-19 06:13:07,813 Val Step[0600/1563], Avg Loss: 1.1551, Avg Acc@1: 0.7358, Avg Acc@5: 0.9208
2022-01-19 06:13:09,627 Val Step[0650/1563], Avg Loss: 1.1530, Avg Acc@1: 0.7369, Avg Acc@5: 0.9208
2022-01-19 06:13:11,502 Val Step[0700/1563], Avg Loss: 1.1506, Avg Acc@1: 0.7377, Avg Acc@5: 0.9217
2022-01-19 06:13:13,452 Val Step[0750/1563], Avg Loss: 1.1572, Avg Acc@1: 0.7361, Avg Acc@5: 0.9209
2022-01-19 06:13:15,337 Val Step[0800/1563], Avg Loss: 1.1566, Avg Acc@1: 0.7368, Avg Acc@5: 0.9211
2022-01-19 06:13:17,246 Val Step[0850/1563], Avg Loss: 1.1586, Avg Acc@1: 0.7363, Avg Acc@5: 0.9202
2022-01-19 06:13:19,189 Val Step[0900/1563], Avg Loss: 1.1545, Avg Acc@1: 0.7367, Avg Acc@5: 0.9204
2022-01-19 06:13:21,017 Val Step[0950/1563], Avg Loss: 1.1542, Avg Acc@1: 0.7374, Avg Acc@5: 0.9205
2022-01-19 06:13:22,845 Val Step[1000/1563], Avg Loss: 1.1555, Avg Acc@1: 0.7370, Avg Acc@5: 0.9203
2022-01-19 06:13:24,752 Val Step[1050/1563], Avg Loss: 1.1571, Avg Acc@1: 0.7366, Avg Acc@5: 0.9201
2022-01-19 06:13:26,599 Val Step[1100/1563], Avg Loss: 1.1569, Avg Acc@1: 0.7368, Avg Acc@5: 0.9198
2022-01-19 06:13:28,504 Val Step[1150/1563], Avg Loss: 1.1555, Avg Acc@1: 0.7368, Avg Acc@5: 0.9199
2022-01-19 06:13:30,428 Val Step[1200/1563], Avg Loss: 1.1545, Avg Acc@1: 0.7372, Avg Acc@5: 0.9199
2022-01-19 06:13:32,456 Val Step[1250/1563], Avg Loss: 1.1531, Avg Acc@1: 0.7375, Avg Acc@5: 0.9203
2022-01-19 06:13:34,401 Val Step[1300/1563], Avg Loss: 1.1558, Avg Acc@1: 0.7371, Avg Acc@5: 0.9200
2022-01-19 06:13:36,291 Val Step[1350/1563], Avg Loss: 1.1567, Avg Acc@1: 0.7370, Avg Acc@5: 0.9199
2022-01-19 06:13:38,160 Val Step[1400/1563], Avg Loss: 1.1567, Avg Acc@1: 0.7370, Avg Acc@5: 0.9197
2022-01-19 06:13:40,000 Val Step[1450/1563], Avg Loss: 1.1563, Avg Acc@1: 0.7372, Avg Acc@5: 0.9195
2022-01-19 06:13:41,853 Val Step[1500/1563], Avg Loss: 1.1561, Avg Acc@1: 0.7374, Avg Acc@5: 0.9198
2022-01-19 06:13:43,686 Val Step[1550/1563], Avg Loss: 1.1564, Avg Acc@1: 0.7372, Avg Acc@5: 0.9198
2022-01-19 06:13:45,626 ----- Epoch[186/300], Validation Loss: 1.1563, Validation Acc@1: 0.7373, Validation Acc@5: 0.9199, time: 141.53
2022-01-19 06:13:45,626 Now training epoch 187. LR=0.000357
2022-01-19 06:15:34,044 Epoch[187/300], Step[0000/1252], Avg Loss: 3.7870, Avg Acc: 0.3906
2022-01-19 06:17:02,419 Epoch[187/300], Step[0050/1252], Avg Loss: 3.3290, Avg Acc: 0.4393
2022-01-19 06:18:29,947 Epoch[187/300], Step[0100/1252], Avg Loss: 3.3131, Avg Acc: 0.4443
2022-01-19 06:19:57,488 Epoch[187/300], Step[0150/1252], Avg Loss: 3.3033, Avg Acc: 0.4371
2022-01-19 06:21:23,734 Epoch[187/300], Step[0200/1252], Avg Loss: 3.2933, Avg Acc: 0.4286
2022-01-19 06:22:50,856 Epoch[187/300], Step[0250/1252], Avg Loss: 3.2926, Avg Acc: 0.4288
2022-01-19 06:24:17,428 Epoch[187/300], Step[0300/1252], Avg Loss: 3.3004, Avg Acc: 0.4288
2022-01-19 06:25:43,942 Epoch[187/300], Step[0350/1252], Avg Loss: 3.2922, Avg Acc: 0.4289
2022-01-19 06:27:09,930 Epoch[187/300], Step[0400/1252], Avg Loss: 3.2913, Avg Acc: 0.4267
2022-01-19 06:28:37,738 Epoch[187/300], Step[0450/1252], Avg Loss: 3.2852, Avg Acc: 0.4270
2022-01-19 06:30:04,812 Epoch[187/300], Step[0500/1252], Avg Loss: 3.2928, Avg Acc: 0.4255
2022-01-19 06:31:31,719 Epoch[187/300], Step[0550/1252], Avg Loss: 3.2931, Avg Acc: 0.4251
2022-01-19 06:32:58,774 Epoch[187/300], Step[0600/1252], Avg Loss: 3.2933, Avg Acc: 0.4235
2022-01-19 06:34:25,466 Epoch[187/300], Step[0650/1252], Avg Loss: 3.2959, Avg Acc: 0.4226
2022-01-19 06:35:51,345 Epoch[187/300], Step[0700/1252], Avg Loss: 3.2961, Avg Acc: 0.4245
2022-01-19 06:37:18,433 Epoch[187/300], Step[0750/1252], Avg Loss: 3.2982, Avg Acc: 0.4222
2022-01-19 06:38:46,281 Epoch[187/300], Step[0800/1252], Avg Loss: 3.3009, Avg Acc: 0.4196
2022-01-19 06:40:13,196 Epoch[187/300], Step[0850/1252], Avg Loss: 3.2991, Avg Acc: 0.4214
2022-01-19 06:41:40,565 Epoch[187/300], Step[0900/1252], Avg Loss: 3.2968, Avg Acc: 0.4225
2022-01-19 06:43:07,176 Epoch[187/300], Step[0950/1252], Avg Loss: 3.2987, Avg Acc: 0.4228
2022-01-19 06:44:34,104 Epoch[187/300], Step[1000/1252], Avg Loss: 3.2997, Avg Acc: 0.4232
2022-01-19 06:46:03,281 Epoch[187/300], Step[1050/1252], Avg Loss: 3.2992, Avg Acc: 0.4228
2022-01-19 06:47:32,476 Epoch[187/300], Step[1100/1252], Avg Loss: 3.2989, Avg Acc: 0.4236
2022-01-19 06:49:01,587 Epoch[187/300], Step[1150/1252], Avg Loss: 3.2968, Avg Acc: 0.4244
2022-01-19 06:50:27,706 Epoch[187/300], Step[1200/1252], Avg Loss: 3.2987, Avg Acc: 0.4245
2022-01-19 06:51:56,716 Epoch[187/300], Step[1250/1252], Avg Loss: 3.2965, Avg Acc: 0.4247
2022-01-19 06:52:03,741 ----- Epoch[187/300], Train Loss: 3.2965, Train Acc: 0.4247, time: 2298.11, Best Val(epoch184) Acc@1: 0.7387
2022-01-19 06:52:03,742 Now training epoch 188. LR=0.000352
2022-01-19 06:53:50,438 Epoch[188/300], Step[0000/1252], Avg Loss: 3.5731, Avg Acc: 0.4414
2022-01-19 06:55:18,509 Epoch[188/300], Step[0050/1252], Avg Loss: 3.3265, Avg Acc: 0.4206
2022-01-19 06:56:45,163 Epoch[188/300], Step[0100/1252], Avg Loss: 3.3020, Avg Acc: 0.4119
2022-01-19 06:58:12,996 Epoch[188/300], Step[0150/1252], Avg Loss: 3.2915, Avg Acc: 0.4113
2022-01-19 06:59:42,672 Epoch[188/300], Step[0200/1252], Avg Loss: 3.2865, Avg Acc: 0.4195
2022-01-19 07:01:11,388 Epoch[188/300], Step[0250/1252], Avg Loss: 3.2790, Avg Acc: 0.4209
2022-01-19 07:02:40,205 Epoch[188/300], Step[0300/1252], Avg Loss: 3.2798, Avg Acc: 0.4198
2022-01-19 07:04:08,516 Epoch[188/300], Step[0350/1252], Avg Loss: 3.2762, Avg Acc: 0.4227
2022-01-19 07:05:37,146 Epoch[188/300], Step[0400/1252], Avg Loss: 3.2699, Avg Acc: 0.4234
2022-01-19 07:07:06,381 Epoch[188/300], Step[0450/1252], Avg Loss: 3.2705, Avg Acc: 0.4225
2022-01-19 07:08:35,125 Epoch[188/300], Step[0500/1252], Avg Loss: 3.2677, Avg Acc: 0.4244
2022-01-19 07:10:03,638 Epoch[188/300], Step[0550/1252], Avg Loss: 3.2711, Avg Acc: 0.4267
2022-01-19 07:11:31,731 Epoch[188/300], Step[0600/1252], Avg Loss: 3.2786, Avg Acc: 0.4262
2022-01-19 07:13:00,488 Epoch[188/300], Step[0650/1252], Avg Loss: 3.2744, Avg Acc: 0.4266
2022-01-19 07:14:29,339 Epoch[188/300], Step[0700/1252], Avg Loss: 3.2750, Avg Acc: 0.4252
2022-01-19 07:15:58,622 Epoch[188/300], Step[0750/1252], Avg Loss: 3.2763, Avg Acc: 0.4259
2022-01-19 07:17:25,383 Epoch[188/300], Step[0800/1252], Avg Loss: 3.2763, Avg Acc: 0.4258
2022-01-19 07:18:54,011 Epoch[188/300], Step[0850/1252], Avg Loss: 3.2731, Avg Acc: 0.4266
2022-01-19 07:20:23,238 Epoch[188/300], Step[0900/1252], Avg Loss: 3.2774, Avg Acc: 0.4260
2022-01-19 07:21:51,405 Epoch[188/300], Step[0950/1252], Avg Loss: 3.2797, Avg Acc: 0.4258
2022-01-19 07:23:20,578 Epoch[188/300], Step[1000/1252], Avg Loss: 3.2811, Avg Acc: 0.4262
2022-01-19 07:24:48,629 Epoch[188/300], Step[1050/1252], Avg Loss: 3.2818, Avg Acc: 0.4261
2022-01-19 07:26:16,711 Epoch[188/300], Step[1100/1252], Avg Loss: 3.2809, Avg Acc: 0.4253
2022-01-19 07:27:44,062 Epoch[188/300], Step[1150/1252], Avg Loss: 3.2834, Avg Acc: 0.4245
2022-01-19 07:29:13,189 Epoch[188/300], Step[1200/1252], Avg Loss: 3.2820, Avg Acc: 0.4262
2022-01-19 07:30:41,571 Epoch[188/300], Step[1250/1252], Avg Loss: 3.2810, Avg Acc: 0.4261
2022-01-19 07:30:48,729 ----- Epoch[188/300], Train Loss: 3.2809, Train Acc: 0.4261, time: 2324.98, Best Val(epoch184) Acc@1: 0.7387
2022-01-19 07:30:48,729 ----- Validation after Epoch: 188
2022-01-19 07:32:02,704 Val Step[0000/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7188, Avg Acc@5: 0.9688
2022-01-19 07:32:04,748 Val Step[0050/1563], Avg Loss: 1.1565, Avg Acc@1: 0.7463, Avg Acc@5: 0.9271
2022-01-19 07:32:06,850 Val Step[0100/1563], Avg Loss: 1.1761, Avg Acc@1: 0.7413, Avg Acc@5: 0.9242
2022-01-19 07:32:08,710 Val Step[0150/1563], Avg Loss: 1.1878, Avg Acc@1: 0.7417, Avg Acc@5: 0.9214
2022-01-19 07:32:10,587 Val Step[0200/1563], Avg Loss: 1.1835, Avg Acc@1: 0.7442, Avg Acc@5: 0.9235
2022-01-19 07:32:12,628 Val Step[0250/1563], Avg Loss: 1.1704, Avg Acc@1: 0.7475, Avg Acc@5: 0.9249
2022-01-19 07:32:14,693 Val Step[0300/1563], Avg Loss: 1.1744, Avg Acc@1: 0.7471, Avg Acc@5: 0.9234
2022-01-19 07:32:16,746 Val Step[0350/1563], Avg Loss: 1.1814, Avg Acc@1: 0.7443, Avg Acc@5: 0.9224
2022-01-19 07:32:18,801 Val Step[0400/1563], Avg Loss: 1.1784, Avg Acc@1: 0.7444, Avg Acc@5: 0.9214
2022-01-19 07:32:20,856 Val Step[0450/1563], Avg Loss: 1.1848, Avg Acc@1: 0.7415, Avg Acc@5: 0.9208
2022-01-19 07:32:22,669 Val Step[0500/1563], Avg Loss: 1.1872, Avg Acc@1: 0.7403, Avg Acc@5: 0.9205
2022-01-19 07:32:24,475 Val Step[0550/1563], Avg Loss: 1.1864, Avg Acc@1: 0.7396, Avg Acc@5: 0.9214
2022-01-19 07:32:26,282 Val Step[0600/1563], Avg Loss: 1.1872, Avg Acc@1: 0.7389, Avg Acc@5: 0.9218
2022-01-19 07:32:28,087 Val Step[0650/1563], Avg Loss: 1.1863, Avg Acc@1: 0.7395, Avg Acc@5: 0.9219
2022-01-19 07:32:29,922 Val Step[0700/1563], Avg Loss: 1.1833, Avg Acc@1: 0.7401, Avg Acc@5: 0.9226
2022-01-19 07:32:31,873 Val Step[0750/1563], Avg Loss: 1.1896, Avg Acc@1: 0.7388, Avg Acc@5: 0.9220
2022-01-19 07:32:33,808 Val Step[0800/1563], Avg Loss: 1.1906, Avg Acc@1: 0.7397, Avg Acc@5: 0.9218
2022-01-19 07:32:35,659 Val Step[0850/1563], Avg Loss: 1.1922, Avg Acc@1: 0.7391, Avg Acc@5: 0.9210
2022-01-19 07:32:37,597 Val Step[0900/1563], Avg Loss: 1.1885, Avg Acc@1: 0.7396, Avg Acc@5: 0.9210
2022-01-19 07:32:39,542 Val Step[0950/1563], Avg Loss: 1.1878, Avg Acc@1: 0.7404, Avg Acc@5: 0.9212
2022-01-19 07:32:41,588 Val Step[1000/1563], Avg Loss: 1.1885, Avg Acc@1: 0.7401, Avg Acc@5: 0.9208
2022-01-19 07:32:43,637 Val Step[1050/1563], Avg Loss: 1.1905, Avg Acc@1: 0.7392, Avg Acc@5: 0.9202
2022-01-19 07:32:45,685 Val Step[1100/1563], Avg Loss: 1.1917, Avg Acc@1: 0.7390, Avg Acc@5: 0.9200
2022-01-19 07:32:47,732 Val Step[1150/1563], Avg Loss: 1.1908, Avg Acc@1: 0.7389, Avg Acc@5: 0.9199
2022-01-19 07:32:49,855 Val Step[1200/1563], Avg Loss: 1.1901, Avg Acc@1: 0.7399, Avg Acc@5: 0.9199
2022-01-19 07:32:52,052 Val Step[1250/1563], Avg Loss: 1.1892, Avg Acc@1: 0.7396, Avg Acc@5: 0.9201
2022-01-19 07:32:54,127 Val Step[1300/1563], Avg Loss: 1.1912, Avg Acc@1: 0.7394, Avg Acc@5: 0.9199
2022-01-19 07:32:56,243 Val Step[1350/1563], Avg Loss: 1.1913, Avg Acc@1: 0.7392, Avg Acc@5: 0.9199
2022-01-19 07:32:58,333 Val Step[1400/1563], Avg Loss: 1.1904, Avg Acc@1: 0.7391, Avg Acc@5: 0.9201
2022-01-19 07:33:00,425 Val Step[1450/1563], Avg Loss: 1.1902, Avg Acc@1: 0.7395, Avg Acc@5: 0.9199
2022-01-19 07:33:02,536 Val Step[1500/1563], Avg Loss: 1.1900, Avg Acc@1: 0.7397, Avg Acc@5: 0.9202
2022-01-19 07:33:04,526 Val Step[1550/1563], Avg Loss: 1.1906, Avg Acc@1: 0.7392, Avg Acc@5: 0.9202
2022-01-19 07:33:06,539 ----- Epoch[188/300], Validation Loss: 1.1903, Validation Acc@1: 0.7393, Validation Acc@5: 0.9203, time: 137.81
2022-01-19 07:33:07,683 the pre best model acc:0.7387, at epoch 184
2022-01-19 07:33:07,684 current best model acc:0.7393, at epoch 188
2022-01-19 07:33:07,684 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 07:33:07,684 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 07:33:07,684 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 07:33:07,684 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 07:33:07,684 Now training epoch 189. LR=0.000347
2022-01-19 07:34:52,555 Epoch[189/300], Step[0000/1252], Avg Loss: 3.2380, Avg Acc: 0.3301
2022-01-19 07:36:19,645 Epoch[189/300], Step[0050/1252], Avg Loss: 3.2632, Avg Acc: 0.4519
2022-01-19 07:37:47,903 Epoch[189/300], Step[0100/1252], Avg Loss: 3.3302, Avg Acc: 0.4250
2022-01-19 07:39:17,030 Epoch[189/300], Step[0150/1252], Avg Loss: 3.3241, Avg Acc: 0.4205
2022-01-19 07:40:45,463 Epoch[189/300], Step[0200/1252], Avg Loss: 3.3211, Avg Acc: 0.4252
2022-01-19 07:42:15,112 Epoch[189/300], Step[0250/1252], Avg Loss: 3.3077, Avg Acc: 0.4180
2022-01-19 07:43:42,653 Epoch[189/300], Step[0300/1252], Avg Loss: 3.2989, Avg Acc: 0.4180
2022-01-19 07:45:11,846 Epoch[189/300], Step[0350/1252], Avg Loss: 3.2956, Avg Acc: 0.4181
2022-01-19 07:46:41,408 Epoch[189/300], Step[0400/1252], Avg Loss: 3.2932, Avg Acc: 0.4185
2022-01-19 07:48:10,366 Epoch[189/300], Step[0450/1252], Avg Loss: 3.2879, Avg Acc: 0.4178
2022-01-19 07:49:40,164 Epoch[189/300], Step[0500/1252], Avg Loss: 3.2851, Avg Acc: 0.4169
2022-01-19 07:51:08,796 Epoch[189/300], Step[0550/1252], Avg Loss: 3.2842, Avg Acc: 0.4179
2022-01-19 07:52:37,619 Epoch[189/300], Step[0600/1252], Avg Loss: 3.2780, Avg Acc: 0.4178
2022-01-19 07:54:06,041 Epoch[189/300], Step[0650/1252], Avg Loss: 3.2804, Avg Acc: 0.4178
2022-01-19 07:55:35,217 Epoch[189/300], Step[0700/1252], Avg Loss: 3.2755, Avg Acc: 0.4191
2022-01-19 07:57:04,237 Epoch[189/300], Step[0750/1252], Avg Loss: 3.2746, Avg Acc: 0.4178
2022-01-19 07:58:31,606 Epoch[189/300], Step[0800/1252], Avg Loss: 3.2767, Avg Acc: 0.4195
2022-01-19 07:59:58,964 Epoch[189/300], Step[0850/1252], Avg Loss: 3.2727, Avg Acc: 0.4208
2022-01-19 08:01:28,164 Epoch[189/300], Step[0900/1252], Avg Loss: 3.2723, Avg Acc: 0.4202
2022-01-19 08:02:57,197 Epoch[189/300], Step[0950/1252], Avg Loss: 3.2728, Avg Acc: 0.4213
2022-01-19 08:04:26,353 Epoch[189/300], Step[1000/1252], Avg Loss: 3.2732, Avg Acc: 0.4224
2022-01-19 08:05:55,896 Epoch[189/300], Step[1050/1252], Avg Loss: 3.2735, Avg Acc: 0.4221
2022-01-19 08:07:25,609 Epoch[189/300], Step[1100/1252], Avg Loss: 3.2735, Avg Acc: 0.4210
2022-01-19 08:08:53,796 Epoch[189/300], Step[1150/1252], Avg Loss: 3.2735, Avg Acc: 0.4208
2022-01-19 08:10:22,568 Epoch[189/300], Step[1200/1252], Avg Loss: 3.2737, Avg Acc: 0.4217
2022-01-19 08:11:51,201 Epoch[189/300], Step[1250/1252], Avg Loss: 3.2749, Avg Acc: 0.4209
2022-01-19 08:11:58,529 ----- Epoch[189/300], Train Loss: 3.2748, Train Acc: 0.4209, time: 2330.84, Best Val(epoch188) Acc@1: 0.7393
2022-01-19 08:11:58,529 Now training epoch 190. LR=0.000342
2022-01-19 08:13:44,304 Epoch[190/300], Step[0000/1252], Avg Loss: 3.4248, Avg Acc: 0.3389
2022-01-19 08:15:11,555 Epoch[190/300], Step[0050/1252], Avg Loss: 3.2458, Avg Acc: 0.4297
2022-01-19 08:16:39,676 Epoch[190/300], Step[0100/1252], Avg Loss: 3.2767, Avg Acc: 0.4235
2022-01-19 08:18:07,524 Epoch[190/300], Step[0150/1252], Avg Loss: 3.2661, Avg Acc: 0.4212
2022-01-19 08:19:35,175 Epoch[190/300], Step[0200/1252], Avg Loss: 3.2449, Avg Acc: 0.4264
2022-01-19 08:21:02,741 Epoch[190/300], Step[0250/1252], Avg Loss: 3.2581, Avg Acc: 0.4258
2022-01-19 08:22:29,759 Epoch[190/300], Step[0300/1252], Avg Loss: 3.2626, Avg Acc: 0.4276
2022-01-19 08:23:57,626 Epoch[190/300], Step[0350/1252], Avg Loss: 3.2614, Avg Acc: 0.4303
2022-01-19 08:25:26,145 Epoch[190/300], Step[0400/1252], Avg Loss: 3.2650, Avg Acc: 0.4279
2022-01-19 08:26:54,576 Epoch[190/300], Step[0450/1252], Avg Loss: 3.2676, Avg Acc: 0.4287
2022-01-19 08:28:24,206 Epoch[190/300], Step[0500/1252], Avg Loss: 3.2667, Avg Acc: 0.4276
2022-01-19 08:29:52,511 Epoch[190/300], Step[0550/1252], Avg Loss: 3.2629, Avg Acc: 0.4245
2022-01-19 08:31:20,869 Epoch[190/300], Step[0600/1252], Avg Loss: 3.2673, Avg Acc: 0.4232
2022-01-19 08:32:47,523 Epoch[190/300], Step[0650/1252], Avg Loss: 3.2682, Avg Acc: 0.4242
2022-01-19 08:34:16,775 Epoch[190/300], Step[0700/1252], Avg Loss: 3.2732, Avg Acc: 0.4222
2022-01-19 08:35:45,447 Epoch[190/300], Step[0750/1252], Avg Loss: 3.2728, Avg Acc: 0.4210
2022-01-19 08:37:14,797 Epoch[190/300], Step[0800/1252], Avg Loss: 3.2752, Avg Acc: 0.4210
2022-01-19 08:38:43,916 Epoch[190/300], Step[0850/1252], Avg Loss: 3.2760, Avg Acc: 0.4202
2022-01-19 08:40:12,208 Epoch[190/300], Step[0900/1252], Avg Loss: 3.2740, Avg Acc: 0.4212
2022-01-19 08:41:39,383 Epoch[190/300], Step[0950/1252], Avg Loss: 3.2747, Avg Acc: 0.4229
2022-01-19 08:43:08,930 Epoch[190/300], Step[1000/1252], Avg Loss: 3.2765, Avg Acc: 0.4225
2022-01-19 08:44:38,006 Epoch[190/300], Step[1050/1252], Avg Loss: 3.2736, Avg Acc: 0.4231
2022-01-19 08:46:07,691 Epoch[190/300], Step[1100/1252], Avg Loss: 3.2754, Avg Acc: 0.4226
2022-01-19 08:47:36,655 Epoch[190/300], Step[1150/1252], Avg Loss: 3.2756, Avg Acc: 0.4221
2022-01-19 08:49:04,493 Epoch[190/300], Step[1200/1252], Avg Loss: 3.2753, Avg Acc: 0.4230
2022-01-19 08:50:34,015 Epoch[190/300], Step[1250/1252], Avg Loss: 3.2753, Avg Acc: 0.4222
2022-01-19 08:50:41,232 ----- Epoch[190/300], Train Loss: 3.2753, Train Acc: 0.4222, time: 2322.70, Best Val(epoch188) Acc@1: 0.7393
2022-01-19 08:50:41,232 ----- Validation after Epoch: 190
2022-01-19 08:51:56,554 Val Step[0000/1563], Avg Loss: 1.0268, Avg Acc@1: 0.7500, Avg Acc@5: 0.9688
2022-01-19 08:51:58,409 Val Step[0050/1563], Avg Loss: 1.1800, Avg Acc@1: 0.7353, Avg Acc@5: 0.9179
2022-01-19 08:52:00,224 Val Step[0100/1563], Avg Loss: 1.1925, Avg Acc@1: 0.7348, Avg Acc@5: 0.9202
2022-01-19 08:52:02,032 Val Step[0150/1563], Avg Loss: 1.1990, Avg Acc@1: 0.7351, Avg Acc@5: 0.9168
2022-01-19 08:52:03,840 Val Step[0200/1563], Avg Loss: 1.1883, Avg Acc@1: 0.7383, Avg Acc@5: 0.9173
2022-01-19 08:52:05,644 Val Step[0250/1563], Avg Loss: 1.1783, Avg Acc@1: 0.7392, Avg Acc@5: 0.9185
2022-01-19 08:52:07,456 Val Step[0300/1563], Avg Loss: 1.1787, Avg Acc@1: 0.7396, Avg Acc@5: 0.9188
2022-01-19 08:52:09,258 Val Step[0350/1563], Avg Loss: 1.1821, Avg Acc@1: 0.7383, Avg Acc@5: 0.9186
2022-01-19 08:52:11,064 Val Step[0400/1563], Avg Loss: 1.1813, Avg Acc@1: 0.7399, Avg Acc@5: 0.9190
2022-01-19 08:52:12,870 Val Step[0450/1563], Avg Loss: 1.1878, Avg Acc@1: 0.7375, Avg Acc@5: 0.9190
2022-01-19 08:52:14,672 Val Step[0500/1563], Avg Loss: 1.1899, Avg Acc@1: 0.7370, Avg Acc@5: 0.9188
2022-01-19 08:52:16,487 Val Step[0550/1563], Avg Loss: 1.1907, Avg Acc@1: 0.7367, Avg Acc@5: 0.9196
2022-01-19 08:52:18,293 Val Step[0600/1563], Avg Loss: 1.1906, Avg Acc@1: 0.7369, Avg Acc@5: 0.9198
2022-01-19 08:52:20,109 Val Step[0650/1563], Avg Loss: 1.1911, Avg Acc@1: 0.7374, Avg Acc@5: 0.9202
2022-01-19 08:52:21,906 Val Step[0700/1563], Avg Loss: 1.1893, Avg Acc@1: 0.7383, Avg Acc@5: 0.9206
2022-01-19 08:52:23,913 Val Step[0750/1563], Avg Loss: 1.1945, Avg Acc@1: 0.7372, Avg Acc@5: 0.9202
2022-01-19 08:52:26,002 Val Step[0800/1563], Avg Loss: 1.1930, Avg Acc@1: 0.7382, Avg Acc@5: 0.9203
2022-01-19 08:52:27,892 Val Step[0850/1563], Avg Loss: 1.1946, Avg Acc@1: 0.7379, Avg Acc@5: 0.9201
2022-01-19 08:52:29,703 Val Step[0900/1563], Avg Loss: 1.1926, Avg Acc@1: 0.7383, Avg Acc@5: 0.9202
2022-01-19 08:52:31,557 Val Step[0950/1563], Avg Loss: 1.1936, Avg Acc@1: 0.7382, Avg Acc@5: 0.9203
2022-01-19 08:52:33,453 Val Step[1000/1563], Avg Loss: 1.1946, Avg Acc@1: 0.7383, Avg Acc@5: 0.9202
2022-01-19 08:52:35,300 Val Step[1050/1563], Avg Loss: 1.1950, Avg Acc@1: 0.7379, Avg Acc@5: 0.9199
2022-01-19 08:52:37,117 Val Step[1100/1563], Avg Loss: 1.1956, Avg Acc@1: 0.7376, Avg Acc@5: 0.9201
2022-01-19 08:52:38,912 Val Step[1150/1563], Avg Loss: 1.1940, Avg Acc@1: 0.7381, Avg Acc@5: 0.9202
2022-01-19 08:52:40,706 Val Step[1200/1563], Avg Loss: 1.1923, Avg Acc@1: 0.7388, Avg Acc@5: 0.9202
2022-01-19 08:52:42,509 Val Step[1250/1563], Avg Loss: 1.1920, Avg Acc@1: 0.7390, Avg Acc@5: 0.9203
2022-01-19 08:52:44,372 Val Step[1300/1563], Avg Loss: 1.1949, Avg Acc@1: 0.7391, Avg Acc@5: 0.9197
2022-01-19 08:52:46,251 Val Step[1350/1563], Avg Loss: 1.1960, Avg Acc@1: 0.7386, Avg Acc@5: 0.9196
2022-01-19 08:52:48,080 Val Step[1400/1563], Avg Loss: 1.1959, Avg Acc@1: 0.7379, Avg Acc@5: 0.9193
2022-01-19 08:52:49,893 Val Step[1450/1563], Avg Loss: 1.1956, Avg Acc@1: 0.7383, Avg Acc@5: 0.9190
2022-01-19 08:52:51,698 Val Step[1500/1563], Avg Loss: 1.1951, Avg Acc@1: 0.7388, Avg Acc@5: 0.9193
2022-01-19 08:52:53,448 Val Step[1550/1563], Avg Loss: 1.1955, Avg Acc@1: 0.7386, Avg Acc@5: 0.9193
2022-01-19 08:52:56,017 ----- Epoch[190/300], Validation Loss: 1.1952, Validation Acc@1: 0.7385, Validation Acc@5: 0.9194, time: 134.78
2022-01-19 08:52:56,017 Now training epoch 191. LR=0.000336
2022-01-19 08:54:47,810 Epoch[191/300], Step[0000/1252], Avg Loss: 3.6662, Avg Acc: 0.5039
2022-01-19 08:56:16,825 Epoch[191/300], Step[0050/1252], Avg Loss: 3.2549, Avg Acc: 0.4502
2022-01-19 08:57:45,324 Epoch[191/300], Step[0100/1252], Avg Loss: 3.2816, Avg Acc: 0.4353
2022-01-19 08:59:13,712 Epoch[191/300], Step[0150/1252], Avg Loss: 3.2741, Avg Acc: 0.4402
2022-01-19 09:00:42,244 Epoch[191/300], Step[0200/1252], Avg Loss: 3.2593, Avg Acc: 0.4427
2022-01-19 09:02:11,168 Epoch[191/300], Step[0250/1252], Avg Loss: 3.2601, Avg Acc: 0.4358
2022-01-19 09:03:39,714 Epoch[191/300], Step[0300/1252], Avg Loss: 3.2609, Avg Acc: 0.4383
2022-01-19 09:05:08,019 Epoch[191/300], Step[0350/1252], Avg Loss: 3.2583, Avg Acc: 0.4378
2022-01-19 09:06:36,619 Epoch[191/300], Step[0400/1252], Avg Loss: 3.2505, Avg Acc: 0.4375
2022-01-19 09:08:05,437 Epoch[191/300], Step[0450/1252], Avg Loss: 3.2432, Avg Acc: 0.4380
2022-01-19 09:09:34,195 Epoch[191/300], Step[0500/1252], Avg Loss: 3.2400, Avg Acc: 0.4375
2022-01-19 09:11:03,134 Epoch[191/300], Step[0550/1252], Avg Loss: 3.2418, Avg Acc: 0.4373
2022-01-19 09:12:32,951 Epoch[191/300], Step[0600/1252], Avg Loss: 3.2480, Avg Acc: 0.4338
2022-01-19 09:14:01,856 Epoch[191/300], Step[0650/1252], Avg Loss: 3.2545, Avg Acc: 0.4358
2022-01-19 09:15:30,557 Epoch[191/300], Step[0700/1252], Avg Loss: 3.2632, Avg Acc: 0.4352
2022-01-19 09:16:59,115 Epoch[191/300], Step[0750/1252], Avg Loss: 3.2661, Avg Acc: 0.4360
2022-01-19 09:18:28,215 Epoch[191/300], Step[0800/1252], Avg Loss: 3.2677, Avg Acc: 0.4355
2022-01-19 09:19:57,355 Epoch[191/300], Step[0850/1252], Avg Loss: 3.2675, Avg Acc: 0.4349
2022-01-19 09:21:25,140 Epoch[191/300], Step[0900/1252], Avg Loss: 3.2664, Avg Acc: 0.4367
2022-01-19 09:22:53,207 Epoch[191/300], Step[0950/1252], Avg Loss: 3.2690, Avg Acc: 0.4382
2022-01-19 09:24:22,294 Epoch[191/300], Step[1000/1252], Avg Loss: 3.2693, Avg Acc: 0.4367
2022-01-19 09:25:51,294 Epoch[191/300], Step[1050/1252], Avg Loss: 3.2689, Avg Acc: 0.4366
2022-01-19 09:27:21,241 Epoch[191/300], Step[1100/1252], Avg Loss: 3.2673, Avg Acc: 0.4359
2022-01-19 09:28:50,256 Epoch[191/300], Step[1150/1252], Avg Loss: 3.2674, Avg Acc: 0.4361
2022-01-19 09:30:19,578 Epoch[191/300], Step[1200/1252], Avg Loss: 3.2680, Avg Acc: 0.4366
2022-01-19 09:31:49,249 Epoch[191/300], Step[1250/1252], Avg Loss: 3.2665, Avg Acc: 0.4359
2022-01-19 09:31:56,534 ----- Epoch[191/300], Train Loss: 3.2665, Train Acc: 0.4359, time: 2340.51, Best Val(epoch188) Acc@1: 0.7393
2022-01-19 09:31:56,534 Now training epoch 192. LR=0.000331
2022-01-19 09:33:44,537 Epoch[192/300], Step[0000/1252], Avg Loss: 3.2450, Avg Acc: 0.4326
2022-01-19 09:35:12,795 Epoch[192/300], Step[0050/1252], Avg Loss: 3.2157, Avg Acc: 0.4504
2022-01-19 09:36:40,967 Epoch[192/300], Step[0100/1252], Avg Loss: 3.2416, Avg Acc: 0.4453
2022-01-19 09:38:08,697 Epoch[192/300], Step[0150/1252], Avg Loss: 3.2471, Avg Acc: 0.4309
2022-01-19 09:39:36,788 Epoch[192/300], Step[0200/1252], Avg Loss: 3.2489, Avg Acc: 0.4309
2022-01-19 09:41:05,910 Epoch[192/300], Step[0250/1252], Avg Loss: 3.2509, Avg Acc: 0.4311
2022-01-19 09:42:34,939 Epoch[192/300], Step[0300/1252], Avg Loss: 3.2572, Avg Acc: 0.4322
2022-01-19 09:44:02,601 Epoch[192/300], Step[0350/1252], Avg Loss: 3.2653, Avg Acc: 0.4304
2022-01-19 09:45:31,900 Epoch[192/300], Step[0400/1252], Avg Loss: 3.2683, Avg Acc: 0.4315
2022-01-19 09:46:59,438 Epoch[192/300], Step[0450/1252], Avg Loss: 3.2720, Avg Acc: 0.4329
2022-01-19 09:48:27,090 Epoch[192/300], Step[0500/1252], Avg Loss: 3.2721, Avg Acc: 0.4341
2022-01-19 09:49:56,222 Epoch[192/300], Step[0550/1252], Avg Loss: 3.2741, Avg Acc: 0.4303
2022-01-19 09:51:25,505 Epoch[192/300], Step[0600/1252], Avg Loss: 3.2765, Avg Acc: 0.4295
2022-01-19 09:52:54,328 Epoch[192/300], Step[0650/1252], Avg Loss: 3.2765, Avg Acc: 0.4309
2022-01-19 09:54:23,026 Epoch[192/300], Step[0700/1252], Avg Loss: 3.2791, Avg Acc: 0.4301
2022-01-19 09:55:50,378 Epoch[192/300], Step[0750/1252], Avg Loss: 3.2765, Avg Acc: 0.4304
2022-01-19 09:57:16,869 Epoch[192/300], Step[0800/1252], Avg Loss: 3.2822, Avg Acc: 0.4308
2022-01-19 09:58:44,005 Epoch[192/300], Step[0850/1252], Avg Loss: 3.2835, Avg Acc: 0.4310
2022-01-19 10:00:10,560 Epoch[192/300], Step[0900/1252], Avg Loss: 3.2817, Avg Acc: 0.4319
2022-01-19 10:01:38,897 Epoch[192/300], Step[0950/1252], Avg Loss: 3.2821, Avg Acc: 0.4316
2022-01-19 10:03:05,604 Epoch[192/300], Step[1000/1252], Avg Loss: 3.2792, Avg Acc: 0.4321
2022-01-19 10:04:32,272 Epoch[192/300], Step[1050/1252], Avg Loss: 3.2776, Avg Acc: 0.4334
2022-01-19 10:06:00,345 Epoch[192/300], Step[1100/1252], Avg Loss: 3.2758, Avg Acc: 0.4333
2022-01-19 10:07:29,852 Epoch[192/300], Step[1150/1252], Avg Loss: 3.2756, Avg Acc: 0.4335
2022-01-19 10:08:58,996 Epoch[192/300], Step[1200/1252], Avg Loss: 3.2762, Avg Acc: 0.4337
2022-01-19 10:10:26,633 Epoch[192/300], Step[1250/1252], Avg Loss: 3.2733, Avg Acc: 0.4350
2022-01-19 10:10:33,404 ----- Epoch[192/300], Train Loss: 3.2733, Train Acc: 0.4350, time: 2316.86, Best Val(epoch188) Acc@1: 0.7393
2022-01-19 10:10:33,404 ----- Validation after Epoch: 192
2022-01-19 10:11:50,305 Val Step[0000/1563], Avg Loss: 0.9560, Avg Acc@1: 0.7812, Avg Acc@5: 0.9688
2022-01-19 10:11:52,271 Val Step[0050/1563], Avg Loss: 1.1252, Avg Acc@1: 0.7500, Avg Acc@5: 0.9234
2022-01-19 10:11:54,074 Val Step[0100/1563], Avg Loss: 1.1298, Avg Acc@1: 0.7447, Avg Acc@5: 0.9248
2022-01-19 10:11:55,920 Val Step[0150/1563], Avg Loss: 1.1302, Avg Acc@1: 0.7436, Avg Acc@5: 0.9247
2022-01-19 10:11:57,719 Val Step[0200/1563], Avg Loss: 1.1233, Avg Acc@1: 0.7469, Avg Acc@5: 0.9262
2022-01-19 10:11:59,518 Val Step[0250/1563], Avg Loss: 1.1098, Avg Acc@1: 0.7495, Avg Acc@5: 0.9253
2022-01-19 10:12:01,327 Val Step[0300/1563], Avg Loss: 1.1143, Avg Acc@1: 0.7502, Avg Acc@5: 0.9234
2022-01-19 10:12:03,137 Val Step[0350/1563], Avg Loss: 1.1190, Avg Acc@1: 0.7487, Avg Acc@5: 0.9238
2022-01-19 10:12:04,945 Val Step[0400/1563], Avg Loss: 1.1183, Avg Acc@1: 0.7488, Avg Acc@5: 0.9236
2022-01-19 10:12:06,772 Val Step[0450/1563], Avg Loss: 1.1225, Avg Acc@1: 0.7458, Avg Acc@5: 0.9236
2022-01-19 10:12:08,657 Val Step[0500/1563], Avg Loss: 1.1233, Avg Acc@1: 0.7460, Avg Acc@5: 0.9237
2022-01-19 10:12:10,614 Val Step[0550/1563], Avg Loss: 1.1268, Avg Acc@1: 0.7440, Avg Acc@5: 0.9235
2022-01-19 10:12:12,482 Val Step[0600/1563], Avg Loss: 1.1261, Avg Acc@1: 0.7443, Avg Acc@5: 0.9235
2022-01-19 10:12:14,356 Val Step[0650/1563], Avg Loss: 1.1252, Avg Acc@1: 0.7446, Avg Acc@5: 0.9237
2022-01-19 10:12:16,161 Val Step[0700/1563], Avg Loss: 1.1235, Avg Acc@1: 0.7449, Avg Acc@5: 0.9243
2022-01-19 10:12:17,977 Val Step[0750/1563], Avg Loss: 1.1301, Avg Acc@1: 0.7437, Avg Acc@5: 0.9235
2022-01-19 10:12:19,817 Val Step[0800/1563], Avg Loss: 1.1303, Avg Acc@1: 0.7440, Avg Acc@5: 0.9234
2022-01-19 10:12:21,694 Val Step[0850/1563], Avg Loss: 1.1319, Avg Acc@1: 0.7435, Avg Acc@5: 0.9231
2022-01-19 10:12:23,565 Val Step[0900/1563], Avg Loss: 1.1291, Avg Acc@1: 0.7435, Avg Acc@5: 0.9234
2022-01-19 10:12:25,398 Val Step[0950/1563], Avg Loss: 1.1288, Avg Acc@1: 0.7440, Avg Acc@5: 0.9237
2022-01-19 10:12:27,283 Val Step[1000/1563], Avg Loss: 1.1297, Avg Acc@1: 0.7442, Avg Acc@5: 0.9234
2022-01-19 10:12:29,170 Val Step[1050/1563], Avg Loss: 1.1313, Avg Acc@1: 0.7435, Avg Acc@5: 0.9231
2022-01-19 10:12:31,018 Val Step[1100/1563], Avg Loss: 1.1323, Avg Acc@1: 0.7432, Avg Acc@5: 0.9228
2022-01-19 10:12:32,929 Val Step[1150/1563], Avg Loss: 1.1308, Avg Acc@1: 0.7433, Avg Acc@5: 0.9231
2022-01-19 10:12:34,734 Val Step[1200/1563], Avg Loss: 1.1294, Avg Acc@1: 0.7437, Avg Acc@5: 0.9231
2022-01-19 10:12:36,552 Val Step[1250/1563], Avg Loss: 1.1293, Avg Acc@1: 0.7437, Avg Acc@5: 0.9230
2022-01-19 10:12:38,374 Val Step[1300/1563], Avg Loss: 1.1321, Avg Acc@1: 0.7434, Avg Acc@5: 0.9226
2022-01-19 10:12:40,183 Val Step[1350/1563], Avg Loss: 1.1340, Avg Acc@1: 0.7424, Avg Acc@5: 0.9222
2022-01-19 10:12:42,051 Val Step[1400/1563], Avg Loss: 1.1340, Avg Acc@1: 0.7419, Avg Acc@5: 0.9221
2022-01-19 10:12:43,854 Val Step[1450/1563], Avg Loss: 1.1337, Avg Acc@1: 0.7425, Avg Acc@5: 0.9218
2022-01-19 10:12:45,760 Val Step[1500/1563], Avg Loss: 1.1327, Avg Acc@1: 0.7430, Avg Acc@5: 0.9223
2022-01-19 10:12:47,554 Val Step[1550/1563], Avg Loss: 1.1332, Avg Acc@1: 0.7427, Avg Acc@5: 0.9221
2022-01-19 10:12:49,385 ----- Epoch[192/300], Validation Loss: 1.1328, Validation Acc@1: 0.7427, Validation Acc@5: 0.9223, time: 135.98
2022-01-19 10:12:50,515 the pre best model acc:0.7393, at epoch 188
2022-01-19 10:12:50,516 current best model acc:0.7427, at epoch 192
2022-01-19 10:12:50,516 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 10:12:50,516 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 10:12:50,516 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 10:12:50,516 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 10:12:50,516 Now training epoch 193. LR=0.000326
2022-01-19 10:14:34,168 Epoch[193/300], Step[0000/1252], Avg Loss: 3.1609, Avg Acc: 0.6494
2022-01-19 10:16:03,297 Epoch[193/300], Step[0050/1252], Avg Loss: 3.2762, Avg Acc: 0.4332
2022-01-19 10:17:30,753 Epoch[193/300], Step[0100/1252], Avg Loss: 3.2788, Avg Acc: 0.4352
2022-01-19 10:18:59,219 Epoch[193/300], Step[0150/1252], Avg Loss: 3.2716, Avg Acc: 0.4343
2022-01-19 10:20:26,088 Epoch[193/300], Step[0200/1252], Avg Loss: 3.2638, Avg Acc: 0.4268
2022-01-19 10:21:52,684 Epoch[193/300], Step[0250/1252], Avg Loss: 3.2652, Avg Acc: 0.4245
2022-01-19 10:23:20,183 Epoch[193/300], Step[0300/1252], Avg Loss: 3.2599, Avg Acc: 0.4293
2022-01-19 10:24:46,840 Epoch[193/300], Step[0350/1252], Avg Loss: 3.2584, Avg Acc: 0.4307
2022-01-19 10:26:13,435 Epoch[193/300], Step[0400/1252], Avg Loss: 3.2644, Avg Acc: 0.4280
2022-01-19 10:27:40,204 Epoch[193/300], Step[0450/1252], Avg Loss: 3.2754, Avg Acc: 0.4269
2022-01-19 10:29:07,570 Epoch[193/300], Step[0500/1252], Avg Loss: 3.2721, Avg Acc: 0.4282
2022-01-19 10:30:33,664 Epoch[193/300], Step[0550/1252], Avg Loss: 3.2708, Avg Acc: 0.4299
2022-01-19 10:31:59,429 Epoch[193/300], Step[0600/1252], Avg Loss: 3.2691, Avg Acc: 0.4330
2022-01-19 10:33:27,471 Epoch[193/300], Step[0650/1252], Avg Loss: 3.2693, Avg Acc: 0.4320
2022-01-19 10:34:56,007 Epoch[193/300], Step[0700/1252], Avg Loss: 3.2672, Avg Acc: 0.4329
2022-01-19 10:36:23,085 Epoch[193/300], Step[0750/1252], Avg Loss: 3.2684, Avg Acc: 0.4321
2022-01-19 10:37:49,952 Epoch[193/300], Step[0800/1252], Avg Loss: 3.2650, Avg Acc: 0.4304
2022-01-19 10:39:17,431 Epoch[193/300], Step[0850/1252], Avg Loss: 3.2664, Avg Acc: 0.4304
2022-01-19 10:40:44,503 Epoch[193/300], Step[0900/1252], Avg Loss: 3.2677, Avg Acc: 0.4303
2022-01-19 10:42:10,773 Epoch[193/300], Step[0950/1252], Avg Loss: 3.2669, Avg Acc: 0.4296
2022-01-19 10:43:37,562 Epoch[193/300], Step[1000/1252], Avg Loss: 3.2662, Avg Acc: 0.4307
2022-01-19 10:45:06,075 Epoch[193/300], Step[1050/1252], Avg Loss: 3.2690, Avg Acc: 0.4301
2022-01-19 10:46:35,046 Epoch[193/300], Step[1100/1252], Avg Loss: 3.2695, Avg Acc: 0.4292
2022-01-19 10:48:01,787 Epoch[193/300], Step[1150/1252], Avg Loss: 3.2712, Avg Acc: 0.4294
2022-01-19 10:49:29,780 Epoch[193/300], Step[1200/1252], Avg Loss: 3.2713, Avg Acc: 0.4301
2022-01-19 10:50:57,804 Epoch[193/300], Step[1250/1252], Avg Loss: 3.2739, Avg Acc: 0.4298
2022-01-19 10:51:04,805 ----- Epoch[193/300], Train Loss: 3.2738, Train Acc: 0.4298, time: 2294.28, Best Val(epoch192) Acc@1: 0.7427
2022-01-19 10:51:04,805 Now training epoch 194. LR=0.000321
2022-01-19 10:52:55,107 Epoch[194/300], Step[0000/1252], Avg Loss: 2.9657, Avg Acc: 0.3330
2022-01-19 10:54:23,156 Epoch[194/300], Step[0050/1252], Avg Loss: 3.2056, Avg Acc: 0.4229
2022-01-19 10:55:52,440 Epoch[194/300], Step[0100/1252], Avg Loss: 3.2351, Avg Acc: 0.4228
2022-01-19 10:57:20,383 Epoch[194/300], Step[0150/1252], Avg Loss: 3.2462, Avg Acc: 0.4302
2022-01-19 10:58:49,597 Epoch[194/300], Step[0200/1252], Avg Loss: 3.2365, Avg Acc: 0.4348
2022-01-19 11:00:15,588 Epoch[194/300], Step[0250/1252], Avg Loss: 3.2298, Avg Acc: 0.4407
2022-01-19 11:01:44,686 Epoch[194/300], Step[0300/1252], Avg Loss: 3.2285, Avg Acc: 0.4408
2022-01-19 11:03:12,553 Epoch[194/300], Step[0350/1252], Avg Loss: 3.2218, Avg Acc: 0.4430
2022-01-19 11:04:40,868 Epoch[194/300], Step[0400/1252], Avg Loss: 3.2221, Avg Acc: 0.4401
2022-01-19 11:06:09,596 Epoch[194/300], Step[0450/1252], Avg Loss: 3.2239, Avg Acc: 0.4376
2022-01-19 11:07:38,634 Epoch[194/300], Step[0500/1252], Avg Loss: 3.2294, Avg Acc: 0.4371
2022-01-19 11:09:06,879 Epoch[194/300], Step[0550/1252], Avg Loss: 3.2308, Avg Acc: 0.4382
2022-01-19 11:10:35,441 Epoch[194/300], Step[0600/1252], Avg Loss: 3.2358, Avg Acc: 0.4363
2022-01-19 11:12:03,782 Epoch[194/300], Step[0650/1252], Avg Loss: 3.2379, Avg Acc: 0.4361
2022-01-19 11:13:32,155 Epoch[194/300], Step[0700/1252], Avg Loss: 3.2454, Avg Acc: 0.4347
2022-01-19 11:15:00,561 Epoch[194/300], Step[0750/1252], Avg Loss: 3.2463, Avg Acc: 0.4341
2022-01-19 11:16:28,770 Epoch[194/300], Step[0800/1252], Avg Loss: 3.2441, Avg Acc: 0.4346
2022-01-19 11:17:55,479 Epoch[194/300], Step[0850/1252], Avg Loss: 3.2444, Avg Acc: 0.4350
2022-01-19 11:19:24,560 Epoch[194/300], Step[0900/1252], Avg Loss: 3.2472, Avg Acc: 0.4353
2022-01-19 11:20:51,887 Epoch[194/300], Step[0950/1252], Avg Loss: 3.2475, Avg Acc: 0.4354
2022-01-19 11:22:19,721 Epoch[194/300], Step[1000/1252], Avg Loss: 3.2445, Avg Acc: 0.4357
2022-01-19 11:23:47,507 Epoch[194/300], Step[1050/1252], Avg Loss: 3.2453, Avg Acc: 0.4353
2022-01-19 11:25:14,825 Epoch[194/300], Step[1100/1252], Avg Loss: 3.2454, Avg Acc: 0.4348
2022-01-19 11:26:44,034 Epoch[194/300], Step[1150/1252], Avg Loss: 3.2482, Avg Acc: 0.4334
2022-01-19 11:28:12,314 Epoch[194/300], Step[1200/1252], Avg Loss: 3.2498, Avg Acc: 0.4331
2022-01-19 11:29:40,124 Epoch[194/300], Step[1250/1252], Avg Loss: 3.2478, Avg Acc: 0.4335
2022-01-19 11:29:46,999 ----- Epoch[194/300], Train Loss: 3.2478, Train Acc: 0.4335, time: 2322.19, Best Val(epoch192) Acc@1: 0.7427
2022-01-19 11:29:46,999 ----- Validation after Epoch: 194
2022-01-19 11:31:04,359 Val Step[0000/1563], Avg Loss: 0.9326, Avg Acc@1: 0.7812, Avg Acc@5: 0.9375
2022-01-19 11:31:06,731 Val Step[0050/1563], Avg Loss: 1.1300, Avg Acc@1: 0.7439, Avg Acc@5: 0.9252
2022-01-19 11:31:08,591 Val Step[0100/1563], Avg Loss: 1.1458, Avg Acc@1: 0.7407, Avg Acc@5: 0.9285
2022-01-19 11:31:10,509 Val Step[0150/1563], Avg Loss: 1.1446, Avg Acc@1: 0.7452, Avg Acc@5: 0.9253
2022-01-19 11:31:12,465 Val Step[0200/1563], Avg Loss: 1.1387, Avg Acc@1: 0.7472, Avg Acc@5: 0.9254
2022-01-19 11:31:14,391 Val Step[0250/1563], Avg Loss: 1.1272, Avg Acc@1: 0.7505, Avg Acc@5: 0.9265
2022-01-19 11:31:16,275 Val Step[0300/1563], Avg Loss: 1.1289, Avg Acc@1: 0.7504, Avg Acc@5: 0.9244
2022-01-19 11:31:18,198 Val Step[0350/1563], Avg Loss: 1.1360, Avg Acc@1: 0.7488, Avg Acc@5: 0.9233
2022-01-19 11:31:20,062 Val Step[0400/1563], Avg Loss: 1.1337, Avg Acc@1: 0.7494, Avg Acc@5: 0.9236
2022-01-19 11:31:21,902 Val Step[0450/1563], Avg Loss: 1.1428, Avg Acc@1: 0.7458, Avg Acc@5: 0.9223
2022-01-19 11:31:23,715 Val Step[0500/1563], Avg Loss: 1.1464, Avg Acc@1: 0.7436, Avg Acc@5: 0.9225
2022-01-19 11:31:25,517 Val Step[0550/1563], Avg Loss: 1.1476, Avg Acc@1: 0.7422, Avg Acc@5: 0.9229
2022-01-19 11:31:27,384 Val Step[0600/1563], Avg Loss: 1.1476, Avg Acc@1: 0.7418, Avg Acc@5: 0.9231
2022-01-19 11:31:29,220 Val Step[0650/1563], Avg Loss: 1.1466, Avg Acc@1: 0.7427, Avg Acc@5: 0.9229
2022-01-19 11:31:31,201 Val Step[0700/1563], Avg Loss: 1.1452, Avg Acc@1: 0.7434, Avg Acc@5: 0.9233
2022-01-19 11:31:33,262 Val Step[0750/1563], Avg Loss: 1.1502, Avg Acc@1: 0.7429, Avg Acc@5: 0.9226
2022-01-19 11:31:35,330 Val Step[0800/1563], Avg Loss: 1.1502, Avg Acc@1: 0.7431, Avg Acc@5: 0.9227
2022-01-19 11:31:37,447 Val Step[0850/1563], Avg Loss: 1.1513, Avg Acc@1: 0.7426, Avg Acc@5: 0.9224
2022-01-19 11:31:39,579 Val Step[0900/1563], Avg Loss: 1.1492, Avg Acc@1: 0.7429, Avg Acc@5: 0.9224
2022-01-19 11:31:41,644 Val Step[0950/1563], Avg Loss: 1.1490, Avg Acc@1: 0.7434, Avg Acc@5: 0.9229
2022-01-19 11:31:43,690 Val Step[1000/1563], Avg Loss: 1.1503, Avg Acc@1: 0.7438, Avg Acc@5: 0.9224
2022-01-19 11:31:45,783 Val Step[1050/1563], Avg Loss: 1.1510, Avg Acc@1: 0.7432, Avg Acc@5: 0.9222
2022-01-19 11:31:47,880 Val Step[1100/1563], Avg Loss: 1.1511, Avg Acc@1: 0.7432, Avg Acc@5: 0.9223
2022-01-19 11:31:49,985 Val Step[1150/1563], Avg Loss: 1.1493, Avg Acc@1: 0.7430, Avg Acc@5: 0.9226
2022-01-19 11:31:52,058 Val Step[1200/1563], Avg Loss: 1.1473, Avg Acc@1: 0.7435, Avg Acc@5: 0.9228
2022-01-19 11:31:54,062 Val Step[1250/1563], Avg Loss: 1.1475, Avg Acc@1: 0.7430, Avg Acc@5: 0.9229
2022-01-19 11:31:55,968 Val Step[1300/1563], Avg Loss: 1.1493, Avg Acc@1: 0.7428, Avg Acc@5: 0.9226
2022-01-19 11:31:57,775 Val Step[1350/1563], Avg Loss: 1.1507, Avg Acc@1: 0.7423, Avg Acc@5: 0.9221
2022-01-19 11:31:59,612 Val Step[1400/1563], Avg Loss: 1.1507, Avg Acc@1: 0.7421, Avg Acc@5: 0.9221
2022-01-19 11:32:01,517 Val Step[1450/1563], Avg Loss: 1.1498, Avg Acc@1: 0.7424, Avg Acc@5: 0.9222
2022-01-19 11:32:03,350 Val Step[1500/1563], Avg Loss: 1.1490, Avg Acc@1: 0.7427, Avg Acc@5: 0.9222
2022-01-19 11:32:05,128 Val Step[1550/1563], Avg Loss: 1.1491, Avg Acc@1: 0.7427, Avg Acc@5: 0.9222
2022-01-19 11:32:07,486 ----- Epoch[194/300], Validation Loss: 1.1490, Validation Acc@1: 0.7427, Validation Acc@5: 0.9224, time: 140.48
2022-01-19 11:32:07,486 Now training epoch 195. LR=0.000316
2022-01-19 11:34:01,902 Epoch[195/300], Step[0000/1252], Avg Loss: 3.9345, Avg Acc: 0.3936
2022-01-19 11:35:30,219 Epoch[195/300], Step[0050/1252], Avg Loss: 3.1928, Avg Acc: 0.4346
2022-01-19 11:36:58,631 Epoch[195/300], Step[0100/1252], Avg Loss: 3.2505, Avg Acc: 0.4363
2022-01-19 11:38:27,372 Epoch[195/300], Step[0150/1252], Avg Loss: 3.2389, Avg Acc: 0.4401
2022-01-19 11:39:54,657 Epoch[195/300], Step[0200/1252], Avg Loss: 3.2447, Avg Acc: 0.4369
2022-01-19 11:41:23,456 Epoch[195/300], Step[0250/1252], Avg Loss: 3.2448, Avg Acc: 0.4301
2022-01-19 11:42:51,340 Epoch[195/300], Step[0300/1252], Avg Loss: 3.2436, Avg Acc: 0.4277
2022-01-19 11:44:17,831 Epoch[195/300], Step[0350/1252], Avg Loss: 3.2407, Avg Acc: 0.4332
2022-01-19 11:45:45,023 Epoch[195/300], Step[0400/1252], Avg Loss: 3.2418, Avg Acc: 0.4321
2022-01-19 11:47:11,949 Epoch[195/300], Step[0450/1252], Avg Loss: 3.2455, Avg Acc: 0.4306
2022-01-19 11:48:39,856 Epoch[195/300], Step[0500/1252], Avg Loss: 3.2499, Avg Acc: 0.4293
2022-01-19 11:50:08,779 Epoch[195/300], Step[0550/1252], Avg Loss: 3.2540, Avg Acc: 0.4294
2022-01-19 11:51:36,375 Epoch[195/300], Step[0600/1252], Avg Loss: 3.2520, Avg Acc: 0.4318
2022-01-19 11:53:04,624 Epoch[195/300], Step[0650/1252], Avg Loss: 3.2557, Avg Acc: 0.4301
2022-01-19 11:54:33,980 Epoch[195/300], Step[0700/1252], Avg Loss: 3.2591, Avg Acc: 0.4304
2022-01-19 11:56:01,830 Epoch[195/300], Step[0750/1252], Avg Loss: 3.2619, Avg Acc: 0.4293
2022-01-19 11:57:29,491 Epoch[195/300], Step[0800/1252], Avg Loss: 3.2589, Avg Acc: 0.4310
2022-01-19 11:58:56,767 Epoch[195/300], Step[0850/1252], Avg Loss: 3.2586, Avg Acc: 0.4312
2022-01-19 12:00:23,548 Epoch[195/300], Step[0900/1252], Avg Loss: 3.2582, Avg Acc: 0.4311
2022-01-19 12:01:51,411 Epoch[195/300], Step[0950/1252], Avg Loss: 3.2594, Avg Acc: 0.4306
2022-01-19 12:03:17,237 Epoch[195/300], Step[1000/1252], Avg Loss: 3.2602, Avg Acc: 0.4295
2022-01-19 12:04:46,538 Epoch[195/300], Step[1050/1252], Avg Loss: 3.2611, Avg Acc: 0.4300
2022-01-19 12:06:15,095 Epoch[195/300], Step[1100/1252], Avg Loss: 3.2602, Avg Acc: 0.4295
2022-01-19 12:07:43,845 Epoch[195/300], Step[1150/1252], Avg Loss: 3.2626, Avg Acc: 0.4293
2022-01-19 12:09:10,209 Epoch[195/300], Step[1200/1252], Avg Loss: 3.2627, Avg Acc: 0.4295
2022-01-19 12:10:36,325 Epoch[195/300], Step[1250/1252], Avg Loss: 3.2610, Avg Acc: 0.4292
2022-01-19 12:10:43,847 ----- Epoch[195/300], Train Loss: 3.2611, Train Acc: 0.4292, time: 2316.36, Best Val(epoch192) Acc@1: 0.7427
2022-01-19 12:10:43,847 Now training epoch 196. LR=0.000310
2022-01-19 12:12:37,710 Epoch[196/300], Step[0000/1252], Avg Loss: 3.7459, Avg Acc: 0.4346
2022-01-19 12:14:06,645 Epoch[196/300], Step[0050/1252], Avg Loss: 3.3349, Avg Acc: 0.4266
2022-01-19 12:15:35,083 Epoch[196/300], Step[0100/1252], Avg Loss: 3.2796, Avg Acc: 0.4377
2022-01-19 12:17:02,840 Epoch[196/300], Step[0150/1252], Avg Loss: 3.2774, Avg Acc: 0.4357
2022-01-19 12:18:30,690 Epoch[196/300], Step[0200/1252], Avg Loss: 3.2781, Avg Acc: 0.4303
2022-01-19 12:19:58,705 Epoch[196/300], Step[0250/1252], Avg Loss: 3.2851, Avg Acc: 0.4336
2022-01-19 12:21:25,589 Epoch[196/300], Step[0300/1252], Avg Loss: 3.2876, Avg Acc: 0.4265
2022-01-19 12:22:53,996 Epoch[196/300], Step[0350/1252], Avg Loss: 3.2823, Avg Acc: 0.4261
2022-01-19 12:24:23,089 Epoch[196/300], Step[0400/1252], Avg Loss: 3.2779, Avg Acc: 0.4232
2022-01-19 12:25:51,548 Epoch[196/300], Step[0450/1252], Avg Loss: 3.2784, Avg Acc: 0.4271
2022-01-19 12:27:19,510 Epoch[196/300], Step[0500/1252], Avg Loss: 3.2747, Avg Acc: 0.4268
2022-01-19 12:28:48,276 Epoch[196/300], Step[0550/1252], Avg Loss: 3.2775, Avg Acc: 0.4269
2022-01-19 12:30:17,300 Epoch[196/300], Step[0600/1252], Avg Loss: 3.2760, Avg Acc: 0.4287
2022-01-19 12:31:44,535 Epoch[196/300], Step[0650/1252], Avg Loss: 3.2768, Avg Acc: 0.4289
2022-01-19 12:33:11,684 Epoch[196/300], Step[0700/1252], Avg Loss: 3.2753, Avg Acc: 0.4290
2022-01-19 12:34:40,427 Epoch[196/300], Step[0750/1252], Avg Loss: 3.2709, Avg Acc: 0.4259
2022-01-19 12:36:07,963 Epoch[196/300], Step[0800/1252], Avg Loss: 3.2727, Avg Acc: 0.4262
2022-01-19 12:37:37,512 Epoch[196/300], Step[0850/1252], Avg Loss: 3.2710, Avg Acc: 0.4249
2022-01-19 12:39:06,697 Epoch[196/300], Step[0900/1252], Avg Loss: 3.2698, Avg Acc: 0.4265
2022-01-19 12:40:34,675 Epoch[196/300], Step[0950/1252], Avg Loss: 3.2719, Avg Acc: 0.4261
2022-01-19 12:42:02,240 Epoch[196/300], Step[1000/1252], Avg Loss: 3.2730, Avg Acc: 0.4261
2022-01-19 12:43:30,321 Epoch[196/300], Step[1050/1252], Avg Loss: 3.2675, Avg Acc: 0.4256
2022-01-19 12:44:59,170 Epoch[196/300], Step[1100/1252], Avg Loss: 3.2657, Avg Acc: 0.4265
2022-01-19 12:46:26,607 Epoch[196/300], Step[1150/1252], Avg Loss: 3.2633, Avg Acc: 0.4273
2022-01-19 12:47:55,307 Epoch[196/300], Step[1200/1252], Avg Loss: 3.2634, Avg Acc: 0.4270
2022-01-19 12:49:22,916 Epoch[196/300], Step[1250/1252], Avg Loss: 3.2614, Avg Acc: 0.4267
2022-01-19 12:49:29,860 ----- Epoch[196/300], Train Loss: 3.2615, Train Acc: 0.4267, time: 2326.01, Best Val(epoch192) Acc@1: 0.7427
2022-01-19 12:49:29,860 ----- Validation after Epoch: 196
2022-01-19 12:50:50,503 Val Step[0000/1563], Avg Loss: 0.9214, Avg Acc@1: 0.7188, Avg Acc@5: 1.0000
2022-01-19 12:50:52,381 Val Step[0050/1563], Avg Loss: 1.1227, Avg Acc@1: 0.7580, Avg Acc@5: 0.9234
2022-01-19 12:50:54,192 Val Step[0100/1563], Avg Loss: 1.1433, Avg Acc@1: 0.7540, Avg Acc@5: 0.9273
2022-01-19 12:50:56,081 Val Step[0150/1563], Avg Loss: 1.1510, Avg Acc@1: 0.7504, Avg Acc@5: 0.9251
2022-01-19 12:50:58,014 Val Step[0200/1563], Avg Loss: 1.1502, Avg Acc@1: 0.7514, Avg Acc@5: 0.9244
2022-01-19 12:50:59,859 Val Step[0250/1563], Avg Loss: 1.1418, Avg Acc@1: 0.7537, Avg Acc@5: 0.9249
2022-01-19 12:51:01,673 Val Step[0300/1563], Avg Loss: 1.1456, Avg Acc@1: 0.7545, Avg Acc@5: 0.9229
2022-01-19 12:51:03,524 Val Step[0350/1563], Avg Loss: 1.1523, Avg Acc@1: 0.7522, Avg Acc@5: 0.9231
2022-01-19 12:51:05,401 Val Step[0400/1563], Avg Loss: 1.1504, Avg Acc@1: 0.7531, Avg Acc@5: 0.9233
2022-01-19 12:51:07,304 Val Step[0450/1563], Avg Loss: 1.1559, Avg Acc@1: 0.7499, Avg Acc@5: 0.9228
2022-01-19 12:51:09,150 Val Step[0500/1563], Avg Loss: 1.1572, Avg Acc@1: 0.7485, Avg Acc@5: 0.9222
2022-01-19 12:51:11,041 Val Step[0550/1563], Avg Loss: 1.1584, Avg Acc@1: 0.7476, Avg Acc@5: 0.9222
2022-01-19 12:51:12,963 Val Step[0600/1563], Avg Loss: 1.1594, Avg Acc@1: 0.7475, Avg Acc@5: 0.9225
2022-01-19 12:51:14,763 Val Step[0650/1563], Avg Loss: 1.1596, Avg Acc@1: 0.7474, Avg Acc@5: 0.9225
2022-01-19 12:51:16,639 Val Step[0700/1563], Avg Loss: 1.1575, Avg Acc@1: 0.7479, Avg Acc@5: 0.9231
2022-01-19 12:51:18,513 Val Step[0750/1563], Avg Loss: 1.1629, Avg Acc@1: 0.7462, Avg Acc@5: 0.9225
2022-01-19 12:51:20,326 Val Step[0800/1563], Avg Loss: 1.1627, Avg Acc@1: 0.7468, Avg Acc@5: 0.9225
2022-01-19 12:51:22,154 Val Step[0850/1563], Avg Loss: 1.1644, Avg Acc@1: 0.7464, Avg Acc@5: 0.9223
2022-01-19 12:51:24,058 Val Step[0900/1563], Avg Loss: 1.1623, Avg Acc@1: 0.7463, Avg Acc@5: 0.9226
2022-01-19 12:51:26,024 Val Step[0950/1563], Avg Loss: 1.1619, Avg Acc@1: 0.7467, Avg Acc@5: 0.9229
2022-01-19 12:51:27,975 Val Step[1000/1563], Avg Loss: 1.1625, Avg Acc@1: 0.7467, Avg Acc@5: 0.9223
2022-01-19 12:51:29,809 Val Step[1050/1563], Avg Loss: 1.1637, Avg Acc@1: 0.7458, Avg Acc@5: 0.9220
2022-01-19 12:51:31,790 Val Step[1100/1563], Avg Loss: 1.1644, Avg Acc@1: 0.7457, Avg Acc@5: 0.9221
2022-01-19 12:51:33,650 Val Step[1150/1563], Avg Loss: 1.1641, Avg Acc@1: 0.7457, Avg Acc@5: 0.9220
2022-01-19 12:51:35,527 Val Step[1200/1563], Avg Loss: 1.1631, Avg Acc@1: 0.7462, Avg Acc@5: 0.9220
2022-01-19 12:51:37,475 Val Step[1250/1563], Avg Loss: 1.1627, Avg Acc@1: 0.7464, Avg Acc@5: 0.9221
2022-01-19 12:51:39,419 Val Step[1300/1563], Avg Loss: 1.1650, Avg Acc@1: 0.7462, Avg Acc@5: 0.9222
2022-01-19 12:51:41,393 Val Step[1350/1563], Avg Loss: 1.1656, Avg Acc@1: 0.7457, Avg Acc@5: 0.9218
2022-01-19 12:51:43,267 Val Step[1400/1563], Avg Loss: 1.1654, Avg Acc@1: 0.7453, Avg Acc@5: 0.9217
2022-01-19 12:51:45,124 Val Step[1450/1563], Avg Loss: 1.1651, Avg Acc@1: 0.7456, Avg Acc@5: 0.9216
2022-01-19 12:51:47,018 Val Step[1500/1563], Avg Loss: 1.1643, Avg Acc@1: 0.7459, Avg Acc@5: 0.9218
2022-01-19 12:51:48,872 Val Step[1550/1563], Avg Loss: 1.1643, Avg Acc@1: 0.7458, Avg Acc@5: 0.9217
2022-01-19 12:51:50,762 ----- Epoch[196/300], Validation Loss: 1.1647, Validation Acc@1: 0.7459, Validation Acc@5: 0.9217, time: 140.90
2022-01-19 12:51:51,924 the pre best model acc:0.7427, at epoch 192
2022-01-19 12:51:51,925 current best model acc:0.7459, at epoch 196
2022-01-19 12:51:51,925 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 12:51:51,925 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 12:51:51,925 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 12:51:51,925 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 12:51:51,925 Now training epoch 197. LR=0.000305
2022-01-19 12:53:40,405 Epoch[197/300], Step[0000/1252], Avg Loss: 2.8537, Avg Acc: 0.6387
2022-01-19 12:55:09,631 Epoch[197/300], Step[0050/1252], Avg Loss: 3.2286, Avg Acc: 0.3992
2022-01-19 12:56:35,882 Epoch[197/300], Step[0100/1252], Avg Loss: 3.2211, Avg Acc: 0.4267
2022-01-19 12:58:04,544 Epoch[197/300], Step[0150/1252], Avg Loss: 3.2281, Avg Acc: 0.4270
2022-01-19 12:59:32,622 Epoch[197/300], Step[0200/1252], Avg Loss: 3.2305, Avg Acc: 0.4305
2022-01-19 13:01:00,527 Epoch[197/300], Step[0250/1252], Avg Loss: 3.2446, Avg Acc: 0.4284
2022-01-19 13:02:27,418 Epoch[197/300], Step[0300/1252], Avg Loss: 3.2437, Avg Acc: 0.4293
2022-01-19 13:03:55,961 Epoch[197/300], Step[0350/1252], Avg Loss: 3.2519, Avg Acc: 0.4284
2022-01-19 13:05:24,195 Epoch[197/300], Step[0400/1252], Avg Loss: 3.2526, Avg Acc: 0.4316
2022-01-19 13:06:52,364 Epoch[197/300], Step[0450/1252], Avg Loss: 3.2479, Avg Acc: 0.4304
2022-01-19 13:08:20,420 Epoch[197/300], Step[0500/1252], Avg Loss: 3.2491, Avg Acc: 0.4300
2022-01-19 13:09:49,811 Epoch[197/300], Step[0550/1252], Avg Loss: 3.2496, Avg Acc: 0.4298
2022-01-19 13:11:18,327 Epoch[197/300], Step[0600/1252], Avg Loss: 3.2502, Avg Acc: 0.4311
2022-01-19 13:12:46,523 Epoch[197/300], Step[0650/1252], Avg Loss: 3.2545, Avg Acc: 0.4322
2022-01-19 13:14:14,671 Epoch[197/300], Step[0700/1252], Avg Loss: 3.2485, Avg Acc: 0.4331
2022-01-19 13:15:42,331 Epoch[197/300], Step[0750/1252], Avg Loss: 3.2467, Avg Acc: 0.4354
2022-01-19 13:17:09,959 Epoch[197/300], Step[0800/1252], Avg Loss: 3.2451, Avg Acc: 0.4361
2022-01-19 13:18:38,236 Epoch[197/300], Step[0850/1252], Avg Loss: 3.2480, Avg Acc: 0.4360
2022-01-19 13:20:06,880 Epoch[197/300], Step[0900/1252], Avg Loss: 3.2508, Avg Acc: 0.4354
2022-01-19 13:21:34,900 Epoch[197/300], Step[0950/1252], Avg Loss: 3.2516, Avg Acc: 0.4347
2022-01-19 13:23:02,292 Epoch[197/300], Step[1000/1252], Avg Loss: 3.2530, Avg Acc: 0.4350
2022-01-19 13:24:29,571 Epoch[197/300], Step[1050/1252], Avg Loss: 3.2533, Avg Acc: 0.4352
2022-01-19 13:25:58,008 Epoch[197/300], Step[1100/1252], Avg Loss: 3.2543, Avg Acc: 0.4362
2022-01-19 13:27:25,785 Epoch[197/300], Step[1150/1252], Avg Loss: 3.2559, Avg Acc: 0.4360
2022-01-19 13:28:51,773 Epoch[197/300], Step[1200/1252], Avg Loss: 3.2558, Avg Acc: 0.4377
2022-01-19 13:30:17,858 Epoch[197/300], Step[1250/1252], Avg Loss: 3.2549, Avg Acc: 0.4374
2022-01-19 13:30:24,883 ----- Epoch[197/300], Train Loss: 3.2549, Train Acc: 0.4374, time: 2312.95, Best Val(epoch196) Acc@1: 0.7459
2022-01-19 13:30:24,883 Now training epoch 198. LR=0.000300
2022-01-19 13:32:23,268 Epoch[198/300], Step[0000/1252], Avg Loss: 2.8825, Avg Acc: 0.6416
2022-01-19 13:33:51,877 Epoch[198/300], Step[0050/1252], Avg Loss: 3.2682, Avg Acc: 0.4476
2022-01-19 13:35:20,955 Epoch[198/300], Step[0100/1252], Avg Loss: 3.2752, Avg Acc: 0.4331
2022-01-19 13:36:48,775 Epoch[198/300], Step[0150/1252], Avg Loss: 3.2601, Avg Acc: 0.4270
2022-01-19 13:38:17,087 Epoch[198/300], Step[0200/1252], Avg Loss: 3.2476, Avg Acc: 0.4303
2022-01-19 13:39:45,845 Epoch[198/300], Step[0250/1252], Avg Loss: 3.2469, Avg Acc: 0.4338
2022-01-19 13:41:14,369 Epoch[198/300], Step[0300/1252], Avg Loss: 3.2408, Avg Acc: 0.4364
2022-01-19 13:42:43,605 Epoch[198/300], Step[0350/1252], Avg Loss: 3.2367, Avg Acc: 0.4372
2022-01-19 13:44:11,062 Epoch[198/300], Step[0400/1252], Avg Loss: 3.2369, Avg Acc: 0.4372
2022-01-19 13:45:40,123 Epoch[198/300], Step[0450/1252], Avg Loss: 3.2380, Avg Acc: 0.4336
2022-01-19 13:47:07,117 Epoch[198/300], Step[0500/1252], Avg Loss: 3.2439, Avg Acc: 0.4347
2022-01-19 13:48:35,595 Epoch[198/300], Step[0550/1252], Avg Loss: 3.2418, Avg Acc: 0.4362
2022-01-19 13:50:05,600 Epoch[198/300], Step[0600/1252], Avg Loss: 3.2351, Avg Acc: 0.4349
2022-01-19 13:51:33,792 Epoch[198/300], Step[0650/1252], Avg Loss: 3.2399, Avg Acc: 0.4342
2022-01-19 13:53:02,670 Epoch[198/300], Step[0700/1252], Avg Loss: 3.2424, Avg Acc: 0.4326
2022-01-19 13:54:31,444 Epoch[198/300], Step[0750/1252], Avg Loss: 3.2398, Avg Acc: 0.4354
2022-01-19 13:56:00,503 Epoch[198/300], Step[0800/1252], Avg Loss: 3.2440, Avg Acc: 0.4355
2022-01-19 13:57:28,397 Epoch[198/300], Step[0850/1252], Avg Loss: 3.2425, Avg Acc: 0.4353
2022-01-19 13:58:56,262 Epoch[198/300], Step[0900/1252], Avg Loss: 3.2470, Avg Acc: 0.4347
2022-01-19 14:00:24,387 Epoch[198/300], Step[0950/1252], Avg Loss: 3.2473, Avg Acc: 0.4345
2022-01-19 14:01:53,343 Epoch[198/300], Step[1000/1252], Avg Loss: 3.2464, Avg Acc: 0.4333
2022-01-19 14:03:22,272 Epoch[198/300], Step[1050/1252], Avg Loss: 3.2478, Avg Acc: 0.4321
2022-01-19 14:04:52,078 Epoch[198/300], Step[1100/1252], Avg Loss: 3.2519, Avg Acc: 0.4322
2022-01-19 14:06:20,806 Epoch[198/300], Step[1150/1252], Avg Loss: 3.2505, Avg Acc: 0.4319
2022-01-19 14:07:48,701 Epoch[198/300], Step[1200/1252], Avg Loss: 3.2507, Avg Acc: 0.4311
2022-01-19 14:09:13,337 Epoch[198/300], Step[1250/1252], Avg Loss: 3.2519, Avg Acc: 0.4319
2022-01-19 14:09:20,218 ----- Epoch[198/300], Train Loss: 3.2519, Train Acc: 0.4319, time: 2335.33, Best Val(epoch196) Acc@1: 0.7459
2022-01-19 14:09:20,218 ----- Validation after Epoch: 198
2022-01-19 14:15:58,729 Val Step[0000/1563], Avg Loss: 0.9351, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-19 14:16:00,600 Val Step[0050/1563], Avg Loss: 1.1273, Avg Acc@1: 0.7506, Avg Acc@5: 0.9234
2022-01-19 14:16:02,446 Val Step[0100/1563], Avg Loss: 1.1510, Avg Acc@1: 0.7506, Avg Acc@5: 0.9211
2022-01-19 14:16:04,510 Val Step[0150/1563], Avg Loss: 1.1376, Avg Acc@1: 0.7531, Avg Acc@5: 0.9240
2022-01-19 14:16:06,580 Val Step[0200/1563], Avg Loss: 1.1395, Avg Acc@1: 0.7531, Avg Acc@5: 0.9246
2022-01-19 14:16:08,640 Val Step[0250/1563], Avg Loss: 1.1352, Avg Acc@1: 0.7526, Avg Acc@5: 0.9246
2022-01-19 14:16:10,667 Val Step[0300/1563], Avg Loss: 1.1378, Avg Acc@1: 0.7531, Avg Acc@5: 0.9236
2022-01-19 14:16:12,716 Val Step[0350/1563], Avg Loss: 1.1422, Avg Acc@1: 0.7523, Avg Acc@5: 0.9234
2022-01-19 14:16:14,621 Val Step[0400/1563], Avg Loss: 1.1415, Avg Acc@1: 0.7516, Avg Acc@5: 0.9237
2022-01-19 14:16:16,537 Val Step[0450/1563], Avg Loss: 1.1472, Avg Acc@1: 0.7486, Avg Acc@5: 0.9227
2022-01-19 14:16:18,479 Val Step[0500/1563], Avg Loss: 1.1480, Avg Acc@1: 0.7476, Avg Acc@5: 0.9232
2022-01-19 14:16:20,387 Val Step[0550/1563], Avg Loss: 1.1499, Avg Acc@1: 0.7468, Avg Acc@5: 0.9236
2022-01-19 14:16:22,299 Val Step[0600/1563], Avg Loss: 1.1487, Avg Acc@1: 0.7460, Avg Acc@5: 0.9239
2022-01-19 14:16:24,232 Val Step[0650/1563], Avg Loss: 1.1500, Avg Acc@1: 0.7459, Avg Acc@5: 0.9239
2022-01-19 14:16:26,113 Val Step[0700/1563], Avg Loss: 1.1468, Avg Acc@1: 0.7462, Avg Acc@5: 0.9246
2022-01-19 14:16:28,058 Val Step[0750/1563], Avg Loss: 1.1521, Avg Acc@1: 0.7448, Avg Acc@5: 0.9240
2022-01-19 14:16:29,944 Val Step[0800/1563], Avg Loss: 1.1522, Avg Acc@1: 0.7452, Avg Acc@5: 0.9238
2022-01-19 14:16:31,843 Val Step[0850/1563], Avg Loss: 1.1551, Avg Acc@1: 0.7440, Avg Acc@5: 0.9234
2022-01-19 14:16:33,647 Val Step[0900/1563], Avg Loss: 1.1524, Avg Acc@1: 0.7442, Avg Acc@5: 0.9237
2022-01-19 14:16:35,543 Val Step[0950/1563], Avg Loss: 1.1523, Avg Acc@1: 0.7446, Avg Acc@5: 0.9235
2022-01-19 14:16:37,464 Val Step[1000/1563], Avg Loss: 1.1528, Avg Acc@1: 0.7447, Avg Acc@5: 0.9235
2022-01-19 14:16:39,354 Val Step[1050/1563], Avg Loss: 1.1532, Avg Acc@1: 0.7447, Avg Acc@5: 0.9234
2022-01-19 14:16:41,188 Val Step[1100/1563], Avg Loss: 1.1535, Avg Acc@1: 0.7446, Avg Acc@5: 0.9234
2022-01-19 14:16:43,125 Val Step[1150/1563], Avg Loss: 1.1534, Avg Acc@1: 0.7444, Avg Acc@5: 0.9233
2022-01-19 14:16:44,987 Val Step[1200/1563], Avg Loss: 1.1529, Avg Acc@1: 0.7448, Avg Acc@5: 0.9231
2022-01-19 14:16:46,796 Val Step[1250/1563], Avg Loss: 1.1527, Avg Acc@1: 0.7447, Avg Acc@5: 0.9231
2022-01-19 14:16:48,597 Val Step[1300/1563], Avg Loss: 1.1556, Avg Acc@1: 0.7444, Avg Acc@5: 0.9228
2022-01-19 14:16:50,403 Val Step[1350/1563], Avg Loss: 1.1564, Avg Acc@1: 0.7440, Avg Acc@5: 0.9227
2022-01-19 14:16:52,201 Val Step[1400/1563], Avg Loss: 1.1557, Avg Acc@1: 0.7441, Avg Acc@5: 0.9226
2022-01-19 14:16:54,293 Val Step[1450/1563], Avg Loss: 1.1559, Avg Acc@1: 0.7440, Avg Acc@5: 0.9223
2022-01-19 14:16:56,442 Val Step[1500/1563], Avg Loss: 1.1554, Avg Acc@1: 0.7444, Avg Acc@5: 0.9225
2022-01-19 14:16:58,467 Val Step[1550/1563], Avg Loss: 1.1558, Avg Acc@1: 0.7441, Avg Acc@5: 0.9225
2022-01-19 14:17:00,394 ----- Epoch[198/300], Validation Loss: 1.1558, Validation Acc@1: 0.7440, Validation Acc@5: 0.9226, time: 460.17
2022-01-19 14:17:00,395 Now training epoch 199. LR=0.000295
2022-01-19 14:18:45,561 Epoch[199/300], Step[0000/1252], Avg Loss: 3.5180, Avg Acc: 0.4258
2022-01-19 14:20:14,306 Epoch[199/300], Step[0050/1252], Avg Loss: 3.2694, Avg Acc: 0.4326
2022-01-19 14:21:42,372 Epoch[199/300], Step[0100/1252], Avg Loss: 3.2492, Avg Acc: 0.4241
2022-01-19 14:23:10,521 Epoch[199/300], Step[0150/1252], Avg Loss: 3.2640, Avg Acc: 0.4272
2022-01-19 14:24:37,509 Epoch[199/300], Step[0200/1252], Avg Loss: 3.2663, Avg Acc: 0.4314
2022-01-19 14:26:05,546 Epoch[199/300], Step[0250/1252], Avg Loss: 3.2661, Avg Acc: 0.4298
2022-01-19 14:27:33,100 Epoch[199/300], Step[0300/1252], Avg Loss: 3.2607, Avg Acc: 0.4317
2022-01-19 14:29:00,605 Epoch[199/300], Step[0350/1252], Avg Loss: 3.2580, Avg Acc: 0.4375
2022-01-19 14:30:28,936 Epoch[199/300], Step[0400/1252], Avg Loss: 3.2531, Avg Acc: 0.4380
2022-01-19 14:31:57,384 Epoch[199/300], Step[0450/1252], Avg Loss: 3.2494, Avg Acc: 0.4375
2022-01-19 14:33:26,864 Epoch[199/300], Step[0500/1252], Avg Loss: 3.2487, Avg Acc: 0.4387
2022-01-19 14:34:54,927 Epoch[199/300], Step[0550/1252], Avg Loss: 3.2453, Avg Acc: 0.4383
2022-01-19 14:36:22,141 Epoch[199/300], Step[0600/1252], Avg Loss: 3.2490, Avg Acc: 0.4379
2022-01-19 14:37:50,982 Epoch[199/300], Step[0650/1252], Avg Loss: 3.2494, Avg Acc: 0.4379
2022-01-19 14:39:18,757 Epoch[199/300], Step[0700/1252], Avg Loss: 3.2480, Avg Acc: 0.4379
2022-01-19 14:40:47,480 Epoch[199/300], Step[0750/1252], Avg Loss: 3.2488, Avg Acc: 0.4351
2022-01-19 14:42:16,207 Epoch[199/300], Step[0800/1252], Avg Loss: 3.2493, Avg Acc: 0.4337
2022-01-19 14:43:44,086 Epoch[199/300], Step[0850/1252], Avg Loss: 3.2478, Avg Acc: 0.4337
2022-01-19 14:45:12,698 Epoch[199/300], Step[0900/1252], Avg Loss: 3.2517, Avg Acc: 0.4329
2022-01-19 14:46:40,925 Epoch[199/300], Step[0950/1252], Avg Loss: 3.2532, Avg Acc: 0.4318
2022-01-19 14:48:08,947 Epoch[199/300], Step[1000/1252], Avg Loss: 3.2527, Avg Acc: 0.4321
2022-01-19 14:49:36,931 Epoch[199/300], Step[1050/1252], Avg Loss: 3.2553, Avg Acc: 0.4315
2022-01-19 14:51:04,929 Epoch[199/300], Step[1100/1252], Avg Loss: 3.2525, Avg Acc: 0.4318
2022-01-19 14:52:33,877 Epoch[199/300], Step[1150/1252], Avg Loss: 3.2491, Avg Acc: 0.4326
2022-01-19 14:54:00,950 Epoch[199/300], Step[1200/1252], Avg Loss: 3.2507, Avg Acc: 0.4329
2022-01-19 14:55:27,913 Epoch[199/300], Step[1250/1252], Avg Loss: 3.2494, Avg Acc: 0.4341
2022-01-19 14:55:34,777 ----- Epoch[199/300], Train Loss: 3.2494, Train Acc: 0.4341, time: 2314.38, Best Val(epoch196) Acc@1: 0.7459
2022-01-19 14:55:34,777 Now training epoch 200. LR=0.000290
2022-01-19 15:02:50,849 Epoch[200/300], Step[0000/1252], Avg Loss: 3.2105, Avg Acc: 0.4189
2022-01-19 15:04:20,615 Epoch[200/300], Step[0050/1252], Avg Loss: 3.2344, Avg Acc: 0.4521
2022-01-19 15:06:05,421 Epoch[200/300], Step[0100/1252], Avg Loss: 3.2791, Avg Acc: 0.4310
2022-01-19 15:07:43,632 Epoch[200/300], Step[0150/1252], Avg Loss: 3.2663, Avg Acc: 0.4336
2022-01-19 15:09:17,193 Epoch[200/300], Step[0200/1252], Avg Loss: 3.2512, Avg Acc: 0.4384
2022-01-19 15:10:51,684 Epoch[200/300], Step[0250/1252], Avg Loss: 3.2450, Avg Acc: 0.4343
2022-01-19 15:12:23,705 Epoch[200/300], Step[0300/1252], Avg Loss: 3.2468, Avg Acc: 0.4312
2022-01-19 15:13:56,637 Epoch[200/300], Step[0350/1252], Avg Loss: 3.2452, Avg Acc: 0.4333
2022-01-19 15:15:30,624 Epoch[200/300], Step[0400/1252], Avg Loss: 3.2489, Avg Acc: 0.4339
2022-01-19 15:17:04,317 Epoch[200/300], Step[0450/1252], Avg Loss: 3.2463, Avg Acc: 0.4312
2022-01-19 15:18:37,020 Epoch[200/300], Step[0500/1252], Avg Loss: 3.2440, Avg Acc: 0.4333
2022-01-19 15:20:11,737 Epoch[200/300], Step[0550/1252], Avg Loss: 3.2504, Avg Acc: 0.4331
2022-01-19 15:21:45,617 Epoch[200/300], Step[0600/1252], Avg Loss: 3.2501, Avg Acc: 0.4338
2022-01-19 15:23:19,105 Epoch[200/300], Step[0650/1252], Avg Loss: 3.2456, Avg Acc: 0.4349
2022-01-19 15:24:52,719 Epoch[200/300], Step[0700/1252], Avg Loss: 3.2372, Avg Acc: 0.4352
2022-01-19 15:26:25,838 Epoch[200/300], Step[0750/1252], Avg Loss: 3.2356, Avg Acc: 0.4350
2022-01-19 15:27:58,341 Epoch[200/300], Step[0800/1252], Avg Loss: 3.2344, Avg Acc: 0.4332
2022-01-19 15:29:32,530 Epoch[200/300], Step[0850/1252], Avg Loss: 3.2354, Avg Acc: 0.4331
2022-01-19 15:31:07,093 Epoch[200/300], Step[0900/1252], Avg Loss: 3.2328, Avg Acc: 0.4323
2022-01-19 15:32:41,991 Epoch[200/300], Step[0950/1252], Avg Loss: 3.2330, Avg Acc: 0.4290
2022-01-19 15:34:16,210 Epoch[200/300], Step[1000/1252], Avg Loss: 3.2349, Avg Acc: 0.4278
2022-01-19 15:35:46,008 Epoch[200/300], Step[1050/1252], Avg Loss: 3.2385, Avg Acc: 0.4274
2022-01-19 15:37:15,002 Epoch[200/300], Step[1100/1252], Avg Loss: 3.2405, Avg Acc: 0.4270
2022-01-19 15:38:43,841 Epoch[200/300], Step[1150/1252], Avg Loss: 3.2417, Avg Acc: 0.4274
2022-01-19 15:40:12,966 Epoch[200/300], Step[1200/1252], Avg Loss: 3.2404, Avg Acc: 0.4276
2022-01-19 15:41:39,740 Epoch[200/300], Step[1250/1252], Avg Loss: 3.2408, Avg Acc: 0.4280
2022-01-19 15:41:47,379 ----- Epoch[200/300], Train Loss: 3.2407, Train Acc: 0.4280, time: 2772.60, Best Val(epoch196) Acc@1: 0.7459
2022-01-19 15:41:47,379 ----- Validation after Epoch: 200
2022-01-19 15:43:06,081 Val Step[0000/1563], Avg Loss: 0.9621, Avg Acc@1: 0.7188, Avg Acc@5: 1.0000
2022-01-19 15:43:08,231 Val Step[0050/1563], Avg Loss: 1.1246, Avg Acc@1: 0.7488, Avg Acc@5: 0.9271
2022-01-19 15:43:10,056 Val Step[0100/1563], Avg Loss: 1.1372, Avg Acc@1: 0.7509, Avg Acc@5: 0.9251
2022-01-19 15:43:11,948 Val Step[0150/1563], Avg Loss: 1.1438, Avg Acc@1: 0.7533, Avg Acc@5: 0.9222
2022-01-19 15:43:13,871 Val Step[0200/1563], Avg Loss: 1.1485, Avg Acc@1: 0.7528, Avg Acc@5: 0.9227
2022-01-19 15:43:15,880 Val Step[0250/1563], Avg Loss: 1.1394, Avg Acc@1: 0.7535, Avg Acc@5: 0.9236
2022-01-19 15:43:17,708 Val Step[0300/1563], Avg Loss: 1.1399, Avg Acc@1: 0.7535, Avg Acc@5: 0.9228
2022-01-19 15:43:19,515 Val Step[0350/1563], Avg Loss: 1.1459, Avg Acc@1: 0.7520, Avg Acc@5: 0.9228
2022-01-19 15:43:21,354 Val Step[0400/1563], Avg Loss: 1.1457, Avg Acc@1: 0.7516, Avg Acc@5: 0.9236
2022-01-19 15:43:23,181 Val Step[0450/1563], Avg Loss: 1.1494, Avg Acc@1: 0.7492, Avg Acc@5: 0.9236
2022-01-19 15:43:25,013 Val Step[0500/1563], Avg Loss: 1.1518, Avg Acc@1: 0.7488, Avg Acc@5: 0.9239
2022-01-19 15:43:26,858 Val Step[0550/1563], Avg Loss: 1.1536, Avg Acc@1: 0.7471, Avg Acc@5: 0.9237
2022-01-19 15:43:28,757 Val Step[0600/1563], Avg Loss: 1.1521, Avg Acc@1: 0.7463, Avg Acc@5: 0.9241
2022-01-19 15:43:30,651 Val Step[0650/1563], Avg Loss: 1.1544, Avg Acc@1: 0.7460, Avg Acc@5: 0.9243
2022-01-19 15:43:32,490 Val Step[0700/1563], Avg Loss: 1.1517, Avg Acc@1: 0.7464, Avg Acc@5: 0.9249
2022-01-19 15:43:34,432 Val Step[0750/1563], Avg Loss: 1.1574, Avg Acc@1: 0.7452, Avg Acc@5: 0.9242
2022-01-19 15:43:36,467 Val Step[0800/1563], Avg Loss: 1.1582, Avg Acc@1: 0.7461, Avg Acc@5: 0.9240
2022-01-19 15:43:38,502 Val Step[0850/1563], Avg Loss: 1.1589, Avg Acc@1: 0.7454, Avg Acc@5: 0.9241
2022-01-19 15:43:40,408 Val Step[0900/1563], Avg Loss: 1.1566, Avg Acc@1: 0.7458, Avg Acc@5: 0.9246
2022-01-19 15:43:42,321 Val Step[0950/1563], Avg Loss: 1.1566, Avg Acc@1: 0.7460, Avg Acc@5: 0.9245
2022-01-19 15:43:44,158 Val Step[1000/1563], Avg Loss: 1.1570, Avg Acc@1: 0.7460, Avg Acc@5: 0.9245
2022-01-19 15:43:45,985 Val Step[1050/1563], Avg Loss: 1.1585, Avg Acc@1: 0.7456, Avg Acc@5: 0.9239
2022-01-19 15:43:47,825 Val Step[1100/1563], Avg Loss: 1.1589, Avg Acc@1: 0.7454, Avg Acc@5: 0.9240
2022-01-19 15:43:49,669 Val Step[1150/1563], Avg Loss: 1.1577, Avg Acc@1: 0.7459, Avg Acc@5: 0.9239
2022-01-19 15:43:51,571 Val Step[1200/1563], Avg Loss: 1.1559, Avg Acc@1: 0.7467, Avg Acc@5: 0.9241
2022-01-19 15:43:53,386 Val Step[1250/1563], Avg Loss: 1.1557, Avg Acc@1: 0.7463, Avg Acc@5: 0.9242
2022-01-19 15:43:55,304 Val Step[1300/1563], Avg Loss: 1.1573, Avg Acc@1: 0.7463, Avg Acc@5: 0.9240
2022-01-19 15:43:57,141 Val Step[1350/1563], Avg Loss: 1.1579, Avg Acc@1: 0.7460, Avg Acc@5: 0.9238
2022-01-19 15:43:58,964 Val Step[1400/1563], Avg Loss: 1.1568, Avg Acc@1: 0.7460, Avg Acc@5: 0.9238
2022-01-19 15:44:00,871 Val Step[1450/1563], Avg Loss: 1.1562, Avg Acc@1: 0.7463, Avg Acc@5: 0.9239
2022-01-19 15:44:02,945 Val Step[1500/1563], Avg Loss: 1.1552, Avg Acc@1: 0.7467, Avg Acc@5: 0.9242
2022-01-19 15:44:04,987 Val Step[1550/1563], Avg Loss: 1.1555, Avg Acc@1: 0.7464, Avg Acc@5: 0.9242
2022-01-19 15:44:06,940 ----- Epoch[200/300], Validation Loss: 1.1552, Validation Acc@1: 0.7465, Validation Acc@5: 0.9242, time: 139.56
2022-01-19 15:44:08,143 the pre best model acc:0.7459, at epoch 196
2022-01-19 15:44:08,144 current best model acc:0.7465, at epoch 200
2022-01-19 15:44:08,144 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 15:44:08,144 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 15:44:08,144 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 15:44:08,144 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 15:44:08,687 ----- Save model: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-200-Loss-3.255183990559099.pdparams
2022-01-19 15:44:08,687 ----- Save optim: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-200-Loss-3.255183990559099.pdopt
2022-01-19 15:44:08,687 Now training epoch 201. LR=0.000285
2022-01-19 15:45:54,275 Epoch[201/300], Step[0000/1252], Avg Loss: 3.3340, Avg Acc: 0.4395
2022-01-19 15:47:22,802 Epoch[201/300], Step[0050/1252], Avg Loss: 3.1336, Avg Acc: 0.4537
2022-01-19 15:48:50,725 Epoch[201/300], Step[0100/1252], Avg Loss: 3.1844, Avg Acc: 0.4403
2022-01-19 15:50:18,093 Epoch[201/300], Step[0150/1252], Avg Loss: 3.1889, Avg Acc: 0.4459
2022-01-19 15:51:45,029 Epoch[201/300], Step[0200/1252], Avg Loss: 3.1963, Avg Acc: 0.4363
2022-01-19 15:53:12,942 Epoch[201/300], Step[0250/1252], Avg Loss: 3.2124, Avg Acc: 0.4361
2022-01-19 15:54:41,289 Epoch[201/300], Step[0300/1252], Avg Loss: 3.2170, Avg Acc: 0.4371
2022-01-19 15:56:09,293 Epoch[201/300], Step[0350/1252], Avg Loss: 3.2167, Avg Acc: 0.4395
2022-01-19 15:57:37,511 Epoch[201/300], Step[0400/1252], Avg Loss: 3.2309, Avg Acc: 0.4367
2022-01-19 15:59:04,821 Epoch[201/300], Step[0450/1252], Avg Loss: 3.2242, Avg Acc: 0.4385
2022-01-19 16:00:32,529 Epoch[201/300], Step[0500/1252], Avg Loss: 3.2313, Avg Acc: 0.4341
2022-01-19 16:01:59,288 Epoch[201/300], Step[0550/1252], Avg Loss: 3.2249, Avg Acc: 0.4324
2022-01-19 16:03:25,443 Epoch[201/300], Step[0600/1252], Avg Loss: 3.2255, Avg Acc: 0.4317
2022-01-19 16:04:53,337 Epoch[201/300], Step[0650/1252], Avg Loss: 3.2288, Avg Acc: 0.4307
2022-01-19 16:06:19,647 Epoch[201/300], Step[0700/1252], Avg Loss: 3.2283, Avg Acc: 0.4315
2022-01-19 16:07:47,013 Epoch[201/300], Step[0750/1252], Avg Loss: 3.2302, Avg Acc: 0.4321
2022-01-19 16:09:14,682 Epoch[201/300], Step[0800/1252], Avg Loss: 3.2316, Avg Acc: 0.4328
2022-01-19 16:10:43,080 Epoch[201/300], Step[0850/1252], Avg Loss: 3.2328, Avg Acc: 0.4326
2022-01-19 16:12:11,672 Epoch[201/300], Step[0900/1252], Avg Loss: 3.2320, Avg Acc: 0.4333
2022-01-19 16:13:40,377 Epoch[201/300], Step[0950/1252], Avg Loss: 3.2305, Avg Acc: 0.4336
2022-01-19 16:15:08,674 Epoch[201/300], Step[1000/1252], Avg Loss: 3.2311, Avg Acc: 0.4332
2022-01-19 16:16:36,942 Epoch[201/300], Step[1050/1252], Avg Loss: 3.2300, Avg Acc: 0.4331
2022-01-19 16:18:04,256 Epoch[201/300], Step[1100/1252], Avg Loss: 3.2333, Avg Acc: 0.4334
2022-01-19 16:19:30,884 Epoch[201/300], Step[1150/1252], Avg Loss: 3.2331, Avg Acc: 0.4336
2022-01-19 16:20:57,614 Epoch[201/300], Step[1200/1252], Avg Loss: 3.2309, Avg Acc: 0.4332
2022-01-19 16:22:22,998 Epoch[201/300], Step[1250/1252], Avg Loss: 3.2322, Avg Acc: 0.4324
2022-01-19 16:22:29,882 ----- Epoch[201/300], Train Loss: 3.2323, Train Acc: 0.4324, time: 2301.19, Best Val(epoch200) Acc@1: 0.7465
2022-01-19 16:22:29,882 Now training epoch 202. LR=0.000280
2022-01-19 16:24:19,417 Epoch[202/300], Step[0000/1252], Avg Loss: 3.4874, Avg Acc: 0.3975
2022-01-19 16:25:45,974 Epoch[202/300], Step[0050/1252], Avg Loss: 3.2857, Avg Acc: 0.4402
2022-01-19 16:27:13,079 Epoch[202/300], Step[0100/1252], Avg Loss: 3.2752, Avg Acc: 0.4317
2022-01-19 16:28:40,466 Epoch[202/300], Step[0150/1252], Avg Loss: 3.2526, Avg Acc: 0.4294
2022-01-19 16:30:08,459 Epoch[202/300], Step[0200/1252], Avg Loss: 3.2572, Avg Acc: 0.4350
2022-01-19 16:31:35,539 Epoch[202/300], Step[0250/1252], Avg Loss: 3.2482, Avg Acc: 0.4403
2022-01-19 16:33:01,750 Epoch[202/300], Step[0300/1252], Avg Loss: 3.2491, Avg Acc: 0.4406
2022-01-19 16:34:27,995 Epoch[202/300], Step[0350/1252], Avg Loss: 3.2468, Avg Acc: 0.4414
2022-01-19 16:35:55,477 Epoch[202/300], Step[0400/1252], Avg Loss: 3.2450, Avg Acc: 0.4376
2022-01-19 16:37:23,618 Epoch[202/300], Step[0450/1252], Avg Loss: 3.2424, Avg Acc: 0.4351
2022-01-19 16:38:51,483 Epoch[202/300], Step[0500/1252], Avg Loss: 3.2408, Avg Acc: 0.4340
2022-01-19 16:40:18,013 Epoch[202/300], Step[0550/1252], Avg Loss: 3.2392, Avg Acc: 0.4342
2022-01-19 16:41:44,627 Epoch[202/300], Step[0600/1252], Avg Loss: 3.2458, Avg Acc: 0.4330
2022-01-19 16:43:11,140 Epoch[202/300], Step[0650/1252], Avg Loss: 3.2435, Avg Acc: 0.4341
2022-01-19 16:44:37,560 Epoch[202/300], Step[0700/1252], Avg Loss: 3.2369, Avg Acc: 0.4368
2022-01-19 16:46:04,640 Epoch[202/300], Step[0750/1252], Avg Loss: 3.2330, Avg Acc: 0.4379
2022-01-19 16:47:32,060 Epoch[202/300], Step[0800/1252], Avg Loss: 3.2354, Avg Acc: 0.4374
2022-01-19 16:48:59,513 Epoch[202/300], Step[0850/1252], Avg Loss: 3.2391, Avg Acc: 0.4365
2022-01-19 16:50:25,723 Epoch[202/300], Step[0900/1252], Avg Loss: 3.2395, Avg Acc: 0.4361
2022-01-19 16:51:54,171 Epoch[202/300], Step[0950/1252], Avg Loss: 3.2409, Avg Acc: 0.4357
2022-01-19 16:53:22,951 Epoch[202/300], Step[1000/1252], Avg Loss: 3.2400, Avg Acc: 0.4356
2022-01-19 16:54:50,626 Epoch[202/300], Step[1050/1252], Avg Loss: 3.2421, Avg Acc: 0.4351
2022-01-19 16:56:17,495 Epoch[202/300], Step[1100/1252], Avg Loss: 3.2416, Avg Acc: 0.4349
2022-01-19 16:57:44,833 Epoch[202/300], Step[1150/1252], Avg Loss: 3.2419, Avg Acc: 0.4346
2022-01-19 16:59:11,695 Epoch[202/300], Step[1200/1252], Avg Loss: 3.2381, Avg Acc: 0.4352
2022-01-19 17:00:38,982 Epoch[202/300], Step[1250/1252], Avg Loss: 3.2403, Avg Acc: 0.4341
2022-01-19 17:00:46,113 ----- Epoch[202/300], Train Loss: 3.2403, Train Acc: 0.4340, time: 2296.23, Best Val(epoch200) Acc@1: 0.7465
2022-01-19 17:00:46,113 ----- Validation after Epoch: 202
2022-01-19 17:02:01,284 Val Step[0000/1563], Avg Loss: 0.8448, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-19 17:02:03,412 Val Step[0050/1563], Avg Loss: 1.1351, Avg Acc@1: 0.7451, Avg Acc@5: 0.9216
2022-01-19 17:02:05,505 Val Step[0100/1563], Avg Loss: 1.1389, Avg Acc@1: 0.7497, Avg Acc@5: 0.9257
2022-01-19 17:02:07,543 Val Step[0150/1563], Avg Loss: 1.1390, Avg Acc@1: 0.7490, Avg Acc@5: 0.9253
2022-01-19 17:02:09,575 Val Step[0200/1563], Avg Loss: 1.1375, Avg Acc@1: 0.7498, Avg Acc@5: 0.9257
2022-01-19 17:02:11,601 Val Step[0250/1563], Avg Loss: 1.1246, Avg Acc@1: 0.7507, Avg Acc@5: 0.9269
2022-01-19 17:02:13,650 Val Step[0300/1563], Avg Loss: 1.1279, Avg Acc@1: 0.7504, Avg Acc@5: 0.9252
2022-01-19 17:02:15,658 Val Step[0350/1563], Avg Loss: 1.1324, Avg Acc@1: 0.7498, Avg Acc@5: 0.9241
2022-01-19 17:02:17,531 Val Step[0400/1563], Avg Loss: 1.1325, Avg Acc@1: 0.7499, Avg Acc@5: 0.9233
2022-01-19 17:02:19,369 Val Step[0450/1563], Avg Loss: 1.1403, Avg Acc@1: 0.7472, Avg Acc@5: 0.9222
2022-01-19 17:02:21,185 Val Step[0500/1563], Avg Loss: 1.1423, Avg Acc@1: 0.7467, Avg Acc@5: 0.9221
2022-01-19 17:02:22,988 Val Step[0550/1563], Avg Loss: 1.1429, Avg Acc@1: 0.7459, Avg Acc@5: 0.9221
2022-01-19 17:02:24,832 Val Step[0600/1563], Avg Loss: 1.1439, Avg Acc@1: 0.7451, Avg Acc@5: 0.9224
2022-01-19 17:02:26,731 Val Step[0650/1563], Avg Loss: 1.1445, Avg Acc@1: 0.7455, Avg Acc@5: 0.9220
2022-01-19 17:02:28,634 Val Step[0700/1563], Avg Loss: 1.1422, Avg Acc@1: 0.7463, Avg Acc@5: 0.9231
2022-01-19 17:02:30,434 Val Step[0750/1563], Avg Loss: 1.1474, Avg Acc@1: 0.7450, Avg Acc@5: 0.9226
2022-01-19 17:02:32,232 Val Step[0800/1563], Avg Loss: 1.1476, Avg Acc@1: 0.7457, Avg Acc@5: 0.9223
2022-01-19 17:02:34,051 Val Step[0850/1563], Avg Loss: 1.1483, Avg Acc@1: 0.7458, Avg Acc@5: 0.9224
2022-01-19 17:02:35,851 Val Step[0900/1563], Avg Loss: 1.1460, Avg Acc@1: 0.7457, Avg Acc@5: 0.9228
2022-01-19 17:02:37,745 Val Step[0950/1563], Avg Loss: 1.1451, Avg Acc@1: 0.7465, Avg Acc@5: 0.9231
2022-01-19 17:02:39,621 Val Step[1000/1563], Avg Loss: 1.1454, Avg Acc@1: 0.7469, Avg Acc@5: 0.9229
2022-01-19 17:02:41,499 Val Step[1050/1563], Avg Loss: 1.1458, Avg Acc@1: 0.7466, Avg Acc@5: 0.9227
2022-01-19 17:02:43,430 Val Step[1100/1563], Avg Loss: 1.1463, Avg Acc@1: 0.7462, Avg Acc@5: 0.9226
2022-01-19 17:02:45,346 Val Step[1150/1563], Avg Loss: 1.1452, Avg Acc@1: 0.7464, Avg Acc@5: 0.9228
2022-01-19 17:02:47,347 Val Step[1200/1563], Avg Loss: 1.1443, Avg Acc@1: 0.7468, Avg Acc@5: 0.9228
2022-01-19 17:02:49,406 Val Step[1250/1563], Avg Loss: 1.1439, Avg Acc@1: 0.7469, Avg Acc@5: 0.9229
2022-01-19 17:02:51,446 Val Step[1300/1563], Avg Loss: 1.1468, Avg Acc@1: 0.7468, Avg Acc@5: 0.9226
2022-01-19 17:02:53,509 Val Step[1350/1563], Avg Loss: 1.1473, Avg Acc@1: 0.7463, Avg Acc@5: 0.9222
2022-01-19 17:02:55,630 Val Step[1400/1563], Avg Loss: 1.1476, Avg Acc@1: 0.7461, Avg Acc@5: 0.9223
2022-01-19 17:02:57,699 Val Step[1450/1563], Avg Loss: 1.1471, Avg Acc@1: 0.7463, Avg Acc@5: 0.9222
2022-01-19 17:02:59,762 Val Step[1500/1563], Avg Loss: 1.1469, Avg Acc@1: 0.7463, Avg Acc@5: 0.9225
2022-01-19 17:03:01,790 Val Step[1550/1563], Avg Loss: 1.1469, Avg Acc@1: 0.7464, Avg Acc@5: 0.9224
2022-01-19 17:03:03,708 ----- Epoch[202/300], Validation Loss: 1.1471, Validation Acc@1: 0.7463, Validation Acc@5: 0.9224, time: 137.59
2022-01-19 17:03:03,708 Now training epoch 203. LR=0.000275
2022-01-19 17:04:54,741 Epoch[203/300], Step[0000/1252], Avg Loss: 3.2965, Avg Acc: 0.3604
2022-01-19 17:06:22,702 Epoch[203/300], Step[0050/1252], Avg Loss: 3.2294, Avg Acc: 0.4349
2022-01-19 17:07:50,156 Epoch[203/300], Step[0100/1252], Avg Loss: 3.1925, Avg Acc: 0.4280
2022-01-19 17:09:17,417 Epoch[203/300], Step[0150/1252], Avg Loss: 3.1875, Avg Acc: 0.4307
2022-01-19 17:10:45,528 Epoch[203/300], Step[0200/1252], Avg Loss: 3.1824, Avg Acc: 0.4332
2022-01-19 17:12:13,059 Epoch[203/300], Step[0250/1252], Avg Loss: 3.1945, Avg Acc: 0.4361
2022-01-19 17:13:40,584 Epoch[203/300], Step[0300/1252], Avg Loss: 3.2043, Avg Acc: 0.4390
2022-01-19 17:15:07,426 Epoch[203/300], Step[0350/1252], Avg Loss: 3.1992, Avg Acc: 0.4428
2022-01-19 17:16:34,037 Epoch[203/300], Step[0400/1252], Avg Loss: 3.1957, Avg Acc: 0.4426
2022-01-19 17:18:01,549 Epoch[203/300], Step[0450/1252], Avg Loss: 3.1983, Avg Acc: 0.4389
2022-01-19 17:19:29,855 Epoch[203/300], Step[0500/1252], Avg Loss: 3.2036, Avg Acc: 0.4413
2022-01-19 17:20:56,917 Epoch[203/300], Step[0550/1252], Avg Loss: 3.2000, Avg Acc: 0.4430
2022-01-19 17:22:25,275 Epoch[203/300], Step[0600/1252], Avg Loss: 3.2004, Avg Acc: 0.4428
2022-01-19 17:23:53,929 Epoch[203/300], Step[0650/1252], Avg Loss: 3.2067, Avg Acc: 0.4413
2022-01-19 17:25:22,148 Epoch[203/300], Step[0700/1252], Avg Loss: 3.2070, Avg Acc: 0.4400
2022-01-19 17:26:49,763 Epoch[203/300], Step[0750/1252], Avg Loss: 3.2103, Avg Acc: 0.4411
2022-01-19 17:28:16,636 Epoch[203/300], Step[0800/1252], Avg Loss: 3.2168, Avg Acc: 0.4404
2022-01-19 17:29:44,141 Epoch[203/300], Step[0850/1252], Avg Loss: 3.2214, Avg Acc: 0.4401
2022-01-19 17:31:11,481 Epoch[203/300], Step[0900/1252], Avg Loss: 3.2186, Avg Acc: 0.4419
2022-01-19 17:32:39,417 Epoch[203/300], Step[0950/1252], Avg Loss: 3.2242, Avg Acc: 0.4418
2022-01-19 17:34:08,318 Epoch[203/300], Step[1000/1252], Avg Loss: 3.2241, Avg Acc: 0.4418
2022-01-19 17:35:37,022 Epoch[203/300], Step[1050/1252], Avg Loss: 3.2265, Avg Acc: 0.4427
2022-01-19 17:37:03,851 Epoch[203/300], Step[1100/1252], Avg Loss: 3.2255, Avg Acc: 0.4423
2022-01-19 17:38:31,052 Epoch[203/300], Step[1150/1252], Avg Loss: 3.2269, Avg Acc: 0.4425
2022-01-19 17:39:58,930 Epoch[203/300], Step[1200/1252], Avg Loss: 3.2266, Avg Acc: 0.4421
2022-01-19 17:41:25,877 Epoch[203/300], Step[1250/1252], Avg Loss: 3.2262, Avg Acc: 0.4415
2022-01-19 17:41:32,941 ----- Epoch[203/300], Train Loss: 3.2262, Train Acc: 0.4415, time: 2309.23, Best Val(epoch200) Acc@1: 0.7465
2022-01-19 17:41:32,941 Now training epoch 204. LR=0.000270
2022-01-19 17:43:26,649 Epoch[204/300], Step[0000/1252], Avg Loss: 3.4587, Avg Acc: 0.0947
2022-01-19 17:44:54,619 Epoch[204/300], Step[0050/1252], Avg Loss: 3.2653, Avg Acc: 0.4199
2022-01-19 17:46:23,043 Epoch[204/300], Step[0100/1252], Avg Loss: 3.2257, Avg Acc: 0.4300
2022-01-19 17:47:52,287 Epoch[204/300], Step[0150/1252], Avg Loss: 3.2223, Avg Acc: 0.4282
2022-01-19 17:49:19,613 Epoch[204/300], Step[0200/1252], Avg Loss: 3.2171, Avg Acc: 0.4344
2022-01-19 17:50:48,251 Epoch[204/300], Step[0250/1252], Avg Loss: 3.2368, Avg Acc: 0.4328
2022-01-19 17:52:17,420 Epoch[204/300], Step[0300/1252], Avg Loss: 3.2273, Avg Acc: 0.4311
2022-01-19 17:53:45,554 Epoch[204/300], Step[0350/1252], Avg Loss: 3.2239, Avg Acc: 0.4365
2022-01-19 17:55:13,231 Epoch[204/300], Step[0400/1252], Avg Loss: 3.2257, Avg Acc: 0.4359
2022-01-19 17:56:40,949 Epoch[204/300], Step[0450/1252], Avg Loss: 3.2262, Avg Acc: 0.4344
2022-01-19 17:58:08,094 Epoch[204/300], Step[0500/1252], Avg Loss: 3.2265, Avg Acc: 0.4370
2022-01-19 17:59:35,481 Epoch[204/300], Step[0550/1252], Avg Loss: 3.2227, Avg Acc: 0.4390
2022-01-19 18:01:03,685 Epoch[204/300], Step[0600/1252], Avg Loss: 3.2217, Avg Acc: 0.4414
2022-01-19 18:02:32,005 Epoch[204/300], Step[0650/1252], Avg Loss: 3.2220, Avg Acc: 0.4402
2022-01-19 18:04:00,746 Epoch[204/300], Step[0700/1252], Avg Loss: 3.2210, Avg Acc: 0.4392
2022-01-19 18:05:29,079 Epoch[204/300], Step[0750/1252], Avg Loss: 3.2216, Avg Acc: 0.4388
2022-01-19 18:06:57,814 Epoch[204/300], Step[0800/1252], Avg Loss: 3.2225, Avg Acc: 0.4369
2022-01-19 18:08:25,338 Epoch[204/300], Step[0850/1252], Avg Loss: 3.2231, Avg Acc: 0.4371
2022-01-19 18:09:53,550 Epoch[204/300], Step[0900/1252], Avg Loss: 3.2208, Avg Acc: 0.4375
2022-01-19 18:11:22,129 Epoch[204/300], Step[0950/1252], Avg Loss: 3.2194, Avg Acc: 0.4377
2022-01-19 18:12:50,242 Epoch[204/300], Step[1000/1252], Avg Loss: 3.2224, Avg Acc: 0.4368
2022-01-19 18:14:18,969 Epoch[204/300], Step[1050/1252], Avg Loss: 3.2266, Avg Acc: 0.4356
2022-01-19 18:15:47,241 Epoch[204/300], Step[1100/1252], Avg Loss: 3.2258, Avg Acc: 0.4375
2022-01-19 18:17:15,284 Epoch[204/300], Step[1150/1252], Avg Loss: 3.2249, Avg Acc: 0.4372
2022-01-19 18:18:43,448 Epoch[204/300], Step[1200/1252], Avg Loss: 3.2271, Avg Acc: 0.4368
2022-01-19 18:20:11,400 Epoch[204/300], Step[1250/1252], Avg Loss: 3.2268, Avg Acc: 0.4373
2022-01-19 18:20:18,402 ----- Epoch[204/300], Train Loss: 3.2268, Train Acc: 0.4373, time: 2325.46, Best Val(epoch200) Acc@1: 0.7465
2022-01-19 18:20:18,402 ----- Validation after Epoch: 204
2022-01-19 18:21:35,563 Val Step[0000/1563], Avg Loss: 0.7737, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-19 18:21:37,427 Val Step[0050/1563], Avg Loss: 1.0919, Avg Acc@1: 0.7598, Avg Acc@5: 0.9271
2022-01-19 18:21:39,260 Val Step[0100/1563], Avg Loss: 1.0999, Avg Acc@1: 0.7568, Avg Acc@5: 0.9291
2022-01-19 18:21:41,057 Val Step[0150/1563], Avg Loss: 1.1061, Avg Acc@1: 0.7568, Avg Acc@5: 0.9280
2022-01-19 18:21:42,860 Val Step[0200/1563], Avg Loss: 1.1072, Avg Acc@1: 0.7556, Avg Acc@5: 0.9291
2022-01-19 18:21:44,702 Val Step[0250/1563], Avg Loss: 1.1030, Avg Acc@1: 0.7545, Avg Acc@5: 0.9292
2022-01-19 18:21:46,532 Val Step[0300/1563], Avg Loss: 1.1059, Avg Acc@1: 0.7536, Avg Acc@5: 0.9282
2022-01-19 18:21:48,457 Val Step[0350/1563], Avg Loss: 1.1083, Avg Acc@1: 0.7529, Avg Acc@5: 0.9278
2022-01-19 18:21:50,411 Val Step[0400/1563], Avg Loss: 1.1075, Avg Acc@1: 0.7530, Avg Acc@5: 0.9274
2022-01-19 18:21:52,293 Val Step[0450/1563], Avg Loss: 1.1162, Avg Acc@1: 0.7499, Avg Acc@5: 0.9268
2022-01-19 18:21:54,279 Val Step[0500/1563], Avg Loss: 1.1185, Avg Acc@1: 0.7506, Avg Acc@5: 0.9268
2022-01-19 18:21:56,185 Val Step[0550/1563], Avg Loss: 1.1193, Avg Acc@1: 0.7504, Avg Acc@5: 0.9268
2022-01-19 18:21:58,048 Val Step[0600/1563], Avg Loss: 1.1199, Avg Acc@1: 0.7494, Avg Acc@5: 0.9271
2022-01-19 18:22:00,072 Val Step[0650/1563], Avg Loss: 1.1207, Avg Acc@1: 0.7493, Avg Acc@5: 0.9270
2022-01-19 18:22:02,097 Val Step[0700/1563], Avg Loss: 1.1198, Avg Acc@1: 0.7499, Avg Acc@5: 0.9276
2022-01-19 18:22:04,156 Val Step[0750/1563], Avg Loss: 1.1253, Avg Acc@1: 0.7489, Avg Acc@5: 0.9271
2022-01-19 18:22:06,254 Val Step[0800/1563], Avg Loss: 1.1262, Avg Acc@1: 0.7490, Avg Acc@5: 0.9267
2022-01-19 18:22:08,340 Val Step[0850/1563], Avg Loss: 1.1297, Avg Acc@1: 0.7478, Avg Acc@5: 0.9263
2022-01-19 18:22:10,455 Val Step[0900/1563], Avg Loss: 1.1259, Avg Acc@1: 0.7483, Avg Acc@5: 0.9266
2022-01-19 18:22:12,478 Val Step[0950/1563], Avg Loss: 1.1245, Avg Acc@1: 0.7486, Avg Acc@5: 0.9268
2022-01-19 18:22:14,402 Val Step[1000/1563], Avg Loss: 1.1252, Avg Acc@1: 0.7488, Avg Acc@5: 0.9265
2022-01-19 18:22:16,256 Val Step[1050/1563], Avg Loss: 1.1257, Avg Acc@1: 0.7481, Avg Acc@5: 0.9262
2022-01-19 18:22:18,153 Val Step[1100/1563], Avg Loss: 1.1258, Avg Acc@1: 0.7477, Avg Acc@5: 0.9259
2022-01-19 18:22:20,161 Val Step[1150/1563], Avg Loss: 1.1241, Avg Acc@1: 0.7482, Avg Acc@5: 0.9262
2022-01-19 18:22:22,054 Val Step[1200/1563], Avg Loss: 1.1228, Avg Acc@1: 0.7490, Avg Acc@5: 0.9261
2022-01-19 18:22:23,931 Val Step[1250/1563], Avg Loss: 1.1226, Avg Acc@1: 0.7487, Avg Acc@5: 0.9261
2022-01-19 18:22:25,761 Val Step[1300/1563], Avg Loss: 1.1257, Avg Acc@1: 0.7480, Avg Acc@5: 0.9257
2022-01-19 18:22:27,619 Val Step[1350/1563], Avg Loss: 1.1265, Avg Acc@1: 0.7480, Avg Acc@5: 0.9255
2022-01-19 18:22:29,507 Val Step[1400/1563], Avg Loss: 1.1258, Avg Acc@1: 0.7479, Avg Acc@5: 0.9252
2022-01-19 18:22:31,341 Val Step[1450/1563], Avg Loss: 1.1256, Avg Acc@1: 0.7482, Avg Acc@5: 0.9253
2022-01-19 18:22:33,128 Val Step[1500/1563], Avg Loss: 1.1253, Avg Acc@1: 0.7483, Avg Acc@5: 0.9257
2022-01-19 18:22:34,868 Val Step[1550/1563], Avg Loss: 1.1253, Avg Acc@1: 0.7481, Avg Acc@5: 0.9257
2022-01-19 18:22:36,853 ----- Epoch[204/300], Validation Loss: 1.1251, Validation Acc@1: 0.7480, Validation Acc@5: 0.9258, time: 138.45
2022-01-19 18:22:37,994 the pre best model acc:0.7465, at epoch 200
2022-01-19 18:22:37,994 current best model acc:0.7480, at epoch 204
2022-01-19 18:22:37,994 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 18:22:37,994 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 18:22:37,994 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 18:22:37,994 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 18:22:37,995 Now training epoch 205. LR=0.000266
2022-01-19 18:24:25,055 Epoch[205/300], Step[0000/1252], Avg Loss: 3.3044, Avg Acc: 0.5459
2022-01-19 18:25:52,981 Epoch[205/300], Step[0050/1252], Avg Loss: 3.2074, Avg Acc: 0.4375
2022-01-19 18:27:19,917 Epoch[205/300], Step[0100/1252], Avg Loss: 3.1830, Avg Acc: 0.4520
2022-01-19 18:28:48,585 Epoch[205/300], Step[0150/1252], Avg Loss: 3.1877, Avg Acc: 0.4528
2022-01-19 18:30:16,593 Epoch[205/300], Step[0200/1252], Avg Loss: 3.1770, Avg Acc: 0.4546
2022-01-19 18:31:44,128 Epoch[205/300], Step[0250/1252], Avg Loss: 3.1761, Avg Acc: 0.4514
2022-01-19 18:33:12,569 Epoch[205/300], Step[0300/1252], Avg Loss: 3.1943, Avg Acc: 0.4472
2022-01-19 18:34:40,878 Epoch[205/300], Step[0350/1252], Avg Loss: 3.1926, Avg Acc: 0.4467
2022-01-19 18:36:09,075 Epoch[205/300], Step[0400/1252], Avg Loss: 3.2027, Avg Acc: 0.4423
2022-01-19 18:37:38,454 Epoch[205/300], Step[0450/1252], Avg Loss: 3.2027, Avg Acc: 0.4397
2022-01-19 18:39:05,939 Epoch[205/300], Step[0500/1252], Avg Loss: 3.2075, Avg Acc: 0.4404
2022-01-19 18:40:33,949 Epoch[205/300], Step[0550/1252], Avg Loss: 3.2070, Avg Acc: 0.4363
2022-01-19 18:42:02,973 Epoch[205/300], Step[0600/1252], Avg Loss: 3.2079, Avg Acc: 0.4349
2022-01-19 18:43:31,421 Epoch[205/300], Step[0650/1252], Avg Loss: 3.2082, Avg Acc: 0.4347
2022-01-19 18:44:58,806 Epoch[205/300], Step[0700/1252], Avg Loss: 3.2068, Avg Acc: 0.4346
2022-01-19 18:46:26,743 Epoch[205/300], Step[0750/1252], Avg Loss: 3.2065, Avg Acc: 0.4357
2022-01-19 18:47:55,335 Epoch[205/300], Step[0800/1252], Avg Loss: 3.2064, Avg Acc: 0.4361
2022-01-19 18:49:22,351 Epoch[205/300], Step[0850/1252], Avg Loss: 3.2079, Avg Acc: 0.4357
2022-01-19 18:50:51,218 Epoch[205/300], Step[0900/1252], Avg Loss: 3.2095, Avg Acc: 0.4358
2022-01-19 18:52:19,808 Epoch[205/300], Step[0950/1252], Avg Loss: 3.2104, Avg Acc: 0.4357
2022-01-19 18:53:48,171 Epoch[205/300], Step[1000/1252], Avg Loss: 3.2142, Avg Acc: 0.4366
2022-01-19 18:55:16,956 Epoch[205/300], Step[1050/1252], Avg Loss: 3.2145, Avg Acc: 0.4354
2022-01-19 18:56:45,350 Epoch[205/300], Step[1100/1252], Avg Loss: 3.2118, Avg Acc: 0.4349
2022-01-19 18:58:13,521 Epoch[205/300], Step[1150/1252], Avg Loss: 3.2108, Avg Acc: 0.4355
2022-01-19 18:59:42,189 Epoch[205/300], Step[1200/1252], Avg Loss: 3.2094, Avg Acc: 0.4369
2022-01-19 19:01:09,478 Epoch[205/300], Step[1250/1252], Avg Loss: 3.2119, Avg Acc: 0.4370
2022-01-19 19:01:16,567 ----- Epoch[205/300], Train Loss: 3.2119, Train Acc: 0.4369, time: 2318.57, Best Val(epoch204) Acc@1: 0.7480
2022-01-19 19:01:16,567 Now training epoch 206. LR=0.000261
2022-01-19 19:03:07,969 Epoch[206/300], Step[0000/1252], Avg Loss: 3.3971, Avg Acc: 0.3057
2022-01-19 19:04:37,071 Epoch[206/300], Step[0050/1252], Avg Loss: 3.2178, Avg Acc: 0.4383
2022-01-19 19:06:03,431 Epoch[206/300], Step[0100/1252], Avg Loss: 3.2089, Avg Acc: 0.4520
2022-01-19 19:07:32,165 Epoch[206/300], Step[0150/1252], Avg Loss: 3.2059, Avg Acc: 0.4387
2022-01-19 19:09:00,760 Epoch[206/300], Step[0200/1252], Avg Loss: 3.2015, Avg Acc: 0.4461
2022-01-19 19:10:28,272 Epoch[206/300], Step[0250/1252], Avg Loss: 3.1990, Avg Acc: 0.4423
2022-01-19 19:11:56,369 Epoch[206/300], Step[0300/1252], Avg Loss: 3.1959, Avg Acc: 0.4418
2022-01-19 19:13:24,683 Epoch[206/300], Step[0350/1252], Avg Loss: 3.1950, Avg Acc: 0.4416
2022-01-19 19:14:52,368 Epoch[206/300], Step[0400/1252], Avg Loss: 3.2040, Avg Acc: 0.4398
2022-01-19 19:16:19,307 Epoch[206/300], Step[0450/1252], Avg Loss: 3.2077, Avg Acc: 0.4395
2022-01-19 19:17:48,280 Epoch[206/300], Step[0500/1252], Avg Loss: 3.2078, Avg Acc: 0.4388
2022-01-19 19:19:15,276 Epoch[206/300], Step[0550/1252], Avg Loss: 3.2046, Avg Acc: 0.4410
2022-01-19 19:20:43,668 Epoch[206/300], Step[0600/1252], Avg Loss: 3.2074, Avg Acc: 0.4408
2022-01-19 19:22:11,792 Epoch[206/300], Step[0650/1252], Avg Loss: 3.2099, Avg Acc: 0.4403
2022-01-19 19:23:40,916 Epoch[206/300], Step[0700/1252], Avg Loss: 3.2094, Avg Acc: 0.4382
2022-01-19 19:25:08,999 Epoch[206/300], Step[0750/1252], Avg Loss: 3.2092, Avg Acc: 0.4398
2022-01-19 19:26:37,251 Epoch[206/300], Step[0800/1252], Avg Loss: 3.2122, Avg Acc: 0.4389
2022-01-19 19:28:05,315 Epoch[206/300], Step[0850/1252], Avg Loss: 3.2127, Avg Acc: 0.4389
2022-01-19 19:29:33,134 Epoch[206/300], Step[0900/1252], Avg Loss: 3.2123, Avg Acc: 0.4403
2022-01-19 19:31:01,447 Epoch[206/300], Step[0950/1252], Avg Loss: 3.2085, Avg Acc: 0.4400
2022-01-19 19:32:29,873 Epoch[206/300], Step[1000/1252], Avg Loss: 3.2091, Avg Acc: 0.4397
2022-01-19 19:33:58,886 Epoch[206/300], Step[1050/1252], Avg Loss: 3.2102, Avg Acc: 0.4384
2022-01-19 19:35:27,033 Epoch[206/300], Step[1100/1252], Avg Loss: 3.2098, Avg Acc: 0.4375
2022-01-19 19:36:56,052 Epoch[206/300], Step[1150/1252], Avg Loss: 3.2064, Avg Acc: 0.4370
2022-01-19 19:38:23,486 Epoch[206/300], Step[1200/1252], Avg Loss: 3.2055, Avg Acc: 0.4377
2022-01-19 19:39:52,236 Epoch[206/300], Step[1250/1252], Avg Loss: 3.2078, Avg Acc: 0.4368
2022-01-19 19:39:59,348 ----- Epoch[206/300], Train Loss: 3.2078, Train Acc: 0.4368, time: 2322.78, Best Val(epoch204) Acc@1: 0.7480
2022-01-19 19:39:59,348 ----- Validation after Epoch: 206
2022-01-19 19:41:20,899 Val Step[0000/1563], Avg Loss: 0.7160, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-19 19:41:23,296 Val Step[0050/1563], Avg Loss: 1.1185, Avg Acc@1: 0.7469, Avg Acc@5: 0.9228
2022-01-19 19:41:25,453 Val Step[0100/1563], Avg Loss: 1.1282, Avg Acc@1: 0.7450, Avg Acc@5: 0.9248
2022-01-19 19:41:27,525 Val Step[0150/1563], Avg Loss: 1.1263, Avg Acc@1: 0.7486, Avg Acc@5: 0.9226
2022-01-19 19:41:29,553 Val Step[0200/1563], Avg Loss: 1.1302, Avg Acc@1: 0.7502, Avg Acc@5: 0.9243
2022-01-19 19:41:31,570 Val Step[0250/1563], Avg Loss: 1.1203, Avg Acc@1: 0.7504, Avg Acc@5: 0.9244
2022-01-19 19:41:33,567 Val Step[0300/1563], Avg Loss: 1.1215, Avg Acc@1: 0.7510, Avg Acc@5: 0.9245
2022-01-19 19:41:35,470 Val Step[0350/1563], Avg Loss: 1.1254, Avg Acc@1: 0.7504, Avg Acc@5: 0.9249
2022-01-19 19:41:37,276 Val Step[0400/1563], Avg Loss: 1.1238, Avg Acc@1: 0.7501, Avg Acc@5: 0.9250
2022-01-19 19:41:39,091 Val Step[0450/1563], Avg Loss: 1.1307, Avg Acc@1: 0.7473, Avg Acc@5: 0.9246
2022-01-19 19:41:40,879 Val Step[0500/1563], Avg Loss: 1.1320, Avg Acc@1: 0.7471, Avg Acc@5: 0.9250
2022-01-19 19:41:42,754 Val Step[0550/1563], Avg Loss: 1.1318, Avg Acc@1: 0.7473, Avg Acc@5: 0.9252
2022-01-19 19:41:44,626 Val Step[0600/1563], Avg Loss: 1.1320, Avg Acc@1: 0.7475, Avg Acc@5: 0.9251
2022-01-19 19:41:46,531 Val Step[0650/1563], Avg Loss: 1.1316, Avg Acc@1: 0.7482, Avg Acc@5: 0.9251
2022-01-19 19:41:48,361 Val Step[0700/1563], Avg Loss: 1.1286, Avg Acc@1: 0.7493, Avg Acc@5: 0.9258
2022-01-19 19:41:50,230 Val Step[0750/1563], Avg Loss: 1.1333, Avg Acc@1: 0.7479, Avg Acc@5: 0.9249
2022-01-19 19:41:52,078 Val Step[0800/1563], Avg Loss: 1.1343, Avg Acc@1: 0.7483, Avg Acc@5: 0.9247
2022-01-19 19:41:53,992 Val Step[0850/1563], Avg Loss: 1.1362, Avg Acc@1: 0.7476, Avg Acc@5: 0.9243
2022-01-19 19:41:55,878 Val Step[0900/1563], Avg Loss: 1.1340, Avg Acc@1: 0.7476, Avg Acc@5: 0.9246
2022-01-19 19:41:57,725 Val Step[0950/1563], Avg Loss: 1.1334, Avg Acc@1: 0.7484, Avg Acc@5: 0.9249
2022-01-19 19:41:59,575 Val Step[1000/1563], Avg Loss: 1.1345, Avg Acc@1: 0.7485, Avg Acc@5: 0.9246
2022-01-19 19:42:01,429 Val Step[1050/1563], Avg Loss: 1.1364, Avg Acc@1: 0.7476, Avg Acc@5: 0.9242
2022-01-19 19:42:03,245 Val Step[1100/1563], Avg Loss: 1.1359, Avg Acc@1: 0.7474, Avg Acc@5: 0.9243
2022-01-19 19:42:05,072 Val Step[1150/1563], Avg Loss: 1.1342, Avg Acc@1: 0.7475, Avg Acc@5: 0.9245
2022-01-19 19:42:06,888 Val Step[1200/1563], Avg Loss: 1.1329, Avg Acc@1: 0.7479, Avg Acc@5: 0.9247
2022-01-19 19:42:08,757 Val Step[1250/1563], Avg Loss: 1.1320, Avg Acc@1: 0.7478, Avg Acc@5: 0.9248
2022-01-19 19:42:10,628 Val Step[1300/1563], Avg Loss: 1.1336, Avg Acc@1: 0.7477, Avg Acc@5: 0.9247
2022-01-19 19:42:12,536 Val Step[1350/1563], Avg Loss: 1.1348, Avg Acc@1: 0.7473, Avg Acc@5: 0.9245
2022-01-19 19:42:14,551 Val Step[1400/1563], Avg Loss: 1.1349, Avg Acc@1: 0.7472, Avg Acc@5: 0.9243
2022-01-19 19:42:16,505 Val Step[1450/1563], Avg Loss: 1.1340, Avg Acc@1: 0.7475, Avg Acc@5: 0.9245
2022-01-19 19:42:18,402 Val Step[1500/1563], Avg Loss: 1.1338, Avg Acc@1: 0.7478, Avg Acc@5: 0.9248
2022-01-19 19:42:20,157 Val Step[1550/1563], Avg Loss: 1.1340, Avg Acc@1: 0.7479, Avg Acc@5: 0.9248
2022-01-19 19:42:22,006 ----- Epoch[206/300], Validation Loss: 1.1340, Validation Acc@1: 0.7479, Validation Acc@5: 0.9249, time: 142.65
2022-01-19 19:42:22,006 Now training epoch 207. LR=0.000256
2022-01-19 19:44:14,193 Epoch[207/300], Step[0000/1252], Avg Loss: 2.6745, Avg Acc: 0.5137
2022-01-19 19:45:41,354 Epoch[207/300], Step[0050/1252], Avg Loss: 3.2027, Avg Acc: 0.4127
2022-01-19 19:47:09,446 Epoch[207/300], Step[0100/1252], Avg Loss: 3.1954, Avg Acc: 0.4263
2022-01-19 19:48:35,127 Epoch[207/300], Step[0150/1252], Avg Loss: 3.2000, Avg Acc: 0.4357
2022-01-19 19:50:02,944 Epoch[207/300], Step[0200/1252], Avg Loss: 3.1917, Avg Acc: 0.4336
2022-01-19 19:51:30,373 Epoch[207/300], Step[0250/1252], Avg Loss: 3.1735, Avg Acc: 0.4394
2022-01-19 19:52:56,996 Epoch[207/300], Step[0300/1252], Avg Loss: 3.1687, Avg Acc: 0.4404
2022-01-19 19:54:24,572 Epoch[207/300], Step[0350/1252], Avg Loss: 3.1767, Avg Acc: 0.4351
2022-01-19 19:55:51,986 Epoch[207/300], Step[0400/1252], Avg Loss: 3.1830, Avg Acc: 0.4353
2022-01-19 19:57:17,118 Epoch[207/300], Step[0450/1252], Avg Loss: 3.1919, Avg Acc: 0.4344
2022-01-19 19:58:44,698 Epoch[207/300], Step[0500/1252], Avg Loss: 3.1965, Avg Acc: 0.4367
2022-01-19 20:00:11,700 Epoch[207/300], Step[0550/1252], Avg Loss: 3.1947, Avg Acc: 0.4356
2022-01-19 20:01:38,403 Epoch[207/300], Step[0600/1252], Avg Loss: 3.1930, Avg Acc: 0.4368
2022-01-19 20:03:06,305 Epoch[207/300], Step[0650/1252], Avg Loss: 3.2001, Avg Acc: 0.4356
2022-01-19 20:04:34,570 Epoch[207/300], Step[0700/1252], Avg Loss: 3.1994, Avg Acc: 0.4360
2022-01-19 20:06:03,111 Epoch[207/300], Step[0750/1252], Avg Loss: 3.1952, Avg Acc: 0.4366
2022-01-19 20:07:31,059 Epoch[207/300], Step[0800/1252], Avg Loss: 3.1931, Avg Acc: 0.4381
2022-01-19 20:09:00,084 Epoch[207/300], Step[0850/1252], Avg Loss: 3.1977, Avg Acc: 0.4379
2022-01-19 20:10:28,946 Epoch[207/300], Step[0900/1252], Avg Loss: 3.2006, Avg Acc: 0.4364
2022-01-19 20:11:56,517 Epoch[207/300], Step[0950/1252], Avg Loss: 3.2008, Avg Acc: 0.4368
2022-01-19 20:13:24,177 Epoch[207/300], Step[1000/1252], Avg Loss: 3.2002, Avg Acc: 0.4389
2022-01-19 20:14:52,931 Epoch[207/300], Step[1050/1252], Avg Loss: 3.2000, Avg Acc: 0.4386
2022-01-19 20:16:21,760 Epoch[207/300], Step[1100/1252], Avg Loss: 3.2036, Avg Acc: 0.4391
2022-01-19 20:17:49,898 Epoch[207/300], Step[1150/1252], Avg Loss: 3.2053, Avg Acc: 0.4373
2022-01-19 20:19:18,376 Epoch[207/300], Step[1200/1252], Avg Loss: 3.2087, Avg Acc: 0.4370
2022-01-19 20:20:46,476 Epoch[207/300], Step[1250/1252], Avg Loss: 3.2086, Avg Acc: 0.4369
2022-01-19 20:20:53,557 ----- Epoch[207/300], Train Loss: 3.2085, Train Acc: 0.4369, time: 2311.55, Best Val(epoch204) Acc@1: 0.7480
2022-01-19 20:20:53,557 Now training epoch 208. LR=0.000251
2022-01-19 20:22:44,082 Epoch[208/300], Step[0000/1252], Avg Loss: 2.6728, Avg Acc: 0.5332
2022-01-19 20:24:12,153 Epoch[208/300], Step[0050/1252], Avg Loss: 3.2047, Avg Acc: 0.4524
2022-01-19 20:25:40,276 Epoch[208/300], Step[0100/1252], Avg Loss: 3.1845, Avg Acc: 0.4512
2022-01-19 20:27:08,266 Epoch[208/300], Step[0150/1252], Avg Loss: 3.2031, Avg Acc: 0.4459
2022-01-19 20:28:35,781 Epoch[208/300], Step[0200/1252], Avg Loss: 3.1980, Avg Acc: 0.4497
2022-01-19 20:30:03,814 Epoch[208/300], Step[0250/1252], Avg Loss: 3.2020, Avg Acc: 0.4450
2022-01-19 20:31:32,119 Epoch[208/300], Step[0300/1252], Avg Loss: 3.1962, Avg Acc: 0.4461
2022-01-19 20:33:00,074 Epoch[208/300], Step[0350/1252], Avg Loss: 3.1975, Avg Acc: 0.4431
2022-01-19 20:34:27,836 Epoch[208/300], Step[0400/1252], Avg Loss: 3.2021, Avg Acc: 0.4425
2022-01-19 20:35:55,305 Epoch[208/300], Step[0450/1252], Avg Loss: 3.2060, Avg Acc: 0.4413
2022-01-19 20:37:22,027 Epoch[208/300], Step[0500/1252], Avg Loss: 3.2066, Avg Acc: 0.4399
2022-01-19 20:38:48,038 Epoch[208/300], Step[0550/1252], Avg Loss: 3.2043, Avg Acc: 0.4415
2022-01-19 20:40:15,082 Epoch[208/300], Step[0600/1252], Avg Loss: 3.2096, Avg Acc: 0.4395
2022-01-19 20:41:40,775 Epoch[208/300], Step[0650/1252], Avg Loss: 3.2054, Avg Acc: 0.4397
2022-01-19 20:43:07,892 Epoch[208/300], Step[0700/1252], Avg Loss: 3.2047, Avg Acc: 0.4416
2022-01-19 20:44:34,493 Epoch[208/300], Step[0750/1252], Avg Loss: 3.2052, Avg Acc: 0.4401
2022-01-19 20:46:02,960 Epoch[208/300], Step[0800/1252], Avg Loss: 3.2044, Avg Acc: 0.4392
2022-01-19 20:47:30,756 Epoch[208/300], Step[0850/1252], Avg Loss: 3.2020, Avg Acc: 0.4376
2022-01-19 20:48:57,301 Epoch[208/300], Step[0900/1252], Avg Loss: 3.2006, Avg Acc: 0.4376
2022-01-19 20:50:24,845 Epoch[208/300], Step[0950/1252], Avg Loss: 3.1969, Avg Acc: 0.4365
2022-01-19 20:51:52,023 Epoch[208/300], Step[1000/1252], Avg Loss: 3.1977, Avg Acc: 0.4365
2022-01-19 20:53:19,781 Epoch[208/300], Step[1050/1252], Avg Loss: 3.2006, Avg Acc: 0.4350
2022-01-19 20:54:47,479 Epoch[208/300], Step[1100/1252], Avg Loss: 3.1990, Avg Acc: 0.4358
2022-01-19 20:56:14,060 Epoch[208/300], Step[1150/1252], Avg Loss: 3.2004, Avg Acc: 0.4356
2022-01-19 20:57:40,759 Epoch[208/300], Step[1200/1252], Avg Loss: 3.2023, Avg Acc: 0.4366
2022-01-19 20:59:07,967 Epoch[208/300], Step[1250/1252], Avg Loss: 3.2030, Avg Acc: 0.4364
2022-01-19 20:59:14,902 ----- Epoch[208/300], Train Loss: 3.2030, Train Acc: 0.4364, time: 2301.34, Best Val(epoch204) Acc@1: 0.7480
2022-01-19 20:59:14,902 ----- Validation after Epoch: 208
2022-01-19 21:00:47,994 Val Step[0000/1563], Avg Loss: 0.7612, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-19 21:00:49,925 Val Step[0050/1563], Avg Loss: 1.0894, Avg Acc@1: 0.7506, Avg Acc@5: 0.9320
2022-01-19 21:00:51,854 Val Step[0100/1563], Avg Loss: 1.1152, Avg Acc@1: 0.7466, Avg Acc@5: 0.9307
2022-01-19 21:00:53,859 Val Step[0150/1563], Avg Loss: 1.1117, Avg Acc@1: 0.7502, Avg Acc@5: 0.9282
2022-01-19 21:00:55,890 Val Step[0200/1563], Avg Loss: 1.1111, Avg Acc@1: 0.7533, Avg Acc@5: 0.9272
2022-01-19 21:00:57,816 Val Step[0250/1563], Avg Loss: 1.1052, Avg Acc@1: 0.7537, Avg Acc@5: 0.9285
2022-01-19 21:00:59,694 Val Step[0300/1563], Avg Loss: 1.1078, Avg Acc@1: 0.7539, Avg Acc@5: 0.9281
2022-01-19 21:01:01,529 Val Step[0350/1563], Avg Loss: 1.1133, Avg Acc@1: 0.7531, Avg Acc@5: 0.9277
2022-01-19 21:01:03,365 Val Step[0400/1563], Avg Loss: 1.1121, Avg Acc@1: 0.7530, Avg Acc@5: 0.9275
2022-01-19 21:01:05,204 Val Step[0450/1563], Avg Loss: 1.1200, Avg Acc@1: 0.7496, Avg Acc@5: 0.9269
2022-01-19 21:01:07,050 Val Step[0500/1563], Avg Loss: 1.1217, Avg Acc@1: 0.7494, Avg Acc@5: 0.9275
2022-01-19 21:01:08,963 Val Step[0550/1563], Avg Loss: 1.1230, Avg Acc@1: 0.7488, Avg Acc@5: 0.9277
2022-01-19 21:01:10,836 Val Step[0600/1563], Avg Loss: 1.1216, Avg Acc@1: 0.7486, Avg Acc@5: 0.9278
2022-01-19 21:01:12,640 Val Step[0650/1563], Avg Loss: 1.1198, Avg Acc@1: 0.7490, Avg Acc@5: 0.9281
2022-01-19 21:01:14,477 Val Step[0700/1563], Avg Loss: 1.1183, Avg Acc@1: 0.7494, Avg Acc@5: 0.9289
2022-01-19 21:01:16,311 Val Step[0750/1563], Avg Loss: 1.1250, Avg Acc@1: 0.7480, Avg Acc@5: 0.9280
2022-01-19 21:01:18,298 Val Step[0800/1563], Avg Loss: 1.1244, Avg Acc@1: 0.7482, Avg Acc@5: 0.9276
2022-01-19 21:01:20,352 Val Step[0850/1563], Avg Loss: 1.1264, Avg Acc@1: 0.7476, Avg Acc@5: 0.9271
2022-01-19 21:01:22,404 Val Step[0900/1563], Avg Loss: 1.1244, Avg Acc@1: 0.7482, Avg Acc@5: 0.9271
2022-01-19 21:01:24,482 Val Step[0950/1563], Avg Loss: 1.1234, Avg Acc@1: 0.7491, Avg Acc@5: 0.9277
2022-01-19 21:01:26,552 Val Step[1000/1563], Avg Loss: 1.1245, Avg Acc@1: 0.7492, Avg Acc@5: 0.9272
2022-01-19 21:01:28,359 Val Step[1050/1563], Avg Loss: 1.1247, Avg Acc@1: 0.7487, Avg Acc@5: 0.9271
2022-01-19 21:01:30,145 Val Step[1100/1563], Avg Loss: 1.1248, Avg Acc@1: 0.7485, Avg Acc@5: 0.9270
2022-01-19 21:01:31,940 Val Step[1150/1563], Avg Loss: 1.1232, Avg Acc@1: 0.7485, Avg Acc@5: 0.9271
2022-01-19 21:01:33,717 Val Step[1200/1563], Avg Loss: 1.1225, Avg Acc@1: 0.7489, Avg Acc@5: 0.9272
2022-01-19 21:01:35,520 Val Step[1250/1563], Avg Loss: 1.1222, Avg Acc@1: 0.7490, Avg Acc@5: 0.9275
2022-01-19 21:01:37,315 Val Step[1300/1563], Avg Loss: 1.1247, Avg Acc@1: 0.7487, Avg Acc@5: 0.9273
2022-01-19 21:01:39,215 Val Step[1350/1563], Avg Loss: 1.1251, Avg Acc@1: 0.7486, Avg Acc@5: 0.9271
2022-01-19 21:01:41,119 Val Step[1400/1563], Avg Loss: 1.1255, Avg Acc@1: 0.7485, Avg Acc@5: 0.9269
2022-01-19 21:01:43,038 Val Step[1450/1563], Avg Loss: 1.1250, Avg Acc@1: 0.7489, Avg Acc@5: 0.9269
2022-01-19 21:01:44,941 Val Step[1500/1563], Avg Loss: 1.1249, Avg Acc@1: 0.7493, Avg Acc@5: 0.9271
2022-01-19 21:01:46,960 Val Step[1550/1563], Avg Loss: 1.1253, Avg Acc@1: 0.7489, Avg Acc@5: 0.9272
2022-01-19 21:01:48,911 ----- Epoch[208/300], Validation Loss: 1.1251, Validation Acc@1: 0.7489, Validation Acc@5: 0.9272, time: 154.01
2022-01-19 21:01:50,056 the pre best model acc:0.7480, at epoch 204
2022-01-19 21:01:50,351 current best model acc:0.7489, at epoch 208
2022-01-19 21:01:50,351 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 21:01:50,351 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 21:01:50,351 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 21:01:50,351 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 21:01:50,351 Now training epoch 209. LR=0.000246
2022-01-19 21:03:48,720 Epoch[209/300], Step[0000/1252], Avg Loss: 3.0582, Avg Acc: 0.4961
2022-01-19 21:05:16,598 Epoch[209/300], Step[0050/1252], Avg Loss: 3.2102, Avg Acc: 0.4530
2022-01-19 21:06:43,810 Epoch[209/300], Step[0100/1252], Avg Loss: 3.1945, Avg Acc: 0.4514
2022-01-19 21:08:11,896 Epoch[209/300], Step[0150/1252], Avg Loss: 3.1912, Avg Acc: 0.4522
2022-01-19 21:09:38,826 Epoch[209/300], Step[0200/1252], Avg Loss: 3.2039, Avg Acc: 0.4472
2022-01-19 21:11:06,574 Epoch[209/300], Step[0250/1252], Avg Loss: 3.1913, Avg Acc: 0.4498
2022-01-19 21:12:34,912 Epoch[209/300], Step[0300/1252], Avg Loss: 3.1962, Avg Acc: 0.4497
2022-01-19 21:14:03,860 Epoch[209/300], Step[0350/1252], Avg Loss: 3.1956, Avg Acc: 0.4423
2022-01-19 21:15:32,550 Epoch[209/300], Step[0400/1252], Avg Loss: 3.1904, Avg Acc: 0.4433
2022-01-19 21:17:01,279 Epoch[209/300], Step[0450/1252], Avg Loss: 3.1923, Avg Acc: 0.4440
2022-01-19 21:18:29,273 Epoch[209/300], Step[0500/1252], Avg Loss: 3.1937, Avg Acc: 0.4424
2022-01-19 21:19:57,542 Epoch[209/300], Step[0550/1252], Avg Loss: 3.1988, Avg Acc: 0.4401
2022-01-19 21:21:25,344 Epoch[209/300], Step[0600/1252], Avg Loss: 3.2009, Avg Acc: 0.4403
2022-01-19 21:22:53,969 Epoch[209/300], Step[0650/1252], Avg Loss: 3.1988, Avg Acc: 0.4390
2022-01-19 21:24:22,517 Epoch[209/300], Step[0700/1252], Avg Loss: 3.2014, Avg Acc: 0.4387
2022-01-19 21:25:49,897 Epoch[209/300], Step[0750/1252], Avg Loss: 3.2047, Avg Acc: 0.4379
2022-01-19 21:27:17,650 Epoch[209/300], Step[0800/1252], Avg Loss: 3.2037, Avg Acc: 0.4389
2022-01-19 21:28:45,716 Epoch[209/300], Step[0850/1252], Avg Loss: 3.2019, Avg Acc: 0.4383
2022-01-19 21:30:13,921 Epoch[209/300], Step[0900/1252], Avg Loss: 3.2054, Avg Acc: 0.4385
2022-01-19 21:31:41,859 Epoch[209/300], Step[0950/1252], Avg Loss: 3.2081, Avg Acc: 0.4384
2022-01-19 21:33:10,856 Epoch[209/300], Step[1000/1252], Avg Loss: 3.2078, Avg Acc: 0.4368
2022-01-19 21:34:38,498 Epoch[209/300], Step[1050/1252], Avg Loss: 3.2080, Avg Acc: 0.4380
2022-01-19 21:36:07,835 Epoch[209/300], Step[1100/1252], Avg Loss: 3.2054, Avg Acc: 0.4380
2022-01-19 21:37:37,019 Epoch[209/300], Step[1150/1252], Avg Loss: 3.2064, Avg Acc: 0.4372
2022-01-19 21:39:06,044 Epoch[209/300], Step[1200/1252], Avg Loss: 3.2077, Avg Acc: 0.4369
2022-01-19 21:40:34,955 Epoch[209/300], Step[1250/1252], Avg Loss: 3.2102, Avg Acc: 0.4350
2022-01-19 21:40:41,864 ----- Epoch[209/300], Train Loss: 3.2102, Train Acc: 0.4350, time: 2331.51, Best Val(epoch208) Acc@1: 0.7489
2022-01-19 21:40:41,864 Now training epoch 210. LR=0.000242
2022-01-19 21:42:47,019 Epoch[210/300], Step[0000/1252], Avg Loss: 2.6212, Avg Acc: 0.7109
2022-01-19 21:44:14,425 Epoch[210/300], Step[0050/1252], Avg Loss: 3.0690, Avg Acc: 0.4604
2022-01-19 21:45:42,137 Epoch[210/300], Step[0100/1252], Avg Loss: 3.0971, Avg Acc: 0.4648
2022-01-19 21:47:10,959 Epoch[210/300], Step[0150/1252], Avg Loss: 3.1041, Avg Acc: 0.4519
2022-01-19 21:48:37,930 Epoch[210/300], Step[0200/1252], Avg Loss: 3.1136, Avg Acc: 0.4536
2022-01-19 21:50:06,094 Epoch[210/300], Step[0250/1252], Avg Loss: 3.1331, Avg Acc: 0.4486
2022-01-19 21:51:34,144 Epoch[210/300], Step[0300/1252], Avg Loss: 3.1342, Avg Acc: 0.4468
2022-01-19 21:53:01,837 Epoch[210/300], Step[0350/1252], Avg Loss: 3.1504, Avg Acc: 0.4493
2022-01-19 21:54:28,908 Epoch[210/300], Step[0400/1252], Avg Loss: 3.1542, Avg Acc: 0.4512
2022-01-19 21:55:57,023 Epoch[210/300], Step[0450/1252], Avg Loss: 3.1567, Avg Acc: 0.4480
2022-01-19 21:57:24,569 Epoch[210/300], Step[0500/1252], Avg Loss: 3.1610, Avg Acc: 0.4446
2022-01-19 21:58:52,694 Epoch[210/300], Step[0550/1252], Avg Loss: 3.1642, Avg Acc: 0.4457
2022-01-19 22:00:21,193 Epoch[210/300], Step[0600/1252], Avg Loss: 3.1700, Avg Acc: 0.4443
2022-01-19 22:01:47,126 Epoch[210/300], Step[0650/1252], Avg Loss: 3.1691, Avg Acc: 0.4454
2022-01-19 22:03:15,352 Epoch[210/300], Step[0700/1252], Avg Loss: 3.1719, Avg Acc: 0.4435
2022-01-19 22:04:43,487 Epoch[210/300], Step[0750/1252], Avg Loss: 3.1690, Avg Acc: 0.4436
2022-01-19 22:06:11,458 Epoch[210/300], Step[0800/1252], Avg Loss: 3.1726, Avg Acc: 0.4435
2022-01-19 22:07:39,160 Epoch[210/300], Step[0850/1252], Avg Loss: 3.1754, Avg Acc: 0.4418
2022-01-19 22:09:07,630 Epoch[210/300], Step[0900/1252], Avg Loss: 3.1747, Avg Acc: 0.4409
2022-01-19 22:10:35,195 Epoch[210/300], Step[0950/1252], Avg Loss: 3.1755, Avg Acc: 0.4420
2022-01-19 22:12:03,875 Epoch[210/300], Step[1000/1252], Avg Loss: 3.1775, Avg Acc: 0.4425
2022-01-19 22:13:32,875 Epoch[210/300], Step[1050/1252], Avg Loss: 3.1787, Avg Acc: 0.4412
2022-01-19 22:15:07,004 Epoch[210/300], Step[1100/1252], Avg Loss: 3.1784, Avg Acc: 0.4424
2022-01-19 22:16:34,035 Epoch[210/300], Step[1150/1252], Avg Loss: 3.1798, Avg Acc: 0.4417
2022-01-19 22:18:02,349 Epoch[210/300], Step[1200/1252], Avg Loss: 3.1822, Avg Acc: 0.4417
2022-01-19 22:19:29,525 Epoch[210/300], Step[1250/1252], Avg Loss: 3.1830, Avg Acc: 0.4401
2022-01-19 22:19:36,676 ----- Epoch[210/300], Train Loss: 3.1829, Train Acc: 0.4401, time: 2334.81, Best Val(epoch208) Acc@1: 0.7489
2022-01-19 22:19:36,676 ----- Validation after Epoch: 210
2022-01-19 22:20:56,661 Val Step[0000/1563], Avg Loss: 0.8208, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-19 22:20:58,850 Val Step[0050/1563], Avg Loss: 1.0902, Avg Acc@1: 0.7463, Avg Acc@5: 0.9271
2022-01-19 22:21:00,936 Val Step[0100/1563], Avg Loss: 1.1049, Avg Acc@1: 0.7503, Avg Acc@5: 0.9261
2022-01-19 22:21:03,054 Val Step[0150/1563], Avg Loss: 1.1118, Avg Acc@1: 0.7514, Avg Acc@5: 0.9224
2022-01-19 22:21:05,132 Val Step[0200/1563], Avg Loss: 1.1104, Avg Acc@1: 0.7547, Avg Acc@5: 0.9244
2022-01-19 22:21:07,213 Val Step[0250/1563], Avg Loss: 1.1001, Avg Acc@1: 0.7577, Avg Acc@5: 0.9260
2022-01-19 22:21:09,322 Val Step[0300/1563], Avg Loss: 1.1023, Avg Acc@1: 0.7572, Avg Acc@5: 0.9249
2022-01-19 22:21:11,431 Val Step[0350/1563], Avg Loss: 1.1063, Avg Acc@1: 0.7553, Avg Acc@5: 0.9248
2022-01-19 22:21:13,341 Val Step[0400/1563], Avg Loss: 1.1061, Avg Acc@1: 0.7557, Avg Acc@5: 0.9245
2022-01-19 22:21:15,254 Val Step[0450/1563], Avg Loss: 1.1107, Avg Acc@1: 0.7529, Avg Acc@5: 0.9244
2022-01-19 22:21:17,068 Val Step[0500/1563], Avg Loss: 1.1136, Avg Acc@1: 0.7523, Avg Acc@5: 0.9245
2022-01-19 22:21:19,130 Val Step[0550/1563], Avg Loss: 1.1144, Avg Acc@1: 0.7514, Avg Acc@5: 0.9246
2022-01-19 22:21:21,211 Val Step[0600/1563], Avg Loss: 1.1146, Avg Acc@1: 0.7510, Avg Acc@5: 0.9243
2022-01-19 22:21:23,308 Val Step[0650/1563], Avg Loss: 1.1157, Avg Acc@1: 0.7505, Avg Acc@5: 0.9245
2022-01-19 22:21:25,382 Val Step[0700/1563], Avg Loss: 1.1139, Avg Acc@1: 0.7514, Avg Acc@5: 0.9256
2022-01-19 22:21:27,440 Val Step[0750/1563], Avg Loss: 1.1191, Avg Acc@1: 0.7501, Avg Acc@5: 0.9253
2022-01-19 22:21:29,476 Val Step[0800/1563], Avg Loss: 1.1196, Avg Acc@1: 0.7507, Avg Acc@5: 0.9251
2022-01-19 22:21:31,318 Val Step[0850/1563], Avg Loss: 1.1207, Avg Acc@1: 0.7500, Avg Acc@5: 0.9251
2022-01-19 22:21:33,125 Val Step[0900/1563], Avg Loss: 1.1177, Avg Acc@1: 0.7508, Avg Acc@5: 0.9256
2022-01-19 22:21:34,936 Val Step[0950/1563], Avg Loss: 1.1158, Avg Acc@1: 0.7516, Avg Acc@5: 0.9260
2022-01-19 22:21:36,838 Val Step[1000/1563], Avg Loss: 1.1166, Avg Acc@1: 0.7513, Avg Acc@5: 0.9259
2022-01-19 22:21:38,746 Val Step[1050/1563], Avg Loss: 1.1185, Avg Acc@1: 0.7504, Avg Acc@5: 0.9253
2022-01-19 22:21:40,555 Val Step[1100/1563], Avg Loss: 1.1188, Avg Acc@1: 0.7503, Avg Acc@5: 0.9251
2022-01-19 22:21:42,394 Val Step[1150/1563], Avg Loss: 1.1174, Avg Acc@1: 0.7504, Avg Acc@5: 0.9254
2022-01-19 22:21:44,312 Val Step[1200/1563], Avg Loss: 1.1156, Avg Acc@1: 0.7509, Avg Acc@5: 0.9258
2022-01-19 22:21:46,131 Val Step[1250/1563], Avg Loss: 1.1143, Avg Acc@1: 0.7507, Avg Acc@5: 0.9262
2022-01-19 22:21:47,994 Val Step[1300/1563], Avg Loss: 1.1181, Avg Acc@1: 0.7505, Avg Acc@5: 0.9256
2022-01-19 22:21:49,961 Val Step[1350/1563], Avg Loss: 1.1185, Avg Acc@1: 0.7505, Avg Acc@5: 0.9254
2022-01-19 22:21:51,947 Val Step[1400/1563], Avg Loss: 1.1180, Avg Acc@1: 0.7505, Avg Acc@5: 0.9251
2022-01-19 22:21:53,781 Val Step[1450/1563], Avg Loss: 1.1169, Avg Acc@1: 0.7509, Avg Acc@5: 0.9252
2022-01-19 22:21:55,693 Val Step[1500/1563], Avg Loss: 1.1167, Avg Acc@1: 0.7514, Avg Acc@5: 0.9255
2022-01-19 22:21:57,505 Val Step[1550/1563], Avg Loss: 1.1170, Avg Acc@1: 0.7512, Avg Acc@5: 0.9255
2022-01-19 22:21:59,438 ----- Epoch[210/300], Validation Loss: 1.1168, Validation Acc@1: 0.7511, Validation Acc@5: 0.9257, time: 142.76
2022-01-19 22:22:00,663 the pre best model acc:0.7489, at epoch 208
2022-01-19 22:22:00,663 current best model acc:0.7511, at epoch 210
2022-01-19 22:22:00,663 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 22:22:00,663 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 22:22:00,663 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-19 22:22:00,663 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-19 22:22:00,664 Now training epoch 211. LR=0.000237
2022-01-19 22:23:52,845 Epoch[211/300], Step[0000/1252], Avg Loss: 3.1004, Avg Acc: 0.3594
2022-01-19 22:25:19,795 Epoch[211/300], Step[0050/1252], Avg Loss: 3.2294, Avg Acc: 0.4298
2022-01-19 22:26:45,442 Epoch[211/300], Step[0100/1252], Avg Loss: 3.2236, Avg Acc: 0.4409
2022-01-19 22:28:11,268 Epoch[211/300], Step[0150/1252], Avg Loss: 3.1995, Avg Acc: 0.4391
2022-01-19 22:29:39,237 Epoch[211/300], Step[0200/1252], Avg Loss: 3.1891, Avg Acc: 0.4438
2022-01-19 22:31:06,061 Epoch[211/300], Step[0250/1252], Avg Loss: 3.1838, Avg Acc: 0.4537
2022-01-19 22:32:34,692 Epoch[211/300], Step[0300/1252], Avg Loss: 3.1943, Avg Acc: 0.4436
2022-01-19 22:34:01,995 Epoch[211/300], Step[0350/1252], Avg Loss: 3.1859, Avg Acc: 0.4456
2022-01-19 22:35:29,904 Epoch[211/300], Step[0400/1252], Avg Loss: 3.1954, Avg Acc: 0.4440
2022-01-19 22:36:58,339 Epoch[211/300], Step[0450/1252], Avg Loss: 3.1999, Avg Acc: 0.4411
2022-01-19 22:38:26,919 Epoch[211/300], Step[0500/1252], Avg Loss: 3.1989, Avg Acc: 0.4415
2022-01-19 22:39:55,628 Epoch[211/300], Step[0550/1252], Avg Loss: 3.1981, Avg Acc: 0.4390
2022-01-19 22:41:23,325 Epoch[211/300], Step[0600/1252], Avg Loss: 3.1956, Avg Acc: 0.4389
2022-01-19 22:42:51,822 Epoch[211/300], Step[0650/1252], Avg Loss: 3.1953, Avg Acc: 0.4380
2022-01-19 22:44:20,159 Epoch[211/300], Step[0700/1252], Avg Loss: 3.1933, Avg Acc: 0.4366
2022-01-19 22:45:49,002 Epoch[211/300], Step[0750/1252], Avg Loss: 3.1973, Avg Acc: 0.4354
2022-01-19 22:47:16,008 Epoch[211/300], Step[0800/1252], Avg Loss: 3.1975, Avg Acc: 0.4383
2022-01-19 22:48:44,010 Epoch[211/300], Step[0850/1252], Avg Loss: 3.1977, Avg Acc: 0.4391
2022-01-19 22:50:11,487 Epoch[211/300], Step[0900/1252], Avg Loss: 3.1978, Avg Acc: 0.4379
2022-01-19 22:51:39,062 Epoch[211/300], Step[0950/1252], Avg Loss: 3.1989, Avg Acc: 0.4374
2022-01-19 22:53:07,000 Epoch[211/300], Step[1000/1252], Avg Loss: 3.1961, Avg Acc: 0.4374
2022-01-19 22:54:33,831 Epoch[211/300], Step[1050/1252], Avg Loss: 3.1979, Avg Acc: 0.4379
2022-01-19 22:56:01,315 Epoch[211/300], Step[1100/1252], Avg Loss: 3.1994, Avg Acc: 0.4365
2022-01-19 22:57:28,247 Epoch[211/300], Step[1150/1252], Avg Loss: 3.1986, Avg Acc: 0.4374
2022-01-19 22:58:56,332 Epoch[211/300], Step[1200/1252], Avg Loss: 3.2017, Avg Acc: 0.4378
2022-01-19 23:00:24,414 Epoch[211/300], Step[1250/1252], Avg Loss: 3.1982, Avg Acc: 0.4388
2022-01-19 23:00:31,381 ----- Epoch[211/300], Train Loss: 3.1982, Train Acc: 0.4388, time: 2310.71, Best Val(epoch210) Acc@1: 0.7511
2022-01-19 23:00:31,382 Now training epoch 212. LR=0.000232
