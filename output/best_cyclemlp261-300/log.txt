2022-01-22 10:16:43,012 
AMP: False
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 256
  BATCH_SIZE_EVAL: 8
  CROP_PCT: 0.9
  DATASET: imagenet2012
  DATA_PATH: /root/paddlejob/workspace/train_data/datasets/Light_ILSVRC2012
  IMAGE_SIZE: 224
  NUM_WORKERS: 16
EVAL: False
LOCAL_RANK: 0
MODEL:
  MIXER:
    EMBED_DIMS: [64, 128, 320, 512]
    LAYERS: [2, 2, 4, 2]
    MLP_RATIOS: [4, 4, 4, 4]
    TRANSITIONS: [True, True, True, True]
  NAME: cyclemlp_b1
  NUM_CLASSES: 1000
  PRETRAINED: None
  RESUME: Best_CycleMLP
  TYPE: CycleMLP
NGPUS: 4
REPORT_FREQ: 50
SAVE: /root/paddlejob/workspace/output//train
SAVE_FREQ: 50
SEED: 0
TAG: default
TRAIN:
  ACCUM_ITER: 1
  AUTO_AUGMENT: True
  BASE_LR: 0.0005
  COLOR_JITTER: 0.4
  CUTMIX_ALPHA: 1.0
  CUTMIX_MINMAX: None
  END_LR: 5e-06
  GRAD_CLIP: 5.0
  LAST_EPOCH: 260
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    MILESTONES: 30, 60, 90
    NAME: warmupcosine
  MIXUP_ALPHA: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  NUM_EPOCHS: 300
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: AdamW
  RANDOM_ERASE_COUNT: 1
  RANDOM_ERASE_MODE: pixel
  RANDOM_ERASE_PROB: 0.25
  RANDOM_ERASE_SPLIT: False
  SMOOTHING: 0.1
  WARMUP_EPOCHS: 20
  WARMUP_START_LR: 5e-07
  WEIGHT_DECAY: 0.05
VALIDATE_FREQ: 2
VALIDATION:
  REQUIREMENTS: 0.789
2022-01-22 10:16:43,012 ----- world_size = 4, local_rank = 0
2022-01-22 10:16:43,767 ----- Total # of train batch (single gpu): 1252
2022-01-22 10:16:43,767 ----- Total # of val batch (single gpu): 1563
2022-01-22 10:16:45,420 ----- Resume Training: Load model and optmizer from Best_CycleMLP
2022-01-22 10:16:45,420 Start training from epoch 261.
2022-01-22 10:16:45,420 Now training epoch 261. LR=0.000057
2022-01-22 10:18:35,276 Epoch[261/300], Step[0000/1252], Avg Loss: 2.9080, Avg Acc: 0.3125
2022-01-22 10:20:03,582 Epoch[261/300], Step[0050/1252], Avg Loss: 3.0259, Avg Acc: 0.4489
2022-01-22 10:21:30,816 Epoch[261/300], Step[0100/1252], Avg Loss: 3.0205, Avg Acc: 0.4620
2022-01-22 10:22:58,681 Epoch[261/300], Step[0150/1252], Avg Loss: 3.0060, Avg Acc: 0.4598
2022-01-22 10:24:27,433 Epoch[261/300], Step[0200/1252], Avg Loss: 2.9883, Avg Acc: 0.4609
2022-01-22 10:25:57,070 Epoch[261/300], Step[0250/1252], Avg Loss: 2.9759, Avg Acc: 0.4639
2022-01-22 10:27:25,300 Epoch[261/300], Step[0300/1252], Avg Loss: 2.9633, Avg Acc: 0.4705
2022-01-22 10:28:54,908 Epoch[261/300], Step[0350/1252], Avg Loss: 2.9796, Avg Acc: 0.4722
2022-01-22 10:30:23,842 Epoch[261/300], Step[0400/1252], Avg Loss: 2.9776, Avg Acc: 0.4703
2022-01-22 10:31:51,882 Epoch[261/300], Step[0450/1252], Avg Loss: 2.9835, Avg Acc: 0.4674
2022-01-22 10:33:20,071 Epoch[261/300], Step[0500/1252], Avg Loss: 2.9817, Avg Acc: 0.4689
2022-01-22 10:34:47,677 Epoch[261/300], Step[0550/1252], Avg Loss: 2.9754, Avg Acc: 0.4704
2022-01-22 10:36:17,439 Epoch[261/300], Step[0600/1252], Avg Loss: 2.9777, Avg Acc: 0.4717
2022-01-22 10:37:47,136 Epoch[261/300], Step[0650/1252], Avg Loss: 2.9800, Avg Acc: 0.4696
2022-01-22 10:39:16,269 Epoch[261/300], Step[0700/1252], Avg Loss: 2.9788, Avg Acc: 0.4711
2022-01-22 10:40:46,341 Epoch[261/300], Step[0750/1252], Avg Loss: 2.9786, Avg Acc: 0.4729
2022-01-22 10:42:15,356 Epoch[261/300], Step[0800/1252], Avg Loss: 2.9794, Avg Acc: 0.4724
2022-01-22 10:43:45,206 Epoch[261/300], Step[0850/1252], Avg Loss: 2.9755, Avg Acc: 0.4713
2022-01-22 10:45:14,908 Epoch[261/300], Step[0900/1252], Avg Loss: 2.9761, Avg Acc: 0.4720
2022-01-22 10:46:45,264 Epoch[261/300], Step[0950/1252], Avg Loss: 2.9738, Avg Acc: 0.4729
2022-01-22 10:48:15,138 Epoch[261/300], Step[1000/1252], Avg Loss: 2.9744, Avg Acc: 0.4717
2022-01-22 10:49:44,331 Epoch[261/300], Step[1050/1252], Avg Loss: 2.9746, Avg Acc: 0.4692
2022-01-22 10:51:13,690 Epoch[261/300], Step[1100/1252], Avg Loss: 2.9746, Avg Acc: 0.4684
2022-01-22 10:52:42,479 Epoch[261/300], Step[1150/1252], Avg Loss: 2.9758, Avg Acc: 0.4681
2022-01-22 10:54:12,446 Epoch[261/300], Step[1200/1252], Avg Loss: 2.9762, Avg Acc: 0.4676
2022-01-22 10:55:41,560 Epoch[261/300], Step[1250/1252], Avg Loss: 2.9763, Avg Acc: 0.4671
2022-01-22 10:55:47,460 ----- Epoch[261/300], Train Loss: 2.9762, Train Acc: 0.4670, time: 2342.04
2022-01-22 10:55:47,460 Now training epoch 262. LR=0.000054
2022-01-22 10:57:33,890 Epoch[262/300], Step[0000/1252], Avg Loss: 3.0155, Avg Acc: 0.2891
2022-01-22 10:59:01,155 Epoch[262/300], Step[0050/1252], Avg Loss: 3.0419, Avg Acc: 0.4606
2022-01-22 11:00:27,787 Epoch[262/300], Step[0100/1252], Avg Loss: 3.0008, Avg Acc: 0.4577
2022-01-22 11:01:53,796 Epoch[262/300], Step[0150/1252], Avg Loss: 3.0071, Avg Acc: 0.4609
2022-01-22 11:03:20,278 Epoch[262/300], Step[0200/1252], Avg Loss: 2.9985, Avg Acc: 0.4656
2022-01-22 11:04:47,408 Epoch[262/300], Step[0250/1252], Avg Loss: 2.9890, Avg Acc: 0.4705
2022-01-22 11:06:12,837 Epoch[262/300], Step[0300/1252], Avg Loss: 2.9903, Avg Acc: 0.4734
2022-01-22 11:07:40,565 Epoch[262/300], Step[0350/1252], Avg Loss: 2.9928, Avg Acc: 0.4710
2022-01-22 11:09:08,302 Epoch[262/300], Step[0400/1252], Avg Loss: 2.9892, Avg Acc: 0.4719
2022-01-22 11:10:35,625 Epoch[262/300], Step[0450/1252], Avg Loss: 2.9888, Avg Acc: 0.4708
2022-01-22 11:12:01,564 Epoch[262/300], Step[0500/1252], Avg Loss: 2.9868, Avg Acc: 0.4682
2022-01-22 11:13:27,253 Epoch[262/300], Step[0550/1252], Avg Loss: 2.9857, Avg Acc: 0.4682
2022-01-22 11:14:52,767 Epoch[262/300], Step[0600/1252], Avg Loss: 2.9833, Avg Acc: 0.4710
2022-01-22 11:16:19,889 Epoch[262/300], Step[0650/1252], Avg Loss: 2.9778, Avg Acc: 0.4691
2022-01-22 11:17:44,504 Epoch[262/300], Step[0700/1252], Avg Loss: 2.9693, Avg Acc: 0.4708
2022-01-22 11:19:10,532 Epoch[262/300], Step[0750/1252], Avg Loss: 2.9668, Avg Acc: 0.4726
2022-01-22 11:20:35,826 Epoch[262/300], Step[0800/1252], Avg Loss: 2.9697, Avg Acc: 0.4703
2022-01-22 11:22:02,657 Epoch[262/300], Step[0850/1252], Avg Loss: 2.9702, Avg Acc: 0.4686
2022-01-22 11:23:28,376 Epoch[262/300], Step[0900/1252], Avg Loss: 2.9733, Avg Acc: 0.4687
2022-01-22 11:24:53,455 Epoch[262/300], Step[0950/1252], Avg Loss: 2.9755, Avg Acc: 0.4687
2022-01-22 11:26:19,249 Epoch[262/300], Step[1000/1252], Avg Loss: 2.9760, Avg Acc: 0.4678
2022-01-22 11:27:46,191 Epoch[262/300], Step[1050/1252], Avg Loss: 2.9755, Avg Acc: 0.4660
2022-01-22 11:29:12,824 Epoch[262/300], Step[1100/1252], Avg Loss: 2.9772, Avg Acc: 0.4661
2022-01-22 11:30:39,091 Epoch[262/300], Step[1150/1252], Avg Loss: 2.9767, Avg Acc: 0.4654
2022-01-22 11:32:06,955 Epoch[262/300], Step[1200/1252], Avg Loss: 2.9778, Avg Acc: 0.4669
2022-01-22 11:33:33,581 Epoch[262/300], Step[1250/1252], Avg Loss: 2.9783, Avg Acc: 0.4680
2022-01-22 11:33:40,136 ----- Epoch[262/300], Train Loss: 2.9783, Train Acc: 0.4679, time: 2272.67
2022-01-22 11:33:40,136 ----- Validation after Epoch: 262
2022-01-22 11:34:56,573 Val Step[0000/1563], Avg Loss: 0.7918, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-22 11:34:58,682 Val Step[0050/1563], Avg Loss: 1.0222, Avg Acc@1: 0.7770, Avg Acc@5: 0.9400
2022-01-22 11:35:00,753 Val Step[0100/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7772, Avg Acc@5: 0.9390
2022-01-22 11:35:02,867 Val Step[0150/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7750, Avg Acc@5: 0.9377
2022-01-22 11:35:04,961 Val Step[0200/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7772, Avg Acc@5: 0.9375
2022-01-22 11:35:06,945 Val Step[0250/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7758, Avg Acc@5: 0.9387
2022-01-22 11:35:08,890 Val Step[0300/1563], Avg Loss: 1.0385, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-22 11:35:10,839 Val Step[0350/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7753, Avg Acc@5: 0.9363
2022-01-22 11:35:12,862 Val Step[0400/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7749, Avg Acc@5: 0.9356
2022-01-22 11:35:14,779 Val Step[0450/1563], Avg Loss: 1.0489, Avg Acc@1: 0.7727, Avg Acc@5: 0.9356
2022-01-22 11:35:16,663 Val Step[0500/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7733, Avg Acc@5: 0.9360
2022-01-22 11:35:18,564 Val Step[0550/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7728, Avg Acc@5: 0.9362
2022-01-22 11:35:20,597 Val Step[0600/1563], Avg Loss: 1.0475, Avg Acc@1: 0.7727, Avg Acc@5: 0.9362
2022-01-22 11:35:22,657 Val Step[0650/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7727, Avg Acc@5: 0.9361
2022-01-22 11:35:24,700 Val Step[0700/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7731, Avg Acc@5: 0.9367
2022-01-22 11:35:26,749 Val Step[0750/1563], Avg Loss: 1.0535, Avg Acc@1: 0.7713, Avg Acc@5: 0.9362
2022-01-22 11:35:28,804 Val Step[0800/1563], Avg Loss: 1.0535, Avg Acc@1: 0.7720, Avg Acc@5: 0.9361
2022-01-22 11:35:30,863 Val Step[0850/1563], Avg Loss: 1.0549, Avg Acc@1: 0.7717, Avg Acc@5: 0.9356
2022-01-22 11:35:32,803 Val Step[0900/1563], Avg Loss: 1.0525, Avg Acc@1: 0.7722, Avg Acc@5: 0.9359
2022-01-22 11:35:34,691 Val Step[0950/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7729, Avg Acc@5: 0.9361
2022-01-22 11:35:36,601 Val Step[1000/1563], Avg Loss: 1.0536, Avg Acc@1: 0.7729, Avg Acc@5: 0.9357
2022-01-22 11:35:38,556 Val Step[1050/1563], Avg Loss: 1.0551, Avg Acc@1: 0.7724, Avg Acc@5: 0.9354
2022-01-22 11:35:40,487 Val Step[1100/1563], Avg Loss: 1.0547, Avg Acc@1: 0.7720, Avg Acc@5: 0.9356
2022-01-22 11:35:42,393 Val Step[1150/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7720, Avg Acc@5: 0.9358
2022-01-22 11:35:44,281 Val Step[1200/1563], Avg Loss: 1.0517, Avg Acc@1: 0.7726, Avg Acc@5: 0.9359
2022-01-22 11:35:46,146 Val Step[1250/1563], Avg Loss: 1.0513, Avg Acc@1: 0.7723, Avg Acc@5: 0.9361
2022-01-22 11:35:48,017 Val Step[1300/1563], Avg Loss: 1.0537, Avg Acc@1: 0.7720, Avg Acc@5: 0.9359
2022-01-22 11:35:49,891 Val Step[1350/1563], Avg Loss: 1.0546, Avg Acc@1: 0.7718, Avg Acc@5: 0.9358
2022-01-22 11:35:51,774 Val Step[1400/1563], Avg Loss: 1.0538, Avg Acc@1: 0.7716, Avg Acc@5: 0.9358
2022-01-22 11:35:53,674 Val Step[1450/1563], Avg Loss: 1.0527, Avg Acc@1: 0.7717, Avg Acc@5: 0.9359
2022-01-22 11:35:55,588 Val Step[1500/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7718, Avg Acc@5: 0.9362
2022-01-22 11:35:57,427 Val Step[1550/1563], Avg Loss: 1.0533, Avg Acc@1: 0.7714, Avg Acc@5: 0.9361
2022-01-22 11:35:59,169 ----- Epoch[262/300], Validation Loss: 1.0531, Validation Acc@1: 0.7714, Validation Acc@5: 0.9361, time: 139.03
2022-01-22 11:35:59,643 the pre best model acc:0.0000, at epoch 0
2022-01-22 11:35:59,643 current best model acc:0.7714, at epoch 262
2022-01-22 11:35:59,643 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 11:35:59,643 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 11:35:59,643 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 11:35:59,643 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 11:35:59,644 Now training epoch 263. LR=0.000052
2022-01-22 11:37:50,736 Epoch[263/300], Step[0000/1252], Avg Loss: 2.7299, Avg Acc: 0.6055
2022-01-22 11:39:18,192 Epoch[263/300], Step[0050/1252], Avg Loss: 2.9400, Avg Acc: 0.5027
2022-01-22 11:40:45,019 Epoch[263/300], Step[0100/1252], Avg Loss: 2.9485, Avg Acc: 0.5035
2022-01-22 11:42:11,604 Epoch[263/300], Step[0150/1252], Avg Loss: 2.9522, Avg Acc: 0.4876
2022-01-22 11:43:37,556 Epoch[263/300], Step[0200/1252], Avg Loss: 2.9611, Avg Acc: 0.4863
2022-01-22 11:45:04,684 Epoch[263/300], Step[0250/1252], Avg Loss: 2.9632, Avg Acc: 0.4875
2022-01-22 11:46:31,589 Epoch[263/300], Step[0300/1252], Avg Loss: 2.9569, Avg Acc: 0.4873
2022-01-22 11:47:58,632 Epoch[263/300], Step[0350/1252], Avg Loss: 2.9613, Avg Acc: 0.4859
2022-01-22 11:49:24,494 Epoch[263/300], Step[0400/1252], Avg Loss: 2.9612, Avg Acc: 0.4859
2022-01-22 11:50:52,178 Epoch[263/300], Step[0450/1252], Avg Loss: 2.9579, Avg Acc: 0.4828
2022-01-22 11:52:19,890 Epoch[263/300], Step[0500/1252], Avg Loss: 2.9571, Avg Acc: 0.4793
2022-01-22 11:53:47,441 Epoch[263/300], Step[0550/1252], Avg Loss: 2.9637, Avg Acc: 0.4783
2022-01-22 11:55:15,288 Epoch[263/300], Step[0600/1252], Avg Loss: 2.9644, Avg Acc: 0.4791
2022-01-22 11:56:43,936 Epoch[263/300], Step[0650/1252], Avg Loss: 2.9638, Avg Acc: 0.4792
2022-01-22 11:58:11,612 Epoch[263/300], Step[0700/1252], Avg Loss: 2.9658, Avg Acc: 0.4761
2022-01-22 11:59:39,550 Epoch[263/300], Step[0750/1252], Avg Loss: 2.9697, Avg Acc: 0.4743
2022-01-22 12:01:07,697 Epoch[263/300], Step[0800/1252], Avg Loss: 2.9718, Avg Acc: 0.4756
2022-01-22 12:02:34,464 Epoch[263/300], Step[0850/1252], Avg Loss: 2.9723, Avg Acc: 0.4747
2022-01-22 12:04:01,542 Epoch[263/300], Step[0900/1252], Avg Loss: 2.9741, Avg Acc: 0.4716
2022-01-22 12:05:28,288 Epoch[263/300], Step[0950/1252], Avg Loss: 2.9716, Avg Acc: 0.4718
2022-01-22 12:06:55,720 Epoch[263/300], Step[1000/1252], Avg Loss: 2.9715, Avg Acc: 0.4724
2022-01-22 12:08:23,957 Epoch[263/300], Step[1050/1252], Avg Loss: 2.9711, Avg Acc: 0.4714
2022-01-22 12:09:52,435 Epoch[263/300], Step[1100/1252], Avg Loss: 2.9718, Avg Acc: 0.4710
2022-01-22 12:11:19,363 Epoch[263/300], Step[1150/1252], Avg Loss: 2.9742, Avg Acc: 0.4709
2022-01-22 12:12:46,294 Epoch[263/300], Step[1200/1252], Avg Loss: 2.9725, Avg Acc: 0.4709
2022-01-22 12:14:14,717 Epoch[263/300], Step[1250/1252], Avg Loss: 2.9757, Avg Acc: 0.4691
2022-01-22 12:14:21,381 ----- Epoch[263/300], Train Loss: 2.9757, Train Acc: 0.4691, time: 2301.73, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 12:14:21,381 Now training epoch 264. LR=0.000050
2022-01-22 12:16:13,860 Epoch[264/300], Step[0000/1252], Avg Loss: 2.2966, Avg Acc: 0.6064
2022-01-22 12:17:40,760 Epoch[264/300], Step[0050/1252], Avg Loss: 2.9801, Avg Acc: 0.4823
2022-01-22 12:19:07,087 Epoch[264/300], Step[0100/1252], Avg Loss: 2.9846, Avg Acc: 0.4770
2022-01-22 12:20:34,097 Epoch[264/300], Step[0150/1252], Avg Loss: 2.9679, Avg Acc: 0.4909
2022-01-22 12:22:01,279 Epoch[264/300], Step[0200/1252], Avg Loss: 2.9716, Avg Acc: 0.4797
2022-01-22 12:23:28,291 Epoch[264/300], Step[0250/1252], Avg Loss: 2.9638, Avg Acc: 0.4710
2022-01-22 12:24:55,820 Epoch[264/300], Step[0300/1252], Avg Loss: 2.9713, Avg Acc: 0.4750
2022-01-22 12:26:23,394 Epoch[264/300], Step[0350/1252], Avg Loss: 2.9627, Avg Acc: 0.4771
2022-01-22 12:27:51,311 Epoch[264/300], Step[0400/1252], Avg Loss: 2.9603, Avg Acc: 0.4774
2022-01-22 12:29:19,076 Epoch[264/300], Step[0450/1252], Avg Loss: 2.9623, Avg Acc: 0.4761
2022-01-22 12:30:46,628 Epoch[264/300], Step[0500/1252], Avg Loss: 2.9681, Avg Acc: 0.4759
2022-01-22 12:32:14,332 Epoch[264/300], Step[0550/1252], Avg Loss: 2.9643, Avg Acc: 0.4776
2022-01-22 12:33:42,827 Epoch[264/300], Step[0600/1252], Avg Loss: 2.9660, Avg Acc: 0.4770
2022-01-22 12:35:09,385 Epoch[264/300], Step[0650/1252], Avg Loss: 2.9668, Avg Acc: 0.4756
2022-01-22 12:36:37,983 Epoch[264/300], Step[0700/1252], Avg Loss: 2.9708, Avg Acc: 0.4740
2022-01-22 12:38:05,737 Epoch[264/300], Step[0750/1252], Avg Loss: 2.9726, Avg Acc: 0.4726
2022-01-22 12:39:33,982 Epoch[264/300], Step[0800/1252], Avg Loss: 2.9763, Avg Acc: 0.4699
2022-01-22 12:41:01,260 Epoch[264/300], Step[0850/1252], Avg Loss: 2.9803, Avg Acc: 0.4684
2022-01-22 12:42:29,150 Epoch[264/300], Step[0900/1252], Avg Loss: 2.9821, Avg Acc: 0.4685
2022-01-22 12:43:56,956 Epoch[264/300], Step[0950/1252], Avg Loss: 2.9835, Avg Acc: 0.4682
2022-01-22 12:45:23,172 Epoch[264/300], Step[1000/1252], Avg Loss: 2.9809, Avg Acc: 0.4684
2022-01-22 12:46:50,221 Epoch[264/300], Step[1050/1252], Avg Loss: 2.9805, Avg Acc: 0.4696
2022-01-22 12:48:17,878 Epoch[264/300], Step[1100/1252], Avg Loss: 2.9794, Avg Acc: 0.4702
2022-01-22 12:49:44,302 Epoch[264/300], Step[1150/1252], Avg Loss: 2.9767, Avg Acc: 0.4711
2022-01-22 12:51:12,609 Epoch[264/300], Step[1200/1252], Avg Loss: 2.9771, Avg Acc: 0.4719
2022-01-22 12:52:41,602 Epoch[264/300], Step[1250/1252], Avg Loss: 2.9784, Avg Acc: 0.4709
2022-01-22 12:52:48,250 ----- Epoch[264/300], Train Loss: 2.9784, Train Acc: 0.4709, time: 2306.86, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 12:52:48,250 ----- Validation after Epoch: 264
2022-01-22 12:54:08,661 Val Step[0000/1563], Avg Loss: 0.8334, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-22 12:54:10,622 Val Step[0050/1563], Avg Loss: 1.0217, Avg Acc@1: 0.7788, Avg Acc@5: 0.9406
2022-01-22 12:54:12,584 Val Step[0100/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7760, Avg Acc@5: 0.9390
2022-01-22 12:54:14,630 Val Step[0150/1563], Avg Loss: 1.0494, Avg Acc@1: 0.7742, Avg Acc@5: 0.9356
2022-01-22 12:54:16,547 Val Step[0200/1563], Avg Loss: 1.0508, Avg Acc@1: 0.7767, Avg Acc@5: 0.9366
2022-01-22 12:54:18,447 Val Step[0250/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7776, Avg Acc@5: 0.9389
2022-01-22 12:54:20,352 Val Step[0300/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7765, Avg Acc@5: 0.9375
2022-01-22 12:54:22,194 Val Step[0350/1563], Avg Loss: 1.0467, Avg Acc@1: 0.7748, Avg Acc@5: 0.9364
2022-01-22 12:54:24,023 Val Step[0400/1563], Avg Loss: 1.0486, Avg Acc@1: 0.7749, Avg Acc@5: 0.9360
2022-01-22 12:54:26,051 Val Step[0450/1563], Avg Loss: 1.0550, Avg Acc@1: 0.7720, Avg Acc@5: 0.9358
2022-01-22 12:54:28,137 Val Step[0500/1563], Avg Loss: 1.0573, Avg Acc@1: 0.7717, Avg Acc@5: 0.9359
2022-01-22 12:54:30,280 Val Step[0550/1563], Avg Loss: 1.0567, Avg Acc@1: 0.7701, Avg Acc@5: 0.9363
2022-01-22 12:54:32,427 Val Step[0600/1563], Avg Loss: 1.0558, Avg Acc@1: 0.7699, Avg Acc@5: 0.9360
2022-01-22 12:54:34,543 Val Step[0650/1563], Avg Loss: 1.0558, Avg Acc@1: 0.7705, Avg Acc@5: 0.9364
2022-01-22 12:54:36,634 Val Step[0700/1563], Avg Loss: 1.0535, Avg Acc@1: 0.7712, Avg Acc@5: 0.9367
2022-01-22 12:54:38,772 Val Step[0750/1563], Avg Loss: 1.0588, Avg Acc@1: 0.7696, Avg Acc@5: 0.9365
2022-01-22 12:54:40,952 Val Step[0800/1563], Avg Loss: 1.0587, Avg Acc@1: 0.7701, Avg Acc@5: 0.9361
2022-01-22 12:54:43,038 Val Step[0850/1563], Avg Loss: 1.0604, Avg Acc@1: 0.7700, Avg Acc@5: 0.9357
2022-01-22 12:54:45,149 Val Step[0900/1563], Avg Loss: 1.0576, Avg Acc@1: 0.7709, Avg Acc@5: 0.9361
2022-01-22 12:54:47,224 Val Step[0950/1563], Avg Loss: 1.0573, Avg Acc@1: 0.7714, Avg Acc@5: 0.9362
2022-01-22 12:54:49,320 Val Step[1000/1563], Avg Loss: 1.0592, Avg Acc@1: 0.7712, Avg Acc@5: 0.9355
2022-01-22 12:54:51,408 Val Step[1050/1563], Avg Loss: 1.0604, Avg Acc@1: 0.7707, Avg Acc@5: 0.9354
2022-01-22 12:54:53,277 Val Step[1100/1563], Avg Loss: 1.0608, Avg Acc@1: 0.7703, Avg Acc@5: 0.9353
2022-01-22 12:54:55,190 Val Step[1150/1563], Avg Loss: 1.0587, Avg Acc@1: 0.7707, Avg Acc@5: 0.9355
2022-01-22 12:54:57,321 Val Step[1200/1563], Avg Loss: 1.0571, Avg Acc@1: 0.7716, Avg Acc@5: 0.9358
2022-01-22 12:54:59,424 Val Step[1250/1563], Avg Loss: 1.0565, Avg Acc@1: 0.7715, Avg Acc@5: 0.9360
2022-01-22 12:55:01,508 Val Step[1300/1563], Avg Loss: 1.0594, Avg Acc@1: 0.7709, Avg Acc@5: 0.9357
2022-01-22 12:55:03,560 Val Step[1350/1563], Avg Loss: 1.0609, Avg Acc@1: 0.7705, Avg Acc@5: 0.9356
2022-01-22 12:55:05,412 Val Step[1400/1563], Avg Loss: 1.0603, Avg Acc@1: 0.7703, Avg Acc@5: 0.9356
2022-01-22 12:55:07,276 Val Step[1450/1563], Avg Loss: 1.0592, Avg Acc@1: 0.7707, Avg Acc@5: 0.9358
2022-01-22 12:55:09,143 Val Step[1500/1563], Avg Loss: 1.0592, Avg Acc@1: 0.7708, Avg Acc@5: 0.9361
2022-01-22 12:55:10,951 Val Step[1550/1563], Avg Loss: 1.0594, Avg Acc@1: 0.7705, Avg Acc@5: 0.9359
2022-01-22 12:55:12,619 ----- Epoch[264/300], Validation Loss: 1.0593, Validation Acc@1: 0.7704, Validation Acc@5: 0.9360, time: 144.37
2022-01-22 12:55:12,619 Now training epoch 265. LR=0.000048
2022-01-22 12:57:02,741 Epoch[265/300], Step[0000/1252], Avg Loss: 2.5085, Avg Acc: 0.7422
2022-01-22 12:58:28,149 Epoch[265/300], Step[0050/1252], Avg Loss: 2.9918, Avg Acc: 0.4494
2022-01-22 12:59:52,488 Epoch[265/300], Step[0100/1252], Avg Loss: 2.9742, Avg Acc: 0.4908
2022-01-22 13:01:19,226 Epoch[265/300], Step[0150/1252], Avg Loss: 2.9524, Avg Acc: 0.4962
2022-01-22 13:02:45,335 Epoch[265/300], Step[0200/1252], Avg Loss: 2.9549, Avg Acc: 0.4851
2022-01-22 13:04:11,864 Epoch[265/300], Step[0250/1252], Avg Loss: 2.9644, Avg Acc: 0.4830
2022-01-22 13:05:39,338 Epoch[265/300], Step[0300/1252], Avg Loss: 2.9667, Avg Acc: 0.4808
2022-01-22 13:07:06,443 Epoch[265/300], Step[0350/1252], Avg Loss: 2.9652, Avg Acc: 0.4779
2022-01-22 13:08:33,543 Epoch[265/300], Step[0400/1252], Avg Loss: 2.9697, Avg Acc: 0.4810
2022-01-22 13:10:01,547 Epoch[265/300], Step[0450/1252], Avg Loss: 2.9718, Avg Acc: 0.4794
2022-01-22 13:11:28,059 Epoch[265/300], Step[0500/1252], Avg Loss: 2.9667, Avg Acc: 0.4796
2022-01-22 13:12:55,212 Epoch[265/300], Step[0550/1252], Avg Loss: 2.9637, Avg Acc: 0.4786
2022-01-22 13:14:24,306 Epoch[265/300], Step[0600/1252], Avg Loss: 2.9670, Avg Acc: 0.4766
2022-01-22 13:15:51,656 Epoch[265/300], Step[0650/1252], Avg Loss: 2.9663, Avg Acc: 0.4730
2022-01-22 13:17:20,294 Epoch[265/300], Step[0700/1252], Avg Loss: 2.9680, Avg Acc: 0.4723
2022-01-22 13:18:48,411 Epoch[265/300], Step[0750/1252], Avg Loss: 2.9651, Avg Acc: 0.4731
2022-01-22 13:20:16,599 Epoch[265/300], Step[0800/1252], Avg Loss: 2.9625, Avg Acc: 0.4733
2022-01-22 13:21:45,222 Epoch[265/300], Step[0850/1252], Avg Loss: 2.9635, Avg Acc: 0.4735
2022-01-22 13:23:13,459 Epoch[265/300], Step[0900/1252], Avg Loss: 2.9663, Avg Acc: 0.4733
2022-01-22 13:24:41,602 Epoch[265/300], Step[0950/1252], Avg Loss: 2.9669, Avg Acc: 0.4740
2022-01-22 13:26:09,761 Epoch[265/300], Step[1000/1252], Avg Loss: 2.9700, Avg Acc: 0.4730
2022-01-22 13:27:38,388 Epoch[265/300], Step[1050/1252], Avg Loss: 2.9668, Avg Acc: 0.4738
2022-01-22 13:29:07,474 Epoch[265/300], Step[1100/1252], Avg Loss: 2.9673, Avg Acc: 0.4744
2022-01-22 13:30:35,541 Epoch[265/300], Step[1150/1252], Avg Loss: 2.9671, Avg Acc: 0.4744
2022-01-22 13:32:03,852 Epoch[265/300], Step[1200/1252], Avg Loss: 2.9667, Avg Acc: 0.4742
2022-01-22 13:33:33,345 Epoch[265/300], Step[1250/1252], Avg Loss: 2.9690, Avg Acc: 0.4730
2022-01-22 13:33:39,526 ----- Epoch[265/300], Train Loss: 2.9689, Train Acc: 0.4730, time: 2306.90, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 13:33:39,527 Now training epoch 266. LR=0.000046
2022-01-22 13:35:31,777 Epoch[266/300], Step[0000/1252], Avg Loss: 3.2118, Avg Acc: 0.1758
2022-01-22 13:36:58,901 Epoch[266/300], Step[0050/1252], Avg Loss: 3.0403, Avg Acc: 0.4610
2022-01-22 13:38:25,385 Epoch[266/300], Step[0100/1252], Avg Loss: 3.0075, Avg Acc: 0.4743
2022-01-22 13:39:52,733 Epoch[266/300], Step[0150/1252], Avg Loss: 3.0167, Avg Acc: 0.4731
2022-01-22 13:41:19,275 Epoch[266/300], Step[0200/1252], Avg Loss: 3.0087, Avg Acc: 0.4623
2022-01-22 13:42:46,775 Epoch[266/300], Step[0250/1252], Avg Loss: 2.9984, Avg Acc: 0.4649
2022-01-22 13:44:13,864 Epoch[266/300], Step[0300/1252], Avg Loss: 3.0039, Avg Acc: 0.4658
2022-01-22 13:45:40,679 Epoch[266/300], Step[0350/1252], Avg Loss: 2.9970, Avg Acc: 0.4656
2022-01-22 13:47:07,622 Epoch[266/300], Step[0400/1252], Avg Loss: 2.9940, Avg Acc: 0.4676
2022-01-22 13:48:34,887 Epoch[266/300], Step[0450/1252], Avg Loss: 2.9830, Avg Acc: 0.4736
2022-01-22 13:50:02,963 Epoch[266/300], Step[0500/1252], Avg Loss: 2.9816, Avg Acc: 0.4719
2022-01-22 13:51:31,272 Epoch[266/300], Step[0550/1252], Avg Loss: 2.9810, Avg Acc: 0.4712
2022-01-22 13:52:59,724 Epoch[266/300], Step[0600/1252], Avg Loss: 2.9754, Avg Acc: 0.4697
2022-01-22 13:54:27,630 Epoch[266/300], Step[0650/1252], Avg Loss: 2.9734, Avg Acc: 0.4693
2022-01-22 13:55:56,239 Epoch[266/300], Step[0700/1252], Avg Loss: 2.9739, Avg Acc: 0.4700
2022-01-22 13:57:23,771 Epoch[266/300], Step[0750/1252], Avg Loss: 2.9706, Avg Acc: 0.4705
2022-01-22 13:58:49,035 Epoch[266/300], Step[0800/1252], Avg Loss: 2.9697, Avg Acc: 0.4727
2022-01-22 14:00:15,969 Epoch[266/300], Step[0850/1252], Avg Loss: 2.9702, Avg Acc: 0.4731
2022-01-22 14:01:44,297 Epoch[266/300], Step[0900/1252], Avg Loss: 2.9714, Avg Acc: 0.4731
2022-01-22 14:03:13,064 Epoch[266/300], Step[0950/1252], Avg Loss: 2.9679, Avg Acc: 0.4725
2022-01-22 14:04:41,424 Epoch[266/300], Step[1000/1252], Avg Loss: 2.9676, Avg Acc: 0.4714
2022-01-22 14:06:09,630 Epoch[266/300], Step[1050/1252], Avg Loss: 2.9681, Avg Acc: 0.4692
2022-01-22 14:07:37,381 Epoch[266/300], Step[1100/1252], Avg Loss: 2.9667, Avg Acc: 0.4694
2022-01-22 14:09:03,865 Epoch[266/300], Step[1150/1252], Avg Loss: 2.9658, Avg Acc: 0.4694
2022-01-22 14:10:31,972 Epoch[266/300], Step[1200/1252], Avg Loss: 2.9660, Avg Acc: 0.4700
2022-01-22 14:12:00,535 Epoch[266/300], Step[1250/1252], Avg Loss: 2.9689, Avg Acc: 0.4716
2022-01-22 14:12:07,276 ----- Epoch[266/300], Train Loss: 2.9689, Train Acc: 0.4716, time: 2307.75, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 14:12:07,276 ----- Validation after Epoch: 266
2022-01-22 14:13:21,605 Val Step[0000/1563], Avg Loss: 0.8379, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-22 14:13:23,476 Val Step[0050/1563], Avg Loss: 1.0141, Avg Acc@1: 0.7739, Avg Acc@5: 0.9387
2022-01-22 14:13:25,368 Val Step[0100/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-22 14:13:27,261 Val Step[0150/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7769, Avg Acc@5: 0.9354
2022-01-22 14:13:29,185 Val Step[0200/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7774, Avg Acc@5: 0.9356
2022-01-22 14:13:30,996 Val Step[0250/1563], Avg Loss: 1.0357, Avg Acc@1: 0.7780, Avg Acc@5: 0.9368
2022-01-22 14:13:32,985 Val Step[0300/1563], Avg Loss: 1.0354, Avg Acc@1: 0.7770, Avg Acc@5: 0.9362
2022-01-22 14:13:34,849 Val Step[0350/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7764, Avg Acc@5: 0.9353
2022-01-22 14:13:36,735 Val Step[0400/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7752, Avg Acc@5: 0.9349
2022-01-22 14:13:38,596 Val Step[0450/1563], Avg Loss: 1.0470, Avg Acc@1: 0.7728, Avg Acc@5: 0.9344
2022-01-22 14:13:40,446 Val Step[0500/1563], Avg Loss: 1.0486, Avg Acc@1: 0.7724, Avg Acc@5: 0.9348
2022-01-22 14:13:42,385 Val Step[0550/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7713, Avg Acc@5: 0.9351
2022-01-22 14:13:44,392 Val Step[0600/1563], Avg Loss: 1.0473, Avg Acc@1: 0.7714, Avg Acc@5: 0.9350
2022-01-22 14:13:46,344 Val Step[0650/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7713, Avg Acc@5: 0.9349
2022-01-22 14:13:48,257 Val Step[0700/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7719, Avg Acc@5: 0.9358
2022-01-22 14:13:50,230 Val Step[0750/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7703, Avg Acc@5: 0.9355
2022-01-22 14:13:52,136 Val Step[0800/1563], Avg Loss: 1.0513, Avg Acc@1: 0.7713, Avg Acc@5: 0.9351
2022-01-22 14:13:54,061 Val Step[0850/1563], Avg Loss: 1.0525, Avg Acc@1: 0.7710, Avg Acc@5: 0.9351
2022-01-22 14:13:55,919 Val Step[0900/1563], Avg Loss: 1.0503, Avg Acc@1: 0.7713, Avg Acc@5: 0.9352
2022-01-22 14:13:57,888 Val Step[0950/1563], Avg Loss: 1.0502, Avg Acc@1: 0.7718, Avg Acc@5: 0.9352
2022-01-22 14:13:59,903 Val Step[1000/1563], Avg Loss: 1.0516, Avg Acc@1: 0.7716, Avg Acc@5: 0.9347
2022-01-22 14:14:01,722 Val Step[1050/1563], Avg Loss: 1.0531, Avg Acc@1: 0.7711, Avg Acc@5: 0.9343
2022-01-22 14:14:03,549 Val Step[1100/1563], Avg Loss: 1.0531, Avg Acc@1: 0.7707, Avg Acc@5: 0.9343
2022-01-22 14:14:05,417 Val Step[1150/1563], Avg Loss: 1.0507, Avg Acc@1: 0.7709, Avg Acc@5: 0.9347
2022-01-22 14:14:07,284 Val Step[1200/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7716, Avg Acc@5: 0.9347
2022-01-22 14:14:09,173 Val Step[1250/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7714, Avg Acc@5: 0.9350
2022-01-22 14:14:11,045 Val Step[1300/1563], Avg Loss: 1.0518, Avg Acc@1: 0.7712, Avg Acc@5: 0.9346
2022-01-22 14:14:12,879 Val Step[1350/1563], Avg Loss: 1.0528, Avg Acc@1: 0.7707, Avg Acc@5: 0.9346
2022-01-22 14:14:14,701 Val Step[1400/1563], Avg Loss: 1.0523, Avg Acc@1: 0.7706, Avg Acc@5: 0.9345
2022-01-22 14:14:16,589 Val Step[1450/1563], Avg Loss: 1.0510, Avg Acc@1: 0.7708, Avg Acc@5: 0.9346
2022-01-22 14:14:18,707 Val Step[1500/1563], Avg Loss: 1.0509, Avg Acc@1: 0.7710, Avg Acc@5: 0.9348
2022-01-22 14:14:20,841 Val Step[1550/1563], Avg Loss: 1.0512, Avg Acc@1: 0.7707, Avg Acc@5: 0.9348
2022-01-22 14:14:22,717 ----- Epoch[266/300], Validation Loss: 1.0510, Validation Acc@1: 0.7708, Validation Acc@5: 0.9349, time: 135.44
2022-01-22 14:14:22,718 Now training epoch 267. LR=0.000044
2022-01-22 14:16:12,337 Epoch[267/300], Step[0000/1252], Avg Loss: 2.5495, Avg Acc: 0.3828
2022-01-22 14:17:39,545 Epoch[267/300], Step[0050/1252], Avg Loss: 2.9780, Avg Acc: 0.4707
2022-01-22 14:19:06,025 Epoch[267/300], Step[0100/1252], Avg Loss: 2.9612, Avg Acc: 0.4705
2022-01-22 14:20:32,745 Epoch[267/300], Step[0150/1252], Avg Loss: 2.9569, Avg Acc: 0.4671
2022-01-22 14:22:00,403 Epoch[267/300], Step[0200/1252], Avg Loss: 2.9509, Avg Acc: 0.4747
2022-01-22 14:23:27,872 Epoch[267/300], Step[0250/1252], Avg Loss: 2.9510, Avg Acc: 0.4760
2022-01-22 14:24:56,052 Epoch[267/300], Step[0300/1252], Avg Loss: 2.9512, Avg Acc: 0.4736
2022-01-22 14:26:23,479 Epoch[267/300], Step[0350/1252], Avg Loss: 2.9505, Avg Acc: 0.4735
2022-01-22 14:27:50,223 Epoch[267/300], Step[0400/1252], Avg Loss: 2.9620, Avg Acc: 0.4727
2022-01-22 14:29:17,905 Epoch[267/300], Step[0450/1252], Avg Loss: 2.9606, Avg Acc: 0.4734
2022-01-22 14:30:45,629 Epoch[267/300], Step[0500/1252], Avg Loss: 2.9571, Avg Acc: 0.4755
2022-01-22 14:32:11,941 Epoch[267/300], Step[0550/1252], Avg Loss: 2.9563, Avg Acc: 0.4748
2022-01-22 14:33:39,623 Epoch[267/300], Step[0600/1252], Avg Loss: 2.9575, Avg Acc: 0.4764
2022-01-22 14:35:07,839 Epoch[267/300], Step[0650/1252], Avg Loss: 2.9533, Avg Acc: 0.4788
2022-01-22 14:36:35,479 Epoch[267/300], Step[0700/1252], Avg Loss: 2.9547, Avg Acc: 0.4776
2022-01-22 14:38:03,336 Epoch[267/300], Step[0750/1252], Avg Loss: 2.9566, Avg Acc: 0.4778
2022-01-22 14:39:31,045 Epoch[267/300], Step[0800/1252], Avg Loss: 2.9592, Avg Acc: 0.4775
2022-01-22 14:40:59,157 Epoch[267/300], Step[0850/1252], Avg Loss: 2.9615, Avg Acc: 0.4776
2022-01-22 14:42:25,666 Epoch[267/300], Step[0900/1252], Avg Loss: 2.9601, Avg Acc: 0.4766
2022-01-22 14:43:54,188 Epoch[267/300], Step[0950/1252], Avg Loss: 2.9598, Avg Acc: 0.4763
2022-01-22 14:45:20,222 Epoch[267/300], Step[1000/1252], Avg Loss: 2.9597, Avg Acc: 0.4776
2022-01-22 14:46:47,987 Epoch[267/300], Step[1050/1252], Avg Loss: 2.9603, Avg Acc: 0.4778
2022-01-22 14:48:14,092 Epoch[267/300], Step[1100/1252], Avg Loss: 2.9631, Avg Acc: 0.4770
2022-01-22 14:49:42,159 Epoch[267/300], Step[1150/1252], Avg Loss: 2.9655, Avg Acc: 0.4763
2022-01-22 14:51:08,428 Epoch[267/300], Step[1200/1252], Avg Loss: 2.9642, Avg Acc: 0.4770
2022-01-22 14:52:36,521 Epoch[267/300], Step[1250/1252], Avg Loss: 2.9644, Avg Acc: 0.4772
2022-01-22 14:52:42,832 ----- Epoch[267/300], Train Loss: 2.9644, Train Acc: 0.4773, time: 2300.11, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 14:52:42,832 Now training epoch 268. LR=0.000042
2022-01-22 14:54:32,641 Epoch[268/300], Step[0000/1252], Avg Loss: 2.6879, Avg Acc: 0.4102
2022-01-22 14:55:58,648 Epoch[268/300], Step[0050/1252], Avg Loss: 2.9324, Avg Acc: 0.5257
2022-01-22 14:57:25,900 Epoch[268/300], Step[0100/1252], Avg Loss: 2.9691, Avg Acc: 0.4844
2022-01-22 14:58:52,578 Epoch[268/300], Step[0150/1252], Avg Loss: 2.9586, Avg Acc: 0.4753
2022-01-22 15:00:19,350 Epoch[268/300], Step[0200/1252], Avg Loss: 2.9515, Avg Acc: 0.4736
2022-01-22 15:01:46,589 Epoch[268/300], Step[0250/1252], Avg Loss: 2.9442, Avg Acc: 0.4748
2022-01-22 15:03:13,720 Epoch[268/300], Step[0300/1252], Avg Loss: 2.9403, Avg Acc: 0.4785
2022-01-22 15:04:41,025 Epoch[268/300], Step[0350/1252], Avg Loss: 2.9395, Avg Acc: 0.4788
2022-01-22 15:06:08,580 Epoch[268/300], Step[0400/1252], Avg Loss: 2.9441, Avg Acc: 0.4814
2022-01-22 15:07:36,084 Epoch[268/300], Step[0450/1252], Avg Loss: 2.9421, Avg Acc: 0.4850
2022-01-22 15:09:03,524 Epoch[268/300], Step[0500/1252], Avg Loss: 2.9406, Avg Acc: 0.4854
2022-01-22 15:10:30,935 Epoch[268/300], Step[0550/1252], Avg Loss: 2.9414, Avg Acc: 0.4800
2022-01-22 15:11:57,531 Epoch[268/300], Step[0600/1252], Avg Loss: 2.9423, Avg Acc: 0.4837
2022-01-22 15:13:25,299 Epoch[268/300], Step[0650/1252], Avg Loss: 2.9478, Avg Acc: 0.4843
2022-01-22 15:14:53,350 Epoch[268/300], Step[0700/1252], Avg Loss: 2.9505, Avg Acc: 0.4839
2022-01-22 15:16:20,980 Epoch[268/300], Step[0750/1252], Avg Loss: 2.9507, Avg Acc: 0.4839
2022-01-22 15:17:48,516 Epoch[268/300], Step[0800/1252], Avg Loss: 2.9478, Avg Acc: 0.4845
2022-01-22 15:19:16,281 Epoch[268/300], Step[0850/1252], Avg Loss: 2.9479, Avg Acc: 0.4847
2022-01-22 15:20:44,000 Epoch[268/300], Step[0900/1252], Avg Loss: 2.9481, Avg Acc: 0.4839
2022-01-22 15:22:12,715 Epoch[268/300], Step[0950/1252], Avg Loss: 2.9505, Avg Acc: 0.4821
2022-01-22 15:23:39,623 Epoch[268/300], Step[1000/1252], Avg Loss: 2.9528, Avg Acc: 0.4810
2022-01-22 15:25:07,718 Epoch[268/300], Step[1050/1252], Avg Loss: 2.9538, Avg Acc: 0.4794
2022-01-22 15:26:35,326 Epoch[268/300], Step[1100/1252], Avg Loss: 2.9525, Avg Acc: 0.4813
2022-01-22 15:28:02,940 Epoch[268/300], Step[1150/1252], Avg Loss: 2.9521, Avg Acc: 0.4809
2022-01-22 15:29:30,779 Epoch[268/300], Step[1200/1252], Avg Loss: 2.9505, Avg Acc: 0.4800
2022-01-22 15:30:59,302 Epoch[268/300], Step[1250/1252], Avg Loss: 2.9482, Avg Acc: 0.4813
2022-01-22 15:31:05,633 ----- Epoch[268/300], Train Loss: 2.9482, Train Acc: 0.4813, time: 2302.80, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 15:31:05,633 ----- Validation after Epoch: 268
2022-01-22 15:32:19,510 Val Step[0000/1563], Avg Loss: 0.8578, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-22 15:32:21,362 Val Step[0050/1563], Avg Loss: 1.0043, Avg Acc@1: 0.7708, Avg Acc@5: 0.9430
2022-01-22 15:32:23,461 Val Step[0100/1563], Avg Loss: 1.0274, Avg Acc@1: 0.7732, Avg Acc@5: 0.9403
2022-01-22 15:32:25,543 Val Step[0150/1563], Avg Loss: 1.0357, Avg Acc@1: 0.7742, Avg Acc@5: 0.9377
2022-01-22 15:32:27,504 Val Step[0200/1563], Avg Loss: 1.0358, Avg Acc@1: 0.7760, Avg Acc@5: 0.9380
2022-01-22 15:32:29,459 Val Step[0250/1563], Avg Loss: 1.0279, Avg Acc@1: 0.7759, Avg Acc@5: 0.9387
2022-01-22 15:32:31,350 Val Step[0300/1563], Avg Loss: 1.0288, Avg Acc@1: 0.7759, Avg Acc@5: 0.9376
2022-01-22 15:32:33,243 Val Step[0350/1563], Avg Loss: 1.0323, Avg Acc@1: 0.7754, Avg Acc@5: 0.9371
2022-01-22 15:32:35,187 Val Step[0400/1563], Avg Loss: 1.0319, Avg Acc@1: 0.7756, Avg Acc@5: 0.9367
2022-01-22 15:32:37,101 Val Step[0450/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7732, Avg Acc@5: 0.9361
2022-01-22 15:32:39,043 Val Step[0500/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7726, Avg Acc@5: 0.9368
2022-01-22 15:32:41,042 Val Step[0550/1563], Avg Loss: 1.0386, Avg Acc@1: 0.7719, Avg Acc@5: 0.9370
2022-01-22 15:32:42,903 Val Step[0600/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7718, Avg Acc@5: 0.9369
2022-01-22 15:32:44,866 Val Step[0650/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7717, Avg Acc@5: 0.9367
2022-01-22 15:32:46,799 Val Step[0700/1563], Avg Loss: 1.0362, Avg Acc@1: 0.7724, Avg Acc@5: 0.9374
2022-01-22 15:32:48,727 Val Step[0750/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7711, Avg Acc@5: 0.9367
2022-01-22 15:32:50,667 Val Step[0800/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7713, Avg Acc@5: 0.9364
2022-01-22 15:32:52,553 Val Step[0850/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7713, Avg Acc@5: 0.9362
2022-01-22 15:32:54,431 Val Step[0900/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7718, Avg Acc@5: 0.9366
2022-01-22 15:32:56,302 Val Step[0950/1563], Avg Loss: 1.0405, Avg Acc@1: 0.7723, Avg Acc@5: 0.9365
2022-01-22 15:32:58,113 Val Step[1000/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7720, Avg Acc@5: 0.9362
2022-01-22 15:33:00,066 Val Step[1050/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7712, Avg Acc@5: 0.9359
2022-01-22 15:33:01,982 Val Step[1100/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7705, Avg Acc@5: 0.9359
2022-01-22 15:33:03,805 Val Step[1150/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7710, Avg Acc@5: 0.9361
2022-01-22 15:33:05,632 Val Step[1200/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7716, Avg Acc@5: 0.9362
2022-01-22 15:33:07,463 Val Step[1250/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7713, Avg Acc@5: 0.9366
2022-01-22 15:33:09,399 Val Step[1300/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7712, Avg Acc@5: 0.9364
2022-01-22 15:33:11,345 Val Step[1350/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7708, Avg Acc@5: 0.9364
2022-01-22 15:33:13,207 Val Step[1400/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7707, Avg Acc@5: 0.9362
2022-01-22 15:33:15,116 Val Step[1450/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7711, Avg Acc@5: 0.9362
2022-01-22 15:33:16,997 Val Step[1500/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7713, Avg Acc@5: 0.9363
2022-01-22 15:33:18,816 Val Step[1550/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7712, Avg Acc@5: 0.9362
2022-01-22 15:33:20,632 ----- Epoch[268/300], Validation Loss: 1.0438, Validation Acc@1: 0.7712, Validation Acc@5: 0.9362, time: 135.00
2022-01-22 15:33:20,633 Now training epoch 269. LR=0.000040
2022-01-22 15:35:09,459 Epoch[269/300], Step[0000/1252], Avg Loss: 3.1503, Avg Acc: 0.3262
2022-01-22 15:36:35,394 Epoch[269/300], Step[0050/1252], Avg Loss: 2.9945, Avg Acc: 0.4769
2022-01-22 15:38:01,895 Epoch[269/300], Step[0100/1252], Avg Loss: 2.9737, Avg Acc: 0.4818
2022-01-22 15:39:28,591 Epoch[269/300], Step[0150/1252], Avg Loss: 2.9570, Avg Acc: 0.4850
2022-01-22 15:40:52,875 Epoch[269/300], Step[0200/1252], Avg Loss: 2.9562, Avg Acc: 0.4796
2022-01-22 15:42:19,222 Epoch[269/300], Step[0250/1252], Avg Loss: 2.9517, Avg Acc: 0.4768
2022-01-22 15:43:45,235 Epoch[269/300], Step[0300/1252], Avg Loss: 2.9520, Avg Acc: 0.4799
2022-01-22 15:45:12,934 Epoch[269/300], Step[0350/1252], Avg Loss: 2.9585, Avg Acc: 0.4783
2022-01-22 15:46:40,504 Epoch[269/300], Step[0400/1252], Avg Loss: 2.9629, Avg Acc: 0.4761
2022-01-22 15:48:08,652 Epoch[269/300], Step[0450/1252], Avg Loss: 2.9573, Avg Acc: 0.4767
2022-01-22 15:49:36,005 Epoch[269/300], Step[0500/1252], Avg Loss: 2.9565, Avg Acc: 0.4749
2022-01-22 15:51:04,418 Epoch[269/300], Step[0550/1252], Avg Loss: 2.9530, Avg Acc: 0.4766
2022-01-22 15:52:31,181 Epoch[269/300], Step[0600/1252], Avg Loss: 2.9543, Avg Acc: 0.4794
2022-01-22 15:53:58,830 Epoch[269/300], Step[0650/1252], Avg Loss: 2.9564, Avg Acc: 0.4759
2022-01-22 15:55:26,420 Epoch[269/300], Step[0700/1252], Avg Loss: 2.9598, Avg Acc: 0.4744
2022-01-22 15:56:53,781 Epoch[269/300], Step[0750/1252], Avg Loss: 2.9604, Avg Acc: 0.4766
2022-01-22 15:58:20,491 Epoch[269/300], Step[0800/1252], Avg Loss: 2.9607, Avg Acc: 0.4793
2022-01-22 15:59:48,172 Epoch[269/300], Step[0850/1252], Avg Loss: 2.9626, Avg Acc: 0.4797
2022-01-22 16:01:15,364 Epoch[269/300], Step[0900/1252], Avg Loss: 2.9613, Avg Acc: 0.4815
2022-01-22 16:02:43,094 Epoch[269/300], Step[0950/1252], Avg Loss: 2.9588, Avg Acc: 0.4824
2022-01-22 16:04:11,020 Epoch[269/300], Step[1000/1252], Avg Loss: 2.9609, Avg Acc: 0.4812
2022-01-22 16:05:38,558 Epoch[269/300], Step[1050/1252], Avg Loss: 2.9589, Avg Acc: 0.4825
2022-01-22 16:07:06,053 Epoch[269/300], Step[1100/1252], Avg Loss: 2.9577, Avg Acc: 0.4824
2022-01-22 16:08:33,676 Epoch[269/300], Step[1150/1252], Avg Loss: 2.9575, Avg Acc: 0.4819
2022-01-22 16:10:00,091 Epoch[269/300], Step[1200/1252], Avg Loss: 2.9557, Avg Acc: 0.4816
2022-01-22 16:11:28,939 Epoch[269/300], Step[1250/1252], Avg Loss: 2.9539, Avg Acc: 0.4830
2022-01-22 16:11:35,586 ----- Epoch[269/300], Train Loss: 2.9538, Train Acc: 0.4830, time: 2294.95, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 16:11:35,586 Now training epoch 270. LR=0.000038
2022-01-22 16:13:25,206 Epoch[270/300], Step[0000/1252], Avg Loss: 3.2032, Avg Acc: 0.6328
2022-01-22 16:14:50,403 Epoch[270/300], Step[0050/1252], Avg Loss: 3.0064, Avg Acc: 0.4530
2022-01-22 16:16:16,630 Epoch[270/300], Step[0100/1252], Avg Loss: 2.9986, Avg Acc: 0.4687
2022-01-22 16:17:43,949 Epoch[270/300], Step[0150/1252], Avg Loss: 2.9810, Avg Acc: 0.4709
2022-01-22 16:19:11,526 Epoch[270/300], Step[0200/1252], Avg Loss: 2.9885, Avg Acc: 0.4632
2022-01-22 16:20:37,810 Epoch[270/300], Step[0250/1252], Avg Loss: 2.9834, Avg Acc: 0.4682
2022-01-22 16:22:05,277 Epoch[270/300], Step[0300/1252], Avg Loss: 2.9802, Avg Acc: 0.4658
2022-01-22 16:23:32,652 Epoch[270/300], Step[0350/1252], Avg Loss: 2.9759, Avg Acc: 0.4699
2022-01-22 16:25:00,106 Epoch[270/300], Step[0400/1252], Avg Loss: 2.9721, Avg Acc: 0.4701
2022-01-22 16:26:27,387 Epoch[270/300], Step[0450/1252], Avg Loss: 2.9710, Avg Acc: 0.4733
2022-01-22 16:27:54,800 Epoch[270/300], Step[0500/1252], Avg Loss: 2.9683, Avg Acc: 0.4762
2022-01-22 16:29:21,110 Epoch[270/300], Step[0550/1252], Avg Loss: 2.9682, Avg Acc: 0.4786
2022-01-22 16:30:48,852 Epoch[270/300], Step[0600/1252], Avg Loss: 2.9678, Avg Acc: 0.4783
2022-01-22 16:32:16,776 Epoch[270/300], Step[0650/1252], Avg Loss: 2.9712, Avg Acc: 0.4759
2022-01-22 16:33:44,835 Epoch[270/300], Step[0700/1252], Avg Loss: 2.9727, Avg Acc: 0.4757
2022-01-22 16:35:12,620 Epoch[270/300], Step[0750/1252], Avg Loss: 2.9674, Avg Acc: 0.4733
2022-01-22 16:36:39,014 Epoch[270/300], Step[0800/1252], Avg Loss: 2.9664, Avg Acc: 0.4757
2022-01-22 16:38:04,754 Epoch[270/300], Step[0850/1252], Avg Loss: 2.9637, Avg Acc: 0.4767
2022-01-22 16:39:32,195 Epoch[270/300], Step[0900/1252], Avg Loss: 2.9632, Avg Acc: 0.4783
2022-01-22 16:41:00,630 Epoch[270/300], Step[0950/1252], Avg Loss: 2.9627, Avg Acc: 0.4776
2022-01-22 16:42:28,680 Epoch[270/300], Step[1000/1252], Avg Loss: 2.9635, Avg Acc: 0.4748
2022-01-22 16:43:56,502 Epoch[270/300], Step[1050/1252], Avg Loss: 2.9632, Avg Acc: 0.4738
2022-01-22 16:45:24,484 Epoch[270/300], Step[1100/1252], Avg Loss: 2.9629, Avg Acc: 0.4738
2022-01-22 16:46:51,973 Epoch[270/300], Step[1150/1252], Avg Loss: 2.9617, Avg Acc: 0.4740
2022-01-22 16:48:18,787 Epoch[270/300], Step[1200/1252], Avg Loss: 2.9629, Avg Acc: 0.4749
2022-01-22 16:49:47,325 Epoch[270/300], Step[1250/1252], Avg Loss: 2.9637, Avg Acc: 0.4752
2022-01-22 16:49:53,798 ----- Epoch[270/300], Train Loss: 2.9637, Train Acc: 0.4752, time: 2298.21, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 16:49:53,798 ----- Validation after Epoch: 270
2022-01-22 16:51:08,187 Val Step[0000/1563], Avg Loss: 0.8535, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-22 16:51:10,291 Val Step[0050/1563], Avg Loss: 1.0217, Avg Acc@1: 0.7782, Avg Acc@5: 0.9430
2022-01-22 16:51:12,358 Val Step[0100/1563], Avg Loss: 1.0463, Avg Acc@1: 0.7766, Avg Acc@5: 0.9400
2022-01-22 16:51:14,208 Val Step[0150/1563], Avg Loss: 1.0504, Avg Acc@1: 0.7786, Avg Acc@5: 0.9354
2022-01-22 16:51:16,096 Val Step[0200/1563], Avg Loss: 1.0505, Avg Acc@1: 0.7788, Avg Acc@5: 0.9344
2022-01-22 16:51:17,996 Val Step[0250/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7784, Avg Acc@5: 0.9365
2022-01-22 16:51:19,866 Val Step[0300/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7776, Avg Acc@5: 0.9358
2022-01-22 16:51:21,707 Val Step[0350/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7762, Avg Acc@5: 0.9355
2022-01-22 16:51:23,653 Val Step[0400/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7764, Avg Acc@5: 0.9352
2022-01-22 16:51:25,764 Val Step[0450/1563], Avg Loss: 1.0506, Avg Acc@1: 0.7736, Avg Acc@5: 0.9347
2022-01-22 16:51:27,788 Val Step[0500/1563], Avg Loss: 1.0532, Avg Acc@1: 0.7733, Avg Acc@5: 0.9355
2022-01-22 16:51:29,677 Val Step[0550/1563], Avg Loss: 1.0536, Avg Acc@1: 0.7720, Avg Acc@5: 0.9356
2022-01-22 16:51:31,572 Val Step[0600/1563], Avg Loss: 1.0530, Avg Acc@1: 0.7723, Avg Acc@5: 0.9353
2022-01-22 16:51:33,413 Val Step[0650/1563], Avg Loss: 1.0538, Avg Acc@1: 0.7723, Avg Acc@5: 0.9354
2022-01-22 16:51:35,290 Val Step[0700/1563], Avg Loss: 1.0515, Avg Acc@1: 0.7728, Avg Acc@5: 0.9358
2022-01-22 16:51:37,177 Val Step[0750/1563], Avg Loss: 1.0568, Avg Acc@1: 0.7713, Avg Acc@5: 0.9353
2022-01-22 16:51:39,166 Val Step[0800/1563], Avg Loss: 1.0572, Avg Acc@1: 0.7718, Avg Acc@5: 0.9352
2022-01-22 16:51:41,153 Val Step[0850/1563], Avg Loss: 1.0584, Avg Acc@1: 0.7716, Avg Acc@5: 0.9352
2022-01-22 16:51:43,057 Val Step[0900/1563], Avg Loss: 1.0561, Avg Acc@1: 0.7717, Avg Acc@5: 0.9356
2022-01-22 16:51:44,959 Val Step[0950/1563], Avg Loss: 1.0557, Avg Acc@1: 0.7721, Avg Acc@5: 0.9357
2022-01-22 16:51:46,830 Val Step[1000/1563], Avg Loss: 1.0575, Avg Acc@1: 0.7718, Avg Acc@5: 0.9354
2022-01-22 16:51:48,700 Val Step[1050/1563], Avg Loss: 1.0591, Avg Acc@1: 0.7713, Avg Acc@5: 0.9352
2022-01-22 16:51:50,580 Val Step[1100/1563], Avg Loss: 1.0593, Avg Acc@1: 0.7710, Avg Acc@5: 0.9352
2022-01-22 16:51:52,487 Val Step[1150/1563], Avg Loss: 1.0569, Avg Acc@1: 0.7714, Avg Acc@5: 0.9355
2022-01-22 16:51:54,365 Val Step[1200/1563], Avg Loss: 1.0560, Avg Acc@1: 0.7719, Avg Acc@5: 0.9354
2022-01-22 16:51:56,303 Val Step[1250/1563], Avg Loss: 1.0559, Avg Acc@1: 0.7715, Avg Acc@5: 0.9358
2022-01-22 16:51:58,234 Val Step[1300/1563], Avg Loss: 1.0591, Avg Acc@1: 0.7714, Avg Acc@5: 0.9356
2022-01-22 16:52:00,100 Val Step[1350/1563], Avg Loss: 1.0604, Avg Acc@1: 0.7710, Avg Acc@5: 0.9356
2022-01-22 16:52:01,934 Val Step[1400/1563], Avg Loss: 1.0599, Avg Acc@1: 0.7709, Avg Acc@5: 0.9355
2022-01-22 16:52:03,848 Val Step[1450/1563], Avg Loss: 1.0587, Avg Acc@1: 0.7711, Avg Acc@5: 0.9358
2022-01-22 16:52:05,744 Val Step[1500/1563], Avg Loss: 1.0585, Avg Acc@1: 0.7714, Avg Acc@5: 0.9360
2022-01-22 16:52:07,577 Val Step[1550/1563], Avg Loss: 1.0588, Avg Acc@1: 0.7712, Avg Acc@5: 0.9358
2022-01-22 16:52:09,516 ----- Epoch[270/300], Validation Loss: 1.0587, Validation Acc@1: 0.7711, Validation Acc@5: 0.9359, time: 135.72
2022-01-22 16:52:09,516 Now training epoch 271. LR=0.000036
2022-01-22 16:53:56,265 Epoch[271/300], Step[0000/1252], Avg Loss: 3.1390, Avg Acc: 0.6055
2022-01-22 16:55:23,987 Epoch[271/300], Step[0050/1252], Avg Loss: 2.9457, Avg Acc: 0.4857
2022-01-22 16:56:51,366 Epoch[271/300], Step[0100/1252], Avg Loss: 2.9623, Avg Acc: 0.4670
2022-01-22 16:58:19,093 Epoch[271/300], Step[0150/1252], Avg Loss: 2.9660, Avg Acc: 0.4607
2022-01-22 16:59:46,586 Epoch[271/300], Step[0200/1252], Avg Loss: 2.9750, Avg Acc: 0.4674
2022-01-22 17:01:14,389 Epoch[271/300], Step[0250/1252], Avg Loss: 2.9629, Avg Acc: 0.4669
2022-01-22 17:02:41,667 Epoch[271/300], Step[0300/1252], Avg Loss: 2.9586, Avg Acc: 0.4669
2022-01-22 17:04:08,716 Epoch[271/300], Step[0350/1252], Avg Loss: 2.9503, Avg Acc: 0.4699
2022-01-22 17:05:35,831 Epoch[271/300], Step[0400/1252], Avg Loss: 2.9568, Avg Acc: 0.4707
2022-01-22 17:07:03,541 Epoch[271/300], Step[0450/1252], Avg Loss: 2.9526, Avg Acc: 0.4755
2022-01-22 17:08:31,226 Epoch[271/300], Step[0500/1252], Avg Loss: 2.9516, Avg Acc: 0.4760
2022-01-22 17:09:57,880 Epoch[271/300], Step[0550/1252], Avg Loss: 2.9514, Avg Acc: 0.4776
2022-01-22 17:11:26,283 Epoch[271/300], Step[0600/1252], Avg Loss: 2.9521, Avg Acc: 0.4766
2022-01-22 17:12:54,451 Epoch[271/300], Step[0650/1252], Avg Loss: 2.9508, Avg Acc: 0.4753
2022-01-22 17:14:22,545 Epoch[271/300], Step[0700/1252], Avg Loss: 2.9513, Avg Acc: 0.4770
2022-01-22 17:15:50,770 Epoch[271/300], Step[0750/1252], Avg Loss: 2.9556, Avg Acc: 0.4755
2022-01-22 17:17:18,571 Epoch[271/300], Step[0800/1252], Avg Loss: 2.9518, Avg Acc: 0.4774
2022-01-22 17:18:47,428 Epoch[271/300], Step[0850/1252], Avg Loss: 2.9528, Avg Acc: 0.4770
2022-01-22 17:20:15,827 Epoch[271/300], Step[0900/1252], Avg Loss: 2.9520, Avg Acc: 0.4771
2022-01-22 17:21:43,925 Epoch[271/300], Step[0950/1252], Avg Loss: 2.9551, Avg Acc: 0.4751
2022-01-22 17:23:11,642 Epoch[271/300], Step[1000/1252], Avg Loss: 2.9532, Avg Acc: 0.4768
2022-01-22 17:24:39,365 Epoch[271/300], Step[1050/1252], Avg Loss: 2.9497, Avg Acc: 0.4780
2022-01-22 17:26:07,854 Epoch[271/300], Step[1100/1252], Avg Loss: 2.9468, Avg Acc: 0.4795
2022-01-22 17:27:34,716 Epoch[271/300], Step[1150/1252], Avg Loss: 2.9449, Avg Acc: 0.4806
2022-01-22 17:29:04,040 Epoch[271/300], Step[1200/1252], Avg Loss: 2.9455, Avg Acc: 0.4804
2022-01-22 17:30:33,146 Epoch[271/300], Step[1250/1252], Avg Loss: 2.9468, Avg Acc: 0.4819
2022-01-22 17:30:39,416 ----- Epoch[271/300], Train Loss: 2.9468, Train Acc: 0.4819, time: 2309.90, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 17:30:39,416 Now training epoch 272. LR=0.000034
2022-01-22 17:32:24,882 Epoch[272/300], Step[0000/1252], Avg Loss: 2.7212, Avg Acc: 0.2959
2022-01-22 17:33:51,547 Epoch[272/300], Step[0050/1252], Avg Loss: 2.8868, Avg Acc: 0.4858
2022-01-22 17:35:17,785 Epoch[272/300], Step[0100/1252], Avg Loss: 2.9062, Avg Acc: 0.4963
2022-01-22 17:36:45,163 Epoch[272/300], Step[0150/1252], Avg Loss: 2.9064, Avg Acc: 0.4885
2022-01-22 17:38:12,499 Epoch[272/300], Step[0200/1252], Avg Loss: 2.9076, Avg Acc: 0.4854
2022-01-22 17:39:39,770 Epoch[272/300], Step[0250/1252], Avg Loss: 2.9104, Avg Acc: 0.4843
2022-01-22 17:41:06,121 Epoch[272/300], Step[0300/1252], Avg Loss: 2.9081, Avg Acc: 0.4878
2022-01-22 17:42:33,305 Epoch[272/300], Step[0350/1252], Avg Loss: 2.9157, Avg Acc: 0.4862
2022-01-22 17:44:00,549 Epoch[272/300], Step[0400/1252], Avg Loss: 2.9221, Avg Acc: 0.4845
2022-01-22 17:45:28,445 Epoch[272/300], Step[0450/1252], Avg Loss: 2.9264, Avg Acc: 0.4825
2022-01-22 17:46:56,336 Epoch[272/300], Step[0500/1252], Avg Loss: 2.9241, Avg Acc: 0.4821
2022-01-22 17:48:24,524 Epoch[272/300], Step[0550/1252], Avg Loss: 2.9210, Avg Acc: 0.4824
2022-01-22 17:49:53,227 Epoch[272/300], Step[0600/1252], Avg Loss: 2.9240, Avg Acc: 0.4842
2022-01-22 17:51:21,640 Epoch[272/300], Step[0650/1252], Avg Loss: 2.9263, Avg Acc: 0.4855
2022-01-22 17:52:50,770 Epoch[272/300], Step[0700/1252], Avg Loss: 2.9310, Avg Acc: 0.4838
2022-01-22 17:54:19,918 Epoch[272/300], Step[0750/1252], Avg Loss: 2.9343, Avg Acc: 0.4816
2022-01-22 17:55:48,321 Epoch[272/300], Step[0800/1252], Avg Loss: 2.9347, Avg Acc: 0.4807
2022-01-22 17:57:16,314 Epoch[272/300], Step[0850/1252], Avg Loss: 2.9372, Avg Acc: 0.4800
2022-01-22 17:58:44,450 Epoch[272/300], Step[0900/1252], Avg Loss: 2.9360, Avg Acc: 0.4807
2022-01-22 18:00:12,901 Epoch[272/300], Step[0950/1252], Avg Loss: 2.9315, Avg Acc: 0.4808
2022-01-22 18:01:42,214 Epoch[272/300], Step[1000/1252], Avg Loss: 2.9342, Avg Acc: 0.4812
2022-01-22 18:03:11,091 Epoch[272/300], Step[1050/1252], Avg Loss: 2.9337, Avg Acc: 0.4817
2022-01-22 18:04:40,829 Epoch[272/300], Step[1100/1252], Avg Loss: 2.9362, Avg Acc: 0.4807
2022-01-22 18:06:10,789 Epoch[272/300], Step[1150/1252], Avg Loss: 2.9367, Avg Acc: 0.4797
2022-01-22 18:07:39,524 Epoch[272/300], Step[1200/1252], Avg Loss: 2.9344, Avg Acc: 0.4803
2022-01-22 18:09:09,279 Epoch[272/300], Step[1250/1252], Avg Loss: 2.9362, Avg Acc: 0.4804
2022-01-22 18:09:16,748 ----- Epoch[272/300], Train Loss: 2.9362, Train Acc: 0.4805, time: 2317.33, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 18:09:16,748 ----- Validation after Epoch: 272
2022-01-22 18:10:29,323 Val Step[0000/1563], Avg Loss: 0.8259, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-22 18:10:31,163 Val Step[0050/1563], Avg Loss: 1.0318, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-22 18:10:33,035 Val Step[0100/1563], Avg Loss: 1.0566, Avg Acc@1: 0.7772, Avg Acc@5: 0.9369
2022-01-22 18:10:34,868 Val Step[0150/1563], Avg Loss: 1.0592, Avg Acc@1: 0.7784, Avg Acc@5: 0.9344
2022-01-22 18:10:36,700 Val Step[0200/1563], Avg Loss: 1.0582, Avg Acc@1: 0.7794, Avg Acc@5: 0.9345
2022-01-22 18:10:38,590 Val Step[0250/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7795, Avg Acc@5: 0.9361
2022-01-22 18:10:40,430 Val Step[0300/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7779, Avg Acc@5: 0.9351
2022-01-22 18:10:42,220 Val Step[0350/1563], Avg Loss: 1.0507, Avg Acc@1: 0.7762, Avg Acc@5: 0.9350
2022-01-22 18:10:44,010 Val Step[0400/1563], Avg Loss: 1.0501, Avg Acc@1: 0.7767, Avg Acc@5: 0.9344
2022-01-22 18:10:45,833 Val Step[0450/1563], Avg Loss: 1.0555, Avg Acc@1: 0.7744, Avg Acc@5: 0.9340
2022-01-22 18:10:47,641 Val Step[0500/1563], Avg Loss: 1.0583, Avg Acc@1: 0.7740, Avg Acc@5: 0.9341
2022-01-22 18:10:49,459 Val Step[0550/1563], Avg Loss: 1.0581, Avg Acc@1: 0.7722, Avg Acc@5: 0.9348
2022-01-22 18:10:51,446 Val Step[0600/1563], Avg Loss: 1.0578, Avg Acc@1: 0.7717, Avg Acc@5: 0.9350
2022-01-22 18:10:53,450 Val Step[0650/1563], Avg Loss: 1.0583, Avg Acc@1: 0.7723, Avg Acc@5: 0.9352
2022-01-22 18:10:55,311 Val Step[0700/1563], Avg Loss: 1.0556, Avg Acc@1: 0.7728, Avg Acc@5: 0.9359
2022-01-22 18:10:57,126 Val Step[0750/1563], Avg Loss: 1.0610, Avg Acc@1: 0.7713, Avg Acc@5: 0.9353
2022-01-22 18:10:58,940 Val Step[0800/1563], Avg Loss: 1.0610, Avg Acc@1: 0.7718, Avg Acc@5: 0.9352
2022-01-22 18:11:00,753 Val Step[0850/1563], Avg Loss: 1.0622, Avg Acc@1: 0.7716, Avg Acc@5: 0.9349
2022-01-22 18:11:02,565 Val Step[0900/1563], Avg Loss: 1.0590, Avg Acc@1: 0.7717, Avg Acc@5: 0.9351
2022-01-22 18:11:04,394 Val Step[0950/1563], Avg Loss: 1.0586, Avg Acc@1: 0.7726, Avg Acc@5: 0.9354
2022-01-22 18:11:06,358 Val Step[1000/1563], Avg Loss: 1.0605, Avg Acc@1: 0.7724, Avg Acc@5: 0.9351
2022-01-22 18:11:08,428 Val Step[1050/1563], Avg Loss: 1.0624, Avg Acc@1: 0.7716, Avg Acc@5: 0.9347
2022-01-22 18:11:10,522 Val Step[1100/1563], Avg Loss: 1.0623, Avg Acc@1: 0.7713, Avg Acc@5: 0.9348
2022-01-22 18:11:12,642 Val Step[1150/1563], Avg Loss: 1.0598, Avg Acc@1: 0.7716, Avg Acc@5: 0.9351
2022-01-22 18:11:14,724 Val Step[1200/1563], Avg Loss: 1.0591, Avg Acc@1: 0.7723, Avg Acc@5: 0.9351
2022-01-22 18:11:16,783 Val Step[1250/1563], Avg Loss: 1.0589, Avg Acc@1: 0.7720, Avg Acc@5: 0.9354
2022-01-22 18:11:18,741 Val Step[1300/1563], Avg Loss: 1.0617, Avg Acc@1: 0.7717, Avg Acc@5: 0.9350
2022-01-22 18:11:20,572 Val Step[1350/1563], Avg Loss: 1.0625, Avg Acc@1: 0.7714, Avg Acc@5: 0.9349
2022-01-22 18:11:22,660 Val Step[1400/1563], Avg Loss: 1.0623, Avg Acc@1: 0.7711, Avg Acc@5: 0.9350
2022-01-22 18:11:24,780 Val Step[1450/1563], Avg Loss: 1.0615, Avg Acc@1: 0.7716, Avg Acc@5: 0.9352
2022-01-22 18:11:26,936 Val Step[1500/1563], Avg Loss: 1.0613, Avg Acc@1: 0.7718, Avg Acc@5: 0.9354
2022-01-22 18:11:28,747 Val Step[1550/1563], Avg Loss: 1.0621, Avg Acc@1: 0.7714, Avg Acc@5: 0.9352
2022-01-22 18:11:30,639 ----- Epoch[272/300], Validation Loss: 1.0620, Validation Acc@1: 0.7714, Validation Acc@5: 0.9353, time: 133.89
2022-01-22 18:11:30,639 Now training epoch 273. LR=0.000033
2022-01-22 18:13:16,572 Epoch[273/300], Step[0000/1252], Avg Loss: 2.8908, Avg Acc: 0.4688
2022-01-22 18:14:43,215 Epoch[273/300], Step[0050/1252], Avg Loss: 2.9023, Avg Acc: 0.5163
2022-01-22 18:16:11,098 Epoch[273/300], Step[0100/1252], Avg Loss: 2.9471, Avg Acc: 0.4648
2022-01-22 18:17:37,857 Epoch[273/300], Step[0150/1252], Avg Loss: 2.9514, Avg Acc: 0.4708
2022-01-22 18:19:04,235 Epoch[273/300], Step[0200/1252], Avg Loss: 2.9480, Avg Acc: 0.4744
2022-01-22 18:20:30,886 Epoch[273/300], Step[0250/1252], Avg Loss: 2.9579, Avg Acc: 0.4697
2022-01-22 18:21:58,972 Epoch[273/300], Step[0300/1252], Avg Loss: 2.9588, Avg Acc: 0.4671
2022-01-22 18:23:25,654 Epoch[273/300], Step[0350/1252], Avg Loss: 2.9628, Avg Acc: 0.4684
2022-01-22 18:24:53,083 Epoch[273/300], Step[0400/1252], Avg Loss: 2.9565, Avg Acc: 0.4718
2022-01-22 18:26:20,871 Epoch[273/300], Step[0450/1252], Avg Loss: 2.9485, Avg Acc: 0.4744
2022-01-22 18:27:46,970 Epoch[273/300], Step[0500/1252], Avg Loss: 2.9460, Avg Acc: 0.4775
2022-01-22 18:29:13,665 Epoch[273/300], Step[0550/1252], Avg Loss: 2.9542, Avg Acc: 0.4738
2022-01-22 18:30:42,954 Epoch[273/300], Step[0600/1252], Avg Loss: 2.9538, Avg Acc: 0.4708
2022-01-22 18:32:10,397 Epoch[273/300], Step[0650/1252], Avg Loss: 2.9555, Avg Acc: 0.4696
2022-01-22 18:33:38,039 Epoch[273/300], Step[0700/1252], Avg Loss: 2.9550, Avg Acc: 0.4701
2022-01-22 18:35:05,771 Epoch[273/300], Step[0750/1252], Avg Loss: 2.9578, Avg Acc: 0.4715
2022-01-22 18:36:34,404 Epoch[273/300], Step[0800/1252], Avg Loss: 2.9544, Avg Acc: 0.4737
2022-01-22 18:38:04,038 Epoch[273/300], Step[0850/1252], Avg Loss: 2.9529, Avg Acc: 0.4742
2022-01-22 18:39:33,783 Epoch[273/300], Step[0900/1252], Avg Loss: 2.9536, Avg Acc: 0.4727
2022-01-22 18:41:03,237 Epoch[273/300], Step[0950/1252], Avg Loss: 2.9523, Avg Acc: 0.4721
2022-01-22 18:42:32,084 Epoch[273/300], Step[1000/1252], Avg Loss: 2.9522, Avg Acc: 0.4737
2022-01-22 18:44:01,829 Epoch[273/300], Step[1050/1252], Avg Loss: 2.9532, Avg Acc: 0.4727
2022-01-22 18:45:29,641 Epoch[273/300], Step[1100/1252], Avg Loss: 2.9534, Avg Acc: 0.4722
2022-01-22 18:46:58,867 Epoch[273/300], Step[1150/1252], Avg Loss: 2.9540, Avg Acc: 0.4729
2022-01-22 18:48:28,891 Epoch[273/300], Step[1200/1252], Avg Loss: 2.9547, Avg Acc: 0.4725
2022-01-22 18:49:57,419 Epoch[273/300], Step[1250/1252], Avg Loss: 2.9528, Avg Acc: 0.4728
2022-01-22 18:50:05,084 ----- Epoch[273/300], Train Loss: 2.9527, Train Acc: 0.4728, time: 2314.44, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 18:50:05,084 Now training epoch 274. LR=0.000031
2022-01-22 18:51:51,324 Epoch[274/300], Step[0000/1252], Avg Loss: 3.1514, Avg Acc: 0.4922
2022-01-22 18:53:19,686 Epoch[274/300], Step[0050/1252], Avg Loss: 2.9207, Avg Acc: 0.4816
2022-01-22 18:54:48,246 Epoch[274/300], Step[0100/1252], Avg Loss: 2.9220, Avg Acc: 0.4758
2022-01-22 18:56:16,176 Epoch[274/300], Step[0150/1252], Avg Loss: 2.9093, Avg Acc: 0.4652
2022-01-22 18:57:43,842 Epoch[274/300], Step[0200/1252], Avg Loss: 2.9205, Avg Acc: 0.4744
2022-01-22 18:59:11,978 Epoch[274/300], Step[0250/1252], Avg Loss: 2.9272, Avg Acc: 0.4727
2022-01-22 19:00:39,065 Epoch[274/300], Step[0300/1252], Avg Loss: 2.9266, Avg Acc: 0.4713
2022-01-22 19:02:07,095 Epoch[274/300], Step[0350/1252], Avg Loss: 2.9309, Avg Acc: 0.4698
2022-01-22 19:03:34,711 Epoch[274/300], Step[0400/1252], Avg Loss: 2.9307, Avg Acc: 0.4757
2022-01-22 19:05:02,375 Epoch[274/300], Step[0450/1252], Avg Loss: 2.9340, Avg Acc: 0.4759
2022-01-22 19:06:29,914 Epoch[274/300], Step[0500/1252], Avg Loss: 2.9358, Avg Acc: 0.4775
2022-01-22 19:07:57,321 Epoch[274/300], Step[0550/1252], Avg Loss: 2.9363, Avg Acc: 0.4795
2022-01-22 19:09:25,083 Epoch[274/300], Step[0600/1252], Avg Loss: 2.9427, Avg Acc: 0.4795
2022-01-22 19:10:52,583 Epoch[274/300], Step[0650/1252], Avg Loss: 2.9370, Avg Acc: 0.4795
2022-01-22 19:12:21,363 Epoch[274/300], Step[0700/1252], Avg Loss: 2.9396, Avg Acc: 0.4787
2022-01-22 19:13:48,252 Epoch[274/300], Step[0750/1252], Avg Loss: 2.9395, Avg Acc: 0.4799
2022-01-22 19:15:15,491 Epoch[274/300], Step[0800/1252], Avg Loss: 2.9420, Avg Acc: 0.4777
2022-01-22 19:16:43,182 Epoch[274/300], Step[0850/1252], Avg Loss: 2.9379, Avg Acc: 0.4761
2022-01-22 19:18:11,407 Epoch[274/300], Step[0900/1252], Avg Loss: 2.9400, Avg Acc: 0.4751
2022-01-22 19:19:39,951 Epoch[274/300], Step[0950/1252], Avg Loss: 2.9380, Avg Acc: 0.4744
2022-01-22 19:21:09,204 Epoch[274/300], Step[1000/1252], Avg Loss: 2.9370, Avg Acc: 0.4745
2022-01-22 19:22:37,471 Epoch[274/300], Step[1050/1252], Avg Loss: 2.9385, Avg Acc: 0.4741
2022-01-22 19:24:04,303 Epoch[274/300], Step[1100/1252], Avg Loss: 2.9377, Avg Acc: 0.4739
2022-01-22 19:25:32,164 Epoch[274/300], Step[1150/1252], Avg Loss: 2.9358, Avg Acc: 0.4750
2022-01-22 19:26:59,744 Epoch[274/300], Step[1200/1252], Avg Loss: 2.9347, Avg Acc: 0.4754
2022-01-22 19:28:28,580 Epoch[274/300], Step[1250/1252], Avg Loss: 2.9333, Avg Acc: 0.4763
2022-01-22 19:28:35,647 ----- Epoch[274/300], Train Loss: 2.9332, Train Acc: 0.4763, time: 2310.56, Best Val(epoch262) Acc@1: 0.7714
2022-01-22 19:28:35,647 ----- Validation after Epoch: 274
2022-01-22 19:31:39,131 Val Step[0000/1563], Avg Loss: 0.7930, Avg Acc@1: 0.8438, Avg Acc@5: 1.0000
2022-01-22 19:31:41,045 Val Step[0050/1563], Avg Loss: 1.0022, Avg Acc@1: 0.7831, Avg Acc@5: 0.9393
2022-01-22 19:31:43,090 Val Step[0100/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7803, Avg Acc@5: 0.9369
2022-01-22 19:31:44,978 Val Step[0150/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7784, Avg Acc@5: 0.9338
2022-01-22 19:31:46,920 Val Step[0200/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7788, Avg Acc@5: 0.9345
2022-01-22 19:31:48,967 Val Step[0250/1563], Avg Loss: 1.0333, Avg Acc@1: 0.7793, Avg Acc@5: 0.9368
2022-01-22 19:31:50,958 Val Step[0300/1563], Avg Loss: 1.0339, Avg Acc@1: 0.7790, Avg Acc@5: 0.9360
2022-01-22 19:31:52,892 Val Step[0350/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7782, Avg Acc@5: 0.9354
2022-01-22 19:31:54,940 Val Step[0400/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7782, Avg Acc@5: 0.9353
2022-01-22 19:31:56,883 Val Step[0450/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7756, Avg Acc@5: 0.9351
2022-01-22 19:31:58,817 Val Step[0500/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7753, Avg Acc@5: 0.9354
2022-01-22 19:32:00,715 Val Step[0550/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7737, Avg Acc@5: 0.9359
2022-01-22 19:32:02,741 Val Step[0600/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7733, Avg Acc@5: 0.9362
2022-01-22 19:32:04,590 Val Step[0650/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7733, Avg Acc@5: 0.9360
2022-01-22 19:32:06,456 Val Step[0700/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7739, Avg Acc@5: 0.9366
2022-01-22 19:32:08,305 Val Step[0750/1563], Avg Loss: 1.0489, Avg Acc@1: 0.7720, Avg Acc@5: 0.9364
2022-01-22 19:32:10,298 Val Step[0800/1563], Avg Loss: 1.0492, Avg Acc@1: 0.7730, Avg Acc@5: 0.9363
2022-01-22 19:32:12,225 Val Step[0850/1563], Avg Loss: 1.0505, Avg Acc@1: 0.7727, Avg Acc@5: 0.9360
2022-01-22 19:32:14,292 Val Step[0900/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7732, Avg Acc@5: 0.9364
2022-01-22 19:32:16,210 Val Step[0950/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7739, Avg Acc@5: 0.9364
2022-01-22 19:32:18,179 Val Step[1000/1563], Avg Loss: 1.0482, Avg Acc@1: 0.7736, Avg Acc@5: 0.9362
2022-01-22 19:32:20,257 Val Step[1050/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7729, Avg Acc@5: 0.9359
2022-01-22 19:32:22,138 Val Step[1100/1563], Avg Loss: 1.0501, Avg Acc@1: 0.7723, Avg Acc@5: 0.9361
2022-01-22 19:32:24,093 Val Step[1150/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7728, Avg Acc@5: 0.9363
2022-01-22 19:32:26,081 Val Step[1200/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7735, Avg Acc@5: 0.9363
2022-01-22 19:32:28,022 Val Step[1250/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7734, Avg Acc@5: 0.9367
2022-01-22 19:32:29,919 Val Step[1300/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7732, Avg Acc@5: 0.9363
2022-01-22 19:32:31,878 Val Step[1350/1563], Avg Loss: 1.0504, Avg Acc@1: 0.7727, Avg Acc@5: 0.9361
2022-01-22 19:32:33,801 Val Step[1400/1563], Avg Loss: 1.0500, Avg Acc@1: 0.7725, Avg Acc@5: 0.9361
2022-01-22 19:32:35,750 Val Step[1450/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7730, Avg Acc@5: 0.9364
2022-01-22 19:32:37,998 Val Step[1500/1563], Avg Loss: 1.0490, Avg Acc@1: 0.7730, Avg Acc@5: 0.9366
2022-01-22 19:32:39,922 Val Step[1550/1563], Avg Loss: 1.0494, Avg Acc@1: 0.7726, Avg Acc@5: 0.9365
2022-01-22 19:32:41,683 ----- Epoch[274/300], Validation Loss: 1.0495, Validation Acc@1: 0.7724, Validation Acc@5: 0.9365, time: 246.03
2022-01-22 19:32:45,437 the pre best model acc:0.7714, at epoch 262
2022-01-22 19:32:45,438 current best model acc:0.7724, at epoch 274
2022-01-22 19:32:45,438 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 19:32:45,438 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 19:32:45,438 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 19:32:45,438 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 19:32:45,438 Now training epoch 275. LR=0.000029
2022-01-22 19:37:33,352 Epoch[275/300], Step[0000/1252], Avg Loss: 2.4664, Avg Acc: 0.7285
2022-01-22 19:38:59,536 Epoch[275/300], Step[0050/1252], Avg Loss: 2.8936, Avg Acc: 0.4738
2022-01-22 19:40:25,299 Epoch[275/300], Step[0100/1252], Avg Loss: 2.8796, Avg Acc: 0.4688
2022-01-22 19:41:51,164 Epoch[275/300], Step[0150/1252], Avg Loss: 2.8973, Avg Acc: 0.4745
2022-01-22 19:43:17,961 Epoch[275/300], Step[0200/1252], Avg Loss: 2.9008, Avg Acc: 0.4761
2022-01-22 19:44:44,723 Epoch[275/300], Step[0250/1252], Avg Loss: 2.9100, Avg Acc: 0.4754
2022-01-22 19:46:11,456 Epoch[275/300], Step[0300/1252], Avg Loss: 2.9064, Avg Acc: 0.4787
2022-01-22 19:47:37,901 Epoch[275/300], Step[0350/1252], Avg Loss: 2.9119, Avg Acc: 0.4825
2022-01-22 19:49:05,228 Epoch[275/300], Step[0400/1252], Avg Loss: 2.9168, Avg Acc: 0.4819
2022-01-22 19:50:31,079 Epoch[275/300], Step[0450/1252], Avg Loss: 2.9171, Avg Acc: 0.4820
2022-01-22 19:51:57,338 Epoch[275/300], Step[0500/1252], Avg Loss: 2.9115, Avg Acc: 0.4830
2022-01-22 19:53:24,956 Epoch[275/300], Step[0550/1252], Avg Loss: 2.9195, Avg Acc: 0.4799
2022-01-22 19:54:52,426 Epoch[275/300], Step[0600/1252], Avg Loss: 2.9240, Avg Acc: 0.4799
2022-01-22 19:56:19,658 Epoch[275/300], Step[0650/1252], Avg Loss: 2.9276, Avg Acc: 0.4807
2022-01-22 19:57:46,121 Epoch[275/300], Step[0700/1252], Avg Loss: 2.9317, Avg Acc: 0.4796
2022-01-22 19:59:13,001 Epoch[275/300], Step[0750/1252], Avg Loss: 2.9337, Avg Acc: 0.4781
2022-01-22 20:00:40,856 Epoch[275/300], Step[0800/1252], Avg Loss: 2.9333, Avg Acc: 0.4782
2022-01-22 20:02:08,709 Epoch[275/300], Step[0850/1252], Avg Loss: 2.9343, Avg Acc: 0.4783
2022-01-22 20:03:35,285 Epoch[275/300], Step[0900/1252], Avg Loss: 2.9371, Avg Acc: 0.4795
2022-01-22 20:05:03,562 Epoch[275/300], Step[0950/1252], Avg Loss: 2.9375, Avg Acc: 0.4799
2022-01-22 20:06:31,314 Epoch[275/300], Step[1000/1252], Avg Loss: 2.9358, Avg Acc: 0.4805
2022-01-22 20:07:59,166 Epoch[275/300], Step[1050/1252], Avg Loss: 2.9362, Avg Acc: 0.4806
2022-01-22 20:09:26,851 Epoch[275/300], Step[1100/1252], Avg Loss: 2.9346, Avg Acc: 0.4809
2022-01-22 20:10:54,995 Epoch[275/300], Step[1150/1252], Avg Loss: 2.9331, Avg Acc: 0.4811
2022-01-22 20:12:24,099 Epoch[275/300], Step[1200/1252], Avg Loss: 2.9333, Avg Acc: 0.4826
2022-01-22 20:13:50,008 Epoch[275/300], Step[1250/1252], Avg Loss: 2.9356, Avg Acc: 0.4812
2022-01-22 20:13:57,206 ----- Epoch[275/300], Train Loss: 2.9356, Train Acc: 0.4812, time: 2471.76, Best Val(epoch274) Acc@1: 0.7724
2022-01-22 20:13:57,206 Now training epoch 276. LR=0.000028
2022-01-22 20:15:47,517 Epoch[276/300], Step[0000/1252], Avg Loss: 3.2607, Avg Acc: 0.2686
2022-01-22 20:17:15,392 Epoch[276/300], Step[0050/1252], Avg Loss: 2.8900, Avg Acc: 0.5112
2022-01-22 20:18:43,560 Epoch[276/300], Step[0100/1252], Avg Loss: 2.8814, Avg Acc: 0.5084
2022-01-22 20:20:12,556 Epoch[276/300], Step[0150/1252], Avg Loss: 2.9071, Avg Acc: 0.5009
2022-01-22 20:21:40,613 Epoch[276/300], Step[0200/1252], Avg Loss: 2.9107, Avg Acc: 0.4955
2022-01-22 20:23:08,268 Epoch[276/300], Step[0250/1252], Avg Loss: 2.9221, Avg Acc: 0.4942
2022-01-22 20:24:37,034 Epoch[276/300], Step[0300/1252], Avg Loss: 2.9198, Avg Acc: 0.4861
2022-01-22 20:26:05,311 Epoch[276/300], Step[0350/1252], Avg Loss: 2.9230, Avg Acc: 0.4871
2022-01-22 20:27:34,438 Epoch[276/300], Step[0400/1252], Avg Loss: 2.9180, Avg Acc: 0.4803
2022-01-22 20:29:01,374 Epoch[276/300], Step[0450/1252], Avg Loss: 2.9254, Avg Acc: 0.4804
2022-01-22 20:30:29,625 Epoch[276/300], Step[0500/1252], Avg Loss: 2.9267, Avg Acc: 0.4818
2022-01-22 20:31:58,369 Epoch[276/300], Step[0550/1252], Avg Loss: 2.9250, Avg Acc: 0.4801
2022-01-22 20:33:28,758 Epoch[276/300], Step[0600/1252], Avg Loss: 2.9269, Avg Acc: 0.4822
2022-01-22 20:34:56,085 Epoch[276/300], Step[0650/1252], Avg Loss: 2.9283, Avg Acc: 0.4832
2022-01-22 20:36:23,326 Epoch[276/300], Step[0700/1252], Avg Loss: 2.9298, Avg Acc: 0.4817
2022-01-22 20:37:51,476 Epoch[276/300], Step[0750/1252], Avg Loss: 2.9303, Avg Acc: 0.4853
2022-01-22 20:39:22,465 Epoch[276/300], Step[0800/1252], Avg Loss: 2.9309, Avg Acc: 0.4850
2022-01-22 20:40:51,575 Epoch[276/300], Step[0850/1252], Avg Loss: 2.9309, Avg Acc: 0.4846
2022-01-22 20:42:19,734 Epoch[276/300], Step[0900/1252], Avg Loss: 2.9272, Avg Acc: 0.4847
2022-01-22 20:43:46,514 Epoch[276/300], Step[0950/1252], Avg Loss: 2.9292, Avg Acc: 0.4844
2022-01-22 20:45:15,141 Epoch[276/300], Step[1000/1252], Avg Loss: 2.9278, Avg Acc: 0.4861
2022-01-22 20:46:43,276 Epoch[276/300], Step[1050/1252], Avg Loss: 2.9270, Avg Acc: 0.4845
2022-01-22 20:48:12,071 Epoch[276/300], Step[1100/1252], Avg Loss: 2.9267, Avg Acc: 0.4842
2022-01-22 20:49:41,170 Epoch[276/300], Step[1150/1252], Avg Loss: 2.9270, Avg Acc: 0.4855
2022-01-22 20:51:08,593 Epoch[276/300], Step[1200/1252], Avg Loss: 2.9268, Avg Acc: 0.4859
2022-01-22 20:52:36,574 Epoch[276/300], Step[1250/1252], Avg Loss: 2.9278, Avg Acc: 0.4853
2022-01-22 20:52:45,682 ----- Epoch[276/300], Train Loss: 2.9279, Train Acc: 0.4852, time: 2328.47, Best Val(epoch274) Acc@1: 0.7724
2022-01-22 20:52:45,683 ----- Validation after Epoch: 276
2022-01-22 21:06:55,359 Val Step[0000/1563], Avg Loss: 0.8372, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-22 21:06:57,355 Val Step[0050/1563], Avg Loss: 1.0220, Avg Acc@1: 0.7770, Avg Acc@5: 0.9400
2022-01-22 21:06:59,661 Val Step[0100/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7800, Avg Acc@5: 0.9378
2022-01-22 21:07:01,472 Val Step[0150/1563], Avg Loss: 1.0476, Avg Acc@1: 0.7802, Avg Acc@5: 0.9365
2022-01-22 21:07:03,275 Val Step[0200/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7814, Avg Acc@5: 0.9363
2022-01-22 21:07:05,077 Val Step[0250/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7798, Avg Acc@5: 0.9380
2022-01-22 21:07:06,889 Val Step[0300/1563], Avg Loss: 1.0368, Avg Acc@1: 0.7788, Avg Acc@5: 0.9371
2022-01-22 21:07:09,023 Val Step[0350/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7780, Avg Acc@5: 0.9367
2022-01-22 21:07:11,090 Val Step[0400/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7784, Avg Acc@5: 0.9364
2022-01-22 21:07:13,173 Val Step[0450/1563], Avg Loss: 1.0474, Avg Acc@1: 0.7761, Avg Acc@5: 0.9356
2022-01-22 21:07:15,290 Val Step[0500/1563], Avg Loss: 1.0504, Avg Acc@1: 0.7751, Avg Acc@5: 0.9359
2022-01-22 21:07:17,447 Val Step[0550/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7733, Avg Acc@5: 0.9361
2022-01-22 21:07:19,591 Val Step[0600/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7737, Avg Acc@5: 0.9361
2022-01-22 21:07:21,688 Val Step[0650/1563], Avg Loss: 1.0494, Avg Acc@1: 0.7734, Avg Acc@5: 0.9362
2022-01-22 21:07:23,820 Val Step[0700/1563], Avg Loss: 1.0468, Avg Acc@1: 0.7741, Avg Acc@5: 0.9367
2022-01-22 21:07:25,906 Val Step[0750/1563], Avg Loss: 1.0525, Avg Acc@1: 0.7723, Avg Acc@5: 0.9364
2022-01-22 21:07:27,981 Val Step[0800/1563], Avg Loss: 1.0519, Avg Acc@1: 0.7734, Avg Acc@5: 0.9364
2022-01-22 21:07:30,065 Val Step[0850/1563], Avg Loss: 1.0536, Avg Acc@1: 0.7731, Avg Acc@5: 0.9361
2022-01-22 21:07:32,121 Val Step[0900/1563], Avg Loss: 1.0506, Avg Acc@1: 0.7736, Avg Acc@5: 0.9365
2022-01-22 21:07:34,198 Val Step[0950/1563], Avg Loss: 1.0502, Avg Acc@1: 0.7745, Avg Acc@5: 0.9366
2022-01-22 21:07:36,271 Val Step[1000/1563], Avg Loss: 1.0518, Avg Acc@1: 0.7743, Avg Acc@5: 0.9363
2022-01-22 21:07:38,361 Val Step[1050/1563], Avg Loss: 1.0533, Avg Acc@1: 0.7736, Avg Acc@5: 0.9362
2022-01-22 21:07:40,340 Val Step[1100/1563], Avg Loss: 1.0532, Avg Acc@1: 0.7732, Avg Acc@5: 0.9363
2022-01-22 21:07:42,163 Val Step[1150/1563], Avg Loss: 1.0511, Avg Acc@1: 0.7737, Avg Acc@5: 0.9367
2022-01-22 21:07:43,978 Val Step[1200/1563], Avg Loss: 1.0501, Avg Acc@1: 0.7745, Avg Acc@5: 0.9367
2022-01-22 21:07:45,779 Val Step[1250/1563], Avg Loss: 1.0497, Avg Acc@1: 0.7741, Avg Acc@5: 0.9369
2022-01-22 21:07:47,680 Val Step[1300/1563], Avg Loss: 1.0526, Avg Acc@1: 0.7738, Avg Acc@5: 0.9366
2022-01-22 21:07:49,512 Val Step[1350/1563], Avg Loss: 1.0535, Avg Acc@1: 0.7732, Avg Acc@5: 0.9364
2022-01-22 21:07:51,298 Val Step[1400/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7729, Avg Acc@5: 0.9364
2022-01-22 21:07:53,111 Val Step[1450/1563], Avg Loss: 1.0519, Avg Acc@1: 0.7733, Avg Acc@5: 0.9365
2022-01-22 21:07:54,936 Val Step[1500/1563], Avg Loss: 1.0522, Avg Acc@1: 0.7735, Avg Acc@5: 0.9367
2022-01-22 21:07:56,679 Val Step[1550/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7732, Avg Acc@5: 0.9367
2022-01-22 21:07:59,205 ----- Epoch[276/300], Validation Loss: 1.0528, Validation Acc@1: 0.7732, Validation Acc@5: 0.9367, time: 913.52
2022-01-22 21:08:00,338 the pre best model acc:0.7724, at epoch 274
2022-01-22 21:08:00,632 current best model acc:0.7732, at epoch 276
2022-01-22 21:08:00,632 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 21:08:00,632 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 21:08:00,632 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 21:08:00,632 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 21:08:00,632 Now training epoch 277. LR=0.000026
2022-01-22 21:09:51,429 Epoch[277/300], Step[0000/1252], Avg Loss: 3.0858, Avg Acc: 0.4609
2022-01-22 21:11:20,758 Epoch[277/300], Step[0050/1252], Avg Loss: 2.9632, Avg Acc: 0.5043
2022-01-22 21:12:48,617 Epoch[277/300], Step[0100/1252], Avg Loss: 2.9410, Avg Acc: 0.5067
2022-01-22 21:14:15,415 Epoch[277/300], Step[0150/1252], Avg Loss: 2.8972, Avg Acc: 0.5106
2022-01-22 21:15:44,432 Epoch[277/300], Step[0200/1252], Avg Loss: 2.9006, Avg Acc: 0.5036
2022-01-22 21:17:14,016 Epoch[277/300], Step[0250/1252], Avg Loss: 2.9086, Avg Acc: 0.5013
2022-01-22 21:18:41,168 Epoch[277/300], Step[0300/1252], Avg Loss: 2.9057, Avg Acc: 0.5056
2022-01-22 21:20:09,198 Epoch[277/300], Step[0350/1252], Avg Loss: 2.9124, Avg Acc: 0.5031
2022-01-22 21:21:37,803 Epoch[277/300], Step[0400/1252], Avg Loss: 2.9122, Avg Acc: 0.5015
2022-01-22 21:23:05,201 Epoch[277/300], Step[0450/1252], Avg Loss: 2.9218, Avg Acc: 0.4977
2022-01-22 21:24:33,666 Epoch[277/300], Step[0500/1252], Avg Loss: 2.9259, Avg Acc: 0.4978
2022-01-22 21:26:02,578 Epoch[277/300], Step[0550/1252], Avg Loss: 2.9210, Avg Acc: 0.4995
2022-01-22 21:27:30,002 Epoch[277/300], Step[0600/1252], Avg Loss: 2.9201, Avg Acc: 0.4968
2022-01-22 21:28:58,897 Epoch[277/300], Step[0650/1252], Avg Loss: 2.9252, Avg Acc: 0.4946
2022-01-22 21:30:27,738 Epoch[277/300], Step[0700/1252], Avg Loss: 2.9253, Avg Acc: 0.4913
2022-01-22 21:31:55,719 Epoch[277/300], Step[0750/1252], Avg Loss: 2.9274, Avg Acc: 0.4897
2022-01-22 21:33:24,403 Epoch[277/300], Step[0800/1252], Avg Loss: 2.9276, Avg Acc: 0.4895
2022-01-22 21:34:52,853 Epoch[277/300], Step[0850/1252], Avg Loss: 2.9262, Avg Acc: 0.4881
2022-01-22 21:36:21,741 Epoch[277/300], Step[0900/1252], Avg Loss: 2.9305, Avg Acc: 0.4879
2022-01-22 21:37:49,008 Epoch[277/300], Step[0950/1252], Avg Loss: 2.9274, Avg Acc: 0.4879
2022-01-22 21:39:17,455 Epoch[277/300], Step[1000/1252], Avg Loss: 2.9280, Avg Acc: 0.4875
2022-01-22 21:40:46,021 Epoch[277/300], Step[1050/1252], Avg Loss: 2.9264, Avg Acc: 0.4863
2022-01-22 21:42:13,681 Epoch[277/300], Step[1100/1252], Avg Loss: 2.9272, Avg Acc: 0.4857
2022-01-22 21:43:40,631 Epoch[277/300], Step[1150/1252], Avg Loss: 2.9270, Avg Acc: 0.4869
2022-01-22 21:45:08,198 Epoch[277/300], Step[1200/1252], Avg Loss: 2.9287, Avg Acc: 0.4870
2022-01-22 21:46:34,776 Epoch[277/300], Step[1250/1252], Avg Loss: 2.9312, Avg Acc: 0.4867
2022-01-22 21:46:41,979 ----- Epoch[277/300], Train Loss: 2.9313, Train Acc: 0.4866, time: 2321.34, Best Val(epoch276) Acc@1: 0.7732
2022-01-22 21:46:41,979 Now training epoch 278. LR=0.000025
2022-01-22 21:48:32,507 Epoch[278/300], Step[0000/1252], Avg Loss: 2.5621, Avg Acc: 0.6279
2022-01-22 21:50:01,836 Epoch[278/300], Step[0050/1252], Avg Loss: 2.9060, Avg Acc: 0.4315
2022-01-22 21:51:31,051 Epoch[278/300], Step[0100/1252], Avg Loss: 2.9217, Avg Acc: 0.4559
2022-01-22 21:53:00,332 Epoch[278/300], Step[0150/1252], Avg Loss: 2.9187, Avg Acc: 0.4670
2022-01-22 21:54:29,484 Epoch[278/300], Step[0200/1252], Avg Loss: 2.9188, Avg Acc: 0.4701
2022-01-22 21:55:57,778 Epoch[278/300], Step[0250/1252], Avg Loss: 2.9173, Avg Acc: 0.4794
2022-01-22 21:57:26,165 Epoch[278/300], Step[0300/1252], Avg Loss: 2.9146, Avg Acc: 0.4820
2022-01-22 21:58:54,386 Epoch[278/300], Step[0350/1252], Avg Loss: 2.9197, Avg Acc: 0.4807
2022-01-22 22:00:23,042 Epoch[278/300], Step[0400/1252], Avg Loss: 2.9195, Avg Acc: 0.4797
2022-01-22 22:01:50,619 Epoch[278/300], Step[0450/1252], Avg Loss: 2.9226, Avg Acc: 0.4796
2022-01-22 22:03:19,808 Epoch[278/300], Step[0500/1252], Avg Loss: 2.9220, Avg Acc: 0.4787
2022-01-22 22:04:48,370 Epoch[278/300], Step[0550/1252], Avg Loss: 2.9228, Avg Acc: 0.4800
2022-01-22 22:06:17,967 Epoch[278/300], Step[0600/1252], Avg Loss: 2.9218, Avg Acc: 0.4802
2022-01-22 22:07:46,807 Epoch[278/300], Step[0650/1252], Avg Loss: 2.9288, Avg Acc: 0.4796
2022-01-22 22:09:15,273 Epoch[278/300], Step[0700/1252], Avg Loss: 2.9257, Avg Acc: 0.4820
2022-01-22 22:10:44,171 Epoch[278/300], Step[0750/1252], Avg Loss: 2.9247, Avg Acc: 0.4814
2022-01-22 22:12:12,626 Epoch[278/300], Step[0800/1252], Avg Loss: 2.9264, Avg Acc: 0.4807
2022-01-22 22:13:40,322 Epoch[278/300], Step[0850/1252], Avg Loss: 2.9263, Avg Acc: 0.4798
2022-01-22 22:15:08,622 Epoch[278/300], Step[0900/1252], Avg Loss: 2.9281, Avg Acc: 0.4781
2022-01-22 22:16:35,755 Epoch[278/300], Step[0950/1252], Avg Loss: 2.9322, Avg Acc: 0.4767
2022-01-22 22:18:03,751 Epoch[278/300], Step[1000/1252], Avg Loss: 2.9347, Avg Acc: 0.4766
2022-01-22 22:19:31,066 Epoch[278/300], Step[1050/1252], Avg Loss: 2.9358, Avg Acc: 0.4758
2022-01-22 22:20:59,244 Epoch[278/300], Step[1100/1252], Avg Loss: 2.9356, Avg Acc: 0.4762
2022-01-22 22:22:28,425 Epoch[278/300], Step[1150/1252], Avg Loss: 2.9347, Avg Acc: 0.4756
2022-01-22 22:23:56,241 Epoch[278/300], Step[1200/1252], Avg Loss: 2.9359, Avg Acc: 0.4765
2022-01-22 22:25:24,767 Epoch[278/300], Step[1250/1252], Avg Loss: 2.9357, Avg Acc: 0.4771
2022-01-22 22:25:32,176 ----- Epoch[278/300], Train Loss: 2.9357, Train Acc: 0.4771, time: 2330.19, Best Val(epoch276) Acc@1: 0.7732
2022-01-22 22:25:32,176 ----- Validation after Epoch: 278
2022-01-22 22:26:50,583 Val Step[0000/1563], Avg Loss: 0.9181, Avg Acc@1: 0.8125, Avg Acc@5: 0.9688
2022-01-22 22:26:52,551 Val Step[0050/1563], Avg Loss: 1.0041, Avg Acc@1: 0.7849, Avg Acc@5: 0.9400
2022-01-22 22:26:54,443 Val Step[0100/1563], Avg Loss: 1.0328, Avg Acc@1: 0.7822, Avg Acc@5: 0.9369
2022-01-22 22:26:56,514 Val Step[0150/1563], Avg Loss: 1.0364, Avg Acc@1: 0.7821, Avg Acc@5: 0.9348
2022-01-22 22:26:58,567 Val Step[0200/1563], Avg Loss: 1.0356, Avg Acc@1: 0.7823, Avg Acc@5: 0.9373
2022-01-22 22:27:00,630 Val Step[0250/1563], Avg Loss: 1.0277, Avg Acc@1: 0.7811, Avg Acc@5: 0.9387
2022-01-22 22:27:02,670 Val Step[0300/1563], Avg Loss: 1.0280, Avg Acc@1: 0.7814, Avg Acc@5: 0.9379
2022-01-22 22:27:04,644 Val Step[0350/1563], Avg Loss: 1.0326, Avg Acc@1: 0.7808, Avg Acc@5: 0.9370
2022-01-22 22:27:06,485 Val Step[0400/1563], Avg Loss: 1.0324, Avg Acc@1: 0.7799, Avg Acc@5: 0.9365
2022-01-22 22:27:08,384 Val Step[0450/1563], Avg Loss: 1.0386, Avg Acc@1: 0.7768, Avg Acc@5: 0.9360
2022-01-22 22:27:10,348 Val Step[0500/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7767, Avg Acc@5: 0.9363
2022-01-22 22:27:12,309 Val Step[0550/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7756, Avg Acc@5: 0.9366
2022-01-22 22:27:14,215 Val Step[0600/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7754, Avg Acc@5: 0.9367
2022-01-22 22:27:16,144 Val Step[0650/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7752, Avg Acc@5: 0.9364
2022-01-22 22:27:17,951 Val Step[0700/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7760, Avg Acc@5: 0.9368
2022-01-22 22:27:19,827 Val Step[0750/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7738, Avg Acc@5: 0.9365
2022-01-22 22:27:21,735 Val Step[0800/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7745, Avg Acc@5: 0.9363
2022-01-22 22:27:23,642 Val Step[0850/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7743, Avg Acc@5: 0.9362
2022-01-22 22:27:25,528 Val Step[0900/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7749, Avg Acc@5: 0.9365
2022-01-22 22:27:27,451 Val Step[0950/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7756, Avg Acc@5: 0.9367
2022-01-22 22:27:29,370 Val Step[1000/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7754, Avg Acc@5: 0.9364
2022-01-22 22:27:31,313 Val Step[1050/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7752, Avg Acc@5: 0.9360
2022-01-22 22:27:33,230 Val Step[1100/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7747, Avg Acc@5: 0.9361
2022-01-22 22:27:35,155 Val Step[1150/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7749, Avg Acc@5: 0.9365
2022-01-22 22:27:37,076 Val Step[1200/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7758, Avg Acc@5: 0.9366
2022-01-22 22:27:38,951 Val Step[1250/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7754, Avg Acc@5: 0.9370
2022-01-22 22:27:40,796 Val Step[1300/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7749, Avg Acc@5: 0.9366
2022-01-22 22:27:42,694 Val Step[1350/1563], Avg Loss: 1.0461, Avg Acc@1: 0.7742, Avg Acc@5: 0.9364
2022-01-22 22:27:44,597 Val Step[1400/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7738, Avg Acc@5: 0.9364
2022-01-22 22:27:46,555 Val Step[1450/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7742, Avg Acc@5: 0.9364
2022-01-22 22:27:48,664 Val Step[1500/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7743, Avg Acc@5: 0.9366
2022-01-22 22:27:50,678 Val Step[1550/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7741, Avg Acc@5: 0.9366
2022-01-22 22:27:52,625 ----- Epoch[278/300], Validation Loss: 1.0454, Validation Acc@1: 0.7741, Validation Acc@5: 0.9367, time: 140.45
2022-01-22 22:27:53,762 the pre best model acc:0.7732, at epoch 276
2022-01-22 22:27:53,763 current best model acc:0.7741, at epoch 278
2022-01-22 22:27:53,763 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 22:27:53,763 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 22:27:53,763 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-22 22:27:53,763 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-22 22:27:53,763 Now training epoch 279. LR=0.000024
2022-01-22 22:29:41,980 Epoch[279/300], Step[0000/1252], Avg Loss: 3.0260, Avg Acc: 0.3760
2022-01-22 22:31:09,998 Epoch[279/300], Step[0050/1252], Avg Loss: 2.9478, Avg Acc: 0.5001
2022-01-22 22:32:38,460 Epoch[279/300], Step[0100/1252], Avg Loss: 2.8989, Avg Acc: 0.4908
2022-01-22 22:34:07,554 Epoch[279/300], Step[0150/1252], Avg Loss: 2.8866, Avg Acc: 0.4916
2022-01-22 22:35:34,936 Epoch[279/300], Step[0200/1252], Avg Loss: 2.9020, Avg Acc: 0.4978
2022-01-22 22:37:03,801 Epoch[279/300], Step[0250/1252], Avg Loss: 2.9109, Avg Acc: 0.4905
2022-01-22 22:38:31,364 Epoch[279/300], Step[0300/1252], Avg Loss: 2.9096, Avg Acc: 0.4917
2022-01-22 22:40:00,012 Epoch[279/300], Step[0350/1252], Avg Loss: 2.9051, Avg Acc: 0.4910
2022-01-22 22:41:27,553 Epoch[279/300], Step[0400/1252], Avg Loss: 2.9085, Avg Acc: 0.4905
2022-01-22 22:42:56,693 Epoch[279/300], Step[0450/1252], Avg Loss: 2.9086, Avg Acc: 0.4880
2022-01-22 22:44:24,619 Epoch[279/300], Step[0500/1252], Avg Loss: 2.9143, Avg Acc: 0.4903
2022-01-22 22:45:53,257 Epoch[279/300], Step[0550/1252], Avg Loss: 2.9134, Avg Acc: 0.4904
2022-01-22 22:47:21,062 Epoch[279/300], Step[0600/1252], Avg Loss: 2.9131, Avg Acc: 0.4891
2022-01-22 22:48:47,193 Epoch[279/300], Step[0650/1252], Avg Loss: 2.9160, Avg Acc: 0.4889
2022-01-22 22:50:13,493 Epoch[279/300], Step[0700/1252], Avg Loss: 2.9175, Avg Acc: 0.4884
2022-01-22 22:51:40,568 Epoch[279/300], Step[0750/1252], Avg Loss: 2.9191, Avg Acc: 0.4882
2022-01-22 22:53:09,421 Epoch[279/300], Step[0800/1252], Avg Loss: 2.9202, Avg Acc: 0.4859
2022-01-22 22:54:37,501 Epoch[279/300], Step[0850/1252], Avg Loss: 2.9165, Avg Acc: 0.4843
2022-01-22 22:56:06,647 Epoch[279/300], Step[0900/1252], Avg Loss: 2.9146, Avg Acc: 0.4841
2022-01-22 22:57:34,898 Epoch[279/300], Step[0950/1252], Avg Loss: 2.9148, Avg Acc: 0.4838
2022-01-22 22:59:03,842 Epoch[279/300], Step[1000/1252], Avg Loss: 2.9168, Avg Acc: 0.4821
2022-01-22 23:00:32,456 Epoch[279/300], Step[1050/1252], Avg Loss: 2.9183, Avg Acc: 0.4826
2022-01-22 23:02:01,592 Epoch[279/300], Step[1100/1252], Avg Loss: 2.9222, Avg Acc: 0.4821
2022-01-22 23:03:31,080 Epoch[279/300], Step[1150/1252], Avg Loss: 2.9213, Avg Acc: 0.4821
2022-01-22 23:04:59,514 Epoch[279/300], Step[1200/1252], Avg Loss: 2.9226, Avg Acc: 0.4822
2022-01-22 23:06:28,582 Epoch[279/300], Step[1250/1252], Avg Loss: 2.9236, Avg Acc: 0.4819
2022-01-22 23:06:36,057 ----- Epoch[279/300], Train Loss: 2.9236, Train Acc: 0.4819, time: 2322.29, Best Val(epoch278) Acc@1: 0.7741
2022-01-22 23:06:36,057 Now training epoch 280. LR=0.000022
2022-01-22 23:08:27,699 Epoch[280/300], Step[0000/1252], Avg Loss: 2.9691, Avg Acc: 0.3760
2022-01-22 23:09:56,041 Epoch[280/300], Step[0050/1252], Avg Loss: 2.9326, Avg Acc: 0.4822
2022-01-22 23:11:25,426 Epoch[280/300], Step[0100/1252], Avg Loss: 2.9460, Avg Acc: 0.4730
2022-01-22 23:12:53,723 Epoch[280/300], Step[0150/1252], Avg Loss: 2.9391, Avg Acc: 0.4790
2022-01-22 23:14:22,738 Epoch[280/300], Step[0200/1252], Avg Loss: 2.9418, Avg Acc: 0.4866
2022-01-22 23:15:52,224 Epoch[280/300], Step[0250/1252], Avg Loss: 2.9281, Avg Acc: 0.4892
2022-01-22 23:17:20,141 Epoch[280/300], Step[0300/1252], Avg Loss: 2.9248, Avg Acc: 0.4889
2022-01-22 23:18:47,751 Epoch[280/300], Step[0350/1252], Avg Loss: 2.9298, Avg Acc: 0.4846
2022-01-22 23:20:16,474 Epoch[280/300], Step[0400/1252], Avg Loss: 2.9360, Avg Acc: 0.4833
2022-01-22 23:21:46,109 Epoch[280/300], Step[0450/1252], Avg Loss: 2.9317, Avg Acc: 0.4819
2022-01-22 23:23:15,483 Epoch[280/300], Step[0500/1252], Avg Loss: 2.9360, Avg Acc: 0.4805
2022-01-22 23:24:43,261 Epoch[280/300], Step[0550/1252], Avg Loss: 2.9365, Avg Acc: 0.4813
2022-01-22 23:26:11,455 Epoch[280/300], Step[0600/1252], Avg Loss: 2.9349, Avg Acc: 0.4820
2022-01-22 23:27:41,158 Epoch[280/300], Step[0650/1252], Avg Loss: 2.9322, Avg Acc: 0.4798
2022-01-22 23:29:09,358 Epoch[280/300], Step[0700/1252], Avg Loss: 2.9271, Avg Acc: 0.4796
2022-01-22 23:30:38,277 Epoch[280/300], Step[0750/1252], Avg Loss: 2.9277, Avg Acc: 0.4765
2022-01-22 23:32:05,907 Epoch[280/300], Step[0800/1252], Avg Loss: 2.9270, Avg Acc: 0.4771
2022-01-22 23:33:34,173 Epoch[280/300], Step[0850/1252], Avg Loss: 2.9285, Avg Acc: 0.4782
2022-01-22 23:35:01,625 Epoch[280/300], Step[0900/1252], Avg Loss: 2.9267, Avg Acc: 0.4787
2022-01-22 23:36:27,801 Epoch[280/300], Step[0950/1252], Avg Loss: 2.9300, Avg Acc: 0.4767
2022-01-22 23:37:54,419 Epoch[280/300], Step[1000/1252], Avg Loss: 2.9289, Avg Acc: 0.4775
2022-01-22 23:39:21,504 Epoch[280/300], Step[1050/1252], Avg Loss: 2.9294, Avg Acc: 0.4768
2022-01-22 23:40:48,182 Epoch[280/300], Step[1100/1252], Avg Loss: 2.9275, Avg Acc: 0.4777
2022-01-22 23:42:14,835 Epoch[280/300], Step[1150/1252], Avg Loss: 2.9264, Avg Acc: 0.4794
2022-01-22 23:43:42,435 Epoch[280/300], Step[1200/1252], Avg Loss: 2.9276, Avg Acc: 0.4789
2022-01-22 23:45:09,470 Epoch[280/300], Step[1250/1252], Avg Loss: 2.9270, Avg Acc: 0.4792
2022-01-22 23:45:16,621 ----- Epoch[280/300], Train Loss: 2.9271, Train Acc: 0.4792, time: 2320.56, Best Val(epoch278) Acc@1: 0.7741
2022-01-22 23:45:16,621 ----- Validation after Epoch: 280
2022-01-22 23:46:27,999 Val Step[0000/1563], Avg Loss: 0.8100, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-22 23:46:30,011 Val Step[0050/1563], Avg Loss: 1.0009, Avg Acc@1: 0.7806, Avg Acc@5: 0.9400
2022-01-22 23:46:31,915 Val Step[0100/1563], Avg Loss: 1.0321, Avg Acc@1: 0.7806, Avg Acc@5: 0.9384
2022-01-22 23:46:33,812 Val Step[0150/1563], Avg Loss: 1.0359, Avg Acc@1: 0.7810, Avg Acc@5: 0.9363
2022-01-22 23:46:35,654 Val Step[0200/1563], Avg Loss: 1.0364, Avg Acc@1: 0.7816, Avg Acc@5: 0.9359
2022-01-22 23:46:37,586 Val Step[0250/1563], Avg Loss: 1.0260, Avg Acc@1: 0.7805, Avg Acc@5: 0.9376
2022-01-22 23:46:39,511 Val Step[0300/1563], Avg Loss: 1.0258, Avg Acc@1: 0.7802, Avg Acc@5: 0.9369
2022-01-22 23:46:41,469 Val Step[0350/1563], Avg Loss: 1.0310, Avg Acc@1: 0.7803, Avg Acc@5: 0.9365
2022-01-22 23:46:43,601 Val Step[0400/1563], Avg Loss: 1.0305, Avg Acc@1: 0.7801, Avg Acc@5: 0.9365
2022-01-22 23:46:45,700 Val Step[0450/1563], Avg Loss: 1.0356, Avg Acc@1: 0.7771, Avg Acc@5: 0.9359
2022-01-22 23:46:47,712 Val Step[0500/1563], Avg Loss: 1.0385, Avg Acc@1: 0.7761, Avg Acc@5: 0.9364
2022-01-22 23:46:49,553 Val Step[0550/1563], Avg Loss: 1.0373, Avg Acc@1: 0.7751, Avg Acc@5: 0.9368
2022-01-22 23:46:51,589 Val Step[0600/1563], Avg Loss: 1.0365, Avg Acc@1: 0.7753, Avg Acc@5: 0.9367
2022-01-22 23:46:53,650 Val Step[0650/1563], Avg Loss: 1.0370, Avg Acc@1: 0.7755, Avg Acc@5: 0.9364
2022-01-22 23:46:55,682 Val Step[0700/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7759, Avg Acc@5: 0.9368
2022-01-22 23:46:57,756 Val Step[0750/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7740, Avg Acc@5: 0.9363
2022-01-22 23:46:59,840 Val Step[0800/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7747, Avg Acc@5: 0.9364
2022-01-22 23:47:01,890 Val Step[0850/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7740, Avg Acc@5: 0.9359
2022-01-22 23:47:03,998 Val Step[0900/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7748, Avg Acc@5: 0.9363
2022-01-22 23:47:06,025 Val Step[0950/1563], Avg Loss: 1.0374, Avg Acc@1: 0.7754, Avg Acc@5: 0.9365
2022-01-22 23:47:08,079 Val Step[1000/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7747, Avg Acc@5: 0.9362
2022-01-22 23:47:10,184 Val Step[1050/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7738, Avg Acc@5: 0.9360
2022-01-22 23:47:12,293 Val Step[1100/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7734, Avg Acc@5: 0.9360
2022-01-22 23:47:14,413 Val Step[1150/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7739, Avg Acc@5: 0.9363
2022-01-22 23:47:16,489 Val Step[1200/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7744, Avg Acc@5: 0.9364
2022-01-22 23:47:18,556 Val Step[1250/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7737, Avg Acc@5: 0.9368
2022-01-22 23:47:20,612 Val Step[1300/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7735, Avg Acc@5: 0.9363
2022-01-22 23:47:22,672 Val Step[1350/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7730, Avg Acc@5: 0.9361
2022-01-22 23:47:24,726 Val Step[1400/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7729, Avg Acc@5: 0.9361
2022-01-22 23:47:26,785 Val Step[1450/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7735, Avg Acc@5: 0.9362
2022-01-22 23:47:28,846 Val Step[1500/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7736, Avg Acc@5: 0.9363
2022-01-22 23:47:30,852 Val Step[1550/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7734, Avg Acc@5: 0.9361
2022-01-22 23:47:32,905 ----- Epoch[280/300], Validation Loss: 1.0402, Validation Acc@1: 0.7733, Validation Acc@5: 0.9362, time: 136.28
2022-01-22 23:47:32,906 Now training epoch 281. LR=0.000021
2022-01-22 23:49:17,454 Epoch[281/300], Step[0000/1252], Avg Loss: 2.8124, Avg Acc: 0.6797
2022-01-22 23:50:45,022 Epoch[281/300], Step[0050/1252], Avg Loss: 2.9112, Avg Acc: 0.4652
2022-01-22 23:52:13,024 Epoch[281/300], Step[0100/1252], Avg Loss: 2.9053, Avg Acc: 0.4987
2022-01-22 23:53:40,475 Epoch[281/300], Step[0150/1252], Avg Loss: 2.9064, Avg Acc: 0.4936
2022-01-22 23:55:07,672 Epoch[281/300], Step[0200/1252], Avg Loss: 2.9360, Avg Acc: 0.4888
2022-01-22 23:56:36,525 Epoch[281/300], Step[0250/1252], Avg Loss: 2.9344, Avg Acc: 0.4945
2022-01-22 23:58:04,681 Epoch[281/300], Step[0300/1252], Avg Loss: 2.9378, Avg Acc: 0.4974
2022-01-22 23:59:31,577 Epoch[281/300], Step[0350/1252], Avg Loss: 2.9314, Avg Acc: 0.4973
2022-01-23 00:00:59,924 Epoch[281/300], Step[0400/1252], Avg Loss: 2.9339, Avg Acc: 0.4996
2022-01-23 00:02:27,323 Epoch[281/300], Step[0450/1252], Avg Loss: 2.9320, Avg Acc: 0.4975
2022-01-23 00:03:54,508 Epoch[281/300], Step[0500/1252], Avg Loss: 2.9244, Avg Acc: 0.4960
2022-01-23 00:05:22,239 Epoch[281/300], Step[0550/1252], Avg Loss: 2.9231, Avg Acc: 0.4967
2022-01-23 00:06:50,761 Epoch[281/300], Step[0600/1252], Avg Loss: 2.9189, Avg Acc: 0.4956
2022-01-23 00:08:19,579 Epoch[281/300], Step[0650/1252], Avg Loss: 2.9212, Avg Acc: 0.4940
2022-01-23 00:09:48,889 Epoch[281/300], Step[0700/1252], Avg Loss: 2.9202, Avg Acc: 0.4927
2022-01-23 00:11:17,826 Epoch[281/300], Step[0750/1252], Avg Loss: 2.9226, Avg Acc: 0.4927
2022-01-23 00:12:47,170 Epoch[281/300], Step[0800/1252], Avg Loss: 2.9229, Avg Acc: 0.4933
2022-01-23 00:14:15,423 Epoch[281/300], Step[0850/1252], Avg Loss: 2.9205, Avg Acc: 0.4939
2022-01-23 00:15:43,076 Epoch[281/300], Step[0900/1252], Avg Loss: 2.9195, Avg Acc: 0.4925
2022-01-23 00:17:08,027 Epoch[281/300], Step[0950/1252], Avg Loss: 2.9186, Avg Acc: 0.4932
2022-01-23 00:18:35,741 Epoch[281/300], Step[1000/1252], Avg Loss: 2.9187, Avg Acc: 0.4918
2022-01-23 00:20:03,444 Epoch[281/300], Step[1050/1252], Avg Loss: 2.9204, Avg Acc: 0.4918
2022-01-23 00:21:32,643 Epoch[281/300], Step[1100/1252], Avg Loss: 2.9218, Avg Acc: 0.4911
2022-01-23 00:23:00,788 Epoch[281/300], Step[1150/1252], Avg Loss: 2.9236, Avg Acc: 0.4902
2022-01-23 00:24:29,929 Epoch[281/300], Step[1200/1252], Avg Loss: 2.9206, Avg Acc: 0.4899
2022-01-23 00:25:58,649 Epoch[281/300], Step[1250/1252], Avg Loss: 2.9190, Avg Acc: 0.4887
2022-01-23 00:26:05,792 ----- Epoch[281/300], Train Loss: 2.9190, Train Acc: 0.4887, time: 2312.88, Best Val(epoch278) Acc@1: 0.7741
2022-01-23 00:26:05,792 Now training epoch 282. LR=0.000020
2022-01-23 00:27:58,290 Epoch[282/300], Step[0000/1252], Avg Loss: 2.4877, Avg Acc: 0.7070
2022-01-23 00:29:24,666 Epoch[282/300], Step[0050/1252], Avg Loss: 2.8686, Avg Acc: 0.4935
2022-01-23 00:30:50,843 Epoch[282/300], Step[0100/1252], Avg Loss: 2.9017, Avg Acc: 0.5070
2022-01-23 00:32:19,084 Epoch[282/300], Step[0150/1252], Avg Loss: 2.8968, Avg Acc: 0.4926
2022-01-23 00:33:47,289 Epoch[282/300], Step[0200/1252], Avg Loss: 2.9028, Avg Acc: 0.4935
2022-01-23 00:35:14,635 Epoch[282/300], Step[0250/1252], Avg Loss: 2.9154, Avg Acc: 0.4921
2022-01-23 00:36:41,100 Epoch[282/300], Step[0300/1252], Avg Loss: 2.9172, Avg Acc: 0.4963
2022-01-23 00:38:09,315 Epoch[282/300], Step[0350/1252], Avg Loss: 2.9152, Avg Acc: 0.4938
2022-01-23 00:39:36,699 Epoch[282/300], Step[0400/1252], Avg Loss: 2.9267, Avg Acc: 0.4904
2022-01-23 00:41:04,377 Epoch[282/300], Step[0450/1252], Avg Loss: 2.9288, Avg Acc: 0.4905
2022-01-23 00:42:33,364 Epoch[282/300], Step[0500/1252], Avg Loss: 2.9261, Avg Acc: 0.4900
2022-01-23 00:44:02,559 Epoch[282/300], Step[0550/1252], Avg Loss: 2.9322, Avg Acc: 0.4895
2022-01-23 00:45:30,930 Epoch[282/300], Step[0600/1252], Avg Loss: 2.9304, Avg Acc: 0.4871
2022-01-23 00:47:00,663 Epoch[282/300], Step[0650/1252], Avg Loss: 2.9301, Avg Acc: 0.4874
2022-01-23 00:48:29,981 Epoch[282/300], Step[0700/1252], Avg Loss: 2.9237, Avg Acc: 0.4870
2022-01-23 00:49:56,751 Epoch[282/300], Step[0750/1252], Avg Loss: 2.9236, Avg Acc: 0.4861
2022-01-23 00:51:25,288 Epoch[282/300], Step[0800/1252], Avg Loss: 2.9197, Avg Acc: 0.4862
2022-01-23 00:52:55,102 Epoch[282/300], Step[0850/1252], Avg Loss: 2.9219, Avg Acc: 0.4854
2022-01-23 00:54:24,012 Epoch[282/300], Step[0900/1252], Avg Loss: 2.9236, Avg Acc: 0.4847
2022-01-23 00:55:53,770 Epoch[282/300], Step[0950/1252], Avg Loss: 2.9224, Avg Acc: 0.4849
2022-01-23 00:57:21,079 Epoch[282/300], Step[1000/1252], Avg Loss: 2.9233, Avg Acc: 0.4836
2022-01-23 00:58:48,764 Epoch[282/300], Step[1050/1252], Avg Loss: 2.9237, Avg Acc: 0.4839
2022-01-23 01:00:18,037 Epoch[282/300], Step[1100/1252], Avg Loss: 2.9229, Avg Acc: 0.4852
2022-01-23 01:01:46,334 Epoch[282/300], Step[1150/1252], Avg Loss: 2.9204, Avg Acc: 0.4859
2022-01-23 01:03:14,696 Epoch[282/300], Step[1200/1252], Avg Loss: 2.9197, Avg Acc: 0.4860
2022-01-23 01:04:43,880 Epoch[282/300], Step[1250/1252], Avg Loss: 2.9219, Avg Acc: 0.4855
2022-01-23 01:04:51,064 ----- Epoch[282/300], Train Loss: 2.9218, Train Acc: 0.4856, time: 2325.27, Best Val(epoch278) Acc@1: 0.7741
2022-01-23 01:04:51,064 ----- Validation after Epoch: 282
2022-01-23 01:06:24,882 Val Step[0000/1563], Avg Loss: 0.8248, Avg Acc@1: 0.8438, Avg Acc@5: 1.0000
2022-01-23 01:06:26,977 Val Step[0050/1563], Avg Loss: 1.0195, Avg Acc@1: 0.7782, Avg Acc@5: 0.9381
2022-01-23 01:06:28,954 Val Step[0100/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7812, Avg Acc@5: 0.9350
2022-01-23 01:06:30,789 Val Step[0150/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7808, Avg Acc@5: 0.9344
2022-01-23 01:06:32,580 Val Step[0200/1563], Avg Loss: 1.0538, Avg Acc@1: 0.7806, Avg Acc@5: 0.9352
2022-01-23 01:06:34,539 Val Step[0250/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7796, Avg Acc@5: 0.9371
2022-01-23 01:06:36,398 Val Step[0300/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7797, Avg Acc@5: 0.9364
2022-01-23 01:06:38,291 Val Step[0350/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7787, Avg Acc@5: 0.9359
2022-01-23 01:06:40,248 Val Step[0400/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7785, Avg Acc@5: 0.9355
2022-01-23 01:06:42,135 Val Step[0450/1563], Avg Loss: 1.0539, Avg Acc@1: 0.7754, Avg Acc@5: 0.9354
2022-01-23 01:06:43,923 Val Step[0500/1563], Avg Loss: 1.0577, Avg Acc@1: 0.7746, Avg Acc@5: 0.9359
2022-01-23 01:06:45,712 Val Step[0550/1563], Avg Loss: 1.0570, Avg Acc@1: 0.7737, Avg Acc@5: 0.9363
2022-01-23 01:06:47,540 Val Step[0600/1563], Avg Loss: 1.0556, Avg Acc@1: 0.7738, Avg Acc@5: 0.9366
2022-01-23 01:06:49,313 Val Step[0650/1563], Avg Loss: 1.0561, Avg Acc@1: 0.7739, Avg Acc@5: 0.9366
2022-01-23 01:06:51,092 Val Step[0700/1563], Avg Loss: 1.0534, Avg Acc@1: 0.7745, Avg Acc@5: 0.9373
2022-01-23 01:06:53,063 Val Step[0750/1563], Avg Loss: 1.0585, Avg Acc@1: 0.7730, Avg Acc@5: 0.9368
2022-01-23 01:06:54,886 Val Step[0800/1563], Avg Loss: 1.0582, Avg Acc@1: 0.7736, Avg Acc@5: 0.9368
2022-01-23 01:06:56,669 Val Step[0850/1563], Avg Loss: 1.0598, Avg Acc@1: 0.7735, Avg Acc@5: 0.9363
2022-01-23 01:06:58,487 Val Step[0900/1563], Avg Loss: 1.0564, Avg Acc@1: 0.7740, Avg Acc@5: 0.9367
2022-01-23 01:07:00,284 Val Step[0950/1563], Avg Loss: 1.0561, Avg Acc@1: 0.7743, Avg Acc@5: 0.9368
2022-01-23 01:07:02,131 Val Step[1000/1563], Avg Loss: 1.0582, Avg Acc@1: 0.7739, Avg Acc@5: 0.9364
2022-01-23 01:07:03,973 Val Step[1050/1563], Avg Loss: 1.0601, Avg Acc@1: 0.7730, Avg Acc@5: 0.9360
2022-01-23 01:07:05,870 Val Step[1100/1563], Avg Loss: 1.0601, Avg Acc@1: 0.7724, Avg Acc@5: 0.9361
2022-01-23 01:07:07,748 Val Step[1150/1563], Avg Loss: 1.0575, Avg Acc@1: 0.7730, Avg Acc@5: 0.9364
2022-01-23 01:07:09,641 Val Step[1200/1563], Avg Loss: 1.0565, Avg Acc@1: 0.7737, Avg Acc@5: 0.9365
2022-01-23 01:07:11,420 Val Step[1250/1563], Avg Loss: 1.0563, Avg Acc@1: 0.7734, Avg Acc@5: 0.9368
2022-01-23 01:07:13,209 Val Step[1300/1563], Avg Loss: 1.0593, Avg Acc@1: 0.7731, Avg Acc@5: 0.9364
2022-01-23 01:07:15,136 Val Step[1350/1563], Avg Loss: 1.0607, Avg Acc@1: 0.7725, Avg Acc@5: 0.9362
2022-01-23 01:07:17,039 Val Step[1400/1563], Avg Loss: 1.0602, Avg Acc@1: 0.7724, Avg Acc@5: 0.9362
2022-01-23 01:07:18,883 Val Step[1450/1563], Avg Loss: 1.0594, Avg Acc@1: 0.7727, Avg Acc@5: 0.9363
2022-01-23 01:07:20,692 Val Step[1500/1563], Avg Loss: 1.0595, Avg Acc@1: 0.7729, Avg Acc@5: 0.9365
2022-01-23 01:07:22,449 Val Step[1550/1563], Avg Loss: 1.0598, Avg Acc@1: 0.7728, Avg Acc@5: 0.9363
2022-01-23 01:07:24,418 ----- Epoch[282/300], Validation Loss: 1.0597, Validation Acc@1: 0.7728, Validation Acc@5: 0.9363, time: 153.35
2022-01-23 01:07:24,418 Now training epoch 283. LR=0.000019
2022-01-23 01:09:23,447 Epoch[283/300], Step[0000/1252], Avg Loss: 2.6681, Avg Acc: 0.6182
2022-01-23 01:10:50,658 Epoch[283/300], Step[0050/1252], Avg Loss: 2.8717, Avg Acc: 0.4756
2022-01-23 01:12:17,655 Epoch[283/300], Step[0100/1252], Avg Loss: 2.9116, Avg Acc: 0.4723
2022-01-23 01:13:45,844 Epoch[283/300], Step[0150/1252], Avg Loss: 2.8971, Avg Acc: 0.4770
2022-01-23 01:15:13,273 Epoch[283/300], Step[0200/1252], Avg Loss: 2.9072, Avg Acc: 0.4789
2022-01-23 01:16:41,819 Epoch[283/300], Step[0250/1252], Avg Loss: 2.9062, Avg Acc: 0.4766
2022-01-23 01:18:09,073 Epoch[283/300], Step[0300/1252], Avg Loss: 2.9172, Avg Acc: 0.4784
2022-01-23 01:19:37,584 Epoch[283/300], Step[0350/1252], Avg Loss: 2.9117, Avg Acc: 0.4777
2022-01-23 01:21:05,473 Epoch[283/300], Step[0400/1252], Avg Loss: 2.9058, Avg Acc: 0.4786
2022-01-23 01:22:33,925 Epoch[283/300], Step[0450/1252], Avg Loss: 2.9078, Avg Acc: 0.4784
2022-01-23 01:24:02,112 Epoch[283/300], Step[0500/1252], Avg Loss: 2.9137, Avg Acc: 0.4814
2022-01-23 01:25:29,085 Epoch[283/300], Step[0550/1252], Avg Loss: 2.9157, Avg Acc: 0.4843
2022-01-23 01:26:57,368 Epoch[283/300], Step[0600/1252], Avg Loss: 2.9126, Avg Acc: 0.4820
2022-01-23 01:28:25,801 Epoch[283/300], Step[0650/1252], Avg Loss: 2.9147, Avg Acc: 0.4807
2022-01-23 01:29:53,702 Epoch[283/300], Step[0700/1252], Avg Loss: 2.9135, Avg Acc: 0.4830
2022-01-23 01:31:20,986 Epoch[283/300], Step[0750/1252], Avg Loss: 2.9123, Avg Acc: 0.4845
2022-01-23 01:32:47,779 Epoch[283/300], Step[0800/1252], Avg Loss: 2.9129, Avg Acc: 0.4847
2022-01-23 01:34:14,788 Epoch[283/300], Step[0850/1252], Avg Loss: 2.9118, Avg Acc: 0.4860
2022-01-23 01:35:43,044 Epoch[283/300], Step[0900/1252], Avg Loss: 2.9081, Avg Acc: 0.4879
2022-01-23 01:37:11,219 Epoch[283/300], Step[0950/1252], Avg Loss: 2.9083, Avg Acc: 0.4872
2022-01-23 01:38:40,070 Epoch[283/300], Step[1000/1252], Avg Loss: 2.9085, Avg Acc: 0.4866
2022-01-23 01:40:08,557 Epoch[283/300], Step[1050/1252], Avg Loss: 2.9104, Avg Acc: 0.4844
2022-01-23 01:41:36,124 Epoch[283/300], Step[1100/1252], Avg Loss: 2.9122, Avg Acc: 0.4825
2022-01-23 01:43:03,831 Epoch[283/300], Step[1150/1252], Avg Loss: 2.9148, Avg Acc: 0.4822
2022-01-23 01:44:32,599 Epoch[283/300], Step[1200/1252], Avg Loss: 2.9155, Avg Acc: 0.4823
2022-01-23 01:46:01,298 Epoch[283/300], Step[1250/1252], Avg Loss: 2.9170, Avg Acc: 0.4817
2022-01-23 01:46:08,374 ----- Epoch[283/300], Train Loss: 2.9170, Train Acc: 0.4817, time: 2323.95, Best Val(epoch278) Acc@1: 0.7741
2022-01-23 01:46:08,374 Now training epoch 284. LR=0.000018
2022-01-23 01:47:54,898 Epoch[284/300], Step[0000/1252], Avg Loss: 2.4146, Avg Acc: 0.1660
2022-01-23 01:49:23,327 Epoch[284/300], Step[0050/1252], Avg Loss: 2.9237, Avg Acc: 0.4942
2022-01-23 01:50:51,678 Epoch[284/300], Step[0100/1252], Avg Loss: 2.9089, Avg Acc: 0.4753
2022-01-23 01:52:19,344 Epoch[284/300], Step[0150/1252], Avg Loss: 2.8985, Avg Acc: 0.4916
2022-01-23 01:53:46,730 Epoch[284/300], Step[0200/1252], Avg Loss: 2.8955, Avg Acc: 0.4914
2022-01-23 01:55:14,620 Epoch[284/300], Step[0250/1252], Avg Loss: 2.8966, Avg Acc: 0.4794
2022-01-23 01:56:42,752 Epoch[284/300], Step[0300/1252], Avg Loss: 2.9064, Avg Acc: 0.4778
2022-01-23 01:58:10,371 Epoch[284/300], Step[0350/1252], Avg Loss: 2.9007, Avg Acc: 0.4845
2022-01-23 01:59:39,008 Epoch[284/300], Step[0400/1252], Avg Loss: 2.8993, Avg Acc: 0.4891
2022-01-23 02:01:07,377 Epoch[284/300], Step[0450/1252], Avg Loss: 2.9027, Avg Acc: 0.4877
2022-01-23 02:02:34,122 Epoch[284/300], Step[0500/1252], Avg Loss: 2.9080, Avg Acc: 0.4862
2022-01-23 02:04:02,260 Epoch[284/300], Step[0550/1252], Avg Loss: 2.9091, Avg Acc: 0.4869
2022-01-23 02:05:30,882 Epoch[284/300], Step[0600/1252], Avg Loss: 2.9075, Avg Acc: 0.4878
2022-01-23 02:06:59,721 Epoch[284/300], Step[0650/1252], Avg Loss: 2.9048, Avg Acc: 0.4865
2022-01-23 02:08:28,837 Epoch[284/300], Step[0700/1252], Avg Loss: 2.9066, Avg Acc: 0.4876
2022-01-23 02:09:58,733 Epoch[284/300], Step[0750/1252], Avg Loss: 2.9040, Avg Acc: 0.4878
2022-01-23 02:11:27,242 Epoch[284/300], Step[0800/1252], Avg Loss: 2.9032, Avg Acc: 0.4854
2022-01-23 02:12:55,823 Epoch[284/300], Step[0850/1252], Avg Loss: 2.9030, Avg Acc: 0.4859
2022-01-23 02:14:23,475 Epoch[284/300], Step[0900/1252], Avg Loss: 2.9061, Avg Acc: 0.4827
2022-01-23 02:15:51,266 Epoch[284/300], Step[0950/1252], Avg Loss: 2.9075, Avg Acc: 0.4828
2022-01-23 02:17:19,593 Epoch[284/300], Step[1000/1252], Avg Loss: 2.9053, Avg Acc: 0.4829
2022-01-23 02:18:47,896 Epoch[284/300], Step[1050/1252], Avg Loss: 2.9080, Avg Acc: 0.4807
2022-01-23 02:20:17,126 Epoch[284/300], Step[1100/1252], Avg Loss: 2.9059, Avg Acc: 0.4838
2022-01-23 02:21:43,857 Epoch[284/300], Step[1150/1252], Avg Loss: 2.9063, Avg Acc: 0.4854
2022-01-23 02:23:12,056 Epoch[284/300], Step[1200/1252], Avg Loss: 2.9091, Avg Acc: 0.4839
2022-01-23 02:24:40,541 Epoch[284/300], Step[1250/1252], Avg Loss: 2.9112, Avg Acc: 0.4842
2022-01-23 02:24:47,884 ----- Epoch[284/300], Train Loss: 2.9112, Train Acc: 0.4842, time: 2319.51, Best Val(epoch278) Acc@1: 0.7741
2022-01-23 02:24:47,884 ----- Validation after Epoch: 284
2022-01-23 02:25:59,525 Val Step[0000/1563], Avg Loss: 0.8425, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 02:26:01,404 Val Step[0050/1563], Avg Loss: 1.0133, Avg Acc@1: 0.7837, Avg Acc@5: 0.9387
2022-01-23 02:26:03,220 Val Step[0100/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7809, Avg Acc@5: 0.9369
2022-01-23 02:26:05,045 Val Step[0150/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7815, Avg Acc@5: 0.9350
2022-01-23 02:26:06,844 Val Step[0200/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7816, Avg Acc@5: 0.9347
2022-01-23 02:26:08,646 Val Step[0250/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7809, Avg Acc@5: 0.9364
2022-01-23 02:26:10,464 Val Step[0300/1563], Avg Loss: 1.0388, Avg Acc@1: 0.7807, Avg Acc@5: 0.9356
2022-01-23 02:26:12,311 Val Step[0350/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7804, Avg Acc@5: 0.9352
2022-01-23 02:26:14,221 Val Step[0400/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7812, Avg Acc@5: 0.9348
2022-01-23 02:26:16,152 Val Step[0450/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7781, Avg Acc@5: 0.9342
2022-01-23 02:26:18,058 Val Step[0500/1563], Avg Loss: 1.0524, Avg Acc@1: 0.7769, Avg Acc@5: 0.9346
2022-01-23 02:26:19,943 Val Step[0550/1563], Avg Loss: 1.0514, Avg Acc@1: 0.7760, Avg Acc@5: 0.9353
2022-01-23 02:26:21,722 Val Step[0600/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7759, Avg Acc@5: 0.9353
2022-01-23 02:26:23,515 Val Step[0650/1563], Avg Loss: 1.0500, Avg Acc@1: 0.7757, Avg Acc@5: 0.9355
2022-01-23 02:26:25,314 Val Step[0700/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7762, Avg Acc@5: 0.9359
2022-01-23 02:26:27,110 Val Step[0750/1563], Avg Loss: 1.0544, Avg Acc@1: 0.7743, Avg Acc@5: 0.9356
2022-01-23 02:26:28,942 Val Step[0800/1563], Avg Loss: 1.0537, Avg Acc@1: 0.7751, Avg Acc@5: 0.9355
2022-01-23 02:26:30,802 Val Step[0850/1563], Avg Loss: 1.0549, Avg Acc@1: 0.7749, Avg Acc@5: 0.9351
2022-01-23 02:26:32,610 Val Step[0900/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7758, Avg Acc@5: 0.9355
2022-01-23 02:26:34,476 Val Step[0950/1563], Avg Loss: 1.0512, Avg Acc@1: 0.7764, Avg Acc@5: 0.9357
2022-01-23 02:26:36,259 Val Step[1000/1563], Avg Loss: 1.0532, Avg Acc@1: 0.7758, Avg Acc@5: 0.9353
2022-01-23 02:26:38,041 Val Step[1050/1563], Avg Loss: 1.0548, Avg Acc@1: 0.7751, Avg Acc@5: 0.9354
2022-01-23 02:26:39,839 Val Step[1100/1563], Avg Loss: 1.0551, Avg Acc@1: 0.7746, Avg Acc@5: 0.9354
2022-01-23 02:26:41,669 Val Step[1150/1563], Avg Loss: 1.0529, Avg Acc@1: 0.7750, Avg Acc@5: 0.9357
2022-01-23 02:26:43,490 Val Step[1200/1563], Avg Loss: 1.0522, Avg Acc@1: 0.7755, Avg Acc@5: 0.9358
2022-01-23 02:26:45,278 Val Step[1250/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7750, Avg Acc@5: 0.9362
2022-01-23 02:26:47,100 Val Step[1300/1563], Avg Loss: 1.0551, Avg Acc@1: 0.7748, Avg Acc@5: 0.9356
2022-01-23 02:26:48,904 Val Step[1350/1563], Avg Loss: 1.0566, Avg Acc@1: 0.7744, Avg Acc@5: 0.9355
2022-01-23 02:26:50,709 Val Step[1400/1563], Avg Loss: 1.0562, Avg Acc@1: 0.7741, Avg Acc@5: 0.9354
2022-01-23 02:26:52,501 Val Step[1450/1563], Avg Loss: 1.0548, Avg Acc@1: 0.7745, Avg Acc@5: 0.9355
2022-01-23 02:26:54,324 Val Step[1500/1563], Avg Loss: 1.0549, Avg Acc@1: 0.7745, Avg Acc@5: 0.9358
2022-01-23 02:26:56,089 Val Step[1550/1563], Avg Loss: 1.0553, Avg Acc@1: 0.7744, Avg Acc@5: 0.9356
2022-01-23 02:26:58,030 ----- Epoch[284/300], Validation Loss: 1.0551, Validation Acc@1: 0.7744, Validation Acc@5: 0.9357, time: 130.14
2022-01-23 02:26:59,210 the pre best model acc:0.7741, at epoch 278
2022-01-23 02:26:59,210 current best model acc:0.7744, at epoch 284
2022-01-23 02:26:59,210 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 02:26:59,210 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 02:26:59,210 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 02:26:59,210 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 02:26:59,211 Now training epoch 285. LR=0.000017
2022-01-23 02:28:46,398 Epoch[285/300], Step[0000/1252], Avg Loss: 2.9304, Avg Acc: 0.4785
2022-01-23 02:30:13,727 Epoch[285/300], Step[0050/1252], Avg Loss: 2.8751, Avg Acc: 0.4771
2022-01-23 02:31:40,524 Epoch[285/300], Step[0100/1252], Avg Loss: 2.9251, Avg Acc: 0.4717
2022-01-23 02:33:08,780 Epoch[285/300], Step[0150/1252], Avg Loss: 2.9363, Avg Acc: 0.4770
2022-01-23 02:34:35,470 Epoch[285/300], Step[0200/1252], Avg Loss: 2.9368, Avg Acc: 0.4791
2022-01-23 02:36:03,688 Epoch[285/300], Step[0250/1252], Avg Loss: 2.9381, Avg Acc: 0.4769
2022-01-23 02:37:31,862 Epoch[285/300], Step[0300/1252], Avg Loss: 2.9340, Avg Acc: 0.4765
2022-01-23 02:38:59,278 Epoch[285/300], Step[0350/1252], Avg Loss: 2.9345, Avg Acc: 0.4770
2022-01-23 02:40:27,185 Epoch[285/300], Step[0400/1252], Avg Loss: 2.9376, Avg Acc: 0.4807
2022-01-23 02:41:54,504 Epoch[285/300], Step[0450/1252], Avg Loss: 2.9410, Avg Acc: 0.4833
2022-01-23 02:43:22,350 Epoch[285/300], Step[0500/1252], Avg Loss: 2.9359, Avg Acc: 0.4808
2022-01-23 02:44:50,043 Epoch[285/300], Step[0550/1252], Avg Loss: 2.9272, Avg Acc: 0.4824
2022-01-23 02:46:17,283 Epoch[285/300], Step[0600/1252], Avg Loss: 2.9250, Avg Acc: 0.4822
2022-01-23 02:47:45,630 Epoch[285/300], Step[0650/1252], Avg Loss: 2.9224, Avg Acc: 0.4817
2022-01-23 02:49:13,168 Epoch[285/300], Step[0700/1252], Avg Loss: 2.9216, Avg Acc: 0.4797
2022-01-23 02:50:41,492 Epoch[285/300], Step[0750/1252], Avg Loss: 2.9212, Avg Acc: 0.4793
2022-01-23 02:52:09,148 Epoch[285/300], Step[0800/1252], Avg Loss: 2.9268, Avg Acc: 0.4794
2022-01-23 02:53:37,846 Epoch[285/300], Step[0850/1252], Avg Loss: 2.9296, Avg Acc: 0.4786
2022-01-23 02:55:06,775 Epoch[285/300], Step[0900/1252], Avg Loss: 2.9286, Avg Acc: 0.4790
2022-01-23 02:56:36,364 Epoch[285/300], Step[0950/1252], Avg Loss: 2.9263, Avg Acc: 0.4792
2022-01-23 02:58:05,331 Epoch[285/300], Step[1000/1252], Avg Loss: 2.9255, Avg Acc: 0.4798
2022-01-23 02:59:34,036 Epoch[285/300], Step[1050/1252], Avg Loss: 2.9241, Avg Acc: 0.4799
2022-01-23 03:01:02,555 Epoch[285/300], Step[1100/1252], Avg Loss: 2.9275, Avg Acc: 0.4791
2022-01-23 03:02:30,620 Epoch[285/300], Step[1150/1252], Avg Loss: 2.9288, Avg Acc: 0.4801
2022-01-23 03:03:59,817 Epoch[285/300], Step[1200/1252], Avg Loss: 2.9279, Avg Acc: 0.4799
2022-01-23 03:05:29,650 Epoch[285/300], Step[1250/1252], Avg Loss: 2.9301, Avg Acc: 0.4801
2022-01-23 03:05:36,460 ----- Epoch[285/300], Train Loss: 2.9301, Train Acc: 0.4801, time: 2317.24, Best Val(epoch284) Acc@1: 0.7744
2022-01-23 03:05:36,460 Now training epoch 286. LR=0.000016
2022-01-23 03:07:38,682 Epoch[286/300], Step[0000/1252], Avg Loss: 3.3043, Avg Acc: 0.5273
2022-01-23 03:09:06,692 Epoch[286/300], Step[0050/1252], Avg Loss: 2.9245, Avg Acc: 0.4952
2022-01-23 03:10:32,881 Epoch[286/300], Step[0100/1252], Avg Loss: 2.9082, Avg Acc: 0.4942
2022-01-23 03:11:59,586 Epoch[286/300], Step[0150/1252], Avg Loss: 2.9140, Avg Acc: 0.4793
2022-01-23 03:13:27,468 Epoch[286/300], Step[0200/1252], Avg Loss: 2.9124, Avg Acc: 0.4772
2022-01-23 03:14:54,497 Epoch[286/300], Step[0250/1252], Avg Loss: 2.9009, Avg Acc: 0.4804
2022-01-23 03:16:22,429 Epoch[286/300], Step[0300/1252], Avg Loss: 2.9032, Avg Acc: 0.4815
2022-01-23 03:17:49,899 Epoch[286/300], Step[0350/1252], Avg Loss: 2.9006, Avg Acc: 0.4837
2022-01-23 03:19:17,740 Epoch[286/300], Step[0400/1252], Avg Loss: 2.9103, Avg Acc: 0.4818
2022-01-23 03:20:45,313 Epoch[286/300], Step[0450/1252], Avg Loss: 2.9139, Avg Acc: 0.4793
2022-01-23 03:22:14,111 Epoch[286/300], Step[0500/1252], Avg Loss: 2.9178, Avg Acc: 0.4751
2022-01-23 03:23:40,863 Epoch[286/300], Step[0550/1252], Avg Loss: 2.9173, Avg Acc: 0.4773
2022-01-23 03:25:08,720 Epoch[286/300], Step[0600/1252], Avg Loss: 2.9184, Avg Acc: 0.4755
2022-01-23 03:26:36,638 Epoch[286/300], Step[0650/1252], Avg Loss: 2.9168, Avg Acc: 0.4742
2022-01-23 03:28:04,064 Epoch[286/300], Step[0700/1252], Avg Loss: 2.9155, Avg Acc: 0.4756
2022-01-23 03:29:32,195 Epoch[286/300], Step[0750/1252], Avg Loss: 2.9143, Avg Acc: 0.4770
2022-01-23 03:30:58,880 Epoch[286/300], Step[0800/1252], Avg Loss: 2.9169, Avg Acc: 0.4784
2022-01-23 03:32:27,097 Epoch[286/300], Step[0850/1252], Avg Loss: 2.9184, Avg Acc: 0.4777
2022-01-23 03:33:54,648 Epoch[286/300], Step[0900/1252], Avg Loss: 2.9231, Avg Acc: 0.4774
2022-01-23 03:35:22,768 Epoch[286/300], Step[0950/1252], Avg Loss: 2.9220, Avg Acc: 0.4757
2022-01-23 03:36:50,448 Epoch[286/300], Step[1000/1252], Avg Loss: 2.9224, Avg Acc: 0.4749
2022-01-23 03:38:18,636 Epoch[286/300], Step[1050/1252], Avg Loss: 2.9235, Avg Acc: 0.4749
2022-01-23 03:39:46,145 Epoch[286/300], Step[1100/1252], Avg Loss: 2.9243, Avg Acc: 0.4750
2022-01-23 03:41:12,948 Epoch[286/300], Step[1150/1252], Avg Loss: 2.9234, Avg Acc: 0.4761
2022-01-23 03:42:38,823 Epoch[286/300], Step[1200/1252], Avg Loss: 2.9203, Avg Acc: 0.4778
2022-01-23 03:44:05,554 Epoch[286/300], Step[1250/1252], Avg Loss: 2.9200, Avg Acc: 0.4790
2022-01-23 03:44:12,747 ----- Epoch[286/300], Train Loss: 2.9199, Train Acc: 0.4790, time: 2316.28, Best Val(epoch284) Acc@1: 0.7744
2022-01-23 03:44:12,747 ----- Validation after Epoch: 286
2022-01-23 03:45:29,942 Val Step[0000/1563], Avg Loss: 0.8186, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 03:45:31,948 Val Step[0050/1563], Avg Loss: 1.0043, Avg Acc@1: 0.7819, Avg Acc@5: 0.9418
2022-01-23 03:45:33,823 Val Step[0100/1563], Avg Loss: 1.0345, Avg Acc@1: 0.7800, Avg Acc@5: 0.9381
2022-01-23 03:45:35,701 Val Step[0150/1563], Avg Loss: 1.0360, Avg Acc@1: 0.7817, Avg Acc@5: 0.9361
2022-01-23 03:45:37,605 Val Step[0200/1563], Avg Loss: 1.0357, Avg Acc@1: 0.7812, Avg Acc@5: 0.9367
2022-01-23 03:45:39,485 Val Step[0250/1563], Avg Loss: 1.0250, Avg Acc@1: 0.7811, Avg Acc@5: 0.9384
2022-01-23 03:45:41,292 Val Step[0300/1563], Avg Loss: 1.0254, Avg Acc@1: 0.7821, Avg Acc@5: 0.9375
2022-01-23 03:45:43,114 Val Step[0350/1563], Avg Loss: 1.0305, Avg Acc@1: 0.7813, Avg Acc@5: 0.9373
2022-01-23 03:45:44,976 Val Step[0400/1563], Avg Loss: 1.0298, Avg Acc@1: 0.7821, Avg Acc@5: 0.9370
2022-01-23 03:45:46,789 Val Step[0450/1563], Avg Loss: 1.0347, Avg Acc@1: 0.7796, Avg Acc@5: 0.9367
2022-01-23 03:45:48,736 Val Step[0500/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7788, Avg Acc@5: 0.9371
2022-01-23 03:45:50,657 Val Step[0550/1563], Avg Loss: 1.0373, Avg Acc@1: 0.7771, Avg Acc@5: 0.9375
2022-01-23 03:45:52,563 Val Step[0600/1563], Avg Loss: 1.0365, Avg Acc@1: 0.7770, Avg Acc@5: 0.9377
2022-01-23 03:45:54,404 Val Step[0650/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7767, Avg Acc@5: 0.9379
2022-01-23 03:45:56,209 Val Step[0700/1563], Avg Loss: 1.0351, Avg Acc@1: 0.7772, Avg Acc@5: 0.9383
2022-01-23 03:45:58,011 Val Step[0750/1563], Avg Loss: 1.0405, Avg Acc@1: 0.7753, Avg Acc@5: 0.9379
2022-01-23 03:45:59,816 Val Step[0800/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7761, Avg Acc@5: 0.9379
2022-01-23 03:46:01,716 Val Step[0850/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7760, Avg Acc@5: 0.9374
2022-01-23 03:46:03,728 Val Step[0900/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7763, Avg Acc@5: 0.9377
2022-01-23 03:46:05,616 Val Step[0950/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7767, Avg Acc@5: 0.9376
2022-01-23 03:46:07,373 Val Step[1000/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7763, Avg Acc@5: 0.9372
2022-01-23 03:46:09,181 Val Step[1050/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-23 03:46:10,983 Val Step[1100/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7751, Avg Acc@5: 0.9369
2022-01-23 03:46:12,778 Val Step[1150/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7754, Avg Acc@5: 0.9372
2022-01-23 03:46:14,570 Val Step[1200/1563], Avg Loss: 1.0388, Avg Acc@1: 0.7760, Avg Acc@5: 0.9372
2022-01-23 03:46:16,362 Val Step[1250/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7753, Avg Acc@5: 0.9376
2022-01-23 03:46:18,146 Val Step[1300/1563], Avg Loss: 1.0415, Avg Acc@1: 0.7750, Avg Acc@5: 0.9372
2022-01-23 03:46:19,969 Val Step[1350/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7748, Avg Acc@5: 0.9371
2022-01-23 03:46:21,774 Val Step[1400/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7745, Avg Acc@5: 0.9370
2022-01-23 03:46:23,709 Val Step[1450/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7750, Avg Acc@5: 0.9371
2022-01-23 03:46:25,669 Val Step[1500/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7751, Avg Acc@5: 0.9372
2022-01-23 03:46:27,563 Val Step[1550/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7747, Avg Acc@5: 0.9370
2022-01-23 03:46:29,580 ----- Epoch[286/300], Validation Loss: 1.0412, Validation Acc@1: 0.7747, Validation Acc@5: 0.9371, time: 136.83
2022-01-23 03:46:30,710 the pre best model acc:0.7744, at epoch 284
2022-01-23 03:46:30,711 current best model acc:0.7747, at epoch 286
2022-01-23 03:46:30,711 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 03:46:30,711 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 03:46:30,711 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 03:46:30,711 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 03:46:30,711 Now training epoch 287. LR=0.000015
2022-01-23 03:48:21,557 Epoch[287/300], Step[0000/1252], Avg Loss: 3.3139, Avg Acc: 0.4629
2022-01-23 03:49:49,886 Epoch[287/300], Step[0050/1252], Avg Loss: 2.9585, Avg Acc: 0.4995
2022-01-23 03:51:17,152 Epoch[287/300], Step[0100/1252], Avg Loss: 2.9415, Avg Acc: 0.5041
2022-01-23 03:52:44,938 Epoch[287/300], Step[0150/1252], Avg Loss: 2.9316, Avg Acc: 0.4959
2022-01-23 03:54:12,307 Epoch[287/300], Step[0200/1252], Avg Loss: 2.9232, Avg Acc: 0.4864
2022-01-23 03:55:41,180 Epoch[287/300], Step[0250/1252], Avg Loss: 2.9208, Avg Acc: 0.4865
2022-01-23 03:57:09,907 Epoch[287/300], Step[0300/1252], Avg Loss: 2.9274, Avg Acc: 0.4867
2022-01-23 03:58:38,707 Epoch[287/300], Step[0350/1252], Avg Loss: 2.9186, Avg Acc: 0.4869
2022-01-23 04:00:06,790 Epoch[287/300], Step[0400/1252], Avg Loss: 2.9162, Avg Acc: 0.4846
2022-01-23 04:01:36,406 Epoch[287/300], Step[0450/1252], Avg Loss: 2.9095, Avg Acc: 0.4855
2022-01-23 04:03:05,432 Epoch[287/300], Step[0500/1252], Avg Loss: 2.9177, Avg Acc: 0.4838
2022-01-23 04:04:34,280 Epoch[287/300], Step[0550/1252], Avg Loss: 2.9176, Avg Acc: 0.4833
2022-01-23 04:06:03,276 Epoch[287/300], Step[0600/1252], Avg Loss: 2.9177, Avg Acc: 0.4817
2022-01-23 04:07:31,902 Epoch[287/300], Step[0650/1252], Avg Loss: 2.9206, Avg Acc: 0.4805
2022-01-23 04:08:59,813 Epoch[287/300], Step[0700/1252], Avg Loss: 2.9215, Avg Acc: 0.4828
2022-01-23 04:10:29,061 Epoch[287/300], Step[0750/1252], Avg Loss: 2.9220, Avg Acc: 0.4807
2022-01-23 04:11:58,764 Epoch[287/300], Step[0800/1252], Avg Loss: 2.9241, Avg Acc: 0.4779
2022-01-23 04:13:27,540 Epoch[287/300], Step[0850/1252], Avg Loss: 2.9223, Avg Acc: 0.4800
2022-01-23 04:14:56,825 Epoch[287/300], Step[0900/1252], Avg Loss: 2.9195, Avg Acc: 0.4813
2022-01-23 04:16:25,070 Epoch[287/300], Step[0950/1252], Avg Loss: 2.9213, Avg Acc: 0.4818
2022-01-23 04:17:52,634 Epoch[287/300], Step[1000/1252], Avg Loss: 2.9218, Avg Acc: 0.4824
2022-01-23 04:19:21,948 Epoch[287/300], Step[1050/1252], Avg Loss: 2.9206, Avg Acc: 0.4819
2022-01-23 04:20:51,137 Epoch[287/300], Step[1100/1252], Avg Loss: 2.9200, Avg Acc: 0.4829
2022-01-23 04:22:20,389 Epoch[287/300], Step[1150/1252], Avg Loss: 2.9179, Avg Acc: 0.4838
2022-01-23 04:23:48,444 Epoch[287/300], Step[1200/1252], Avg Loss: 2.9194, Avg Acc: 0.4840
2022-01-23 04:25:18,419 Epoch[287/300], Step[1250/1252], Avg Loss: 2.9173, Avg Acc: 0.4843
2022-01-23 04:25:25,579 ----- Epoch[287/300], Train Loss: 2.9173, Train Acc: 0.4843, time: 2334.86, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 04:25:25,579 Now training epoch 288. LR=0.000014
2022-01-23 04:27:19,018 Epoch[288/300], Step[0000/1252], Avg Loss: 3.1113, Avg Acc: 0.5215
2022-01-23 04:28:47,020 Epoch[288/300], Step[0050/1252], Avg Loss: 2.9549, Avg Acc: 0.4768
2022-01-23 04:30:14,168 Epoch[288/300], Step[0100/1252], Avg Loss: 2.9307, Avg Acc: 0.4659
2022-01-23 04:31:41,854 Epoch[288/300], Step[0150/1252], Avg Loss: 2.9252, Avg Acc: 0.4650
2022-01-23 04:33:10,890 Epoch[288/300], Step[0200/1252], Avg Loss: 2.9202, Avg Acc: 0.4746
2022-01-23 04:34:38,895 Epoch[288/300], Step[0250/1252], Avg Loss: 2.9134, Avg Acc: 0.4775
2022-01-23 04:36:08,074 Epoch[288/300], Step[0300/1252], Avg Loss: 2.9129, Avg Acc: 0.4762
2022-01-23 04:37:35,966 Epoch[288/300], Step[0350/1252], Avg Loss: 2.9089, Avg Acc: 0.4794
2022-01-23 04:39:03,120 Epoch[288/300], Step[0400/1252], Avg Loss: 2.9034, Avg Acc: 0.4798
2022-01-23 04:40:30,975 Epoch[288/300], Step[0450/1252], Avg Loss: 2.9037, Avg Acc: 0.4793
2022-01-23 04:41:58,852 Epoch[288/300], Step[0500/1252], Avg Loss: 2.9013, Avg Acc: 0.4816
2022-01-23 04:43:25,615 Epoch[288/300], Step[0550/1252], Avg Loss: 2.9035, Avg Acc: 0.4846
2022-01-23 04:44:51,561 Epoch[288/300], Step[0600/1252], Avg Loss: 2.9100, Avg Acc: 0.4844
2022-01-23 04:46:18,047 Epoch[288/300], Step[0650/1252], Avg Loss: 2.9060, Avg Acc: 0.4846
2022-01-23 04:47:45,587 Epoch[288/300], Step[0700/1252], Avg Loss: 2.9065, Avg Acc: 0.4831
2022-01-23 04:49:13,727 Epoch[288/300], Step[0750/1252], Avg Loss: 2.9079, Avg Acc: 0.4841
2022-01-23 04:50:40,000 Epoch[288/300], Step[0800/1252], Avg Loss: 2.9073, Avg Acc: 0.4841
2022-01-23 04:52:08,038 Epoch[288/300], Step[0850/1252], Avg Loss: 2.9037, Avg Acc: 0.4846
2022-01-23 04:53:36,299 Epoch[288/300], Step[0900/1252], Avg Loss: 2.9076, Avg Acc: 0.4841
2022-01-23 04:55:04,188 Epoch[288/300], Step[0950/1252], Avg Loss: 2.9096, Avg Acc: 0.4843
2022-01-23 04:56:33,164 Epoch[288/300], Step[1000/1252], Avg Loss: 2.9108, Avg Acc: 0.4848
2022-01-23 04:58:00,963 Epoch[288/300], Step[1050/1252], Avg Loss: 2.9108, Avg Acc: 0.4846
2022-01-23 04:59:29,051 Epoch[288/300], Step[1100/1252], Avg Loss: 2.9098, Avg Acc: 0.4839
2022-01-23 05:00:56,363 Epoch[288/300], Step[1150/1252], Avg Loss: 2.9119, Avg Acc: 0.4831
2022-01-23 05:02:25,405 Epoch[288/300], Step[1200/1252], Avg Loss: 2.9106, Avg Acc: 0.4851
2022-01-23 05:03:53,792 Epoch[288/300], Step[1250/1252], Avg Loss: 2.9084, Avg Acc: 0.4850
2022-01-23 05:04:01,073 ----- Epoch[288/300], Train Loss: 2.9084, Train Acc: 0.4850, time: 2315.49, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 05:04:01,073 ----- Validation after Epoch: 288
2022-01-23 05:05:28,125 Val Step[0000/1563], Avg Loss: 0.8228, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 05:05:30,243 Val Step[0050/1563], Avg Loss: 1.0057, Avg Acc@1: 0.7794, Avg Acc@5: 0.9381
2022-01-23 05:05:32,752 Val Step[0100/1563], Avg Loss: 1.0352, Avg Acc@1: 0.7812, Avg Acc@5: 0.9360
2022-01-23 05:05:34,729 Val Step[0150/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7802, Avg Acc@5: 0.9348
2022-01-23 05:05:36,767 Val Step[0200/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7797, Avg Acc@5: 0.9359
2022-01-23 05:05:38,810 Val Step[0250/1563], Avg Loss: 1.0270, Avg Acc@1: 0.7791, Avg Acc@5: 0.9375
2022-01-23 05:05:40,858 Val Step[0300/1563], Avg Loss: 1.0279, Avg Acc@1: 0.7798, Avg Acc@5: 0.9369
2022-01-23 05:05:42,894 Val Step[0350/1563], Avg Loss: 1.0329, Avg Acc@1: 0.7789, Avg Acc@5: 0.9370
2022-01-23 05:05:44,942 Val Step[0400/1563], Avg Loss: 1.0328, Avg Acc@1: 0.7794, Avg Acc@5: 0.9367
2022-01-23 05:05:46,977 Val Step[0450/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7769, Avg Acc@5: 0.9365
2022-01-23 05:05:49,017 Val Step[0500/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7763, Avg Acc@5: 0.9371
2022-01-23 05:05:50,855 Val Step[0550/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7754, Avg Acc@5: 0.9374
2022-01-23 05:05:52,825 Val Step[0600/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7756, Avg Acc@5: 0.9373
2022-01-23 05:05:54,872 Val Step[0650/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7756, Avg Acc@5: 0.9374
2022-01-23 05:05:56,930 Val Step[0700/1563], Avg Loss: 1.0371, Avg Acc@1: 0.7764, Avg Acc@5: 0.9377
2022-01-23 05:05:58,984 Val Step[0750/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7745, Avg Acc@5: 0.9372
2022-01-23 05:06:00,990 Val Step[0800/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7752, Avg Acc@5: 0.9371
2022-01-23 05:06:02,887 Val Step[0850/1563], Avg Loss: 1.0446, Avg Acc@1: 0.7749, Avg Acc@5: 0.9368
2022-01-23 05:06:04,773 Val Step[0900/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7753, Avg Acc@5: 0.9372
2022-01-23 05:06:06,783 Val Step[0950/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7757, Avg Acc@5: 0.9372
2022-01-23 05:06:08,838 Val Step[1000/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7753, Avg Acc@5: 0.9369
2022-01-23 05:06:10,867 Val Step[1050/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7747, Avg Acc@5: 0.9366
2022-01-23 05:06:12,950 Val Step[1100/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7742, Avg Acc@5: 0.9369
2022-01-23 05:06:15,068 Val Step[1150/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7746, Avg Acc@5: 0.9372
2022-01-23 05:06:17,168 Val Step[1200/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7754, Avg Acc@5: 0.9372
2022-01-23 05:06:19,282 Val Step[1250/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7749, Avg Acc@5: 0.9375
2022-01-23 05:06:21,400 Val Step[1300/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7748, Avg Acc@5: 0.9371
2022-01-23 05:06:23,462 Val Step[1350/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7744, Avg Acc@5: 0.9368
2022-01-23 05:06:25,537 Val Step[1400/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7738, Avg Acc@5: 0.9369
2022-01-23 05:06:27,449 Val Step[1450/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7743, Avg Acc@5: 0.9369
2022-01-23 05:06:29,303 Val Step[1500/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7747, Avg Acc@5: 0.9372
2022-01-23 05:06:31,076 Val Step[1550/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7744, Avg Acc@5: 0.9371
2022-01-23 05:06:34,350 ----- Epoch[288/300], Validation Loss: 1.0440, Validation Acc@1: 0.7743, Validation Acc@5: 0.9372, time: 153.27
2022-01-23 05:06:34,350 Now training epoch 289. LR=0.000014
2022-01-23 05:08:29,388 Epoch[289/300], Step[0000/1252], Avg Loss: 2.9295, Avg Acc: 0.3789
2022-01-23 05:09:56,320 Epoch[289/300], Step[0050/1252], Avg Loss: 2.9056, Avg Acc: 0.5115
2022-01-23 05:11:23,971 Epoch[289/300], Step[0100/1252], Avg Loss: 2.9660, Avg Acc: 0.4822
2022-01-23 05:12:52,478 Epoch[289/300], Step[0150/1252], Avg Loss: 2.9568, Avg Acc: 0.4782
2022-01-23 05:14:20,276 Epoch[289/300], Step[0200/1252], Avg Loss: 2.9541, Avg Acc: 0.4823
2022-01-23 05:15:49,365 Epoch[289/300], Step[0250/1252], Avg Loss: 2.9419, Avg Acc: 0.4742
2022-01-23 05:17:16,371 Epoch[289/300], Step[0300/1252], Avg Loss: 2.9362, Avg Acc: 0.4735
2022-01-23 05:18:44,823 Epoch[289/300], Step[0350/1252], Avg Loss: 2.9321, Avg Acc: 0.4737
2022-01-23 05:20:13,764 Epoch[289/300], Step[0400/1252], Avg Loss: 2.9283, Avg Acc: 0.4743
2022-01-23 05:21:42,173 Epoch[289/300], Step[0450/1252], Avg Loss: 2.9221, Avg Acc: 0.4735
2022-01-23 05:23:11,240 Epoch[289/300], Step[0500/1252], Avg Loss: 2.9199, Avg Acc: 0.4730
2022-01-23 05:24:37,831 Epoch[289/300], Step[0550/1252], Avg Loss: 2.9188, Avg Acc: 0.4739
2022-01-23 05:26:05,246 Epoch[289/300], Step[0600/1252], Avg Loss: 2.9132, Avg Acc: 0.4738
2022-01-23 05:27:32,277 Epoch[289/300], Step[0650/1252], Avg Loss: 2.9137, Avg Acc: 0.4741
2022-01-23 05:29:00,501 Epoch[289/300], Step[0700/1252], Avg Loss: 2.9089, Avg Acc: 0.4756
2022-01-23 05:30:29,187 Epoch[289/300], Step[0750/1252], Avg Loss: 2.9067, Avg Acc: 0.4740
2022-01-23 05:31:56,297 Epoch[289/300], Step[0800/1252], Avg Loss: 2.9084, Avg Acc: 0.4762
2022-01-23 05:33:23,564 Epoch[289/300], Step[0850/1252], Avg Loss: 2.9046, Avg Acc: 0.4776
2022-01-23 05:34:52,412 Epoch[289/300], Step[0900/1252], Avg Loss: 2.9041, Avg Acc: 0.4769
2022-01-23 05:36:20,714 Epoch[289/300], Step[0950/1252], Avg Loss: 2.9034, Avg Acc: 0.4784
2022-01-23 05:37:48,990 Epoch[289/300], Step[1000/1252], Avg Loss: 2.9039, Avg Acc: 0.4798
2022-01-23 05:39:17,333 Epoch[289/300], Step[1050/1252], Avg Loss: 2.9041, Avg Acc: 0.4795
2022-01-23 05:40:45,886 Epoch[289/300], Step[1100/1252], Avg Loss: 2.9034, Avg Acc: 0.4785
2022-01-23 05:42:13,397 Epoch[289/300], Step[1150/1252], Avg Loss: 2.9031, Avg Acc: 0.4783
2022-01-23 05:43:41,264 Epoch[289/300], Step[1200/1252], Avg Loss: 2.9029, Avg Acc: 0.4793
2022-01-23 05:45:09,359 Epoch[289/300], Step[1250/1252], Avg Loss: 2.9030, Avg Acc: 0.4786
2022-01-23 05:45:16,556 ----- Epoch[289/300], Train Loss: 2.9030, Train Acc: 0.4786, time: 2322.20, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 05:45:16,556 Now training epoch 290. LR=0.000013
2022-01-23 05:47:11,270 Epoch[290/300], Step[0000/1252], Avg Loss: 3.0468, Avg Acc: 0.3848
2022-01-23 05:48:39,692 Epoch[290/300], Step[0050/1252], Avg Loss: 2.8787, Avg Acc: 0.4867
2022-01-23 05:50:07,629 Epoch[290/300], Step[0100/1252], Avg Loss: 2.9146, Avg Acc: 0.4798
2022-01-23 05:51:35,752 Epoch[290/300], Step[0150/1252], Avg Loss: 2.9024, Avg Acc: 0.4773
2022-01-23 05:53:03,721 Epoch[290/300], Step[0200/1252], Avg Loss: 2.8834, Avg Acc: 0.4821
2022-01-23 05:54:31,273 Epoch[290/300], Step[0250/1252], Avg Loss: 2.8956, Avg Acc: 0.4819
2022-01-23 05:55:58,646 Epoch[290/300], Step[0300/1252], Avg Loss: 2.8999, Avg Acc: 0.4847
2022-01-23 05:57:26,998 Epoch[290/300], Step[0350/1252], Avg Loss: 2.9002, Avg Acc: 0.4876
2022-01-23 05:58:56,068 Epoch[290/300], Step[0400/1252], Avg Loss: 2.9022, Avg Acc: 0.4852
2022-01-23 06:00:24,383 Epoch[290/300], Step[0450/1252], Avg Loss: 2.9051, Avg Acc: 0.4862
2022-01-23 06:01:53,685 Epoch[290/300], Step[0500/1252], Avg Loss: 2.9032, Avg Acc: 0.4853
2022-01-23 06:03:22,668 Epoch[290/300], Step[0550/1252], Avg Loss: 2.8990, Avg Acc: 0.4819
2022-01-23 06:04:52,005 Epoch[290/300], Step[0600/1252], Avg Loss: 2.9025, Avg Acc: 0.4805
2022-01-23 06:06:19,595 Epoch[290/300], Step[0650/1252], Avg Loss: 2.9026, Avg Acc: 0.4819
2022-01-23 06:07:48,875 Epoch[290/300], Step[0700/1252], Avg Loss: 2.9071, Avg Acc: 0.4795
2022-01-23 06:09:17,571 Epoch[290/300], Step[0750/1252], Avg Loss: 2.9057, Avg Acc: 0.4782
2022-01-23 06:10:46,804 Epoch[290/300], Step[0800/1252], Avg Loss: 2.9072, Avg Acc: 0.4786
2022-01-23 06:12:15,862 Epoch[290/300], Step[0850/1252], Avg Loss: 2.9082, Avg Acc: 0.4776
2022-01-23 06:13:43,870 Epoch[290/300], Step[0900/1252], Avg Loss: 2.9060, Avg Acc: 0.4787
2022-01-23 06:15:11,377 Epoch[290/300], Step[0950/1252], Avg Loss: 2.9063, Avg Acc: 0.4808
2022-01-23 06:16:40,278 Epoch[290/300], Step[1000/1252], Avg Loss: 2.9076, Avg Acc: 0.4804
2022-01-23 06:18:08,783 Epoch[290/300], Step[1050/1252], Avg Loss: 2.9047, Avg Acc: 0.4813
2022-01-23 06:19:37,965 Epoch[290/300], Step[1100/1252], Avg Loss: 2.9064, Avg Acc: 0.4807
2022-01-23 06:21:06,697 Epoch[290/300], Step[1150/1252], Avg Loss: 2.9064, Avg Acc: 0.4802
2022-01-23 06:22:34,429 Epoch[290/300], Step[1200/1252], Avg Loss: 2.9054, Avg Acc: 0.4814
2022-01-23 06:24:04,067 Epoch[290/300], Step[1250/1252], Avg Loss: 2.9050, Avg Acc: 0.4806
2022-01-23 06:24:11,158 ----- Epoch[290/300], Train Loss: 2.9050, Train Acc: 0.4806, time: 2334.60, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 06:24:11,158 ----- Validation after Epoch: 290
2022-01-23 06:25:34,617 Val Step[0000/1563], Avg Loss: 0.8471, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 06:25:36,551 Val Step[0050/1563], Avg Loss: 1.0073, Avg Acc@1: 0.7819, Avg Acc@5: 0.9381
2022-01-23 06:25:38,379 Val Step[0100/1563], Avg Loss: 1.0394, Avg Acc@1: 0.7825, Avg Acc@5: 0.9375
2022-01-23 06:25:40,256 Val Step[0150/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7806, Avg Acc@5: 0.9348
2022-01-23 06:25:42,145 Val Step[0200/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7811, Avg Acc@5: 0.9353
2022-01-23 06:25:44,044 Val Step[0250/1563], Avg Loss: 1.0323, Avg Acc@1: 0.7808, Avg Acc@5: 0.9373
2022-01-23 06:25:45,954 Val Step[0300/1563], Avg Loss: 1.0318, Avg Acc@1: 0.7817, Avg Acc@5: 0.9367
2022-01-23 06:25:47,844 Val Step[0350/1563], Avg Loss: 1.0362, Avg Acc@1: 0.7812, Avg Acc@5: 0.9363
2022-01-23 06:25:49,729 Val Step[0400/1563], Avg Loss: 1.0356, Avg Acc@1: 0.7809, Avg Acc@5: 0.9361
2022-01-23 06:25:51,593 Val Step[0450/1563], Avg Loss: 1.0400, Avg Acc@1: 0.7781, Avg Acc@5: 0.9356
2022-01-23 06:25:53,429 Val Step[0500/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7770, Avg Acc@5: 0.9359
2022-01-23 06:25:55,253 Val Step[0550/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7763, Avg Acc@5: 0.9365
2022-01-23 06:25:57,092 Val Step[0600/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7757, Avg Acc@5: 0.9367
2022-01-23 06:25:58,948 Val Step[0650/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7756, Avg Acc@5: 0.9367
2022-01-23 06:26:00,770 Val Step[0700/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-23 06:26:02,560 Val Step[0750/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7740, Avg Acc@5: 0.9370
2022-01-23 06:26:04,372 Val Step[0800/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7745, Avg Acc@5: 0.9369
2022-01-23 06:26:06,239 Val Step[0850/1563], Avg Loss: 1.0467, Avg Acc@1: 0.7742, Avg Acc@5: 0.9366
2022-01-23 06:26:08,086 Val Step[0900/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7748, Avg Acc@5: 0.9369
2022-01-23 06:26:09,930 Val Step[0950/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7752, Avg Acc@5: 0.9369
2022-01-23 06:26:11,744 Val Step[1000/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7748, Avg Acc@5: 0.9366
2022-01-23 06:26:13,541 Val Step[1050/1563], Avg Loss: 1.0472, Avg Acc@1: 0.7742, Avg Acc@5: 0.9364
2022-01-23 06:26:15,471 Val Step[1100/1563], Avg Loss: 1.0473, Avg Acc@1: 0.7738, Avg Acc@5: 0.9366
2022-01-23 06:26:17,527 Val Step[1150/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7740, Avg Acc@5: 0.9368
2022-01-23 06:26:19,601 Val Step[1200/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7747, Avg Acc@5: 0.9369
2022-01-23 06:26:21,680 Val Step[1250/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7744, Avg Acc@5: 0.9372
2022-01-23 06:26:23,753 Val Step[1300/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7742, Avg Acc@5: 0.9368
2022-01-23 06:26:25,721 Val Step[1350/1563], Avg Loss: 1.0477, Avg Acc@1: 0.7737, Avg Acc@5: 0.9367
2022-01-23 06:26:27,578 Val Step[1400/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7735, Avg Acc@5: 0.9367
2022-01-23 06:26:29,475 Val Step[1450/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7739, Avg Acc@5: 0.9367
2022-01-23 06:26:31,365 Val Step[1500/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7741, Avg Acc@5: 0.9369
2022-01-23 06:26:33,173 Val Step[1550/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7740, Avg Acc@5: 0.9367
2022-01-23 06:26:35,010 ----- Epoch[290/300], Validation Loss: 1.0463, Validation Acc@1: 0.7739, Validation Acc@5: 0.9368, time: 143.85
2022-01-23 06:26:35,010 Now training epoch 291. LR=0.000013
2022-01-23 06:28:18,258 Epoch[291/300], Step[0000/1252], Avg Loss: 3.2592, Avg Acc: 0.5449
2022-01-23 06:29:46,717 Epoch[291/300], Step[0050/1252], Avg Loss: 2.8896, Avg Acc: 0.5094
2022-01-23 06:31:14,354 Epoch[291/300], Step[0100/1252], Avg Loss: 2.9215, Avg Acc: 0.4936
2022-01-23 06:32:41,095 Epoch[291/300], Step[0150/1252], Avg Loss: 2.9108, Avg Acc: 0.4998
2022-01-23 06:34:07,444 Epoch[291/300], Step[0200/1252], Avg Loss: 2.8968, Avg Acc: 0.5024
2022-01-23 06:35:33,865 Epoch[291/300], Step[0250/1252], Avg Loss: 2.8975, Avg Acc: 0.4945
2022-01-23 06:37:00,215 Epoch[291/300], Step[0300/1252], Avg Loss: 2.8979, Avg Acc: 0.4972
2022-01-23 06:38:26,266 Epoch[291/300], Step[0350/1252], Avg Loss: 2.8936, Avg Acc: 0.4969
2022-01-23 06:39:52,367 Epoch[291/300], Step[0400/1252], Avg Loss: 2.8857, Avg Acc: 0.4968
2022-01-23 06:41:18,688 Epoch[291/300], Step[0450/1252], Avg Loss: 2.8790, Avg Acc: 0.4970
2022-01-23 06:42:45,301 Epoch[291/300], Step[0500/1252], Avg Loss: 2.8768, Avg Acc: 0.4963
2022-01-23 06:44:13,701 Epoch[291/300], Step[0550/1252], Avg Loss: 2.8784, Avg Acc: 0.4962
2022-01-23 06:45:43,004 Epoch[291/300], Step[0600/1252], Avg Loss: 2.8842, Avg Acc: 0.4921
2022-01-23 06:47:10,602 Epoch[291/300], Step[0650/1252], Avg Loss: 2.8898, Avg Acc: 0.4945
2022-01-23 06:48:38,360 Epoch[291/300], Step[0700/1252], Avg Loss: 2.8979, Avg Acc: 0.4941
2022-01-23 06:50:06,877 Epoch[291/300], Step[0750/1252], Avg Loss: 2.9006, Avg Acc: 0.4948
2022-01-23 06:51:35,893 Epoch[291/300], Step[0800/1252], Avg Loss: 2.9020, Avg Acc: 0.4943
2022-01-23 06:53:04,788 Epoch[291/300], Step[0850/1252], Avg Loss: 2.9022, Avg Acc: 0.4936
2022-01-23 06:54:32,264 Epoch[291/300], Step[0900/1252], Avg Loss: 2.9011, Avg Acc: 0.4958
2022-01-23 06:55:59,664 Epoch[291/300], Step[0950/1252], Avg Loss: 2.9029, Avg Acc: 0.4976
2022-01-23 06:57:28,187 Epoch[291/300], Step[1000/1252], Avg Loss: 2.9021, Avg Acc: 0.4961
2022-01-23 06:58:57,118 Epoch[291/300], Step[1050/1252], Avg Loss: 2.9014, Avg Acc: 0.4962
2022-01-23 07:00:26,672 Epoch[291/300], Step[1100/1252], Avg Loss: 2.8990, Avg Acc: 0.4955
2022-01-23 07:01:55,952 Epoch[291/300], Step[1150/1252], Avg Loss: 2.8991, Avg Acc: 0.4959
2022-01-23 07:03:25,380 Epoch[291/300], Step[1200/1252], Avg Loss: 2.8994, Avg Acc: 0.4964
2022-01-23 07:04:55,792 Epoch[291/300], Step[1250/1252], Avg Loss: 2.8976, Avg Acc: 0.4955
2022-01-23 07:05:03,045 ----- Epoch[291/300], Train Loss: 2.8976, Train Acc: 0.4955, time: 2308.03, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 07:05:03,046 Now training epoch 292. LR=0.000012
2022-01-23 07:06:47,715 Epoch[292/300], Step[0000/1252], Avg Loss: 2.8514, Avg Acc: 0.5088
2022-01-23 07:08:16,074 Epoch[292/300], Step[0050/1252], Avg Loss: 2.8488, Avg Acc: 0.5130
2022-01-23 07:09:44,200 Epoch[292/300], Step[0100/1252], Avg Loss: 2.8835, Avg Acc: 0.5046
2022-01-23 07:11:12,134 Epoch[292/300], Step[0150/1252], Avg Loss: 2.8943, Avg Acc: 0.4883
2022-01-23 07:12:40,402 Epoch[292/300], Step[0200/1252], Avg Loss: 2.8942, Avg Acc: 0.4883
2022-01-23 07:14:09,427 Epoch[292/300], Step[0250/1252], Avg Loss: 2.8950, Avg Acc: 0.4885
2022-01-23 07:15:38,268 Epoch[292/300], Step[0300/1252], Avg Loss: 2.8998, Avg Acc: 0.4897
2022-01-23 07:17:06,064 Epoch[292/300], Step[0350/1252], Avg Loss: 2.9073, Avg Acc: 0.4877
2022-01-23 07:18:35,394 Epoch[292/300], Step[0400/1252], Avg Loss: 2.9089, Avg Acc: 0.4887
2022-01-23 07:20:03,268 Epoch[292/300], Step[0450/1252], Avg Loss: 2.9122, Avg Acc: 0.4903
2022-01-23 07:21:30,933 Epoch[292/300], Step[0500/1252], Avg Loss: 2.9117, Avg Acc: 0.4917
2022-01-23 07:22:59,981 Epoch[292/300], Step[0550/1252], Avg Loss: 2.9136, Avg Acc: 0.4877
2022-01-23 07:24:29,303 Epoch[292/300], Step[0600/1252], Avg Loss: 2.9157, Avg Acc: 0.4866
2022-01-23 07:25:58,068 Epoch[292/300], Step[0650/1252], Avg Loss: 2.9154, Avg Acc: 0.4882
2022-01-23 07:27:27,020 Epoch[292/300], Step[0700/1252], Avg Loss: 2.9177, Avg Acc: 0.4871
2022-01-23 07:28:55,761 Epoch[292/300], Step[0750/1252], Avg Loss: 2.9146, Avg Acc: 0.4873
2022-01-23 07:30:23,464 Epoch[292/300], Step[0800/1252], Avg Loss: 2.9202, Avg Acc: 0.4880
2022-01-23 07:31:52,017 Epoch[292/300], Step[0850/1252], Avg Loss: 2.9216, Avg Acc: 0.4882
2022-01-23 07:33:19,993 Epoch[292/300], Step[0900/1252], Avg Loss: 2.9195, Avg Acc: 0.4894
2022-01-23 07:34:49,672 Epoch[292/300], Step[0950/1252], Avg Loss: 2.9194, Avg Acc: 0.4891
2022-01-23 07:36:17,667 Epoch[292/300], Step[1000/1252], Avg Loss: 2.9169, Avg Acc: 0.4896
2022-01-23 07:37:45,864 Epoch[292/300], Step[1050/1252], Avg Loss: 2.9152, Avg Acc: 0.4910
2022-01-23 07:39:14,633 Epoch[292/300], Step[1100/1252], Avg Loss: 2.9132, Avg Acc: 0.4910
2022-01-23 07:40:44,272 Epoch[292/300], Step[1150/1252], Avg Loss: 2.9130, Avg Acc: 0.4911
2022-01-23 07:42:13,988 Epoch[292/300], Step[1200/1252], Avg Loss: 2.9129, Avg Acc: 0.4914
2022-01-23 07:43:42,484 Epoch[292/300], Step[1250/1252], Avg Loss: 2.9106, Avg Acc: 0.4930
2022-01-23 07:43:49,575 ----- Epoch[292/300], Train Loss: 2.9106, Train Acc: 0.4930, time: 2326.52, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 07:43:49,575 ----- Validation after Epoch: 292
2022-01-23 07:44:58,892 Val Step[0000/1563], Avg Loss: 0.8470, Avg Acc@1: 0.8438, Avg Acc@5: 1.0000
2022-01-23 07:45:00,824 Val Step[0050/1563], Avg Loss: 1.0011, Avg Acc@1: 0.7825, Avg Acc@5: 0.9393
2022-01-23 07:45:02,672 Val Step[0100/1563], Avg Loss: 1.0341, Avg Acc@1: 0.7819, Avg Acc@5: 0.9360
2022-01-23 07:45:04,486 Val Step[0150/1563], Avg Loss: 1.0366, Avg Acc@1: 0.7808, Avg Acc@5: 0.9342
2022-01-23 07:45:06,297 Val Step[0200/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7799, Avg Acc@5: 0.9352
2022-01-23 07:45:08,105 Val Step[0250/1563], Avg Loss: 1.0289, Avg Acc@1: 0.7791, Avg Acc@5: 0.9375
2022-01-23 07:45:09,913 Val Step[0300/1563], Avg Loss: 1.0290, Avg Acc@1: 0.7793, Avg Acc@5: 0.9363
2022-01-23 07:45:11,770 Val Step[0350/1563], Avg Loss: 1.0330, Avg Acc@1: 0.7791, Avg Acc@5: 0.9363
2022-01-23 07:45:13,596 Val Step[0400/1563], Avg Loss: 1.0318, Avg Acc@1: 0.7793, Avg Acc@5: 0.9365
2022-01-23 07:45:15,419 Val Step[0450/1563], Avg Loss: 1.0362, Avg Acc@1: 0.7772, Avg Acc@5: 0.9363
2022-01-23 07:45:17,560 Val Step[0500/1563], Avg Loss: 1.0390, Avg Acc@1: 0.7764, Avg Acc@5: 0.9364
2022-01-23 07:45:19,718 Val Step[0550/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7756, Avg Acc@5: 0.9370
2022-01-23 07:45:21,870 Val Step[0600/1563], Avg Loss: 1.0367, Avg Acc@1: 0.7752, Avg Acc@5: 0.9369
2022-01-23 07:45:23,950 Val Step[0650/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7753, Avg Acc@5: 0.9370
2022-01-23 07:45:25,995 Val Step[0700/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7755, Avg Acc@5: 0.9376
2022-01-23 07:45:28,033 Val Step[0750/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7736, Avg Acc@5: 0.9373
2022-01-23 07:45:30,060 Val Step[0800/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7745, Avg Acc@5: 0.9373
2022-01-23 07:45:31,909 Val Step[0850/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7743, Avg Acc@5: 0.9370
2022-01-23 07:45:33,812 Val Step[0900/1563], Avg Loss: 1.0395, Avg Acc@1: 0.7748, Avg Acc@5: 0.9373
2022-01-23 07:45:35,720 Val Step[0950/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7753, Avg Acc@5: 0.9375
2022-01-23 07:45:37,640 Val Step[1000/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7751, Avg Acc@5: 0.9372
2022-01-23 07:45:39,444 Val Step[1050/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7745, Avg Acc@5: 0.9370
2022-01-23 07:45:41,239 Val Step[1100/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7738, Avg Acc@5: 0.9370
2022-01-23 07:45:43,031 Val Step[1150/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7743, Avg Acc@5: 0.9373
2022-01-23 07:45:44,875 Val Step[1200/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7752, Avg Acc@5: 0.9373
2022-01-23 07:45:46,706 Val Step[1250/1563], Avg Loss: 1.0386, Avg Acc@1: 0.7748, Avg Acc@5: 0.9376
2022-01-23 07:45:48,504 Val Step[1300/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7748, Avg Acc@5: 0.9373
2022-01-23 07:45:50,296 Val Step[1350/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7744, Avg Acc@5: 0.9371
2022-01-23 07:45:52,087 Val Step[1400/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7741, Avg Acc@5: 0.9371
2022-01-23 07:45:53,909 Val Step[1450/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7748, Avg Acc@5: 0.9372
2022-01-23 07:45:55,717 Val Step[1500/1563], Avg Loss: 1.0412, Avg Acc@1: 0.7749, Avg Acc@5: 0.9374
2022-01-23 07:45:57,458 Val Step[1550/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7745, Avg Acc@5: 0.9372
2022-01-23 07:45:59,374 ----- Epoch[292/300], Validation Loss: 1.0416, Validation Acc@1: 0.7745, Validation Acc@5: 0.9373, time: 129.80
2022-01-23 07:45:59,374 Now training epoch 293. LR=0.000012
2022-01-23 07:47:45,818 Epoch[293/300], Step[0000/1252], Avg Loss: 2.8444, Avg Acc: 0.7539
2022-01-23 07:49:15,251 Epoch[293/300], Step[0050/1252], Avg Loss: 2.9170, Avg Acc: 0.4894
2022-01-23 07:50:43,380 Epoch[293/300], Step[0100/1252], Avg Loss: 2.9248, Avg Acc: 0.4912
2022-01-23 07:52:12,170 Epoch[293/300], Step[0150/1252], Avg Loss: 2.9148, Avg Acc: 0.4916
2022-01-23 07:53:40,673 Epoch[293/300], Step[0200/1252], Avg Loss: 2.9088, Avg Acc: 0.4828
2022-01-23 07:55:07,634 Epoch[293/300], Step[0250/1252], Avg Loss: 2.9109, Avg Acc: 0.4800
2022-01-23 07:56:35,702 Epoch[293/300], Step[0300/1252], Avg Loss: 2.9069, Avg Acc: 0.4850
2022-01-23 07:58:03,888 Epoch[293/300], Step[0350/1252], Avg Loss: 2.9051, Avg Acc: 0.4868
2022-01-23 07:59:32,564 Epoch[293/300], Step[0400/1252], Avg Loss: 2.9100, Avg Acc: 0.4840
2022-01-23 08:01:01,115 Epoch[293/300], Step[0450/1252], Avg Loss: 2.9200, Avg Acc: 0.4830
2022-01-23 08:02:30,165 Epoch[293/300], Step[0500/1252], Avg Loss: 2.9164, Avg Acc: 0.4845
2022-01-23 08:03:57,682 Epoch[293/300], Step[0550/1252], Avg Loss: 2.9149, Avg Acc: 0.4863
2022-01-23 08:05:25,148 Epoch[293/300], Step[0600/1252], Avg Loss: 2.9142, Avg Acc: 0.4896
2022-01-23 08:06:54,992 Epoch[293/300], Step[0650/1252], Avg Loss: 2.9137, Avg Acc: 0.4888
2022-01-23 08:08:24,268 Epoch[293/300], Step[0700/1252], Avg Loss: 2.9110, Avg Acc: 0.4898
2022-01-23 08:09:52,151 Epoch[293/300], Step[0750/1252], Avg Loss: 2.9118, Avg Acc: 0.4890
2022-01-23 08:11:20,915 Epoch[293/300], Step[0800/1252], Avg Loss: 2.9080, Avg Acc: 0.4872
2022-01-23 08:12:50,385 Epoch[293/300], Step[0850/1252], Avg Loss: 2.9092, Avg Acc: 0.4872
2022-01-23 08:14:19,357 Epoch[293/300], Step[0900/1252], Avg Loss: 2.9093, Avg Acc: 0.4872
2022-01-23 08:15:47,705 Epoch[293/300], Step[0950/1252], Avg Loss: 2.9081, Avg Acc: 0.4866
2022-01-23 08:17:16,173 Epoch[293/300], Step[1000/1252], Avg Loss: 2.9075, Avg Acc: 0.4877
2022-01-23 08:18:44,775 Epoch[293/300], Step[1050/1252], Avg Loss: 2.9096, Avg Acc: 0.4871
2022-01-23 08:20:14,301 Epoch[293/300], Step[1100/1252], Avg Loss: 2.9099, Avg Acc: 0.4862
2022-01-23 08:21:41,474 Epoch[293/300], Step[1150/1252], Avg Loss: 2.9112, Avg Acc: 0.4866
2022-01-23 08:23:09,655 Epoch[293/300], Step[1200/1252], Avg Loss: 2.9106, Avg Acc: 0.4875
2022-01-23 08:24:38,415 Epoch[293/300], Step[1250/1252], Avg Loss: 2.9129, Avg Acc: 0.4873
2022-01-23 08:24:45,563 ----- Epoch[293/300], Train Loss: 2.9129, Train Acc: 0.4873, time: 2326.18, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 08:24:45,563 Now training epoch 294. LR=0.000011
2022-01-23 08:26:29,609 Epoch[294/300], Step[0000/1252], Avg Loss: 2.6666, Avg Acc: 0.3721
2022-01-23 08:27:58,019 Epoch[294/300], Step[0050/1252], Avg Loss: 2.8532, Avg Acc: 0.4748
2022-01-23 08:29:27,627 Epoch[294/300], Step[0100/1252], Avg Loss: 2.8861, Avg Acc: 0.4746
2022-01-23 08:30:55,474 Epoch[294/300], Step[0150/1252], Avg Loss: 2.8999, Avg Acc: 0.4834
2022-01-23 08:32:24,965 Epoch[294/300], Step[0200/1252], Avg Loss: 2.8873, Avg Acc: 0.4887
2022-01-23 08:33:51,431 Epoch[294/300], Step[0250/1252], Avg Loss: 2.8812, Avg Acc: 0.4962
2022-01-23 08:35:20,463 Epoch[294/300], Step[0300/1252], Avg Loss: 2.8793, Avg Acc: 0.4961
2022-01-23 08:36:47,796 Epoch[294/300], Step[0350/1252], Avg Loss: 2.8724, Avg Acc: 0.4989
2022-01-23 08:38:15,715 Epoch[294/300], Step[0400/1252], Avg Loss: 2.8726, Avg Acc: 0.4959
2022-01-23 08:39:44,122 Epoch[294/300], Step[0450/1252], Avg Loss: 2.8740, Avg Acc: 0.4934
2022-01-23 08:41:12,597 Epoch[294/300], Step[0500/1252], Avg Loss: 2.8787, Avg Acc: 0.4930
2022-01-23 08:42:40,637 Epoch[294/300], Step[0550/1252], Avg Loss: 2.8804, Avg Acc: 0.4941
2022-01-23 08:44:08,533 Epoch[294/300], Step[0600/1252], Avg Loss: 2.8851, Avg Acc: 0.4923
2022-01-23 08:45:36,727 Epoch[294/300], Step[0650/1252], Avg Loss: 2.8865, Avg Acc: 0.4922
2022-01-23 08:47:04,462 Epoch[294/300], Step[0700/1252], Avg Loss: 2.8933, Avg Acc: 0.4907
2022-01-23 08:48:32,573 Epoch[294/300], Step[0750/1252], Avg Loss: 2.8940, Avg Acc: 0.4901
2022-01-23 08:50:01,068 Epoch[294/300], Step[0800/1252], Avg Loss: 2.8909, Avg Acc: 0.4907
2022-01-23 08:51:28,277 Epoch[294/300], Step[0850/1252], Avg Loss: 2.8911, Avg Acc: 0.4911
2022-01-23 08:52:57,124 Epoch[294/300], Step[0900/1252], Avg Loss: 2.8930, Avg Acc: 0.4917
2022-01-23 08:54:24,610 Epoch[294/300], Step[0950/1252], Avg Loss: 2.8930, Avg Acc: 0.4918
2022-01-23 08:55:52,626 Epoch[294/300], Step[1000/1252], Avg Loss: 2.8896, Avg Acc: 0.4922
2022-01-23 08:57:20,375 Epoch[294/300], Step[1050/1252], Avg Loss: 2.8903, Avg Acc: 0.4918
2022-01-23 08:58:47,831 Epoch[294/300], Step[1100/1252], Avg Loss: 2.8903, Avg Acc: 0.4913
2022-01-23 09:00:16,969 Epoch[294/300], Step[1150/1252], Avg Loss: 2.8923, Avg Acc: 0.4900
2022-01-23 09:01:45,138 Epoch[294/300], Step[1200/1252], Avg Loss: 2.8935, Avg Acc: 0.4898
2022-01-23 09:03:13,395 Epoch[294/300], Step[1250/1252], Avg Loss: 2.8911, Avg Acc: 0.4903
2022-01-23 09:03:20,649 ----- Epoch[294/300], Train Loss: 2.8911, Train Acc: 0.4903, time: 2315.08, Best Val(epoch286) Acc@1: 0.7747
2022-01-23 09:03:20,649 ----- Validation after Epoch: 294
2022-01-23 09:04:40,666 Val Step[0000/1563], Avg Loss: 0.8099, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 09:04:42,834 Val Step[0050/1563], Avg Loss: 0.9929, Avg Acc@1: 0.7868, Avg Acc@5: 0.9418
2022-01-23 09:04:44,947 Val Step[0100/1563], Avg Loss: 1.0268, Avg Acc@1: 0.7834, Avg Acc@5: 0.9378
2022-01-23 09:04:46,773 Val Step[0150/1563], Avg Loss: 1.0307, Avg Acc@1: 0.7831, Avg Acc@5: 0.9356
2022-01-23 09:04:48,572 Val Step[0200/1563], Avg Loss: 1.0306, Avg Acc@1: 0.7837, Avg Acc@5: 0.9355
2022-01-23 09:04:50,372 Val Step[0250/1563], Avg Loss: 1.0208, Avg Acc@1: 0.7831, Avg Acc@5: 0.9375
2022-01-23 09:04:52,202 Val Step[0300/1563], Avg Loss: 1.0215, Avg Acc@1: 0.7830, Avg Acc@5: 0.9368
2022-01-23 09:04:54,067 Val Step[0350/1563], Avg Loss: 1.0263, Avg Acc@1: 0.7825, Avg Acc@5: 0.9365
2022-01-23 09:04:55,931 Val Step[0400/1563], Avg Loss: 1.0257, Avg Acc@1: 0.7823, Avg Acc@5: 0.9369
2022-01-23 09:04:57,816 Val Step[0450/1563], Avg Loss: 1.0307, Avg Acc@1: 0.7797, Avg Acc@5: 0.9367
2022-01-23 09:04:59,615 Val Step[0500/1563], Avg Loss: 1.0341, Avg Acc@1: 0.7785, Avg Acc@5: 0.9369
2022-01-23 09:05:01,418 Val Step[0550/1563], Avg Loss: 1.0335, Avg Acc@1: 0.7775, Avg Acc@5: 0.9372
2022-01-23 09:05:03,313 Val Step[0600/1563], Avg Loss: 1.0323, Avg Acc@1: 0.7773, Avg Acc@5: 0.9373
2022-01-23 09:05:05,250 Val Step[0650/1563], Avg Loss: 1.0327, Avg Acc@1: 0.7773, Avg Acc@5: 0.9372
2022-01-23 09:05:07,211 Val Step[0700/1563], Avg Loss: 1.0304, Avg Acc@1: 0.7773, Avg Acc@5: 0.9380
2022-01-23 09:05:09,180 Val Step[0750/1563], Avg Loss: 1.0368, Avg Acc@1: 0.7751, Avg Acc@5: 0.9374
2022-01-23 09:05:10,985 Val Step[0800/1563], Avg Loss: 1.0368, Avg Acc@1: 0.7757, Avg Acc@5: 0.9376
2022-01-23 09:05:12,893 Val Step[0850/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7756, Avg Acc@5: 0.9371
2022-01-23 09:05:14,670 Val Step[0900/1563], Avg Loss: 1.0353, Avg Acc@1: 0.7763, Avg Acc@5: 0.9375
2022-01-23 09:05:16,485 Val Step[0950/1563], Avg Loss: 1.0346, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-23 09:05:18,294 Val Step[1000/1563], Avg Loss: 1.0363, Avg Acc@1: 0.7766, Avg Acc@5: 0.9371
2022-01-23 09:05:20,102 Val Step[1050/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7758, Avg Acc@5: 0.9368
2022-01-23 09:05:22,016 Val Step[1100/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-23 09:05:23,823 Val Step[1150/1563], Avg Loss: 1.0356, Avg Acc@1: 0.7752, Avg Acc@5: 0.9374
2022-01-23 09:05:25,649 Val Step[1200/1563], Avg Loss: 1.0344, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-23 09:05:27,447 Val Step[1250/1563], Avg Loss: 1.0342, Avg Acc@1: 0.7756, Avg Acc@5: 0.9375
2022-01-23 09:05:29,237 Val Step[1300/1563], Avg Loss: 1.0370, Avg Acc@1: 0.7757, Avg Acc@5: 0.9371
2022-01-23 09:05:31,126 Val Step[1350/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7752, Avg Acc@5: 0.9370
2022-01-23 09:05:32,918 Val Step[1400/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7749, Avg Acc@5: 0.9369
2022-01-23 09:05:34,803 Val Step[1450/1563], Avg Loss: 1.0365, Avg Acc@1: 0.7754, Avg Acc@5: 0.9371
2022-01-23 09:05:36,614 Val Step[1500/1563], Avg Loss: 1.0367, Avg Acc@1: 0.7757, Avg Acc@5: 0.9372
2022-01-23 09:05:38,388 Val Step[1550/1563], Avg Loss: 1.0373, Avg Acc@1: 0.7754, Avg Acc@5: 0.9371
2022-01-23 09:05:40,336 ----- Epoch[294/300], Validation Loss: 1.0373, Validation Acc@1: 0.7754, Validation Acc@5: 0.9371, time: 139.68
2022-01-23 09:05:41,463 the pre best model acc:0.7747, at epoch 286
2022-01-23 09:05:41,464 current best model acc:0.7754, at epoch 294
2022-01-23 09:05:41,464 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 09:05:41,464 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 09:05:41,464 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 09:05:41,464 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 09:05:41,464 Now training epoch 295. LR=0.000011
2022-01-23 09:07:29,330 Epoch[295/300], Step[0000/1252], Avg Loss: 3.5436, Avg Acc: 0.4453
2022-01-23 09:08:58,164 Epoch[295/300], Step[0050/1252], Avg Loss: 2.8467, Avg Acc: 0.4914
2022-01-23 09:10:25,164 Epoch[295/300], Step[0100/1252], Avg Loss: 2.8980, Avg Acc: 0.4919
2022-01-23 09:11:52,333 Epoch[295/300], Step[0150/1252], Avg Loss: 2.8893, Avg Acc: 0.4952
2022-01-23 09:13:18,646 Epoch[295/300], Step[0200/1252], Avg Loss: 2.8993, Avg Acc: 0.4911
2022-01-23 09:14:46,509 Epoch[295/300], Step[0250/1252], Avg Loss: 2.8992, Avg Acc: 0.4836
2022-01-23 09:16:13,948 Epoch[295/300], Step[0300/1252], Avg Loss: 2.8973, Avg Acc: 0.4812
2022-01-23 09:17:41,088 Epoch[295/300], Step[0350/1252], Avg Loss: 2.8945, Avg Acc: 0.4877
2022-01-23 09:19:08,657 Epoch[295/300], Step[0400/1252], Avg Loss: 2.8966, Avg Acc: 0.4864
2022-01-23 09:20:36,290 Epoch[295/300], Step[0450/1252], Avg Loss: 2.8982, Avg Acc: 0.4850
2022-01-23 09:22:05,967 Epoch[295/300], Step[0500/1252], Avg Loss: 2.9007, Avg Acc: 0.4839
2022-01-23 09:23:34,702 Epoch[295/300], Step[0550/1252], Avg Loss: 2.9051, Avg Acc: 0.4840
2022-01-23 09:25:02,779 Epoch[295/300], Step[0600/1252], Avg Loss: 2.9027, Avg Acc: 0.4867
2022-01-23 09:26:31,218 Epoch[295/300], Step[0650/1252], Avg Loss: 2.9053, Avg Acc: 0.4850
2022-01-23 09:28:00,664 Epoch[295/300], Step[0700/1252], Avg Loss: 2.9085, Avg Acc: 0.4855
2022-01-23 09:29:28,760 Epoch[295/300], Step[0750/1252], Avg Loss: 2.9102, Avg Acc: 0.4844
2022-01-23 09:30:57,635 Epoch[295/300], Step[0800/1252], Avg Loss: 2.9071, Avg Acc: 0.4864
2022-01-23 09:32:26,919 Epoch[295/300], Step[0850/1252], Avg Loss: 2.9069, Avg Acc: 0.4867
2022-01-23 09:33:56,722 Epoch[295/300], Step[0900/1252], Avg Loss: 2.9060, Avg Acc: 0.4868
2022-01-23 09:35:26,227 Epoch[295/300], Step[0950/1252], Avg Loss: 2.9067, Avg Acc: 0.4862
2022-01-23 09:36:53,641 Epoch[295/300], Step[1000/1252], Avg Loss: 2.9070, Avg Acc: 0.4849
2022-01-23 09:38:23,560 Epoch[295/300], Step[1050/1252], Avg Loss: 2.9078, Avg Acc: 0.4854
2022-01-23 09:39:53,007 Epoch[295/300], Step[1100/1252], Avg Loss: 2.9071, Avg Acc: 0.4850
2022-01-23 09:41:22,033 Epoch[295/300], Step[1150/1252], Avg Loss: 2.9092, Avg Acc: 0.4847
2022-01-23 09:42:50,182 Epoch[295/300], Step[1200/1252], Avg Loss: 2.9091, Avg Acc: 0.4850
2022-01-23 09:44:19,161 Epoch[295/300], Step[1250/1252], Avg Loss: 2.9070, Avg Acc: 0.4850
2022-01-23 09:44:26,248 ----- Epoch[295/300], Train Loss: 2.9070, Train Acc: 0.4850, time: 2324.78, Best Val(epoch294) Acc@1: 0.7754
2022-01-23 09:44:26,248 Now training epoch 296. LR=0.000010
2022-01-23 09:46:13,748 Epoch[296/300], Step[0000/1252], Avg Loss: 3.3164, Avg Acc: 0.5039
2022-01-23 09:47:42,504 Epoch[296/300], Step[0050/1252], Avg Loss: 2.9766, Avg Acc: 0.4797
2022-01-23 09:49:11,498 Epoch[296/300], Step[0100/1252], Avg Loss: 2.9354, Avg Acc: 0.4902
2022-01-23 09:50:39,587 Epoch[296/300], Step[0150/1252], Avg Loss: 2.9308, Avg Acc: 0.4895
2022-01-23 09:52:07,672 Epoch[296/300], Step[0200/1252], Avg Loss: 2.9308, Avg Acc: 0.4841
2022-01-23 09:53:35,779 Epoch[296/300], Step[0250/1252], Avg Loss: 2.9376, Avg Acc: 0.4883
2022-01-23 09:55:02,829 Epoch[296/300], Step[0300/1252], Avg Loss: 2.9400, Avg Acc: 0.4802
2022-01-23 09:56:31,576 Epoch[296/300], Step[0350/1252], Avg Loss: 2.9342, Avg Acc: 0.4799
2022-01-23 09:58:01,183 Epoch[296/300], Step[0400/1252], Avg Loss: 2.9293, Avg Acc: 0.4770
2022-01-23 09:59:29,986 Epoch[296/300], Step[0450/1252], Avg Loss: 2.9302, Avg Acc: 0.4809
2022-01-23 10:00:58,533 Epoch[296/300], Step[0500/1252], Avg Loss: 2.9236, Avg Acc: 0.4812
2022-01-23 10:02:27,672 Epoch[296/300], Step[0550/1252], Avg Loss: 2.9256, Avg Acc: 0.4815
2022-01-23 10:03:57,403 Epoch[296/300], Step[0600/1252], Avg Loss: 2.9245, Avg Acc: 0.4834
2022-01-23 10:05:24,919 Epoch[296/300], Step[0650/1252], Avg Loss: 2.9244, Avg Acc: 0.4840
2022-01-23 10:06:52,742 Epoch[296/300], Step[0700/1252], Avg Loss: 2.9226, Avg Acc: 0.4841
2022-01-23 10:08:21,794 Epoch[296/300], Step[0750/1252], Avg Loss: 2.9182, Avg Acc: 0.4807
2022-01-23 10:09:49,851 Epoch[296/300], Step[0800/1252], Avg Loss: 2.9197, Avg Acc: 0.4812
2022-01-23 10:11:19,801 Epoch[296/300], Step[0850/1252], Avg Loss: 2.9182, Avg Acc: 0.4798
2022-01-23 10:12:49,024 Epoch[296/300], Step[0900/1252], Avg Loss: 2.9171, Avg Acc: 0.4816
2022-01-23 10:14:16,989 Epoch[296/300], Step[0950/1252], Avg Loss: 2.9188, Avg Acc: 0.4812
2022-01-23 10:15:44,522 Epoch[296/300], Step[1000/1252], Avg Loss: 2.9194, Avg Acc: 0.4812
2022-01-23 10:17:12,637 Epoch[296/300], Step[1050/1252], Avg Loss: 2.9139, Avg Acc: 0.4806
2022-01-23 10:18:41,365 Epoch[296/300], Step[1100/1252], Avg Loss: 2.9124, Avg Acc: 0.4815
2022-01-23 10:20:08,344 Epoch[296/300], Step[1150/1252], Avg Loss: 2.9100, Avg Acc: 0.4826
2022-01-23 10:21:36,345 Epoch[296/300], Step[1200/1252], Avg Loss: 2.9101, Avg Acc: 0.4823
2022-01-23 10:23:04,478 Epoch[296/300], Step[1250/1252], Avg Loss: 2.9083, Avg Acc: 0.4821
2022-01-23 10:23:11,572 ----- Epoch[296/300], Train Loss: 2.9084, Train Acc: 0.4821, time: 2325.32, Best Val(epoch294) Acc@1: 0.7754
2022-01-23 10:23:11,573 ----- Validation after Epoch: 296
2022-01-23 10:24:21,652 Val Step[0000/1563], Avg Loss: 0.8056, Avg Acc@1: 0.8438, Avg Acc@5: 1.0000
2022-01-23 10:24:23,542 Val Step[0050/1563], Avg Loss: 1.0020, Avg Acc@1: 0.7837, Avg Acc@5: 0.9412
2022-01-23 10:24:25,484 Val Step[0100/1563], Avg Loss: 1.0347, Avg Acc@1: 0.7831, Avg Acc@5: 0.9372
2022-01-23 10:24:27,431 Val Step[0150/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7823, Avg Acc@5: 0.9356
2022-01-23 10:24:29,283 Val Step[0200/1563], Avg Loss: 1.0395, Avg Acc@1: 0.7826, Avg Acc@5: 0.9358
2022-01-23 10:24:31,099 Val Step[0250/1563], Avg Loss: 1.0294, Avg Acc@1: 0.7829, Avg Acc@5: 0.9375
2022-01-23 10:24:32,909 Val Step[0300/1563], Avg Loss: 1.0306, Avg Acc@1: 0.7829, Avg Acc@5: 0.9364
2022-01-23 10:24:34,726 Val Step[0350/1563], Avg Loss: 1.0355, Avg Acc@1: 0.7823, Avg Acc@5: 0.9363
2022-01-23 10:24:36,587 Val Step[0400/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7827, Avg Acc@5: 0.9362
2022-01-23 10:24:38,440 Val Step[0450/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7797, Avg Acc@5: 0.9360
2022-01-23 10:24:40,341 Val Step[0500/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7791, Avg Acc@5: 0.9363
2022-01-23 10:24:42,144 Val Step[0550/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7778, Avg Acc@5: 0.9364
2022-01-23 10:24:43,954 Val Step[0600/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7775, Avg Acc@5: 0.9366
2022-01-23 10:24:45,776 Val Step[0650/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7777, Avg Acc@5: 0.9368
2022-01-23 10:24:47,652 Val Step[0700/1563], Avg Loss: 1.0390, Avg Acc@1: 0.7780, Avg Acc@5: 0.9373
2022-01-23 10:24:49,561 Val Step[0750/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7760, Avg Acc@5: 0.9370
2022-01-23 10:24:51,563 Val Step[0800/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7765, Avg Acc@5: 0.9369
2022-01-23 10:24:53,412 Val Step[0850/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7764, Avg Acc@5: 0.9367
2022-01-23 10:24:55,308 Val Step[0900/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7770, Avg Acc@5: 0.9372
2022-01-23 10:24:57,281 Val Step[0950/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7775, Avg Acc@5: 0.9372
2022-01-23 10:24:59,184 Val Step[1000/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7771, Avg Acc@5: 0.9369
2022-01-23 10:25:01,143 Val Step[1050/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7764, Avg Acc@5: 0.9368
2022-01-23 10:25:03,054 Val Step[1100/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7759, Avg Acc@5: 0.9369
2022-01-23 10:25:04,917 Val Step[1150/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7760, Avg Acc@5: 0.9372
2022-01-23 10:25:06,780 Val Step[1200/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7766, Avg Acc@5: 0.9372
2022-01-23 10:25:08,620 Val Step[1250/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7763, Avg Acc@5: 0.9375
2022-01-23 10:25:10,479 Val Step[1300/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7762, Avg Acc@5: 0.9371
2022-01-23 10:25:12,394 Val Step[1350/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7756, Avg Acc@5: 0.9370
2022-01-23 10:25:14,194 Val Step[1400/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-23 10:25:16,082 Val Step[1450/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7755, Avg Acc@5: 0.9371
2022-01-23 10:25:17,971 Val Step[1500/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7756, Avg Acc@5: 0.9373
2022-01-23 10:25:19,728 Val Step[1550/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7755, Avg Acc@5: 0.9372
2022-01-23 10:25:21,600 ----- Epoch[296/300], Validation Loss: 1.0452, Validation Acc@1: 0.7755, Validation Acc@5: 0.9372, time: 130.03
2022-01-23 10:25:22,745 the pre best model acc:0.7754, at epoch 294
2022-01-23 10:25:22,745 current best model acc:0.7755, at epoch 296
2022-01-23 10:25:22,745 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 10:25:22,745 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 10:25:22,745 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 10:25:22,745 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 10:25:22,746 Now training epoch 297. LR=0.000010
2022-01-23 10:27:05,547 Epoch[297/300], Step[0000/1252], Avg Loss: 2.5915, Avg Acc: 0.6885
2022-01-23 10:28:34,672 Epoch[297/300], Step[0050/1252], Avg Loss: 2.8943, Avg Acc: 0.4474
2022-01-23 10:30:00,458 Epoch[297/300], Step[0100/1252], Avg Loss: 2.8834, Avg Acc: 0.4785
2022-01-23 10:31:28,498 Epoch[297/300], Step[0150/1252], Avg Loss: 2.8873, Avg Acc: 0.4790
2022-01-23 10:32:56,456 Epoch[297/300], Step[0200/1252], Avg Loss: 2.8901, Avg Acc: 0.4842
2022-01-23 10:34:23,779 Epoch[297/300], Step[0250/1252], Avg Loss: 2.9016, Avg Acc: 0.4825
2022-01-23 10:35:50,759 Epoch[297/300], Step[0300/1252], Avg Loss: 2.8999, Avg Acc: 0.4836
2022-01-23 10:37:18,866 Epoch[297/300], Step[0350/1252], Avg Loss: 2.9083, Avg Acc: 0.4826
2022-01-23 10:38:46,426 Epoch[297/300], Step[0400/1252], Avg Loss: 2.9086, Avg Acc: 0.4863
2022-01-23 10:40:14,139 Epoch[297/300], Step[0450/1252], Avg Loss: 2.9027, Avg Acc: 0.4852
2022-01-23 10:41:41,896 Epoch[297/300], Step[0500/1252], Avg Loss: 2.9032, Avg Acc: 0.4853
2022-01-23 10:43:10,816 Epoch[297/300], Step[0550/1252], Avg Loss: 2.9046, Avg Acc: 0.4849
2022-01-23 10:44:38,707 Epoch[297/300], Step[0600/1252], Avg Loss: 2.9059, Avg Acc: 0.4862
2022-01-23 10:46:06,212 Epoch[297/300], Step[0650/1252], Avg Loss: 2.9103, Avg Acc: 0.4875
2022-01-23 10:47:33,635 Epoch[297/300], Step[0700/1252], Avg Loss: 2.9036, Avg Acc: 0.4885
2022-01-23 10:49:00,610 Epoch[297/300], Step[0750/1252], Avg Loss: 2.9021, Avg Acc: 0.4912
2022-01-23 10:50:27,314 Epoch[297/300], Step[0800/1252], Avg Loss: 2.9008, Avg Acc: 0.4919
2022-01-23 10:51:54,683 Epoch[297/300], Step[0850/1252], Avg Loss: 2.9031, Avg Acc: 0.4918
2022-01-23 10:53:22,641 Epoch[297/300], Step[0900/1252], Avg Loss: 2.9053, Avg Acc: 0.4912
2022-01-23 10:54:50,871 Epoch[297/300], Step[0950/1252], Avg Loss: 2.9066, Avg Acc: 0.4902
2022-01-23 10:56:18,571 Epoch[297/300], Step[1000/1252], Avg Loss: 2.9081, Avg Acc: 0.4906
2022-01-23 10:57:46,621 Epoch[297/300], Step[1050/1252], Avg Loss: 2.9079, Avg Acc: 0.4909
2022-01-23 10:59:15,189 Epoch[297/300], Step[1100/1252], Avg Loss: 2.9087, Avg Acc: 0.4920
2022-01-23 11:00:43,703 Epoch[297/300], Step[1150/1252], Avg Loss: 2.9093, Avg Acc: 0.4919
2022-01-23 11:02:10,722 Epoch[297/300], Step[1200/1252], Avg Loss: 2.9090, Avg Acc: 0.4939
2022-01-23 11:03:37,688 Epoch[297/300], Step[1250/1252], Avg Loss: 2.9081, Avg Acc: 0.4935
2022-01-23 11:03:44,721 ----- Epoch[297/300], Train Loss: 2.9081, Train Acc: 0.4935, time: 2301.97, Best Val(epoch296) Acc@1: 0.7755
2022-01-23 11:03:44,721 Now training epoch 298. LR=0.000010
2022-01-23 11:05:33,503 Epoch[298/300], Step[0000/1252], Avg Loss: 2.5872, Avg Acc: 0.7344
2022-01-23 11:07:03,626 Epoch[298/300], Step[0050/1252], Avg Loss: 2.9185, Avg Acc: 0.5025
2022-01-23 11:08:33,345 Epoch[298/300], Step[0100/1252], Avg Loss: 2.9320, Avg Acc: 0.4871
2022-01-23 11:10:02,235 Epoch[298/300], Step[0150/1252], Avg Loss: 2.9166, Avg Acc: 0.4800
2022-01-23 11:11:30,400 Epoch[298/300], Step[0200/1252], Avg Loss: 2.9059, Avg Acc: 0.4841
2022-01-23 11:12:58,790 Epoch[298/300], Step[0250/1252], Avg Loss: 2.9070, Avg Acc: 0.4878
2022-01-23 11:14:26,763 Epoch[298/300], Step[0300/1252], Avg Loss: 2.8997, Avg Acc: 0.4909
2022-01-23 11:15:55,022 Epoch[298/300], Step[0350/1252], Avg Loss: 2.8940, Avg Acc: 0.4921
2022-01-23 11:17:21,786 Epoch[298/300], Step[0400/1252], Avg Loss: 2.8955, Avg Acc: 0.4920
2022-01-23 11:18:50,002 Epoch[298/300], Step[0450/1252], Avg Loss: 2.8965, Avg Acc: 0.4877
2022-01-23 11:20:15,927 Epoch[298/300], Step[0500/1252], Avg Loss: 2.9031, Avg Acc: 0.4888
2022-01-23 11:21:43,692 Epoch[298/300], Step[0550/1252], Avg Loss: 2.9013, Avg Acc: 0.4902
2022-01-23 11:23:13,144 Epoch[298/300], Step[0600/1252], Avg Loss: 2.8939, Avg Acc: 0.4889
2022-01-23 11:24:41,045 Epoch[298/300], Step[0650/1252], Avg Loss: 2.8990, Avg Acc: 0.4880
2022-01-23 11:26:10,340 Epoch[298/300], Step[0700/1252], Avg Loss: 2.9004, Avg Acc: 0.4862
2022-01-23 11:27:39,139 Epoch[298/300], Step[0750/1252], Avg Loss: 2.8975, Avg Acc: 0.4896
2022-01-23 11:29:08,563 Epoch[298/300], Step[0800/1252], Avg Loss: 2.9020, Avg Acc: 0.4895
2022-01-23 11:30:36,735 Epoch[298/300], Step[0850/1252], Avg Loss: 2.9010, Avg Acc: 0.4894
2022-01-23 11:32:04,891 Epoch[298/300], Step[0900/1252], Avg Loss: 2.9056, Avg Acc: 0.4887
2022-01-23 11:33:33,435 Epoch[298/300], Step[0950/1252], Avg Loss: 2.9058, Avg Acc: 0.4886
2022-01-23 11:35:02,808 Epoch[298/300], Step[1000/1252], Avg Loss: 2.9049, Avg Acc: 0.4875
2022-01-23 11:36:31,966 Epoch[298/300], Step[1050/1252], Avg Loss: 2.9062, Avg Acc: 0.4862
2022-01-23 11:38:01,432 Epoch[298/300], Step[1100/1252], Avg Loss: 2.9102, Avg Acc: 0.4865
2022-01-23 11:39:30,194 Epoch[298/300], Step[1150/1252], Avg Loss: 2.9079, Avg Acc: 0.4864
2022-01-23 11:40:59,216 Epoch[298/300], Step[1200/1252], Avg Loss: 2.9076, Avg Acc: 0.4855
2022-01-23 11:42:26,703 Epoch[298/300], Step[1250/1252], Avg Loss: 2.9083, Avg Acc: 0.4865
2022-01-23 11:42:33,846 ----- Epoch[298/300], Train Loss: 2.9082, Train Acc: 0.4866, time: 2329.12, Best Val(epoch296) Acc@1: 0.7755
2022-01-23 11:42:33,846 ----- Validation after Epoch: 298
2022-01-23 11:43:48,395 Val Step[0000/1563], Avg Loss: 0.8095, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 11:43:50,389 Val Step[0050/1563], Avg Loss: 1.0053, Avg Acc@1: 0.7855, Avg Acc@5: 0.9400
2022-01-23 11:43:52,246 Val Step[0100/1563], Avg Loss: 1.0383, Avg Acc@1: 0.7847, Avg Acc@5: 0.9369
2022-01-23 11:43:54,075 Val Step[0150/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7833, Avg Acc@5: 0.9352
2022-01-23 11:43:55,915 Val Step[0200/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7834, Avg Acc@5: 0.9353
2022-01-23 11:43:57,783 Val Step[0250/1563], Avg Loss: 1.0316, Avg Acc@1: 0.7831, Avg Acc@5: 0.9377
2022-01-23 11:43:59,687 Val Step[0300/1563], Avg Loss: 1.0308, Avg Acc@1: 0.7837, Avg Acc@5: 0.9371
2022-01-23 11:44:01,505 Val Step[0350/1563], Avg Loss: 1.0357, Avg Acc@1: 0.7828, Avg Acc@5: 0.9367
2022-01-23 11:44:03,418 Val Step[0400/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7827, Avg Acc@5: 0.9366
2022-01-23 11:44:05,223 Val Step[0450/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7794, Avg Acc@5: 0.9365
2022-01-23 11:44:07,012 Val Step[0500/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7783, Avg Acc@5: 0.9366
2022-01-23 11:44:08,839 Val Step[0550/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7776, Avg Acc@5: 0.9367
2022-01-23 11:44:10,626 Val Step[0600/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7770, Avg Acc@5: 0.9368
2022-01-23 11:44:12,447 Val Step[0650/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7772, Avg Acc@5: 0.9370
2022-01-23 11:44:14,234 Val Step[0700/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7775, Avg Acc@5: 0.9374
2022-01-23 11:44:16,086 Val Step[0750/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7758, Avg Acc@5: 0.9371
2022-01-23 11:44:17,868 Val Step[0800/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7765, Avg Acc@5: 0.9371
2022-01-23 11:44:19,944 Val Step[0850/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7762, Avg Acc@5: 0.9368
2022-01-23 11:44:22,026 Val Step[0900/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7766, Avg Acc@5: 0.9372
2022-01-23 11:44:24,071 Val Step[0950/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7774, Avg Acc@5: 0.9372
2022-01-23 11:44:26,128 Val Step[1000/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7770, Avg Acc@5: 0.9370
2022-01-23 11:44:28,240 Val Step[1050/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7763, Avg Acc@5: 0.9367
2022-01-23 11:44:30,302 Val Step[1100/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7760, Avg Acc@5: 0.9368
2022-01-23 11:44:32,419 Val Step[1150/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7763, Avg Acc@5: 0.9370
2022-01-23 11:44:34,546 Val Step[1200/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7770, Avg Acc@5: 0.9370
2022-01-23 11:44:36,600 Val Step[1250/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7766, Avg Acc@5: 0.9373
2022-01-23 11:44:38,548 Val Step[1300/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7764, Avg Acc@5: 0.9368
2022-01-23 11:44:40,388 Val Step[1350/1563], Avg Loss: 1.0463, Avg Acc@1: 0.7761, Avg Acc@5: 0.9368
2022-01-23 11:44:42,229 Val Step[1400/1563], Avg Loss: 1.0461, Avg Acc@1: 0.7758, Avg Acc@5: 0.9367
2022-01-23 11:44:44,040 Val Step[1450/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7762, Avg Acc@5: 0.9367
2022-01-23 11:44:45,905 Val Step[1500/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7764, Avg Acc@5: 0.9369
2022-01-23 11:44:47,661 Val Step[1550/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7762, Avg Acc@5: 0.9368
2022-01-23 11:44:49,616 ----- Epoch[298/300], Validation Loss: 1.0454, Validation Acc@1: 0.7762, Validation Acc@5: 0.9368, time: 135.77
2022-01-23 11:44:50,759 the pre best model acc:0.7755, at epoch 296
2022-01-23 11:44:50,759 current best model acc:0.7762, at epoch 298
2022-01-23 11:44:50,760 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 11:44:50,760 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 11:44:50,760 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 11:44:50,760 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 11:44:50,760 Now training epoch 299. LR=0.000010
2022-01-23 11:46:32,963 Epoch[299/300], Step[0000/1252], Avg Loss: 3.1611, Avg Acc: 0.4688
2022-01-23 11:48:02,824 Epoch[299/300], Step[0050/1252], Avg Loss: 2.9437, Avg Acc: 0.4821
2022-01-23 11:49:31,623 Epoch[299/300], Step[0100/1252], Avg Loss: 2.9190, Avg Acc: 0.4728
2022-01-23 11:50:59,831 Epoch[299/300], Step[0150/1252], Avg Loss: 2.9289, Avg Acc: 0.4777
2022-01-23 11:52:25,427 Epoch[299/300], Step[0200/1252], Avg Loss: 2.9336, Avg Acc: 0.4825
2022-01-23 11:53:52,153 Epoch[299/300], Step[0250/1252], Avg Loss: 2.9336, Avg Acc: 0.4816
2022-01-23 11:55:18,517 Epoch[299/300], Step[0300/1252], Avg Loss: 2.9272, Avg Acc: 0.4846
2022-01-23 11:56:44,652 Epoch[299/300], Step[0350/1252], Avg Loss: 2.9241, Avg Acc: 0.4913
2022-01-23 11:58:11,833 Epoch[299/300], Step[0400/1252], Avg Loss: 2.9184, Avg Acc: 0.4922
2022-01-23 11:59:39,020 Epoch[299/300], Step[0450/1252], Avg Loss: 2.9154, Avg Acc: 0.4913
2022-01-23 12:01:06,974 Epoch[299/300], Step[0500/1252], Avg Loss: 2.9164, Avg Acc: 0.4928
2022-01-23 12:02:33,961 Epoch[299/300], Step[0550/1252], Avg Loss: 2.9118, Avg Acc: 0.4924
2022-01-23 12:04:00,258 Epoch[299/300], Step[0600/1252], Avg Loss: 2.9154, Avg Acc: 0.4918
2022-01-23 12:05:28,163 Epoch[299/300], Step[0650/1252], Avg Loss: 2.9155, Avg Acc: 0.4918
2022-01-23 12:06:54,668 Epoch[299/300], Step[0700/1252], Avg Loss: 2.9144, Avg Acc: 0.4917
2022-01-23 12:08:22,238 Epoch[299/300], Step[0750/1252], Avg Loss: 2.9148, Avg Acc: 0.4887
2022-01-23 12:09:50,271 Epoch[299/300], Step[0800/1252], Avg Loss: 2.9151, Avg Acc: 0.4871
2022-01-23 12:11:17,386 Epoch[299/300], Step[0850/1252], Avg Loss: 2.9127, Avg Acc: 0.4873
2022-01-23 12:12:45,141 Epoch[299/300], Step[0900/1252], Avg Loss: 2.9156, Avg Acc: 0.4866
2022-01-23 12:14:12,679 Epoch[299/300], Step[0950/1252], Avg Loss: 2.9163, Avg Acc: 0.4855
2022-01-23 12:15:40,140 Epoch[299/300], Step[1000/1252], Avg Loss: 2.9150, Avg Acc: 0.4861
2022-01-23 12:17:07,809 Epoch[299/300], Step[1050/1252], Avg Loss: 2.9169, Avg Acc: 0.4856
2022-01-23 12:18:35,537 Epoch[299/300], Step[1100/1252], Avg Loss: 2.9140, Avg Acc: 0.4859
2022-01-23 12:20:04,865 Epoch[299/300], Step[1150/1252], Avg Loss: 2.9101, Avg Acc: 0.4870
2022-01-23 12:21:32,405 Epoch[299/300], Step[1200/1252], Avg Loss: 2.9109, Avg Acc: 0.4874
2022-01-23 12:23:00,935 Epoch[299/300], Step[1250/1252], Avg Loss: 2.9092, Avg Acc: 0.4888
2022-01-23 12:23:07,509 ----- Epoch[299/300], Train Loss: 2.9092, Train Acc: 0.4888, time: 2296.74, Best Val(epoch298) Acc@1: 0.7762
2022-01-23 12:23:07,509 Now training epoch 300. LR=0.000010
2022-01-23 12:25:09,646 Epoch[300/300], Step[0000/1252], Avg Loss: 2.9335, Avg Acc: 0.4746
2022-01-23 12:26:38,328 Epoch[300/300], Step[0050/1252], Avg Loss: 2.9038, Avg Acc: 0.5078
2022-01-23 12:28:05,974 Epoch[300/300], Step[0100/1252], Avg Loss: 2.9403, Avg Acc: 0.4847
2022-01-23 12:29:34,600 Epoch[300/300], Step[0150/1252], Avg Loss: 2.9301, Avg Acc: 0.4868
2022-01-23 12:31:03,118 Epoch[300/300], Step[0200/1252], Avg Loss: 2.9160, Avg Acc: 0.4914
2022-01-23 12:32:32,137 Epoch[300/300], Step[0250/1252], Avg Loss: 2.9123, Avg Acc: 0.4871
2022-01-23 12:33:59,401 Epoch[300/300], Step[0300/1252], Avg Loss: 2.9142, Avg Acc: 0.4844
2022-01-23 12:35:27,243 Epoch[300/300], Step[0350/1252], Avg Loss: 2.9110, Avg Acc: 0.4869
2022-01-23 12:36:55,666 Epoch[300/300], Step[0400/1252], Avg Loss: 2.9147, Avg Acc: 0.4873
2022-01-23 12:38:24,587 Epoch[300/300], Step[0450/1252], Avg Loss: 2.9113, Avg Acc: 0.4842
2022-01-23 12:39:52,226 Epoch[300/300], Step[0500/1252], Avg Loss: 2.9087, Avg Acc: 0.4867
2022-01-23 12:41:21,143 Epoch[300/300], Step[0550/1252], Avg Loss: 2.9134, Avg Acc: 0.4863
2022-01-23 12:42:50,175 Epoch[300/300], Step[0600/1252], Avg Loss: 2.9127, Avg Acc: 0.4870
2022-01-23 12:44:18,925 Epoch[300/300], Step[0650/1252], Avg Loss: 2.9090, Avg Acc: 0.4881
2022-01-23 12:45:47,207 Epoch[300/300], Step[0700/1252], Avg Loss: 2.9009, Avg Acc: 0.4884
2022-01-23 12:47:15,072 Epoch[300/300], Step[0750/1252], Avg Loss: 2.9000, Avg Acc: 0.4884
2022-01-23 12:48:42,748 Epoch[300/300], Step[0800/1252], Avg Loss: 2.8990, Avg Acc: 0.4862
2022-01-23 12:50:11,513 Epoch[300/300], Step[0850/1252], Avg Loss: 2.8997, Avg Acc: 0.4861
2022-01-23 12:51:40,771 Epoch[300/300], Step[0900/1252], Avg Loss: 2.8969, Avg Acc: 0.4853
2022-01-23 12:53:09,686 Epoch[300/300], Step[0950/1252], Avg Loss: 2.8970, Avg Acc: 0.4817
2022-01-23 12:54:38,590 Epoch[300/300], Step[1000/1252], Avg Loss: 2.8983, Avg Acc: 0.4806
2022-01-23 12:56:07,121 Epoch[300/300], Step[1050/1252], Avg Loss: 2.9018, Avg Acc: 0.4801
2022-01-23 12:57:36,484 Epoch[300/300], Step[1100/1252], Avg Loss: 2.9037, Avg Acc: 0.4797
2022-01-23 12:59:06,163 Epoch[300/300], Step[1150/1252], Avg Loss: 2.9049, Avg Acc: 0.4801
2022-01-23 13:00:34,677 Epoch[300/300], Step[1200/1252], Avg Loss: 2.9035, Avg Acc: 0.4803
2022-01-23 13:02:01,456 Epoch[300/300], Step[1250/1252], Avg Loss: 2.9038, Avg Acc: 0.4808
2022-01-23 13:02:08,021 ----- Epoch[300/300], Train Loss: 2.9038, Train Acc: 0.4808, time: 2340.51, Best Val(epoch298) Acc@1: 0.7762
2022-01-23 13:02:08,022 ----- Validation after Epoch: 300
2022-01-23 13:03:20,489 Val Step[0000/1563], Avg Loss: 0.8264, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 13:03:22,676 Val Step[0050/1563], Avg Loss: 1.0087, Avg Acc@1: 0.7843, Avg Acc@5: 0.9375
2022-01-23 13:03:24,863 Val Step[0100/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7834, Avg Acc@5: 0.9360
2022-01-23 13:03:26,847 Val Step[0150/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7829, Avg Acc@5: 0.9350
2022-01-23 13:03:28,770 Val Step[0200/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7826, Avg Acc@5: 0.9352
2022-01-23 13:03:30,639 Val Step[0250/1563], Avg Loss: 1.0334, Avg Acc@1: 0.7829, Avg Acc@5: 0.9369
2022-01-23 13:03:32,484 Val Step[0300/1563], Avg Loss: 1.0341, Avg Acc@1: 0.7825, Avg Acc@5: 0.9362
2022-01-23 13:03:34,346 Val Step[0350/1563], Avg Loss: 1.0388, Avg Acc@1: 0.7813, Avg Acc@5: 0.9357
2022-01-23 13:03:36,150 Val Step[0400/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7817, Avg Acc@5: 0.9355
2022-01-23 13:03:38,035 Val Step[0450/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7791, Avg Acc@5: 0.9356
2022-01-23 13:03:39,869 Val Step[0500/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7786, Avg Acc@5: 0.9361
2022-01-23 13:03:41,783 Val Step[0550/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7776, Avg Acc@5: 0.9365
2022-01-23 13:03:43,625 Val Step[0600/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7771, Avg Acc@5: 0.9366
2022-01-23 13:03:45,489 Val Step[0650/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7773, Avg Acc@5: 0.9368
2022-01-23 13:03:47,312 Val Step[0700/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7778, Avg Acc@5: 0.9374
2022-01-23 13:03:49,218 Val Step[0750/1563], Avg Loss: 1.0473, Avg Acc@1: 0.7760, Avg Acc@5: 0.9368
2022-01-23 13:03:51,097 Val Step[0800/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7766, Avg Acc@5: 0.9368
2022-01-23 13:03:53,070 Val Step[0850/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7761, Avg Acc@5: 0.9363
2022-01-23 13:03:55,015 Val Step[0900/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7768, Avg Acc@5: 0.9368
2022-01-23 13:03:56,966 Val Step[0950/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7773, Avg Acc@5: 0.9368
2022-01-23 13:03:58,803 Val Step[1000/1563], Avg Loss: 1.0468, Avg Acc@1: 0.7769, Avg Acc@5: 0.9365
2022-01-23 13:04:00,620 Val Step[1050/1563], Avg Loss: 1.0489, Avg Acc@1: 0.7765, Avg Acc@5: 0.9362
2022-01-23 13:04:02,572 Val Step[1100/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7759, Avg Acc@5: 0.9365
2022-01-23 13:04:04,380 Val Step[1150/1563], Avg Loss: 1.0467, Avg Acc@1: 0.7762, Avg Acc@5: 0.9368
2022-01-23 13:04:06,198 Val Step[1200/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7770, Avg Acc@5: 0.9368
2022-01-23 13:04:08,038 Val Step[1250/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7763, Avg Acc@5: 0.9369
2022-01-23 13:04:09,964 Val Step[1300/1563], Avg Loss: 1.0482, Avg Acc@1: 0.7761, Avg Acc@5: 0.9366
2022-01-23 13:04:11,801 Val Step[1350/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7755, Avg Acc@5: 0.9365
2022-01-23 13:04:13,677 Val Step[1400/1563], Avg Loss: 1.0486, Avg Acc@1: 0.7753, Avg Acc@5: 0.9366
2022-01-23 13:04:15,550 Val Step[1450/1563], Avg Loss: 1.0473, Avg Acc@1: 0.7758, Avg Acc@5: 0.9367
2022-01-23 13:04:17,466 Val Step[1500/1563], Avg Loss: 1.0475, Avg Acc@1: 0.7759, Avg Acc@5: 0.9370
2022-01-23 13:04:19,275 Val Step[1550/1563], Avg Loss: 1.0481, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-23 13:04:21,074 ----- Epoch[300/300], Validation Loss: 1.0479, Validation Acc@1: 0.7757, Validation Acc@5: 0.9370, time: 133.05
2022-01-23 13:04:21,539 ----- Save model: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-300-Loss-2.9198463886133976.pdparams
2022-01-23 13:04:21,539 ----- Save optim: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-300-Loss-2.9198463886133976.pdopt
