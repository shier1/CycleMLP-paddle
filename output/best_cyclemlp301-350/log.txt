2022-01-23 14:17:06,290 
AMP: False
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 256
  BATCH_SIZE_EVAL: 8
  CROP_PCT: 0.9
  DATASET: imagenet2012
  DATA_PATH: /root/paddlejob/workspace/train_data/datasets/Light_ILSVRC2012
  IMAGE_SIZE: 224
  NUM_WORKERS: 16
EVAL: False
LOCAL_RANK: 0
MODEL:
  MIXER:
    EMBED_DIMS: [64, 128, 320, 512]
    LAYERS: [2, 2, 4, 2]
    MLP_RATIOS: [4, 4, 4, 4]
    TRANSITIONS: [True, True, True, True]
  NAME: cyclemlp_b1
  NUM_CLASSES: 1000
  PRETRAINED: CycleMLP-Epoch-300-Loss-2.9198463886133976
  RESUME: None
  TYPE: CycleMLP
NGPUS: 4
REPORT_FREQ: 50
SAVE: /root/paddlejob/workspace/output//train
SAVE_FREQ: 50
SEED: 0
TAG: default
TRAIN:
  ACCUM_ITER: 1
  AUTO_AUGMENT: True
  BASE_LR: 5e-06
  COLOR_JITTER: 0.4
  CUTMIX_ALPHA: 1.0
  CUTMIX_MINMAX: None
  END_LR: 5e-08
  GRAD_CLIP: 5.0
  LAST_EPOCH: 0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    MILESTONES: 30, 60, 90
    NAME: warmupcosine
  MIXUP_ALPHA: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  NUM_EPOCHS: 50
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: AdamW
  RANDOM_ERASE_COUNT: 1
  RANDOM_ERASE_MODE: pixel
  RANDOM_ERASE_PROB: 0.25
  RANDOM_ERASE_SPLIT: False
  SMOOTHING: 0.1
  WARMUP_EPOCHS: 3
  WARMUP_START_LR: 5e-07
  WEIGHT_DECAY: 0.05
VALIDATE_FREQ: 2
VALIDATION:
  REQUIREMENTS: 0.789
2022-01-23 14:17:06,291 ----- world_size = 4, local_rank = 0
2022-01-23 14:17:07,024 ----- Total # of train batch (single gpu): 1252
2022-01-23 14:17:07,024 ----- Total # of val batch (single gpu): 1563
2022-01-23 14:17:07,425 ----- Pretrained: Load model state from CycleMLP-Epoch-300-Loss-2.9198463886133976
2022-01-23 14:17:07,425 Start training from epoch 1.
2022-01-23 14:17:07,425 Now training epoch 1. LR=0.000004
2022-01-23 14:18:58,167 Epoch[001/050], Step[0000/1252], Avg Loss: 2.9202, Avg Acc: 0.3027
2022-01-23 14:20:41,360 Epoch[001/050], Step[0050/1252], Avg Loss: 2.9503, Avg Acc: 0.4589
2022-01-23 14:22:10,267 Epoch[001/050], Step[0100/1252], Avg Loss: 2.9449, Avg Acc: 0.4721
2022-01-23 14:23:39,005 Epoch[001/050], Step[0150/1252], Avg Loss: 2.9281, Avg Acc: 0.4709
2022-01-23 14:25:08,640 Epoch[001/050], Step[0200/1252], Avg Loss: 2.9120, Avg Acc: 0.4710
2022-01-23 14:26:38,866 Epoch[001/050], Step[0250/1252], Avg Loss: 2.8969, Avg Acc: 0.4753
2022-01-23 14:28:07,107 Epoch[001/050], Step[0300/1252], Avg Loss: 2.8845, Avg Acc: 0.4825
2022-01-23 14:29:36,940 Epoch[001/050], Step[0350/1252], Avg Loss: 2.8992, Avg Acc: 0.4842
2022-01-23 14:31:06,529 Epoch[001/050], Step[0400/1252], Avg Loss: 2.8952, Avg Acc: 0.4826
2022-01-23 14:32:35,518 Epoch[001/050], Step[0450/1252], Avg Loss: 2.9024, Avg Acc: 0.4797
2022-01-23 14:34:04,953 Epoch[001/050], Step[0500/1252], Avg Loss: 2.8999, Avg Acc: 0.4814
2022-01-23 14:35:33,159 Epoch[001/050], Step[0550/1252], Avg Loss: 2.8931, Avg Acc: 0.4831
2022-01-23 14:37:03,631 Epoch[001/050], Step[0600/1252], Avg Loss: 2.8954, Avg Acc: 0.4845
2022-01-23 14:38:34,035 Epoch[001/050], Step[0650/1252], Avg Loss: 2.8972, Avg Acc: 0.4824
2022-01-23 14:40:03,798 Epoch[001/050], Step[0700/1252], Avg Loss: 2.8960, Avg Acc: 0.4841
2022-01-23 14:41:34,488 Epoch[001/050], Step[0750/1252], Avg Loss: 2.8954, Avg Acc: 0.4861
2022-01-23 14:43:03,746 Epoch[001/050], Step[0800/1252], Avg Loss: 2.8966, Avg Acc: 0.4854
2022-01-23 14:44:33,690 Epoch[001/050], Step[0850/1252], Avg Loss: 2.8924, Avg Acc: 0.4845
2022-01-23 14:46:03,645 Epoch[001/050], Step[0900/1252], Avg Loss: 2.8918, Avg Acc: 0.4854
2022-01-23 14:47:34,315 Epoch[001/050], Step[0950/1252], Avg Loss: 2.8899, Avg Acc: 0.4864
2022-01-23 14:49:04,561 Epoch[001/050], Step[1000/1252], Avg Loss: 2.8904, Avg Acc: 0.4852
2022-01-23 14:50:33,958 Epoch[001/050], Step[1050/1252], Avg Loss: 2.8905, Avg Acc: 0.4827
2022-01-23 14:52:03,694 Epoch[001/050], Step[1100/1252], Avg Loss: 2.8905, Avg Acc: 0.4819
2022-01-23 14:53:33,215 Epoch[001/050], Step[1150/1252], Avg Loss: 2.8914, Avg Acc: 0.4815
2022-01-23 14:55:03,697 Epoch[001/050], Step[1200/1252], Avg Loss: 2.8914, Avg Acc: 0.4812
2022-01-23 14:56:32,465 Epoch[001/050], Step[1250/1252], Avg Loss: 2.8915, Avg Acc: 0.4808
2022-01-23 14:56:39,745 ----- Epoch[001/050], Train Loss: 2.8915, Train Acc: 0.4808, time: 2372.32
2022-01-23 14:56:39,745 Now training epoch 2. LR=0.000007
2022-01-23 14:58:25,293 Epoch[002/050], Step[0000/1252], Avg Loss: 3.0025, Avg Acc: 0.2930
2022-01-23 14:59:50,913 Epoch[002/050], Step[0050/1252], Avg Loss: 2.9633, Avg Acc: 0.4771
2022-01-23 15:01:15,486 Epoch[002/050], Step[0100/1252], Avg Loss: 2.9258, Avg Acc: 0.4706
2022-01-23 15:02:39,761 Epoch[002/050], Step[0150/1252], Avg Loss: 2.9281, Avg Acc: 0.4753
2022-01-23 15:04:05,160 Epoch[002/050], Step[0200/1252], Avg Loss: 2.9181, Avg Acc: 0.4798
2022-01-23 15:05:31,023 Epoch[002/050], Step[0250/1252], Avg Loss: 2.9093, Avg Acc: 0.4841
2022-01-23 15:06:54,809 Epoch[002/050], Step[0300/1252], Avg Loss: 2.9085, Avg Acc: 0.4868
2022-01-23 15:08:20,815 Epoch[002/050], Step[0350/1252], Avg Loss: 2.9108, Avg Acc: 0.4841
2022-01-23 15:09:46,584 Epoch[002/050], Step[0400/1252], Avg Loss: 2.9070, Avg Acc: 0.4847
2022-01-23 15:11:11,465 Epoch[002/050], Step[0450/1252], Avg Loss: 2.9061, Avg Acc: 0.4834
2022-01-23 15:12:36,041 Epoch[002/050], Step[0500/1252], Avg Loss: 2.9036, Avg Acc: 0.4808
2022-01-23 15:14:00,431 Epoch[002/050], Step[0550/1252], Avg Loss: 2.9024, Avg Acc: 0.4811
2022-01-23 15:15:24,714 Epoch[002/050], Step[0600/1252], Avg Loss: 2.8995, Avg Acc: 0.4842
2022-01-23 15:16:52,323 Epoch[002/050], Step[0650/1252], Avg Loss: 2.8941, Avg Acc: 0.4823
2022-01-23 15:18:17,457 Epoch[002/050], Step[0700/1252], Avg Loss: 2.8871, Avg Acc: 0.4839
2022-01-23 15:19:44,185 Epoch[002/050], Step[0750/1252], Avg Loss: 2.8838, Avg Acc: 0.4859
2022-01-23 15:21:10,242 Epoch[002/050], Step[0800/1252], Avg Loss: 2.8871, Avg Acc: 0.4835
2022-01-23 15:22:37,654 Epoch[002/050], Step[0850/1252], Avg Loss: 2.8872, Avg Acc: 0.4817
2022-01-23 15:24:04,244 Epoch[002/050], Step[0900/1252], Avg Loss: 2.8904, Avg Acc: 0.4817
2022-01-23 15:25:30,105 Epoch[002/050], Step[0950/1252], Avg Loss: 2.8929, Avg Acc: 0.4816
2022-01-23 15:26:56,741 Epoch[002/050], Step[1000/1252], Avg Loss: 2.8936, Avg Acc: 0.4808
2022-01-23 15:28:24,135 Epoch[002/050], Step[1050/1252], Avg Loss: 2.8924, Avg Acc: 0.4791
2022-01-23 15:29:51,207 Epoch[002/050], Step[1100/1252], Avg Loss: 2.8943, Avg Acc: 0.4792
2022-01-23 15:31:17,816 Epoch[002/050], Step[1150/1252], Avg Loss: 2.8939, Avg Acc: 0.4786
2022-01-23 15:32:44,946 Epoch[002/050], Step[1200/1252], Avg Loss: 2.8946, Avg Acc: 0.4803
2022-01-23 15:34:11,001 Epoch[002/050], Step[1250/1252], Avg Loss: 2.8953, Avg Acc: 0.4814
2022-01-23 15:34:18,182 ----- Epoch[002/050], Train Loss: 2.8952, Train Acc: 0.4814, time: 2258.43
2022-01-23 15:34:18,183 ----- Validation after Epoch: 2
2022-01-23 15:35:31,621 Val Step[0000/1563], Avg Loss: 0.8177, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 15:35:33,653 Val Step[0050/1563], Avg Loss: 1.0098, Avg Acc@1: 0.7831, Avg Acc@5: 0.9412
2022-01-23 15:35:35,660 Val Step[0100/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7819, Avg Acc@5: 0.9378
2022-01-23 15:35:37,682 Val Step[0150/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7819, Avg Acc@5: 0.9354
2022-01-23 15:35:39,708 Val Step[0200/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7814, Avg Acc@5: 0.9353
2022-01-23 15:35:41,626 Val Step[0250/1563], Avg Loss: 1.0345, Avg Acc@1: 0.7811, Avg Acc@5: 0.9376
2022-01-23 15:35:43,508 Val Step[0300/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7811, Avg Acc@5: 0.9364
2022-01-23 15:35:45,486 Val Step[0350/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7807, Avg Acc@5: 0.9361
2022-01-23 15:35:47,542 Val Step[0400/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7814, Avg Acc@5: 0.9360
2022-01-23 15:35:49,570 Val Step[0450/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7785, Avg Acc@5: 0.9358
2022-01-23 15:35:51,574 Val Step[0500/1563], Avg Loss: 1.0461, Avg Acc@1: 0.7781, Avg Acc@5: 0.9362
2022-01-23 15:35:53,554 Val Step[0550/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7775, Avg Acc@5: 0.9364
2022-01-23 15:35:55,631 Val Step[0600/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7770, Avg Acc@5: 0.9364
2022-01-23 15:35:57,580 Val Step[0650/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7770, Avg Acc@5: 0.9366
2022-01-23 15:35:59,435 Val Step[0700/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7774, Avg Acc@5: 0.9371
2022-01-23 15:36:01,323 Val Step[0750/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7753, Avg Acc@5: 0.9368
2022-01-23 15:36:03,200 Val Step[0800/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7758, Avg Acc@5: 0.9368
2022-01-23 15:36:05,081 Val Step[0850/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7754, Avg Acc@5: 0.9364
2022-01-23 15:36:07,032 Val Step[0900/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7761, Avg Acc@5: 0.9367
2022-01-23 15:36:08,916 Val Step[0950/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7766, Avg Acc@5: 0.9370
2022-01-23 15:36:10,766 Val Step[1000/1563], Avg Loss: 1.0473, Avg Acc@1: 0.7764, Avg Acc@5: 0.9366
2022-01-23 15:36:12,675 Val Step[1050/1563], Avg Loss: 1.0492, Avg Acc@1: 0.7757, Avg Acc@5: 0.9364
2022-01-23 15:36:14,668 Val Step[1100/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7754, Avg Acc@5: 0.9366
2022-01-23 15:36:16,530 Val Step[1150/1563], Avg Loss: 1.0469, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-23 15:36:18,415 Val Step[1200/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7765, Avg Acc@5: 0.9368
2022-01-23 15:36:20,262 Val Step[1250/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7762, Avg Acc@5: 0.9372
2022-01-23 15:36:22,069 Val Step[1300/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7760, Avg Acc@5: 0.9369
2022-01-23 15:36:23,889 Val Step[1350/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7754, Avg Acc@5: 0.9368
2022-01-23 15:36:25,710 Val Step[1400/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7751, Avg Acc@5: 0.9368
2022-01-23 15:36:27,589 Val Step[1450/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7757, Avg Acc@5: 0.9369
2022-01-23 15:36:29,487 Val Step[1500/1563], Avg Loss: 1.0481, Avg Acc@1: 0.7758, Avg Acc@5: 0.9371
2022-01-23 15:36:31,259 Val Step[1550/1563], Avg Loss: 1.0486, Avg Acc@1: 0.7755, Avg Acc@5: 0.9371
2022-01-23 15:36:33,201 ----- Epoch[002/050], Validation Loss: 1.0484, Validation Acc@1: 0.7755, Validation Acc@5: 0.9372, time: 135.01
2022-01-23 15:36:33,784 the pre best model acc:0.0000, at epoch 0
2022-01-23 15:36:33,784 current best model acc:0.7755, at epoch 2
2022-01-23 15:36:33,784 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 15:36:33,785 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 15:36:33,785 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 15:36:33,785 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 15:36:33,785 Now training epoch 3. LR=0.000010
2022-01-23 15:38:18,882 Epoch[003/050], Step[0000/1252], Avg Loss: 2.6093, Avg Acc: 0.6338
2022-01-23 15:39:46,265 Epoch[003/050], Step[0050/1252], Avg Loss: 2.8587, Avg Acc: 0.5152
2022-01-23 15:41:13,244 Epoch[003/050], Step[0100/1252], Avg Loss: 2.8716, Avg Acc: 0.5155
2022-01-23 15:42:39,773 Epoch[003/050], Step[0150/1252], Avg Loss: 2.8777, Avg Acc: 0.4986
2022-01-23 15:44:06,246 Epoch[003/050], Step[0200/1252], Avg Loss: 2.8879, Avg Acc: 0.4977
2022-01-23 15:45:34,099 Epoch[003/050], Step[0250/1252], Avg Loss: 2.8901, Avg Acc: 0.4987
2022-01-23 15:47:01,405 Epoch[003/050], Step[0300/1252], Avg Loss: 2.8835, Avg Acc: 0.4987
2022-01-23 15:48:27,770 Epoch[003/050], Step[0350/1252], Avg Loss: 2.8876, Avg Acc: 0.4976
2022-01-23 15:49:53,103 Epoch[003/050], Step[0400/1252], Avg Loss: 2.8874, Avg Acc: 0.4973
2022-01-23 15:51:19,885 Epoch[003/050], Step[0450/1252], Avg Loss: 2.8839, Avg Acc: 0.4943
2022-01-23 15:52:46,236 Epoch[003/050], Step[0500/1252], Avg Loss: 2.8834, Avg Acc: 0.4909
2022-01-23 15:54:12,758 Epoch[003/050], Step[0550/1252], Avg Loss: 2.8901, Avg Acc: 0.4898
2022-01-23 15:55:39,075 Epoch[003/050], Step[0600/1252], Avg Loss: 2.8897, Avg Acc: 0.4909
2022-01-23 15:57:05,404 Epoch[003/050], Step[0650/1252], Avg Loss: 2.8897, Avg Acc: 0.4908
2022-01-23 15:58:31,152 Epoch[003/050], Step[0700/1252], Avg Loss: 2.8911, Avg Acc: 0.4878
2022-01-23 15:59:57,736 Epoch[003/050], Step[0750/1252], Avg Loss: 2.8949, Avg Acc: 0.4859
2022-01-23 16:01:23,894 Epoch[003/050], Step[0800/1252], Avg Loss: 2.8974, Avg Acc: 0.4873
2022-01-23 16:02:49,377 Epoch[003/050], Step[0850/1252], Avg Loss: 2.8971, Avg Acc: 0.4866
2022-01-23 16:04:16,530 Epoch[003/050], Step[0900/1252], Avg Loss: 2.8985, Avg Acc: 0.4835
2022-01-23 16:05:43,528 Epoch[003/050], Step[0950/1252], Avg Loss: 2.8957, Avg Acc: 0.4837
2022-01-23 16:07:11,078 Epoch[003/050], Step[1000/1252], Avg Loss: 2.8955, Avg Acc: 0.4843
2022-01-23 16:08:39,302 Epoch[003/050], Step[1050/1252], Avg Loss: 2.8951, Avg Acc: 0.4832
2022-01-23 16:10:07,112 Epoch[003/050], Step[1100/1252], Avg Loss: 2.8952, Avg Acc: 0.4828
2022-01-23 16:11:34,150 Epoch[003/050], Step[1150/1252], Avg Loss: 2.8976, Avg Acc: 0.4828
2022-01-23 16:13:01,287 Epoch[003/050], Step[1200/1252], Avg Loss: 2.8955, Avg Acc: 0.4830
2022-01-23 16:14:29,650 Epoch[003/050], Step[1250/1252], Avg Loss: 2.8988, Avg Acc: 0.4811
2022-01-23 16:14:36,847 ----- Epoch[003/050], Train Loss: 2.8989, Train Acc: 0.4812, time: 2283.06, Best Val(epoch2) Acc@1: 0.7755
2022-01-23 16:14:36,848 Now training epoch 4. LR=0.000010
2022-01-23 16:16:24,799 Epoch[004/050], Step[0000/1252], Avg Loss: 2.2547, Avg Acc: 0.6211
2022-01-23 16:17:51,686 Epoch[004/050], Step[0050/1252], Avg Loss: 2.9053, Avg Acc: 0.4939
2022-01-23 16:19:18,329 Epoch[004/050], Step[0100/1252], Avg Loss: 2.9122, Avg Acc: 0.4899
2022-01-23 16:20:44,992 Epoch[004/050], Step[0150/1252], Avg Loss: 2.8948, Avg Acc: 0.5048
2022-01-23 16:22:11,974 Epoch[004/050], Step[0200/1252], Avg Loss: 2.8991, Avg Acc: 0.4929
2022-01-23 16:23:39,105 Epoch[004/050], Step[0250/1252], Avg Loss: 2.8906, Avg Acc: 0.4844
2022-01-23 16:25:06,678 Epoch[004/050], Step[0300/1252], Avg Loss: 2.8978, Avg Acc: 0.4885
2022-01-23 16:26:34,126 Epoch[004/050], Step[0350/1252], Avg Loss: 2.8901, Avg Acc: 0.4902
2022-01-23 16:28:01,509 Epoch[004/050], Step[0400/1252], Avg Loss: 2.8884, Avg Acc: 0.4903
2022-01-23 16:29:28,860 Epoch[004/050], Step[0450/1252], Avg Loss: 2.8908, Avg Acc: 0.4888
2022-01-23 16:30:56,052 Epoch[004/050], Step[0500/1252], Avg Loss: 2.8957, Avg Acc: 0.4883
2022-01-23 16:32:23,410 Epoch[004/050], Step[0550/1252], Avg Loss: 2.8923, Avg Acc: 0.4897
2022-01-23 16:33:51,562 Epoch[004/050], Step[0600/1252], Avg Loss: 2.8937, Avg Acc: 0.4893
2022-01-23 16:35:18,046 Epoch[004/050], Step[0650/1252], Avg Loss: 2.8948, Avg Acc: 0.4880
2022-01-23 16:36:46,327 Epoch[004/050], Step[0700/1252], Avg Loss: 2.8983, Avg Acc: 0.4862
2022-01-23 16:38:13,959 Epoch[004/050], Step[0750/1252], Avg Loss: 2.9001, Avg Acc: 0.4847
2022-01-23 16:39:42,071 Epoch[004/050], Step[0800/1252], Avg Loss: 2.9037, Avg Acc: 0.4818
2022-01-23 16:41:09,511 Epoch[004/050], Step[0850/1252], Avg Loss: 2.9077, Avg Acc: 0.4801
2022-01-23 16:42:37,627 Epoch[004/050], Step[0900/1252], Avg Loss: 2.9090, Avg Acc: 0.4806
2022-01-23 16:44:05,267 Epoch[004/050], Step[0950/1252], Avg Loss: 2.9106, Avg Acc: 0.4804
2022-01-23 16:45:31,156 Epoch[004/050], Step[1000/1252], Avg Loss: 2.9080, Avg Acc: 0.4805
2022-01-23 16:46:57,667 Epoch[004/050], Step[1050/1252], Avg Loss: 2.9080, Avg Acc: 0.4818
2022-01-23 16:48:24,597 Epoch[004/050], Step[1100/1252], Avg Loss: 2.9070, Avg Acc: 0.4822
2022-01-23 16:49:49,334 Epoch[004/050], Step[1150/1252], Avg Loss: 2.9042, Avg Acc: 0.4832
2022-01-23 16:51:15,716 Epoch[004/050], Step[1200/1252], Avg Loss: 2.9048, Avg Acc: 0.4840
2022-01-23 16:52:43,562 Epoch[004/050], Step[1250/1252], Avg Loss: 2.9059, Avg Acc: 0.4830
2022-01-23 16:52:50,717 ----- Epoch[004/050], Train Loss: 2.9059, Train Acc: 0.4830, time: 2293.87, Best Val(epoch2) Acc@1: 0.7755
2022-01-23 16:52:50,717 ----- Validation after Epoch: 4
2022-01-23 16:54:01,363 Val Step[0000/1563], Avg Loss: 0.8253, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-23 16:54:03,158 Val Step[0050/1563], Avg Loss: 1.0095, Avg Acc@1: 0.7831, Avg Acc@5: 0.9393
2022-01-23 16:54:04,920 Val Step[0100/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7816, Avg Acc@5: 0.9381
2022-01-23 16:54:06,762 Val Step[0150/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7821, Avg Acc@5: 0.9367
2022-01-23 16:54:08,584 Val Step[0200/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7828, Avg Acc@5: 0.9364
2022-01-23 16:54:10,358 Val Step[0250/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7819, Avg Acc@5: 0.9381
2022-01-23 16:54:12,129 Val Step[0300/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7818, Avg Acc@5: 0.9373
2022-01-23 16:54:13,922 Val Step[0350/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7811, Avg Acc@5: 0.9369
2022-01-23 16:54:15,723 Val Step[0400/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7814, Avg Acc@5: 0.9366
2022-01-23 16:54:17,628 Val Step[0450/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7792, Avg Acc@5: 0.9362
2022-01-23 16:54:19,478 Val Step[0500/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7786, Avg Acc@5: 0.9364
2022-01-23 16:54:21,483 Val Step[0550/1563], Avg Loss: 1.0481, Avg Acc@1: 0.7777, Avg Acc@5: 0.9365
2022-01-23 16:54:23,436 Val Step[0600/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7769, Avg Acc@5: 0.9367
2022-01-23 16:54:25,319 Val Step[0650/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7770, Avg Acc@5: 0.9369
2022-01-23 16:54:27,205 Val Step[0700/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7773, Avg Acc@5: 0.9374
2022-01-23 16:54:29,048 Val Step[0750/1563], Avg Loss: 1.0504, Avg Acc@1: 0.7750, Avg Acc@5: 0.9372
2022-01-23 16:54:31,070 Val Step[0800/1563], Avg Loss: 1.0505, Avg Acc@1: 0.7753, Avg Acc@5: 0.9371
2022-01-23 16:54:33,118 Val Step[0850/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7751, Avg Acc@5: 0.9368
2022-01-23 16:54:35,151 Val Step[0900/1563], Avg Loss: 1.0492, Avg Acc@1: 0.7759, Avg Acc@5: 0.9372
2022-01-23 16:54:37,184 Val Step[0950/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7766, Avg Acc@5: 0.9373
2022-01-23 16:54:39,238 Val Step[1000/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7764, Avg Acc@5: 0.9367
2022-01-23 16:54:41,294 Val Step[1050/1563], Avg Loss: 1.0517, Avg Acc@1: 0.7759, Avg Acc@5: 0.9365
2022-01-23 16:54:43,320 Val Step[1100/1563], Avg Loss: 1.0519, Avg Acc@1: 0.7754, Avg Acc@5: 0.9367
2022-01-23 16:54:45,364 Val Step[1150/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7757, Avg Acc@5: 0.9370
2022-01-23 16:54:47,414 Val Step[1200/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7765, Avg Acc@5: 0.9371
2022-01-23 16:54:49,505 Val Step[1250/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-23 16:54:51,544 Val Step[1300/1563], Avg Loss: 1.0507, Avg Acc@1: 0.7759, Avg Acc@5: 0.9370
2022-01-23 16:54:53,590 Val Step[1350/1563], Avg Loss: 1.0522, Avg Acc@1: 0.7754, Avg Acc@5: 0.9368
2022-01-23 16:54:55,626 Val Step[1400/1563], Avg Loss: 1.0519, Avg Acc@1: 0.7750, Avg Acc@5: 0.9368
2022-01-23 16:54:57,657 Val Step[1450/1563], Avg Loss: 1.0508, Avg Acc@1: 0.7755, Avg Acc@5: 0.9369
2022-01-23 16:54:59,717 Val Step[1500/1563], Avg Loss: 1.0509, Avg Acc@1: 0.7758, Avg Acc@5: 0.9371
2022-01-23 16:55:01,718 Val Step[1550/1563], Avg Loss: 1.0514, Avg Acc@1: 0.7756, Avg Acc@5: 0.9370
2022-01-23 16:55:05,340 ----- Epoch[004/050], Validation Loss: 1.0513, Validation Acc@1: 0.7756, Validation Acc@5: 0.9371, time: 134.62
2022-01-23 16:55:06,664 the pre best model acc:0.7755, at epoch 2
2022-01-23 16:55:06,664 current best model acc:0.7756, at epoch 4
2022-01-23 16:55:06,664 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 16:55:06,664 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 16:55:06,664 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 16:55:06,664 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 16:55:06,665 Now training epoch 5. LR=0.000010
2022-01-23 16:56:47,671 Epoch[005/050], Step[0000/1252], Avg Loss: 2.4058, Avg Acc: 0.7529
2022-01-23 16:58:14,485 Epoch[005/050], Step[0050/1252], Avg Loss: 2.9161, Avg Acc: 0.4594
2022-01-23 16:59:39,744 Epoch[005/050], Step[0100/1252], Avg Loss: 2.9058, Avg Acc: 0.5016
2022-01-23 17:01:07,130 Epoch[005/050], Step[0150/1252], Avg Loss: 2.8832, Avg Acc: 0.5071
2022-01-23 17:02:34,160 Epoch[005/050], Step[0200/1252], Avg Loss: 2.8832, Avg Acc: 0.4968
2022-01-23 17:04:01,203 Epoch[005/050], Step[0250/1252], Avg Loss: 2.8913, Avg Acc: 0.4955
2022-01-23 17:05:29,021 Epoch[005/050], Step[0300/1252], Avg Loss: 2.8939, Avg Acc: 0.4925
2022-01-23 17:06:56,337 Epoch[005/050], Step[0350/1252], Avg Loss: 2.8933, Avg Acc: 0.4896
2022-01-23 17:08:23,724 Epoch[005/050], Step[0400/1252], Avg Loss: 2.8979, Avg Acc: 0.4928
2022-01-23 17:09:51,597 Epoch[005/050], Step[0450/1252], Avg Loss: 2.9010, Avg Acc: 0.4911
2022-01-23 17:11:17,927 Epoch[005/050], Step[0500/1252], Avg Loss: 2.8967, Avg Acc: 0.4915
2022-01-23 17:12:44,010 Epoch[005/050], Step[0550/1252], Avg Loss: 2.8934, Avg Acc: 0.4903
2022-01-23 17:14:12,017 Epoch[005/050], Step[0600/1252], Avg Loss: 2.8966, Avg Acc: 0.4880
2022-01-23 17:15:38,238 Epoch[005/050], Step[0650/1252], Avg Loss: 2.8961, Avg Acc: 0.4843
2022-01-23 17:17:05,995 Epoch[005/050], Step[0700/1252], Avg Loss: 2.8971, Avg Acc: 0.4836
2022-01-23 17:18:32,948 Epoch[005/050], Step[0750/1252], Avg Loss: 2.8957, Avg Acc: 0.4841
2022-01-23 17:20:00,344 Epoch[005/050], Step[0800/1252], Avg Loss: 2.8933, Avg Acc: 0.4845
2022-01-23 17:21:28,206 Epoch[005/050], Step[0850/1252], Avg Loss: 2.8939, Avg Acc: 0.4847
2022-01-23 17:22:55,241 Epoch[005/050], Step[0900/1252], Avg Loss: 2.8964, Avg Acc: 0.4844
2022-01-23 17:24:22,737 Epoch[005/050], Step[0950/1252], Avg Loss: 2.8963, Avg Acc: 0.4853
2022-01-23 17:25:49,924 Epoch[005/050], Step[1000/1252], Avg Loss: 2.8990, Avg Acc: 0.4844
2022-01-23 17:27:17,233 Epoch[005/050], Step[1050/1252], Avg Loss: 2.8954, Avg Acc: 0.4853
2022-01-23 17:28:45,007 Epoch[005/050], Step[1100/1252], Avg Loss: 2.8959, Avg Acc: 0.4858
2022-01-23 17:30:12,421 Epoch[005/050], Step[1150/1252], Avg Loss: 2.8954, Avg Acc: 0.4859
2022-01-23 17:31:40,326 Epoch[005/050], Step[1200/1252], Avg Loss: 2.8950, Avg Acc: 0.4856
2022-01-23 17:33:09,296 Epoch[005/050], Step[1250/1252], Avg Loss: 2.8976, Avg Acc: 0.4845
2022-01-23 17:33:16,372 ----- Epoch[005/050], Train Loss: 2.8976, Train Acc: 0.4845, time: 2289.70, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 17:33:16,372 Now training epoch 6. LR=0.000010
2022-01-23 17:34:59,397 Epoch[006/050], Step[0000/1252], Avg Loss: 3.2257, Avg Acc: 0.1768
2022-01-23 17:36:27,141 Epoch[006/050], Step[0050/1252], Avg Loss: 2.9764, Avg Acc: 0.4700
2022-01-23 17:37:54,749 Epoch[006/050], Step[0100/1252], Avg Loss: 2.9425, Avg Acc: 0.4810
2022-01-23 17:39:22,901 Epoch[006/050], Step[0150/1252], Avg Loss: 2.9497, Avg Acc: 0.4816
2022-01-23 17:40:50,181 Epoch[006/050], Step[0200/1252], Avg Loss: 2.9424, Avg Acc: 0.4712
2022-01-23 17:42:18,379 Epoch[006/050], Step[0250/1252], Avg Loss: 2.9312, Avg Acc: 0.4738
2022-01-23 17:43:46,256 Epoch[006/050], Step[0300/1252], Avg Loss: 2.9388, Avg Acc: 0.4748
2022-01-23 17:45:13,576 Epoch[006/050], Step[0350/1252], Avg Loss: 2.9329, Avg Acc: 0.4749
2022-01-23 17:46:40,230 Epoch[006/050], Step[0400/1252], Avg Loss: 2.9293, Avg Acc: 0.4769
2022-01-23 17:48:07,697 Epoch[006/050], Step[0450/1252], Avg Loss: 2.9194, Avg Acc: 0.4828
2022-01-23 17:49:36,088 Epoch[006/050], Step[0500/1252], Avg Loss: 2.9175, Avg Acc: 0.4813
2022-01-23 17:51:03,642 Epoch[006/050], Step[0550/1252], Avg Loss: 2.9163, Avg Acc: 0.4807
2022-01-23 17:52:31,066 Epoch[006/050], Step[0600/1252], Avg Loss: 2.9095, Avg Acc: 0.4794
2022-01-23 17:53:58,336 Epoch[006/050], Step[0650/1252], Avg Loss: 2.9085, Avg Acc: 0.4786
2022-01-23 17:55:26,258 Epoch[006/050], Step[0700/1252], Avg Loss: 2.9078, Avg Acc: 0.4798
2022-01-23 17:56:53,009 Epoch[006/050], Step[0750/1252], Avg Loss: 2.9051, Avg Acc: 0.4803
2022-01-23 17:58:17,613 Epoch[006/050], Step[0800/1252], Avg Loss: 2.9039, Avg Acc: 0.4826
2022-01-23 17:59:43,797 Epoch[006/050], Step[0850/1252], Avg Loss: 2.9037, Avg Acc: 0.4830
2022-01-23 18:01:11,283 Epoch[006/050], Step[0900/1252], Avg Loss: 2.9048, Avg Acc: 0.4832
2022-01-23 18:02:38,866 Epoch[006/050], Step[0950/1252], Avg Loss: 2.9014, Avg Acc: 0.4826
2022-01-23 18:04:06,387 Epoch[006/050], Step[1000/1252], Avg Loss: 2.9011, Avg Acc: 0.4817
2022-01-23 18:05:34,327 Epoch[006/050], Step[1050/1252], Avg Loss: 2.9014, Avg Acc: 0.4794
2022-01-23 18:07:01,683 Epoch[006/050], Step[1100/1252], Avg Loss: 2.8999, Avg Acc: 0.4797
2022-01-23 18:08:28,136 Epoch[006/050], Step[1150/1252], Avg Loss: 2.8989, Avg Acc: 0.4796
2022-01-23 18:09:55,961 Epoch[006/050], Step[1200/1252], Avg Loss: 2.8987, Avg Acc: 0.4803
2022-01-23 18:11:23,990 Epoch[006/050], Step[1250/1252], Avg Loss: 2.9016, Avg Acc: 0.4819
2022-01-23 18:11:31,220 ----- Epoch[006/050], Train Loss: 2.9016, Train Acc: 0.4819, time: 2294.84, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 18:11:31,220 ----- Validation after Epoch: 6
2022-01-23 18:12:37,182 Val Step[0000/1563], Avg Loss: 0.8375, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-23 18:12:39,104 Val Step[0050/1563], Avg Loss: 1.0126, Avg Acc@1: 0.7825, Avg Acc@5: 0.9418
2022-01-23 18:12:41,003 Val Step[0100/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7819, Avg Acc@5: 0.9390
2022-01-23 18:12:42,955 Val Step[0150/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7798, Avg Acc@5: 0.9371
2022-01-23 18:12:44,803 Val Step[0200/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7802, Avg Acc@5: 0.9372
2022-01-23 18:12:46,677 Val Step[0250/1563], Avg Loss: 1.0379, Avg Acc@1: 0.7803, Avg Acc@5: 0.9391
2022-01-23 18:12:48,562 Val Step[0300/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7807, Avg Acc@5: 0.9376
2022-01-23 18:12:50,364 Val Step[0350/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7811, Avg Acc@5: 0.9373
2022-01-23 18:12:52,253 Val Step[0400/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7815, Avg Acc@5: 0.9370
2022-01-23 18:12:54,144 Val Step[0450/1563], Avg Loss: 1.0463, Avg Acc@1: 0.7792, Avg Acc@5: 0.9367
2022-01-23 18:12:56,016 Val Step[0500/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7788, Avg Acc@5: 0.9370
2022-01-23 18:12:57,821 Val Step[0550/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7778, Avg Acc@5: 0.9371
2022-01-23 18:12:59,622 Val Step[0600/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7772, Avg Acc@5: 0.9372
2022-01-23 18:13:01,395 Val Step[0650/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7771, Avg Acc@5: 0.9374
2022-01-23 18:13:03,296 Val Step[0700/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7776, Avg Acc@5: 0.9378
2022-01-23 18:13:05,075 Val Step[0750/1563], Avg Loss: 1.0512, Avg Acc@1: 0.7753, Avg Acc@5: 0.9374
2022-01-23 18:13:06,959 Val Step[0800/1563], Avg Loss: 1.0509, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-23 18:13:08,852 Val Step[0850/1563], Avg Loss: 1.0525, Avg Acc@1: 0.7756, Avg Acc@5: 0.9371
2022-01-23 18:13:10,737 Val Step[0900/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7762, Avg Acc@5: 0.9374
2022-01-23 18:13:12,633 Val Step[0950/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7767, Avg Acc@5: 0.9375
2022-01-23 18:13:14,509 Val Step[1000/1563], Avg Loss: 1.0515, Avg Acc@1: 0.7764, Avg Acc@5: 0.9370
2022-01-23 18:13:16,318 Val Step[1050/1563], Avg Loss: 1.0534, Avg Acc@1: 0.7758, Avg Acc@5: 0.9367
2022-01-23 18:13:18,119 Val Step[1100/1563], Avg Loss: 1.0535, Avg Acc@1: 0.7751, Avg Acc@5: 0.9369
2022-01-23 18:13:19,988 Val Step[1150/1563], Avg Loss: 1.0513, Avg Acc@1: 0.7756, Avg Acc@5: 0.9372
2022-01-23 18:13:21,884 Val Step[1200/1563], Avg Loss: 1.0502, Avg Acc@1: 0.7762, Avg Acc@5: 0.9373
2022-01-23 18:13:23,796 Val Step[1250/1563], Avg Loss: 1.0497, Avg Acc@1: 0.7758, Avg Acc@5: 0.9376
2022-01-23 18:13:25,683 Val Step[1300/1563], Avg Loss: 1.0524, Avg Acc@1: 0.7757, Avg Acc@5: 0.9372
2022-01-23 18:13:27,573 Val Step[1350/1563], Avg Loss: 1.0538, Avg Acc@1: 0.7750, Avg Acc@5: 0.9371
2022-01-23 18:13:29,492 Val Step[1400/1563], Avg Loss: 1.0537, Avg Acc@1: 0.7747, Avg Acc@5: 0.9369
2022-01-23 18:13:31,368 Val Step[1450/1563], Avg Loss: 1.0524, Avg Acc@1: 0.7753, Avg Acc@5: 0.9370
2022-01-23 18:13:33,166 Val Step[1500/1563], Avg Loss: 1.0523, Avg Acc@1: 0.7756, Avg Acc@5: 0.9373
2022-01-23 18:13:35,055 Val Step[1550/1563], Avg Loss: 1.0528, Avg Acc@1: 0.7754, Avg Acc@5: 0.9372
2022-01-23 18:13:37,026 ----- Epoch[006/050], Validation Loss: 1.0526, Validation Acc@1: 0.7754, Validation Acc@5: 0.9373, time: 125.80
2022-01-23 18:13:37,026 Now training epoch 7. LR=0.000010
2022-01-23 18:15:18,312 Epoch[007/050], Step[0000/1252], Avg Loss: 2.4395, Avg Acc: 0.3848
2022-01-23 18:16:44,055 Epoch[007/050], Step[0050/1252], Avg Loss: 2.9145, Avg Acc: 0.4835
2022-01-23 18:18:09,145 Epoch[007/050], Step[0100/1252], Avg Loss: 2.9004, Avg Acc: 0.4808
2022-01-23 18:19:33,949 Epoch[007/050], Step[0150/1252], Avg Loss: 2.8923, Avg Acc: 0.4777
2022-01-23 18:20:59,321 Epoch[007/050], Step[0200/1252], Avg Loss: 2.8871, Avg Acc: 0.4854
2022-01-23 18:22:24,918 Epoch[007/050], Step[0250/1252], Avg Loss: 2.8867, Avg Acc: 0.4865
2022-01-23 18:23:52,530 Epoch[007/050], Step[0300/1252], Avg Loss: 2.8865, Avg Acc: 0.4838
2022-01-23 18:25:19,841 Epoch[007/050], Step[0350/1252], Avg Loss: 2.8857, Avg Acc: 0.4840
2022-01-23 18:26:46,323 Epoch[007/050], Step[0400/1252], Avg Loss: 2.8974, Avg Acc: 0.4833
2022-01-23 18:28:13,431 Epoch[007/050], Step[0450/1252], Avg Loss: 2.8968, Avg Acc: 0.4841
2022-01-23 18:29:40,384 Epoch[007/050], Step[0500/1252], Avg Loss: 2.8939, Avg Acc: 0.4860
2022-01-23 18:31:05,895 Epoch[007/050], Step[0550/1252], Avg Loss: 2.8931, Avg Acc: 0.4852
2022-01-23 18:32:33,022 Epoch[007/050], Step[0600/1252], Avg Loss: 2.8934, Avg Acc: 0.4870
2022-01-23 18:34:00,502 Epoch[007/050], Step[0650/1252], Avg Loss: 2.8902, Avg Acc: 0.4891
2022-01-23 18:35:27,725 Epoch[007/050], Step[0700/1252], Avg Loss: 2.8910, Avg Acc: 0.4882
2022-01-23 18:36:54,953 Epoch[007/050], Step[0750/1252], Avg Loss: 2.8923, Avg Acc: 0.4882
2022-01-23 18:38:22,633 Epoch[007/050], Step[0800/1252], Avg Loss: 2.8949, Avg Acc: 0.4878
2022-01-23 18:39:50,664 Epoch[007/050], Step[0850/1252], Avg Loss: 2.8969, Avg Acc: 0.4880
2022-01-23 18:41:17,021 Epoch[007/050], Step[0900/1252], Avg Loss: 2.8955, Avg Acc: 0.4871
2022-01-23 18:42:45,529 Epoch[007/050], Step[0950/1252], Avg Loss: 2.8946, Avg Acc: 0.4869
2022-01-23 18:44:11,401 Epoch[007/050], Step[1000/1252], Avg Loss: 2.8949, Avg Acc: 0.4882
2022-01-23 18:45:38,673 Epoch[007/050], Step[1050/1252], Avg Loss: 2.8954, Avg Acc: 0.4884
2022-01-23 18:47:04,752 Epoch[007/050], Step[1100/1252], Avg Loss: 2.8977, Avg Acc: 0.4877
2022-01-23 18:48:32,472 Epoch[007/050], Step[1150/1252], Avg Loss: 2.9003, Avg Acc: 0.4870
2022-01-23 18:49:59,018 Epoch[007/050], Step[1200/1252], Avg Loss: 2.8985, Avg Acc: 0.4878
2022-01-23 18:51:27,135 Epoch[007/050], Step[1250/1252], Avg Loss: 2.8986, Avg Acc: 0.4880
2022-01-23 18:51:34,272 ----- Epoch[007/050], Train Loss: 2.8986, Train Acc: 0.4880, time: 2277.24, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 18:51:34,273 Now training epoch 8. LR=0.000010
2022-01-23 18:53:14,707 Epoch[008/050], Step[0000/1252], Avg Loss: 2.6366, Avg Acc: 0.4023
2022-01-23 18:54:40,603 Epoch[008/050], Step[0050/1252], Avg Loss: 2.8749, Avg Acc: 0.5374
2022-01-23 18:56:08,425 Epoch[008/050], Step[0100/1252], Avg Loss: 2.9130, Avg Acc: 0.4946
2022-01-23 18:57:35,526 Epoch[008/050], Step[0150/1252], Avg Loss: 2.9003, Avg Acc: 0.4851
2022-01-23 18:59:02,751 Epoch[008/050], Step[0200/1252], Avg Loss: 2.8916, Avg Acc: 0.4833
2022-01-23 19:00:30,176 Epoch[008/050], Step[0250/1252], Avg Loss: 2.8854, Avg Acc: 0.4845
2022-01-23 19:01:57,808 Epoch[008/050], Step[0300/1252], Avg Loss: 2.8812, Avg Acc: 0.4879
2022-01-23 19:03:25,518 Epoch[008/050], Step[0350/1252], Avg Loss: 2.8804, Avg Acc: 0.4884
2022-01-23 19:04:53,458 Epoch[008/050], Step[0400/1252], Avg Loss: 2.8855, Avg Acc: 0.4908
2022-01-23 19:06:21,071 Epoch[008/050], Step[0450/1252], Avg Loss: 2.8827, Avg Acc: 0.4946
2022-01-23 19:07:48,257 Epoch[008/050], Step[0500/1252], Avg Loss: 2.8805, Avg Acc: 0.4952
2022-01-23 19:09:15,699 Epoch[008/050], Step[0550/1252], Avg Loss: 2.8810, Avg Acc: 0.4898
2022-01-23 19:10:42,379 Epoch[008/050], Step[0600/1252], Avg Loss: 2.8830, Avg Acc: 0.4934
2022-01-23 19:12:10,194 Epoch[008/050], Step[0650/1252], Avg Loss: 2.8877, Avg Acc: 0.4941
2022-01-23 19:13:38,263 Epoch[008/050], Step[0700/1252], Avg Loss: 2.8901, Avg Acc: 0.4938
2022-01-23 19:15:05,843 Epoch[008/050], Step[0750/1252], Avg Loss: 2.8905, Avg Acc: 0.4939
2022-01-23 19:16:32,933 Epoch[008/050], Step[0800/1252], Avg Loss: 2.8872, Avg Acc: 0.4945
2022-01-23 19:18:00,416 Epoch[008/050], Step[0850/1252], Avg Loss: 2.8878, Avg Acc: 0.4946
2022-01-23 19:19:27,554 Epoch[008/050], Step[0900/1252], Avg Loss: 2.8877, Avg Acc: 0.4936
2022-01-23 19:20:56,146 Epoch[008/050], Step[0950/1252], Avg Loss: 2.8902, Avg Acc: 0.4917
2022-01-23 19:22:22,858 Epoch[008/050], Step[1000/1252], Avg Loss: 2.8926, Avg Acc: 0.4906
2022-01-23 19:23:50,652 Epoch[008/050], Step[1050/1252], Avg Loss: 2.8932, Avg Acc: 0.4890
2022-01-23 19:25:18,136 Epoch[008/050], Step[1100/1252], Avg Loss: 2.8922, Avg Acc: 0.4909
2022-01-23 19:26:45,600 Epoch[008/050], Step[1150/1252], Avg Loss: 2.8918, Avg Acc: 0.4904
2022-01-23 19:28:13,601 Epoch[008/050], Step[1200/1252], Avg Loss: 2.8899, Avg Acc: 0.4896
2022-01-23 19:29:41,769 Epoch[008/050], Step[1250/1252], Avg Loss: 2.8871, Avg Acc: 0.4910
2022-01-23 19:29:48,958 ----- Epoch[008/050], Train Loss: 2.8871, Train Acc: 0.4910, time: 2294.68, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 19:29:48,958 ----- Validation after Epoch: 8
2022-01-23 19:30:59,644 Val Step[0000/1563], Avg Loss: 0.8424, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 19:31:01,469 Val Step[0050/1563], Avg Loss: 1.0107, Avg Acc@1: 0.7757, Avg Acc@5: 0.9406
2022-01-23 19:31:03,652 Val Step[0100/1563], Avg Loss: 1.0395, Avg Acc@1: 0.7794, Avg Acc@5: 0.9378
2022-01-23 19:31:05,795 Val Step[0150/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7794, Avg Acc@5: 0.9365
2022-01-23 19:31:07,828 Val Step[0200/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7802, Avg Acc@5: 0.9372
2022-01-23 19:31:09,882 Val Step[0250/1563], Avg Loss: 1.0312, Avg Acc@1: 0.7800, Avg Acc@5: 0.9390
2022-01-23 19:31:11,965 Val Step[0300/1563], Avg Loss: 1.0320, Avg Acc@1: 0.7803, Avg Acc@5: 0.9374
2022-01-23 19:31:14,060 Val Step[0350/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7802, Avg Acc@5: 0.9374
2022-01-23 19:31:16,078 Val Step[0400/1563], Avg Loss: 1.0370, Avg Acc@1: 0.7807, Avg Acc@5: 0.9370
2022-01-23 19:31:18,209 Val Step[0450/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7782, Avg Acc@5: 0.9368
2022-01-23 19:31:20,271 Val Step[0500/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7776, Avg Acc@5: 0.9370
2022-01-23 19:31:22,301 Val Step[0550/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7768, Avg Acc@5: 0.9373
2022-01-23 19:31:24,322 Val Step[0600/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7762, Avg Acc@5: 0.9375
2022-01-23 19:31:26,370 Val Step[0650/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7760, Avg Acc@5: 0.9375
2022-01-23 19:31:28,475 Val Step[0700/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7763, Avg Acc@5: 0.9381
2022-01-23 19:31:30,486 Val Step[0750/1563], Avg Loss: 1.0481, Avg Acc@1: 0.7745, Avg Acc@5: 0.9375
2022-01-23 19:31:32,502 Val Step[0800/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7751, Avg Acc@5: 0.9372
2022-01-23 19:31:34,393 Val Step[0850/1563], Avg Loss: 1.0497, Avg Acc@1: 0.7749, Avg Acc@5: 0.9369
2022-01-23 19:31:36,251 Val Step[0900/1563], Avg Loss: 1.0469, Avg Acc@1: 0.7755, Avg Acc@5: 0.9375
2022-01-23 19:31:38,124 Val Step[0950/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7762, Avg Acc@5: 0.9377
2022-01-23 19:31:40,146 Val Step[1000/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7758, Avg Acc@5: 0.9374
2022-01-23 19:31:42,167 Val Step[1050/1563], Avg Loss: 1.0500, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-23 19:31:44,183 Val Step[1100/1563], Avg Loss: 1.0502, Avg Acc@1: 0.7745, Avg Acc@5: 0.9371
2022-01-23 19:31:46,197 Val Step[1150/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7747, Avg Acc@5: 0.9373
2022-01-23 19:31:48,268 Val Step[1200/1563], Avg Loss: 1.0468, Avg Acc@1: 0.7755, Avg Acc@5: 0.9373
2022-01-23 19:31:50,372 Val Step[1250/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7749, Avg Acc@5: 0.9376
2022-01-23 19:31:52,386 Val Step[1300/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7748, Avg Acc@5: 0.9372
2022-01-23 19:31:54,409 Val Step[1350/1563], Avg Loss: 1.0503, Avg Acc@1: 0.7742, Avg Acc@5: 0.9372
2022-01-23 19:31:56,409 Val Step[1400/1563], Avg Loss: 1.0500, Avg Acc@1: 0.7739, Avg Acc@5: 0.9372
2022-01-23 19:31:58,407 Val Step[1450/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7744, Avg Acc@5: 0.9372
2022-01-23 19:32:00,398 Val Step[1500/1563], Avg Loss: 1.0490, Avg Acc@1: 0.7745, Avg Acc@5: 0.9374
2022-01-23 19:32:02,369 Val Step[1550/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7742, Avg Acc@5: 0.9373
2022-01-23 19:32:04,316 ----- Epoch[008/050], Validation Loss: 1.0491, Validation Acc@1: 0.7743, Validation Acc@5: 0.9374, time: 135.36
2022-01-23 19:32:04,316 Now training epoch 9. LR=0.000010
2022-01-23 19:33:51,024 Epoch[009/050], Step[0000/1252], Avg Loss: 3.1365, Avg Acc: 0.3340
2022-01-23 19:35:16,324 Epoch[009/050], Step[0050/1252], Avg Loss: 2.9399, Avg Acc: 0.4870
2022-01-23 19:36:42,183 Epoch[009/050], Step[0100/1252], Avg Loss: 2.9197, Avg Acc: 0.4919
2022-01-23 19:38:08,303 Epoch[009/050], Step[0150/1252], Avg Loss: 2.9031, Avg Acc: 0.4946
2022-01-23 19:39:31,546 Epoch[009/050], Step[0200/1252], Avg Loss: 2.9015, Avg Acc: 0.4890
2022-01-23 19:40:56,847 Epoch[009/050], Step[0250/1252], Avg Loss: 2.8961, Avg Acc: 0.4865
2022-01-23 19:42:21,986 Epoch[009/050], Step[0300/1252], Avg Loss: 2.8973, Avg Acc: 0.4898
2022-01-23 19:43:50,277 Epoch[009/050], Step[0350/1252], Avg Loss: 2.9037, Avg Acc: 0.4881
2022-01-23 19:45:18,165 Epoch[009/050], Step[0400/1252], Avg Loss: 2.9077, Avg Acc: 0.4857
2022-01-23 19:46:45,819 Epoch[009/050], Step[0450/1252], Avg Loss: 2.9020, Avg Acc: 0.4863
2022-01-23 19:48:12,067 Epoch[009/050], Step[0500/1252], Avg Loss: 2.8998, Avg Acc: 0.4847
2022-01-23 19:49:39,604 Epoch[009/050], Step[0550/1252], Avg Loss: 2.8968, Avg Acc: 0.4863
2022-01-23 19:51:06,343 Epoch[009/050], Step[0600/1252], Avg Loss: 2.8975, Avg Acc: 0.4888
2022-01-23 19:52:34,250 Epoch[009/050], Step[0650/1252], Avg Loss: 2.8987, Avg Acc: 0.4852
2022-01-23 19:54:01,817 Epoch[009/050], Step[0700/1252], Avg Loss: 2.9015, Avg Acc: 0.4838
2022-01-23 19:55:29,089 Epoch[009/050], Step[0750/1252], Avg Loss: 2.9019, Avg Acc: 0.4857
2022-01-23 19:56:55,583 Epoch[009/050], Step[0800/1252], Avg Loss: 2.9018, Avg Acc: 0.4885
2022-01-23 19:58:22,661 Epoch[009/050], Step[0850/1252], Avg Loss: 2.9033, Avg Acc: 0.4891
2022-01-23 19:59:49,773 Epoch[009/050], Step[0900/1252], Avg Loss: 2.9019, Avg Acc: 0.4910
2022-01-23 20:01:17,110 Epoch[009/050], Step[0950/1252], Avg Loss: 2.8999, Avg Acc: 0.4919
2022-01-23 20:02:44,770 Epoch[009/050], Step[1000/1252], Avg Loss: 2.9016, Avg Acc: 0.4906
2022-01-23 20:04:12,724 Epoch[009/050], Step[1050/1252], Avg Loss: 2.8997, Avg Acc: 0.4920
2022-01-23 20:05:40,660 Epoch[009/050], Step[1100/1252], Avg Loss: 2.8987, Avg Acc: 0.4919
2022-01-23 20:07:08,456 Epoch[009/050], Step[1150/1252], Avg Loss: 2.8980, Avg Acc: 0.4913
2022-01-23 20:08:34,615 Epoch[009/050], Step[1200/1252], Avg Loss: 2.8962, Avg Acc: 0.4909
2022-01-23 20:10:03,168 Epoch[009/050], Step[1250/1252], Avg Loss: 2.8943, Avg Acc: 0.4923
2022-01-23 20:10:10,162 ----- Epoch[009/050], Train Loss: 2.8943, Train Acc: 0.4923, time: 2285.84, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 20:10:10,163 Now training epoch 10. LR=0.000009
2022-01-23 20:12:04,949 Epoch[010/050], Step[0000/1252], Avg Loss: 3.1350, Avg Acc: 0.6523
2022-01-23 20:13:30,428 Epoch[010/050], Step[0050/1252], Avg Loss: 2.9587, Avg Acc: 0.4602
2022-01-23 20:14:56,315 Epoch[010/050], Step[0100/1252], Avg Loss: 2.9455, Avg Acc: 0.4772
2022-01-23 20:16:23,198 Epoch[010/050], Step[0150/1252], Avg Loss: 2.9314, Avg Acc: 0.4785
2022-01-23 20:17:50,330 Epoch[010/050], Step[0200/1252], Avg Loss: 2.9379, Avg Acc: 0.4703
2022-01-23 20:19:17,129 Epoch[010/050], Step[0250/1252], Avg Loss: 2.9316, Avg Acc: 0.4754
2022-01-23 20:20:44,951 Epoch[010/050], Step[0300/1252], Avg Loss: 2.9276, Avg Acc: 0.4733
2022-01-23 20:22:12,461 Epoch[010/050], Step[0350/1252], Avg Loss: 2.9253, Avg Acc: 0.4773
2022-01-23 20:23:39,868 Epoch[010/050], Step[0400/1252], Avg Loss: 2.9223, Avg Acc: 0.4775
2022-01-23 20:25:07,371 Epoch[010/050], Step[0450/1252], Avg Loss: 2.9211, Avg Acc: 0.4810
2022-01-23 20:26:33,253 Epoch[010/050], Step[0500/1252], Avg Loss: 2.9182, Avg Acc: 0.4842
2022-01-23 20:27:59,285 Epoch[010/050], Step[0550/1252], Avg Loss: 2.9176, Avg Acc: 0.4864
2022-01-23 20:29:26,520 Epoch[010/050], Step[0600/1252], Avg Loss: 2.9170, Avg Acc: 0.4864
2022-01-23 20:30:53,530 Epoch[010/050], Step[0650/1252], Avg Loss: 2.9208, Avg Acc: 0.4840
2022-01-23 20:32:21,050 Epoch[010/050], Step[0700/1252], Avg Loss: 2.9223, Avg Acc: 0.4838
2022-01-23 20:33:48,666 Epoch[010/050], Step[0750/1252], Avg Loss: 2.9167, Avg Acc: 0.4814
2022-01-23 20:35:15,080 Epoch[010/050], Step[0800/1252], Avg Loss: 2.9156, Avg Acc: 0.4837
2022-01-23 20:36:40,766 Epoch[010/050], Step[0850/1252], Avg Loss: 2.9126, Avg Acc: 0.4848
2022-01-23 20:38:08,160 Epoch[010/050], Step[0900/1252], Avg Loss: 2.9116, Avg Acc: 0.4864
2022-01-23 20:39:36,342 Epoch[010/050], Step[0950/1252], Avg Loss: 2.9108, Avg Acc: 0.4857
2022-01-23 20:41:04,375 Epoch[010/050], Step[1000/1252], Avg Loss: 2.9109, Avg Acc: 0.4830
2022-01-23 20:42:31,818 Epoch[010/050], Step[1050/1252], Avg Loss: 2.9108, Avg Acc: 0.4821
2022-01-23 20:43:59,087 Epoch[010/050], Step[1100/1252], Avg Loss: 2.9095, Avg Acc: 0.4822
2022-01-23 20:45:26,642 Epoch[010/050], Step[1150/1252], Avg Loss: 2.9082, Avg Acc: 0.4824
2022-01-23 20:46:53,075 Epoch[010/050], Step[1200/1252], Avg Loss: 2.9088, Avg Acc: 0.4835
2022-01-23 20:48:20,973 Epoch[010/050], Step[1250/1252], Avg Loss: 2.9096, Avg Acc: 0.4837
2022-01-23 20:48:28,046 ----- Epoch[010/050], Train Loss: 2.9096, Train Acc: 0.4837, time: 2297.88, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 20:48:28,046 ----- Validation after Epoch: 10
2022-01-23 20:49:44,073 Val Step[0000/1563], Avg Loss: 0.8297, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-23 20:49:46,147 Val Step[0050/1563], Avg Loss: 1.0036, Avg Acc@1: 0.7757, Avg Acc@5: 0.9412
2022-01-23 20:49:47,976 Val Step[0100/1563], Avg Loss: 1.0338, Avg Acc@1: 0.7785, Avg Acc@5: 0.9384
2022-01-23 20:49:49,821 Val Step[0150/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7798, Avg Acc@5: 0.9369
2022-01-23 20:49:51,727 Val Step[0200/1563], Avg Loss: 1.0362, Avg Acc@1: 0.7795, Avg Acc@5: 0.9378
2022-01-23 20:49:53,517 Val Step[0250/1563], Avg Loss: 1.0271, Avg Acc@1: 0.7793, Avg Acc@5: 0.9392
2022-01-23 20:49:55,387 Val Step[0300/1563], Avg Loss: 1.0275, Avg Acc@1: 0.7797, Avg Acc@5: 0.9377
2022-01-23 20:49:57,233 Val Step[0350/1563], Avg Loss: 1.0326, Avg Acc@1: 0.7789, Avg Acc@5: 0.9372
2022-01-23 20:49:59,057 Val Step[0400/1563], Avg Loss: 1.0318, Avg Acc@1: 0.7804, Avg Acc@5: 0.9370
2022-01-23 20:50:00,886 Val Step[0450/1563], Avg Loss: 1.0362, Avg Acc@1: 0.7781, Avg Acc@5: 0.9368
2022-01-23 20:50:02,742 Val Step[0500/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7774, Avg Acc@5: 0.9371
2022-01-23 20:50:04,564 Val Step[0550/1563], Avg Loss: 1.0383, Avg Acc@1: 0.7763, Avg Acc@5: 0.9370
2022-01-23 20:50:06,428 Val Step[0600/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7766, Avg Acc@5: 0.9371
2022-01-23 20:50:08,286 Val Step[0650/1563], Avg Loss: 1.0376, Avg Acc@1: 0.7763, Avg Acc@5: 0.9372
2022-01-23 20:50:10,207 Val Step[0700/1563], Avg Loss: 1.0354, Avg Acc@1: 0.7766, Avg Acc@5: 0.9377
2022-01-23 20:50:12,170 Val Step[0750/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7744, Avg Acc@5: 0.9373
2022-01-23 20:50:14,074 Val Step[0800/1563], Avg Loss: 1.0415, Avg Acc@1: 0.7753, Avg Acc@5: 0.9373
2022-01-23 20:50:15,921 Val Step[0850/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-23 20:50:17,789 Val Step[0900/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7755, Avg Acc@5: 0.9373
2022-01-23 20:50:19,823 Val Step[0950/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7762, Avg Acc@5: 0.9375
2022-01-23 20:50:21,859 Val Step[1000/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7758, Avg Acc@5: 0.9372
2022-01-23 20:50:23,957 Val Step[1050/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7753, Avg Acc@5: 0.9368
2022-01-23 20:50:25,911 Val Step[1100/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7748, Avg Acc@5: 0.9370
2022-01-23 20:50:27,833 Val Step[1150/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7751, Avg Acc@5: 0.9372
2022-01-23 20:50:29,766 Val Step[1200/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7757, Avg Acc@5: 0.9374
2022-01-23 20:50:31,814 Val Step[1250/1563], Avg Loss: 1.0400, Avg Acc@1: 0.7756, Avg Acc@5: 0.9377
2022-01-23 20:50:33,884 Val Step[1300/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7756, Avg Acc@5: 0.9372
2022-01-23 20:50:35,719 Val Step[1350/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7749, Avg Acc@5: 0.9372
2022-01-23 20:50:37,507 Val Step[1400/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7745, Avg Acc@5: 0.9372
2022-01-23 20:50:39,296 Val Step[1450/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7750, Avg Acc@5: 0.9374
2022-01-23 20:50:41,100 Val Step[1500/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7752, Avg Acc@5: 0.9376
2022-01-23 20:50:42,904 Val Step[1550/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7749, Avg Acc@5: 0.9374
2022-01-23 20:50:44,803 ----- Epoch[010/050], Validation Loss: 1.0427, Validation Acc@1: 0.7750, Validation Acc@5: 0.9375, time: 136.75
2022-01-23 20:50:44,803 Now training epoch 11. LR=0.000009
2022-01-23 20:52:29,711 Epoch[011/050], Step[0000/1252], Avg Loss: 3.0978, Avg Acc: 0.6104
2022-01-23 20:53:57,128 Epoch[011/050], Step[0050/1252], Avg Loss: 2.8971, Avg Acc: 0.4923
2022-01-23 20:55:23,998 Epoch[011/050], Step[0100/1252], Avg Loss: 2.9136, Avg Acc: 0.4730
2022-01-23 20:56:50,528 Epoch[011/050], Step[0150/1252], Avg Loss: 2.9182, Avg Acc: 0.4675
2022-01-23 20:58:17,188 Epoch[011/050], Step[0200/1252], Avg Loss: 2.9239, Avg Acc: 0.4756
2022-01-23 20:59:44,218 Epoch[011/050], Step[0250/1252], Avg Loss: 2.9139, Avg Acc: 0.4743
2022-01-23 21:01:10,466 Epoch[011/050], Step[0300/1252], Avg Loss: 2.9098, Avg Acc: 0.4740
2022-01-23 21:02:36,760 Epoch[011/050], Step[0350/1252], Avg Loss: 2.9017, Avg Acc: 0.4771
2022-01-23 21:04:03,154 Epoch[011/050], Step[0400/1252], Avg Loss: 2.9085, Avg Acc: 0.4779
2022-01-23 21:05:29,711 Epoch[011/050], Step[0450/1252], Avg Loss: 2.9033, Avg Acc: 0.4827
2022-01-23 21:06:57,340 Epoch[011/050], Step[0500/1252], Avg Loss: 2.9018, Avg Acc: 0.4834
2022-01-23 21:08:23,747 Epoch[011/050], Step[0550/1252], Avg Loss: 2.9016, Avg Acc: 0.4854
2022-01-23 21:09:51,922 Epoch[011/050], Step[0600/1252], Avg Loss: 2.9020, Avg Acc: 0.4847
2022-01-23 21:11:19,412 Epoch[011/050], Step[0650/1252], Avg Loss: 2.9010, Avg Acc: 0.4832
2022-01-23 21:12:46,821 Epoch[011/050], Step[0700/1252], Avg Loss: 2.9016, Avg Acc: 0.4851
2022-01-23 21:14:14,123 Epoch[011/050], Step[0750/1252], Avg Loss: 2.9060, Avg Acc: 0.4835
2022-01-23 21:15:40,802 Epoch[011/050], Step[0800/1252], Avg Loss: 2.9020, Avg Acc: 0.4852
2022-01-23 21:17:08,919 Epoch[011/050], Step[0850/1252], Avg Loss: 2.9023, Avg Acc: 0.4848
2022-01-23 21:18:36,487 Epoch[011/050], Step[0900/1252], Avg Loss: 2.9011, Avg Acc: 0.4851
2022-01-23 21:20:03,635 Epoch[011/050], Step[0950/1252], Avg Loss: 2.9035, Avg Acc: 0.4829
2022-01-23 21:21:30,502 Epoch[011/050], Step[1000/1252], Avg Loss: 2.9011, Avg Acc: 0.4849
2022-01-23 21:22:57,230 Epoch[011/050], Step[1050/1252], Avg Loss: 2.8977, Avg Acc: 0.4861
2022-01-23 21:24:24,732 Epoch[011/050], Step[1100/1252], Avg Loss: 2.8948, Avg Acc: 0.4876
2022-01-23 21:25:50,552 Epoch[011/050], Step[1150/1252], Avg Loss: 2.8930, Avg Acc: 0.4887
2022-01-23 21:27:18,967 Epoch[011/050], Step[1200/1252], Avg Loss: 2.8940, Avg Acc: 0.4886
2022-01-23 21:28:46,700 Epoch[011/050], Step[1250/1252], Avg Loss: 2.8950, Avg Acc: 0.4901
2022-01-23 21:28:53,712 ----- Epoch[011/050], Train Loss: 2.8951, Train Acc: 0.4901, time: 2288.91, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 21:28:53,713 Now training epoch 12. LR=0.000009
2022-01-23 21:30:55,875 Epoch[012/050], Step[0000/1252], Avg Loss: 2.7001, Avg Acc: 0.2979
2022-01-23 21:32:23,029 Epoch[012/050], Step[0050/1252], Avg Loss: 2.8465, Avg Acc: 0.4914
2022-01-23 21:33:49,913 Epoch[012/050], Step[0100/1252], Avg Loss: 2.8651, Avg Acc: 0.5023
2022-01-23 21:35:17,363 Epoch[012/050], Step[0150/1252], Avg Loss: 2.8639, Avg Acc: 0.4947
2022-01-23 21:36:44,988 Epoch[012/050], Step[0200/1252], Avg Loss: 2.8622, Avg Acc: 0.4929
2022-01-23 21:38:12,154 Epoch[012/050], Step[0250/1252], Avg Loss: 2.8659, Avg Acc: 0.4916
2022-01-23 21:39:37,450 Epoch[012/050], Step[0300/1252], Avg Loss: 2.8634, Avg Acc: 0.4947
2022-01-23 21:41:03,799 Epoch[012/050], Step[0350/1252], Avg Loss: 2.8716, Avg Acc: 0.4930
2022-01-23 21:42:30,816 Epoch[012/050], Step[0400/1252], Avg Loss: 2.8770, Avg Acc: 0.4913
2022-01-23 21:43:57,952 Epoch[012/050], Step[0450/1252], Avg Loss: 2.8820, Avg Acc: 0.4893
2022-01-23 21:45:24,658 Epoch[012/050], Step[0500/1252], Avg Loss: 2.8801, Avg Acc: 0.4887
2022-01-23 21:46:50,014 Epoch[012/050], Step[0550/1252], Avg Loss: 2.8756, Avg Acc: 0.4893
2022-01-23 21:48:15,515 Epoch[012/050], Step[0600/1252], Avg Loss: 2.8788, Avg Acc: 0.4911
2022-01-23 21:49:40,941 Epoch[012/050], Step[0650/1252], Avg Loss: 2.8814, Avg Acc: 0.4923
2022-01-23 21:51:07,002 Epoch[012/050], Step[0700/1252], Avg Loss: 2.8854, Avg Acc: 0.4909
2022-01-23 21:52:32,821 Epoch[012/050], Step[0750/1252], Avg Loss: 2.8882, Avg Acc: 0.4886
2022-01-23 21:53:58,568 Epoch[012/050], Step[0800/1252], Avg Loss: 2.8889, Avg Acc: 0.4875
2022-01-23 21:55:25,476 Epoch[012/050], Step[0850/1252], Avg Loss: 2.8909, Avg Acc: 0.4869
2022-01-23 21:56:51,692 Epoch[012/050], Step[0900/1252], Avg Loss: 2.8898, Avg Acc: 0.4875
2022-01-23 21:58:18,389 Epoch[012/050], Step[0950/1252], Avg Loss: 2.8854, Avg Acc: 0.4877
2022-01-23 21:59:45,772 Epoch[012/050], Step[1000/1252], Avg Loss: 2.8876, Avg Acc: 0.4882
2022-01-23 22:01:12,546 Epoch[012/050], Step[1050/1252], Avg Loss: 2.8871, Avg Acc: 0.4887
2022-01-23 22:02:40,300 Epoch[012/050], Step[1100/1252], Avg Loss: 2.8892, Avg Acc: 0.4878
2022-01-23 22:04:07,726 Epoch[012/050], Step[1150/1252], Avg Loss: 2.8894, Avg Acc: 0.4869
2022-01-23 22:05:35,359 Epoch[012/050], Step[1200/1252], Avg Loss: 2.8867, Avg Acc: 0.4877
2022-01-23 22:07:03,995 Epoch[012/050], Step[1250/1252], Avg Loss: 2.8885, Avg Acc: 0.4880
2022-01-23 22:07:11,113 ----- Epoch[012/050], Train Loss: 2.8884, Train Acc: 0.4880, time: 2297.40, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 22:07:11,113 ----- Validation after Epoch: 12
2022-01-23 22:08:46,703 Val Step[0000/1563], Avg Loss: 0.8479, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 22:08:48,520 Val Step[0050/1563], Avg Loss: 1.0128, Avg Acc@1: 0.7794, Avg Acc@5: 0.9412
2022-01-23 22:08:50,317 Val Step[0100/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7800, Avg Acc@5: 0.9384
2022-01-23 22:08:52,101 Val Step[0150/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7815, Avg Acc@5: 0.9363
2022-01-23 22:08:53,912 Val Step[0200/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7822, Avg Acc@5: 0.9366
2022-01-23 22:08:55,909 Val Step[0250/1563], Avg Loss: 1.0334, Avg Acc@1: 0.7814, Avg Acc@5: 0.9381
2022-01-23 22:08:57,972 Val Step[0300/1563], Avg Loss: 1.0340, Avg Acc@1: 0.7805, Avg Acc@5: 0.9373
2022-01-23 22:09:00,074 Val Step[0350/1563], Avg Loss: 1.0385, Avg Acc@1: 0.7793, Avg Acc@5: 0.9368
2022-01-23 22:09:02,154 Val Step[0400/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7799, Avg Acc@5: 0.9366
2022-01-23 22:09:04,212 Val Step[0450/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7772, Avg Acc@5: 0.9364
2022-01-23 22:09:06,314 Val Step[0500/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7764, Avg Acc@5: 0.9367
2022-01-23 22:09:08,378 Val Step[0550/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7756, Avg Acc@5: 0.9368
2022-01-23 22:09:10,398 Val Step[0600/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-23 22:09:12,393 Val Step[0650/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7750, Avg Acc@5: 0.9374
2022-01-23 22:09:14,425 Val Step[0700/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7757, Avg Acc@5: 0.9377
2022-01-23 22:09:16,483 Val Step[0750/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7737, Avg Acc@5: 0.9372
2022-01-23 22:09:18,529 Val Step[0800/1563], Avg Loss: 1.0482, Avg Acc@1: 0.7746, Avg Acc@5: 0.9371
2022-01-23 22:09:20,525 Val Step[0850/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7743, Avg Acc@5: 0.9368
2022-01-23 22:09:22,514 Val Step[0900/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-23 22:09:24,402 Val Step[0950/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-23 22:09:26,197 Val Step[1000/1563], Avg Loss: 1.0477, Avg Acc@1: 0.7757, Avg Acc@5: 0.9370
2022-01-23 22:09:27,983 Val Step[1050/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7752, Avg Acc@5: 0.9368
2022-01-23 22:09:29,918 Val Step[1100/1563], Avg Loss: 1.0501, Avg Acc@1: 0.7747, Avg Acc@5: 0.9368
2022-01-23 22:09:31,698 Val Step[1150/1563], Avg Loss: 1.0477, Avg Acc@1: 0.7750, Avg Acc@5: 0.9371
2022-01-23 22:09:33,503 Val Step[1200/1563], Avg Loss: 1.0468, Avg Acc@1: 0.7756, Avg Acc@5: 0.9371
2022-01-23 22:09:35,333 Val Step[1250/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7753, Avg Acc@5: 0.9374
2022-01-23 22:09:37,130 Val Step[1300/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-23 22:09:39,047 Val Step[1350/1563], Avg Loss: 1.0506, Avg Acc@1: 0.7746, Avg Acc@5: 0.9369
2022-01-23 22:09:40,857 Val Step[1400/1563], Avg Loss: 1.0502, Avg Acc@1: 0.7744, Avg Acc@5: 0.9369
2022-01-23 22:09:42,638 Val Step[1450/1563], Avg Loss: 1.0489, Avg Acc@1: 0.7749, Avg Acc@5: 0.9369
2022-01-23 22:09:44,441 Val Step[1500/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7750, Avg Acc@5: 0.9371
2022-01-23 22:09:46,205 Val Step[1550/1563], Avg Loss: 1.0492, Avg Acc@1: 0.7749, Avg Acc@5: 0.9370
2022-01-23 22:09:48,132 ----- Epoch[012/050], Validation Loss: 1.0491, Validation Acc@1: 0.7749, Validation Acc@5: 0.9371, time: 157.02
2022-01-23 22:09:48,132 Now training epoch 13. LR=0.000009
2022-01-23 22:11:44,123 Epoch[013/050], Step[0000/1252], Avg Loss: 2.8885, Avg Acc: 0.4756
2022-01-23 22:13:11,326 Epoch[013/050], Step[0050/1252], Avg Loss: 2.8618, Avg Acc: 0.5245
2022-01-23 22:14:39,146 Epoch[013/050], Step[0100/1252], Avg Loss: 2.9046, Avg Acc: 0.4713
2022-01-23 22:16:06,144 Epoch[013/050], Step[0150/1252], Avg Loss: 2.9046, Avg Acc: 0.4783
2022-01-23 22:17:33,277 Epoch[013/050], Step[0200/1252], Avg Loss: 2.9013, Avg Acc: 0.4823
2022-01-23 22:19:00,193 Epoch[013/050], Step[0250/1252], Avg Loss: 2.9119, Avg Acc: 0.4772
2022-01-23 22:20:28,324 Epoch[013/050], Step[0300/1252], Avg Loss: 2.9116, Avg Acc: 0.4746
2022-01-23 22:21:54,997 Epoch[013/050], Step[0350/1252], Avg Loss: 2.9171, Avg Acc: 0.4758
2022-01-23 22:23:21,899 Epoch[013/050], Step[0400/1252], Avg Loss: 2.9109, Avg Acc: 0.4790
2022-01-23 22:24:49,240 Epoch[013/050], Step[0450/1252], Avg Loss: 2.9032, Avg Acc: 0.4819
2022-01-23 22:26:15,785 Epoch[013/050], Step[0500/1252], Avg Loss: 2.8997, Avg Acc: 0.4853
2022-01-23 22:27:43,239 Epoch[013/050], Step[0550/1252], Avg Loss: 2.9074, Avg Acc: 0.4815
2022-01-23 22:29:11,286 Epoch[013/050], Step[0600/1252], Avg Loss: 2.9068, Avg Acc: 0.4786
2022-01-23 22:30:38,664 Epoch[013/050], Step[0650/1252], Avg Loss: 2.9085, Avg Acc: 0.4774
2022-01-23 22:32:05,574 Epoch[013/050], Step[0700/1252], Avg Loss: 2.9070, Avg Acc: 0.4780
2022-01-23 22:33:31,196 Epoch[013/050], Step[0750/1252], Avg Loss: 2.9094, Avg Acc: 0.4794
2022-01-23 22:34:58,088 Epoch[013/050], Step[0800/1252], Avg Loss: 2.9065, Avg Acc: 0.4816
2022-01-23 22:36:25,155 Epoch[013/050], Step[0850/1252], Avg Loss: 2.9049, Avg Acc: 0.4821
2022-01-23 22:37:52,457 Epoch[013/050], Step[0900/1252], Avg Loss: 2.9052, Avg Acc: 0.4805
2022-01-23 22:39:20,047 Epoch[013/050], Step[0950/1252], Avg Loss: 2.9037, Avg Acc: 0.4799
2022-01-23 22:40:46,799 Epoch[013/050], Step[1000/1252], Avg Loss: 2.9034, Avg Acc: 0.4815
2022-01-23 22:42:14,262 Epoch[013/050], Step[1050/1252], Avg Loss: 2.9044, Avg Acc: 0.4806
2022-01-23 22:43:40,247 Epoch[013/050], Step[1100/1252], Avg Loss: 2.9046, Avg Acc: 0.4800
2022-01-23 22:45:07,722 Epoch[013/050], Step[1150/1252], Avg Loss: 2.9054, Avg Acc: 0.4807
2022-01-23 22:46:36,027 Epoch[013/050], Step[1200/1252], Avg Loss: 2.9063, Avg Acc: 0.4804
2022-01-23 22:48:03,284 Epoch[013/050], Step[1250/1252], Avg Loss: 2.9043, Avg Acc: 0.4808
2022-01-23 22:48:10,434 ----- Epoch[013/050], Train Loss: 2.9042, Train Acc: 0.4808, time: 2302.30, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 22:48:10,434 Now training epoch 14. LR=0.000009
2022-01-23 22:49:58,913 Epoch[014/050], Step[0000/1252], Avg Loss: 3.1563, Avg Acc: 0.4844
2022-01-23 22:51:26,533 Epoch[014/050], Step[0050/1252], Avg Loss: 2.8668, Avg Acc: 0.4896
2022-01-23 22:52:53,971 Epoch[014/050], Step[0100/1252], Avg Loss: 2.8714, Avg Acc: 0.4832
2022-01-23 22:54:20,776 Epoch[014/050], Step[0150/1252], Avg Loss: 2.8605, Avg Acc: 0.4727
2022-01-23 22:55:47,223 Epoch[014/050], Step[0200/1252], Avg Loss: 2.8704, Avg Acc: 0.4820
2022-01-23 22:57:13,924 Epoch[014/050], Step[0250/1252], Avg Loss: 2.8768, Avg Acc: 0.4809
2022-01-23 22:58:40,227 Epoch[014/050], Step[0300/1252], Avg Loss: 2.8764, Avg Acc: 0.4792
2022-01-23 23:00:08,255 Epoch[014/050], Step[0350/1252], Avg Loss: 2.8816, Avg Acc: 0.4777
2022-01-23 23:01:35,199 Epoch[014/050], Step[0400/1252], Avg Loss: 2.8819, Avg Acc: 0.4835
2022-01-23 23:03:02,499 Epoch[014/050], Step[0450/1252], Avg Loss: 2.8866, Avg Acc: 0.4833
2022-01-23 23:04:30,008 Epoch[014/050], Step[0500/1252], Avg Loss: 2.8902, Avg Acc: 0.4842
2022-01-23 23:05:57,468 Epoch[014/050], Step[0550/1252], Avg Loss: 2.8905, Avg Acc: 0.4862
2022-01-23 23:07:25,714 Epoch[014/050], Step[0600/1252], Avg Loss: 2.8972, Avg Acc: 0.4860
2022-01-23 23:08:52,948 Epoch[014/050], Step[0650/1252], Avg Loss: 2.8917, Avg Acc: 0.4862
2022-01-23 23:10:21,422 Epoch[014/050], Step[0700/1252], Avg Loss: 2.8939, Avg Acc: 0.4855
2022-01-23 23:11:48,262 Epoch[014/050], Step[0750/1252], Avg Loss: 2.8933, Avg Acc: 0.4867
2022-01-23 23:13:15,112 Epoch[014/050], Step[0800/1252], Avg Loss: 2.8956, Avg Acc: 0.4846
2022-01-23 23:14:42,276 Epoch[014/050], Step[0850/1252], Avg Loss: 2.8913, Avg Acc: 0.4830
2022-01-23 23:16:09,787 Epoch[014/050], Step[0900/1252], Avg Loss: 2.8938, Avg Acc: 0.4819
2022-01-23 23:17:37,775 Epoch[014/050], Step[0950/1252], Avg Loss: 2.8923, Avg Acc: 0.4813
2022-01-23 23:19:06,431 Epoch[014/050], Step[1000/1252], Avg Loss: 2.8916, Avg Acc: 0.4814
2022-01-23 23:20:34,566 Epoch[014/050], Step[1050/1252], Avg Loss: 2.8925, Avg Acc: 0.4811
2022-01-23 23:22:01,125 Epoch[014/050], Step[1100/1252], Avg Loss: 2.8916, Avg Acc: 0.4810
2022-01-23 23:23:28,874 Epoch[014/050], Step[1150/1252], Avg Loss: 2.8899, Avg Acc: 0.4823
2022-01-23 23:24:56,337 Epoch[014/050], Step[1200/1252], Avg Loss: 2.8884, Avg Acc: 0.4826
2022-01-23 23:26:24,710 Epoch[014/050], Step[1250/1252], Avg Loss: 2.8869, Avg Acc: 0.4837
2022-01-23 23:26:31,952 ----- Epoch[014/050], Train Loss: 2.8869, Train Acc: 0.4836, time: 2301.51, Best Val(epoch4) Acc@1: 0.7756
2022-01-23 23:26:31,952 ----- Validation after Epoch: 14
2022-01-23 23:27:45,170 Val Step[0000/1563], Avg Loss: 0.8206, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-23 23:27:47,259 Val Step[0050/1563], Avg Loss: 1.0033, Avg Acc@1: 0.7812, Avg Acc@5: 0.9424
2022-01-23 23:27:49,235 Val Step[0100/1563], Avg Loss: 1.0367, Avg Acc@1: 0.7825, Avg Acc@5: 0.9378
2022-01-23 23:27:51,175 Val Step[0150/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7806, Avg Acc@5: 0.9348
2022-01-23 23:27:53,259 Val Step[0200/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7825, Avg Acc@5: 0.9361
2022-01-23 23:27:55,288 Val Step[0250/1563], Avg Loss: 1.0284, Avg Acc@1: 0.7820, Avg Acc@5: 0.9375
2022-01-23 23:27:57,375 Val Step[0300/1563], Avg Loss: 1.0284, Avg Acc@1: 0.7820, Avg Acc@5: 0.9367
2022-01-23 23:27:59,403 Val Step[0350/1563], Avg Loss: 1.0327, Avg Acc@1: 0.7812, Avg Acc@5: 0.9362
2022-01-23 23:28:01,430 Val Step[0400/1563], Avg Loss: 1.0325, Avg Acc@1: 0.7817, Avg Acc@5: 0.9359
2022-01-23 23:28:03,445 Val Step[0450/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7795, Avg Acc@5: 0.9358
2022-01-23 23:28:05,474 Val Step[0500/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7785, Avg Acc@5: 0.9364
2022-01-23 23:28:07,513 Val Step[0550/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7775, Avg Acc@5: 0.9363
2022-01-23 23:28:09,568 Val Step[0600/1563], Avg Loss: 1.0390, Avg Acc@1: 0.7772, Avg Acc@5: 0.9364
2022-01-23 23:28:11,605 Val Step[0650/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7767, Avg Acc@5: 0.9365
2022-01-23 23:28:13,678 Val Step[0700/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7769, Avg Acc@5: 0.9371
2022-01-23 23:28:15,740 Val Step[0750/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7751, Avg Acc@5: 0.9369
2022-01-23 23:28:17,777 Val Step[0800/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7756, Avg Acc@5: 0.9369
2022-01-23 23:28:19,800 Val Step[0850/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7752, Avg Acc@5: 0.9365
2022-01-23 23:28:21,807 Val Step[0900/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7760, Avg Acc@5: 0.9369
2022-01-23 23:28:23,879 Val Step[0950/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7767, Avg Acc@5: 0.9371
2022-01-23 23:28:25,907 Val Step[1000/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7767, Avg Acc@5: 0.9369
2022-01-23 23:28:27,953 Val Step[1050/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7762, Avg Acc@5: 0.9366
2022-01-23 23:28:29,988 Val Step[1100/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7758, Avg Acc@5: 0.9368
2022-01-23 23:28:32,036 Val Step[1150/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7761, Avg Acc@5: 0.9370
2022-01-23 23:28:33,928 Val Step[1200/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7768, Avg Acc@5: 0.9370
2022-01-23 23:28:35,798 Val Step[1250/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7764, Avg Acc@5: 0.9372
2022-01-23 23:28:37,893 Val Step[1300/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7762, Avg Acc@5: 0.9368
2022-01-23 23:28:39,961 Val Step[1350/1563], Avg Loss: 1.0469, Avg Acc@1: 0.7756, Avg Acc@5: 0.9368
2022-01-23 23:28:42,014 Val Step[1400/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7753, Avg Acc@5: 0.9368
2022-01-23 23:28:44,216 Val Step[1450/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7758, Avg Acc@5: 0.9368
2022-01-23 23:28:46,375 Val Step[1500/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7759, Avg Acc@5: 0.9370
2022-01-23 23:28:48,420 Val Step[1550/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7757, Avg Acc@5: 0.9370
2022-01-23 23:28:50,335 ----- Epoch[014/050], Validation Loss: 1.0456, Validation Acc@1: 0.7757, Validation Acc@5: 0.9371, time: 138.38
2022-01-23 23:28:51,953 the pre best model acc:0.7756, at epoch 4
2022-01-23 23:28:52,023 current best model acc:0.7757, at epoch 14
2022-01-23 23:28:52,023 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 23:28:52,024 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 23:28:52,024 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-23 23:28:52,024 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-23 23:28:52,024 Now training epoch 15. LR=0.000008
2022-01-23 23:30:38,714 Epoch[015/050], Step[0000/1252], Avg Loss: 2.4609, Avg Acc: 0.7188
2022-01-23 23:32:06,269 Epoch[015/050], Step[0050/1252], Avg Loss: 2.8503, Avg Acc: 0.4826
2022-01-23 23:33:33,593 Epoch[015/050], Step[0100/1252], Avg Loss: 2.8404, Avg Acc: 0.4764
2022-01-23 23:35:00,877 Epoch[015/050], Step[0150/1252], Avg Loss: 2.8549, Avg Acc: 0.4819
2022-01-23 23:36:28,851 Epoch[015/050], Step[0200/1252], Avg Loss: 2.8599, Avg Acc: 0.4833
2022-01-23 23:37:56,625 Epoch[015/050], Step[0250/1252], Avg Loss: 2.8691, Avg Acc: 0.4822
2022-01-23 23:39:24,017 Epoch[015/050], Step[0300/1252], Avg Loss: 2.8653, Avg Acc: 0.4856
2022-01-23 23:40:50,731 Epoch[015/050], Step[0350/1252], Avg Loss: 2.8694, Avg Acc: 0.4899
2022-01-23 23:42:17,811 Epoch[015/050], Step[0400/1252], Avg Loss: 2.8738, Avg Acc: 0.4891
2022-01-23 23:43:43,792 Epoch[015/050], Step[0450/1252], Avg Loss: 2.8751, Avg Acc: 0.4892
2022-01-23 23:45:10,109 Epoch[015/050], Step[0500/1252], Avg Loss: 2.8696, Avg Acc: 0.4899
2022-01-23 23:46:37,494 Epoch[015/050], Step[0550/1252], Avg Loss: 2.8773, Avg Acc: 0.4863
2022-01-23 23:48:05,130 Epoch[015/050], Step[0600/1252], Avg Loss: 2.8816, Avg Acc: 0.4865
2022-01-23 23:49:32,975 Epoch[015/050], Step[0650/1252], Avg Loss: 2.8840, Avg Acc: 0.4875
2022-01-23 23:50:59,528 Epoch[015/050], Step[0700/1252], Avg Loss: 2.8875, Avg Acc: 0.4865
2022-01-23 23:52:26,883 Epoch[015/050], Step[0750/1252], Avg Loss: 2.8885, Avg Acc: 0.4851
2022-01-23 23:53:54,160 Epoch[015/050], Step[0800/1252], Avg Loss: 2.8889, Avg Acc: 0.4851
2022-01-23 23:55:21,942 Epoch[015/050], Step[0850/1252], Avg Loss: 2.8895, Avg Acc: 0.4852
2022-01-23 23:56:47,868 Epoch[015/050], Step[0900/1252], Avg Loss: 2.8922, Avg Acc: 0.4866
2022-01-23 23:58:15,466 Epoch[015/050], Step[0950/1252], Avg Loss: 2.8927, Avg Acc: 0.4869
2022-01-23 23:59:42,795 Epoch[015/050], Step[1000/1252], Avg Loss: 2.8912, Avg Acc: 0.4876
2022-01-24 00:01:10,119 Epoch[015/050], Step[1050/1252], Avg Loss: 2.8915, Avg Acc: 0.4877
2022-01-24 00:02:37,356 Epoch[015/050], Step[1100/1252], Avg Loss: 2.8899, Avg Acc: 0.4881
2022-01-24 00:04:04,992 Epoch[015/050], Step[1150/1252], Avg Loss: 2.8886, Avg Acc: 0.4882
2022-01-24 00:05:31,729 Epoch[015/050], Step[1200/1252], Avg Loss: 2.8889, Avg Acc: 0.4896
2022-01-24 00:06:56,357 Epoch[015/050], Step[1250/1252], Avg Loss: 2.8909, Avg Acc: 0.4884
2022-01-24 00:07:03,656 ----- Epoch[015/050], Train Loss: 2.8909, Train Acc: 0.4884, time: 2291.63, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 00:07:03,656 Now training epoch 16. LR=0.000008
2022-01-24 00:09:05,119 Epoch[016/050], Step[0000/1252], Avg Loss: 3.1618, Avg Acc: 0.2686
2022-01-24 00:10:32,312 Epoch[016/050], Step[0050/1252], Avg Loss: 2.8496, Avg Acc: 0.5159
2022-01-24 00:11:59,696 Epoch[016/050], Step[0100/1252], Avg Loss: 2.8471, Avg Acc: 0.5135
2022-01-24 00:13:27,453 Epoch[016/050], Step[0150/1252], Avg Loss: 2.8744, Avg Acc: 0.5057
2022-01-24 00:14:54,749 Epoch[016/050], Step[0200/1252], Avg Loss: 2.8779, Avg Acc: 0.5009
2022-01-24 00:16:21,549 Epoch[016/050], Step[0250/1252], Avg Loss: 2.8848, Avg Acc: 0.5003
2022-01-24 00:17:49,489 Epoch[016/050], Step[0300/1252], Avg Loss: 2.8794, Avg Acc: 0.4929
2022-01-24 00:19:17,230 Epoch[016/050], Step[0350/1252], Avg Loss: 2.8828, Avg Acc: 0.4942
2022-01-24 00:20:45,645 Epoch[016/050], Step[0400/1252], Avg Loss: 2.8764, Avg Acc: 0.4874
2022-01-24 00:22:12,286 Epoch[016/050], Step[0450/1252], Avg Loss: 2.8839, Avg Acc: 0.4875
2022-01-24 00:23:40,246 Epoch[016/050], Step[0500/1252], Avg Loss: 2.8854, Avg Acc: 0.4887
2022-01-24 00:25:08,329 Epoch[016/050], Step[0550/1252], Avg Loss: 2.8837, Avg Acc: 0.4869
2022-01-24 00:26:36,011 Epoch[016/050], Step[0600/1252], Avg Loss: 2.8853, Avg Acc: 0.4891
2022-01-24 00:28:02,668 Epoch[016/050], Step[0650/1252], Avg Loss: 2.8873, Avg Acc: 0.4901
2022-01-24 00:29:29,661 Epoch[016/050], Step[0700/1252], Avg Loss: 2.8882, Avg Acc: 0.4886
2022-01-24 00:30:57,587 Epoch[016/050], Step[0750/1252], Avg Loss: 2.8885, Avg Acc: 0.4924
2022-01-24 00:32:25,279 Epoch[016/050], Step[0800/1252], Avg Loss: 2.8893, Avg Acc: 0.4921
2022-01-24 00:33:53,574 Epoch[016/050], Step[0850/1252], Avg Loss: 2.8891, Avg Acc: 0.4916
2022-01-24 00:35:20,994 Epoch[016/050], Step[0900/1252], Avg Loss: 2.8848, Avg Acc: 0.4918
2022-01-24 00:36:48,073 Epoch[016/050], Step[0950/1252], Avg Loss: 2.8877, Avg Acc: 0.4915
2022-01-24 00:38:16,010 Epoch[016/050], Step[1000/1252], Avg Loss: 2.8862, Avg Acc: 0.4931
2022-01-24 00:39:43,144 Epoch[016/050], Step[1050/1252], Avg Loss: 2.8858, Avg Acc: 0.4916
2022-01-24 00:41:10,403 Epoch[016/050], Step[1100/1252], Avg Loss: 2.8854, Avg Acc: 0.4914
2022-01-24 00:42:39,029 Epoch[016/050], Step[1150/1252], Avg Loss: 2.8859, Avg Acc: 0.4924
2022-01-24 00:44:06,275 Epoch[016/050], Step[1200/1252], Avg Loss: 2.8857, Avg Acc: 0.4929
2022-01-24 00:45:33,306 Epoch[016/050], Step[1250/1252], Avg Loss: 2.8867, Avg Acc: 0.4923
2022-01-24 00:45:40,420 ----- Epoch[016/050], Train Loss: 2.8868, Train Acc: 0.4923, time: 2316.76, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 00:45:40,421 ----- Validation after Epoch: 16
2022-01-24 00:46:50,877 Val Step[0000/1563], Avg Loss: 0.8186, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 00:46:53,053 Val Step[0050/1563], Avg Loss: 1.0124, Avg Acc@1: 0.7794, Avg Acc@5: 0.9436
2022-01-24 00:46:54,825 Val Step[0100/1563], Avg Loss: 1.0407, Avg Acc@1: 0.7828, Avg Acc@5: 0.9403
2022-01-24 00:46:56,694 Val Step[0150/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7810, Avg Acc@5: 0.9377
2022-01-24 00:46:58,459 Val Step[0200/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7826, Avg Acc@5: 0.9370
2022-01-24 00:47:00,302 Val Step[0250/1563], Avg Loss: 1.0330, Avg Acc@1: 0.7817, Avg Acc@5: 0.9381
2022-01-24 00:47:02,159 Val Step[0300/1563], Avg Loss: 1.0327, Avg Acc@1: 0.7817, Avg Acc@5: 0.9368
2022-01-24 00:47:04,022 Val Step[0350/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7808, Avg Acc@5: 0.9365
2022-01-24 00:47:05,922 Val Step[0400/1563], Avg Loss: 1.0374, Avg Acc@1: 0.7809, Avg Acc@5: 0.9364
2022-01-24 00:47:07,754 Val Step[0450/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7783, Avg Acc@5: 0.9362
2022-01-24 00:47:09,580 Val Step[0500/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7781, Avg Acc@5: 0.9366
2022-01-24 00:47:11,382 Val Step[0550/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7772, Avg Acc@5: 0.9366
2022-01-24 00:47:13,226 Val Step[0600/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7773, Avg Acc@5: 0.9367
2022-01-24 00:47:15,063 Val Step[0650/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7771, Avg Acc@5: 0.9369
2022-01-24 00:47:16,844 Val Step[0700/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7774, Avg Acc@5: 0.9375
2022-01-24 00:47:18,748 Val Step[0750/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7751, Avg Acc@5: 0.9372
2022-01-24 00:47:20,650 Val Step[0800/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7758, Avg Acc@5: 0.9371
2022-01-24 00:47:22,578 Val Step[0850/1563], Avg Loss: 1.0493, Avg Acc@1: 0.7756, Avg Acc@5: 0.9367
2022-01-24 00:47:24,464 Val Step[0900/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7760, Avg Acc@5: 0.9371
2022-01-24 00:47:26,398 Val Step[0950/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7767, Avg Acc@5: 0.9372
2022-01-24 00:47:28,211 Val Step[1000/1563], Avg Loss: 1.0475, Avg Acc@1: 0.7763, Avg Acc@5: 0.9368
2022-01-24 00:47:30,061 Val Step[1050/1563], Avg Loss: 1.0495, Avg Acc@1: 0.7757, Avg Acc@5: 0.9366
2022-01-24 00:47:31,860 Val Step[1100/1563], Avg Loss: 1.0494, Avg Acc@1: 0.7754, Avg Acc@5: 0.9368
2022-01-24 00:47:33,717 Val Step[1150/1563], Avg Loss: 1.0470, Avg Acc@1: 0.7757, Avg Acc@5: 0.9373
2022-01-24 00:47:35,634 Val Step[1200/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7764, Avg Acc@5: 0.9373
2022-01-24 00:47:37,495 Val Step[1250/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7759, Avg Acc@5: 0.9375
2022-01-24 00:47:39,356 Val Step[1300/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7757, Avg Acc@5: 0.9372
2022-01-24 00:47:41,243 Val Step[1350/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-24 00:47:43,178 Val Step[1400/1563], Avg Loss: 1.0491, Avg Acc@1: 0.7746, Avg Acc@5: 0.9369
2022-01-24 00:47:45,146 Val Step[1450/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7750, Avg Acc@5: 0.9370
2022-01-24 00:47:47,141 Val Step[1500/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7752, Avg Acc@5: 0.9372
2022-01-24 00:47:49,181 Val Step[1550/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7749, Avg Acc@5: 0.9371
2022-01-24 00:47:51,232 ----- Epoch[016/050], Validation Loss: 1.0482, Validation Acc@1: 0.7749, Validation Acc@5: 0.9371, time: 130.81
2022-01-24 00:47:51,232 Now training epoch 17. LR=0.000008
2022-01-24 00:49:37,869 Epoch[017/050], Step[0000/1252], Avg Loss: 3.0719, Avg Acc: 0.4736
2022-01-24 00:51:05,302 Epoch[017/050], Step[0050/1252], Avg Loss: 2.9187, Avg Acc: 0.5100
2022-01-24 00:52:31,594 Epoch[017/050], Step[0100/1252], Avg Loss: 2.8977, Avg Acc: 0.5140
2022-01-24 00:53:57,052 Epoch[017/050], Step[0150/1252], Avg Loss: 2.8568, Avg Acc: 0.5167
2022-01-24 00:55:24,501 Epoch[017/050], Step[0200/1252], Avg Loss: 2.8600, Avg Acc: 0.5097
2022-01-24 00:56:52,140 Epoch[017/050], Step[0250/1252], Avg Loss: 2.8675, Avg Acc: 0.5075
2022-01-24 00:58:17,545 Epoch[017/050], Step[0300/1252], Avg Loss: 2.8651, Avg Acc: 0.5110
2022-01-24 00:59:43,728 Epoch[017/050], Step[0350/1252], Avg Loss: 2.8722, Avg Acc: 0.5088
2022-01-24 01:01:11,021 Epoch[017/050], Step[0400/1252], Avg Loss: 2.8727, Avg Acc: 0.5072
2022-01-24 01:02:37,450 Epoch[017/050], Step[0450/1252], Avg Loss: 2.8828, Avg Acc: 0.5034
2022-01-24 01:04:04,726 Epoch[017/050], Step[0500/1252], Avg Loss: 2.8885, Avg Acc: 0.5031
2022-01-24 01:05:32,574 Epoch[017/050], Step[0550/1252], Avg Loss: 2.8837, Avg Acc: 0.5048
2022-01-24 01:06:58,595 Epoch[017/050], Step[0600/1252], Avg Loss: 2.8830, Avg Acc: 0.5023
2022-01-24 01:08:25,377 Epoch[017/050], Step[0650/1252], Avg Loss: 2.8883, Avg Acc: 0.5001
2022-01-24 01:09:52,183 Epoch[017/050], Step[0700/1252], Avg Loss: 2.8882, Avg Acc: 0.4969
2022-01-24 01:11:18,604 Epoch[017/050], Step[0750/1252], Avg Loss: 2.8905, Avg Acc: 0.4955
2022-01-24 01:12:46,194 Epoch[017/050], Step[0800/1252], Avg Loss: 2.8898, Avg Acc: 0.4954
2022-01-24 01:14:13,913 Epoch[017/050], Step[0850/1252], Avg Loss: 2.8875, Avg Acc: 0.4942
2022-01-24 01:15:42,066 Epoch[017/050], Step[0900/1252], Avg Loss: 2.8919, Avg Acc: 0.4940
2022-01-24 01:17:08,600 Epoch[017/050], Step[0950/1252], Avg Loss: 2.8891, Avg Acc: 0.4940
2022-01-24 01:18:36,630 Epoch[017/050], Step[1000/1252], Avg Loss: 2.8900, Avg Acc: 0.4937
2022-01-24 01:20:04,356 Epoch[017/050], Step[1050/1252], Avg Loss: 2.8878, Avg Acc: 0.4928
2022-01-24 01:21:31,417 Epoch[017/050], Step[1100/1252], Avg Loss: 2.8883, Avg Acc: 0.4922
2022-01-24 01:22:57,576 Epoch[017/050], Step[1150/1252], Avg Loss: 2.8884, Avg Acc: 0.4933
2022-01-24 01:24:24,303 Epoch[017/050], Step[1200/1252], Avg Loss: 2.8898, Avg Acc: 0.4935
2022-01-24 01:25:51,031 Epoch[017/050], Step[1250/1252], Avg Loss: 2.8925, Avg Acc: 0.4932
2022-01-24 01:25:58,112 ----- Epoch[017/050], Train Loss: 2.8926, Train Acc: 0.4932, time: 2286.88, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 01:25:58,113 Now training epoch 18. LR=0.000008
2022-01-24 01:27:38,632 Epoch[018/050], Step[0000/1252], Avg Loss: 2.5423, Avg Acc: 0.6113
2022-01-24 01:29:04,595 Epoch[018/050], Step[0050/1252], Avg Loss: 2.8724, Avg Acc: 0.4356
2022-01-24 01:30:30,212 Epoch[018/050], Step[0100/1252], Avg Loss: 2.8899, Avg Acc: 0.4607
2022-01-24 01:31:56,821 Epoch[018/050], Step[0150/1252], Avg Loss: 2.8829, Avg Acc: 0.4729
2022-01-24 01:33:23,822 Epoch[018/050], Step[0200/1252], Avg Loss: 2.8837, Avg Acc: 0.4760
2022-01-24 01:34:50,529 Epoch[018/050], Step[0250/1252], Avg Loss: 2.8809, Avg Acc: 0.4854
2022-01-24 01:36:17,601 Epoch[018/050], Step[0300/1252], Avg Loss: 2.8783, Avg Acc: 0.4874
2022-01-24 01:37:44,004 Epoch[018/050], Step[0350/1252], Avg Loss: 2.8834, Avg Acc: 0.4859
2022-01-24 01:39:11,268 Epoch[018/050], Step[0400/1252], Avg Loss: 2.8825, Avg Acc: 0.4850
2022-01-24 01:40:37,785 Epoch[018/050], Step[0450/1252], Avg Loss: 2.8850, Avg Acc: 0.4850
2022-01-24 01:42:05,856 Epoch[018/050], Step[0500/1252], Avg Loss: 2.8837, Avg Acc: 0.4842
2022-01-24 01:43:33,045 Epoch[018/050], Step[0550/1252], Avg Loss: 2.8852, Avg Acc: 0.4854
2022-01-24 01:45:01,004 Epoch[018/050], Step[0600/1252], Avg Loss: 2.8834, Avg Acc: 0.4857
2022-01-24 01:46:28,481 Epoch[018/050], Step[0650/1252], Avg Loss: 2.8905, Avg Acc: 0.4852
2022-01-24 01:47:55,823 Epoch[018/050], Step[0700/1252], Avg Loss: 2.8876, Avg Acc: 0.4875
2022-01-24 01:49:22,917 Epoch[018/050], Step[0750/1252], Avg Loss: 2.8869, Avg Acc: 0.4866
2022-01-24 01:50:50,775 Epoch[018/050], Step[0800/1252], Avg Loss: 2.8878, Avg Acc: 0.4861
2022-01-24 01:52:18,043 Epoch[018/050], Step[0850/1252], Avg Loss: 2.8874, Avg Acc: 0.4853
2022-01-24 01:53:45,904 Epoch[018/050], Step[0900/1252], Avg Loss: 2.8894, Avg Acc: 0.4835
2022-01-24 01:55:12,405 Epoch[018/050], Step[0950/1252], Avg Loss: 2.8934, Avg Acc: 0.4821
2022-01-24 01:56:39,429 Epoch[018/050], Step[1000/1252], Avg Loss: 2.8957, Avg Acc: 0.4820
2022-01-24 01:58:05,052 Epoch[018/050], Step[1050/1252], Avg Loss: 2.8969, Avg Acc: 0.4813
2022-01-24 01:59:32,217 Epoch[018/050], Step[1100/1252], Avg Loss: 2.8965, Avg Acc: 0.4816
2022-01-24 02:01:00,227 Epoch[018/050], Step[1150/1252], Avg Loss: 2.8953, Avg Acc: 0.4811
2022-01-24 02:02:27,113 Epoch[018/050], Step[1200/1252], Avg Loss: 2.8965, Avg Acc: 0.4819
2022-01-24 02:03:54,360 Epoch[018/050], Step[1250/1252], Avg Loss: 2.8964, Avg Acc: 0.4826
2022-01-24 02:04:01,559 ----- Epoch[018/050], Train Loss: 2.8965, Train Acc: 0.4826, time: 2283.44, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 02:04:01,559 ----- Validation after Epoch: 18
2022-01-24 02:05:28,713 Val Step[0000/1563], Avg Loss: 0.8645, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-24 02:05:30,552 Val Step[0050/1563], Avg Loss: 1.0201, Avg Acc@1: 0.7825, Avg Acc@5: 0.9412
2022-01-24 02:05:32,456 Val Step[0100/1563], Avg Loss: 1.0516, Avg Acc@1: 0.7840, Avg Acc@5: 0.9369
2022-01-24 02:05:34,257 Val Step[0150/1563], Avg Loss: 1.0531, Avg Acc@1: 0.7829, Avg Acc@5: 0.9354
2022-01-24 02:05:36,048 Val Step[0200/1563], Avg Loss: 1.0525, Avg Acc@1: 0.7842, Avg Acc@5: 0.9364
2022-01-24 02:05:37,836 Val Step[0250/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7820, Avg Acc@5: 0.9377
2022-01-24 02:05:39,681 Val Step[0300/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7814, Avg Acc@5: 0.9370
2022-01-24 02:05:41,633 Val Step[0350/1563], Avg Loss: 1.0476, Avg Acc@1: 0.7804, Avg Acc@5: 0.9367
2022-01-24 02:05:43,462 Val Step[0400/1563], Avg Loss: 1.0469, Avg Acc@1: 0.7809, Avg Acc@5: 0.9361
2022-01-24 02:05:45,305 Val Step[0450/1563], Avg Loss: 1.0516, Avg Acc@1: 0.7785, Avg Acc@5: 0.9359
2022-01-24 02:05:47,143 Val Step[0500/1563], Avg Loss: 1.0544, Avg Acc@1: 0.7776, Avg Acc@5: 0.9364
2022-01-24 02:05:48,930 Val Step[0550/1563], Avg Loss: 1.0533, Avg Acc@1: 0.7766, Avg Acc@5: 0.9368
2022-01-24 02:05:50,710 Val Step[0600/1563], Avg Loss: 1.0520, Avg Acc@1: 0.7758, Avg Acc@5: 0.9370
2022-01-24 02:05:52,473 Val Step[0650/1563], Avg Loss: 1.0524, Avg Acc@1: 0.7759, Avg Acc@5: 0.9370
2022-01-24 02:05:54,420 Val Step[0700/1563], Avg Loss: 1.0504, Avg Acc@1: 0.7764, Avg Acc@5: 0.9374
2022-01-24 02:05:56,184 Val Step[0750/1563], Avg Loss: 1.0566, Avg Acc@1: 0.7746, Avg Acc@5: 0.9370
2022-01-24 02:05:58,035 Val Step[0800/1563], Avg Loss: 1.0564, Avg Acc@1: 0.7754, Avg Acc@5: 0.9366
2022-01-24 02:05:59,954 Val Step[0850/1563], Avg Loss: 1.0579, Avg Acc@1: 0.7752, Avg Acc@5: 0.9364
2022-01-24 02:06:02,001 Val Step[0900/1563], Avg Loss: 1.0553, Avg Acc@1: 0.7757, Avg Acc@5: 0.9368
2022-01-24 02:06:04,024 Val Step[0950/1563], Avg Loss: 1.0546, Avg Acc@1: 0.7763, Avg Acc@5: 0.9370
2022-01-24 02:06:06,055 Val Step[1000/1563], Avg Loss: 1.0562, Avg Acc@1: 0.7761, Avg Acc@5: 0.9367
2022-01-24 02:06:08,061 Val Step[1050/1563], Avg Loss: 1.0584, Avg Acc@1: 0.7753, Avg Acc@5: 0.9364
2022-01-24 02:06:10,102 Val Step[1100/1563], Avg Loss: 1.0584, Avg Acc@1: 0.7748, Avg Acc@5: 0.9366
2022-01-24 02:06:12,167 Val Step[1150/1563], Avg Loss: 1.0559, Avg Acc@1: 0.7750, Avg Acc@5: 0.9369
2022-01-24 02:06:14,241 Val Step[1200/1563], Avg Loss: 1.0549, Avg Acc@1: 0.7758, Avg Acc@5: 0.9370
2022-01-24 02:06:16,300 Val Step[1250/1563], Avg Loss: 1.0545, Avg Acc@1: 0.7756, Avg Acc@5: 0.9373
2022-01-24 02:06:18,370 Val Step[1300/1563], Avg Loss: 1.0577, Avg Acc@1: 0.7754, Avg Acc@5: 0.9369
2022-01-24 02:06:20,517 Val Step[1350/1563], Avg Loss: 1.0590, Avg Acc@1: 0.7748, Avg Acc@5: 0.9368
2022-01-24 02:06:22,613 Val Step[1400/1563], Avg Loss: 1.0585, Avg Acc@1: 0.7745, Avg Acc@5: 0.9367
2022-01-24 02:06:24,729 Val Step[1450/1563], Avg Loss: 1.0574, Avg Acc@1: 0.7750, Avg Acc@5: 0.9367
2022-01-24 02:06:26,832 Val Step[1500/1563], Avg Loss: 1.0574, Avg Acc@1: 0.7751, Avg Acc@5: 0.9368
2022-01-24 02:06:28,841 Val Step[1550/1563], Avg Loss: 1.0578, Avg Acc@1: 0.7749, Avg Acc@5: 0.9368
2022-01-24 02:06:30,914 ----- Epoch[018/050], Validation Loss: 1.0577, Validation Acc@1: 0.7749, Validation Acc@5: 0.9368, time: 149.35
2022-01-24 02:06:30,914 Now training epoch 19. LR=0.000007
2022-01-24 02:08:25,175 Epoch[019/050], Step[0000/1252], Avg Loss: 3.0070, Avg Acc: 0.3721
2022-01-24 02:09:51,982 Epoch[019/050], Step[0050/1252], Avg Loss: 2.9186, Avg Acc: 0.5016
2022-01-24 02:11:19,626 Epoch[019/050], Step[0100/1252], Avg Loss: 2.8696, Avg Acc: 0.4939
2022-01-24 02:12:47,608 Epoch[019/050], Step[0150/1252], Avg Loss: 2.8572, Avg Acc: 0.4958
2022-01-24 02:14:13,761 Epoch[019/050], Step[0200/1252], Avg Loss: 2.8701, Avg Acc: 0.5022
2022-01-24 02:15:41,674 Epoch[019/050], Step[0250/1252], Avg Loss: 2.8787, Avg Acc: 0.4950
2022-01-24 02:17:08,341 Epoch[019/050], Step[0300/1252], Avg Loss: 2.8775, Avg Acc: 0.4965
2022-01-24 02:18:35,858 Epoch[019/050], Step[0350/1252], Avg Loss: 2.8715, Avg Acc: 0.4961
2022-01-24 02:20:01,462 Epoch[019/050], Step[0400/1252], Avg Loss: 2.8750, Avg Acc: 0.4956
2022-01-24 02:21:28,582 Epoch[019/050], Step[0450/1252], Avg Loss: 2.8736, Avg Acc: 0.4935
2022-01-24 02:22:54,906 Epoch[019/050], Step[0500/1252], Avg Loss: 2.8790, Avg Acc: 0.4957
2022-01-24 02:24:22,583 Epoch[019/050], Step[0550/1252], Avg Loss: 2.8782, Avg Acc: 0.4958
2022-01-24 02:25:49,954 Epoch[019/050], Step[0600/1252], Avg Loss: 2.8779, Avg Acc: 0.4943
2022-01-24 02:27:17,142 Epoch[019/050], Step[0650/1252], Avg Loss: 2.8808, Avg Acc: 0.4944
2022-01-24 02:28:44,797 Epoch[019/050], Step[0700/1252], Avg Loss: 2.8823, Avg Acc: 0.4941
2022-01-24 02:30:11,560 Epoch[019/050], Step[0750/1252], Avg Loss: 2.8839, Avg Acc: 0.4942
2022-01-24 02:31:39,338 Epoch[019/050], Step[0800/1252], Avg Loss: 2.8852, Avg Acc: 0.4919
2022-01-24 02:33:06,800 Epoch[019/050], Step[0850/1252], Avg Loss: 2.8816, Avg Acc: 0.4901
2022-01-24 02:34:35,200 Epoch[019/050], Step[0900/1252], Avg Loss: 2.8796, Avg Acc: 0.4898
2022-01-24 02:36:02,876 Epoch[019/050], Step[0950/1252], Avg Loss: 2.8802, Avg Acc: 0.4894
2022-01-24 02:37:30,940 Epoch[019/050], Step[1000/1252], Avg Loss: 2.8817, Avg Acc: 0.4877
2022-01-24 02:38:57,869 Epoch[019/050], Step[1050/1252], Avg Loss: 2.8826, Avg Acc: 0.4884
2022-01-24 02:40:25,724 Epoch[019/050], Step[1100/1252], Avg Loss: 2.8871, Avg Acc: 0.4879
2022-01-24 02:41:52,415 Epoch[019/050], Step[1150/1252], Avg Loss: 2.8862, Avg Acc: 0.4880
2022-01-24 02:43:18,129 Epoch[019/050], Step[1200/1252], Avg Loss: 2.8875, Avg Acc: 0.4880
2022-01-24 02:44:45,934 Epoch[019/050], Step[1250/1252], Avg Loss: 2.8887, Avg Acc: 0.4876
2022-01-24 02:44:52,953 ----- Epoch[019/050], Train Loss: 2.8887, Train Acc: 0.4876, time: 2302.03, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 02:44:52,954 Now training epoch 20. LR=0.000007
2022-01-24 02:46:35,938 Epoch[020/050], Step[0000/1252], Avg Loss: 2.8698, Avg Acc: 0.3867
2022-01-24 02:48:02,798 Epoch[020/050], Step[0050/1252], Avg Loss: 2.8945, Avg Acc: 0.4876
2022-01-24 02:49:30,448 Epoch[020/050], Step[0100/1252], Avg Loss: 2.9101, Avg Acc: 0.4783
2022-01-24 02:50:56,606 Epoch[020/050], Step[0150/1252], Avg Loss: 2.9032, Avg Acc: 0.4847
2022-01-24 02:52:23,639 Epoch[020/050], Step[0200/1252], Avg Loss: 2.9069, Avg Acc: 0.4915
2022-01-24 02:53:51,656 Epoch[020/050], Step[0250/1252], Avg Loss: 2.8924, Avg Acc: 0.4944
2022-01-24 02:55:17,924 Epoch[020/050], Step[0300/1252], Avg Loss: 2.8900, Avg Acc: 0.4941
2022-01-24 02:56:43,827 Epoch[020/050], Step[0350/1252], Avg Loss: 2.8939, Avg Acc: 0.4893
2022-01-24 02:58:11,013 Epoch[020/050], Step[0400/1252], Avg Loss: 2.8971, Avg Acc: 0.4887
2022-01-24 02:59:39,172 Epoch[020/050], Step[0450/1252], Avg Loss: 2.8943, Avg Acc: 0.4874
2022-01-24 03:01:06,877 Epoch[020/050], Step[0500/1252], Avg Loss: 2.8996, Avg Acc: 0.4860
2022-01-24 03:02:32,562 Epoch[020/050], Step[0550/1252], Avg Loss: 2.9017, Avg Acc: 0.4866
2022-01-24 03:03:59,982 Epoch[020/050], Step[0600/1252], Avg Loss: 2.9010, Avg Acc: 0.4873
2022-01-24 03:05:27,627 Epoch[020/050], Step[0650/1252], Avg Loss: 2.8985, Avg Acc: 0.4850
2022-01-24 03:06:53,616 Epoch[020/050], Step[0700/1252], Avg Loss: 2.8935, Avg Acc: 0.4847
2022-01-24 03:08:21,041 Epoch[020/050], Step[0750/1252], Avg Loss: 2.8944, Avg Acc: 0.4817
2022-01-24 03:09:47,972 Epoch[020/050], Step[0800/1252], Avg Loss: 2.8935, Avg Acc: 0.4823
2022-01-24 03:11:15,444 Epoch[020/050], Step[0850/1252], Avg Loss: 2.8952, Avg Acc: 0.4832
2022-01-24 03:12:42,776 Epoch[020/050], Step[0900/1252], Avg Loss: 2.8934, Avg Acc: 0.4838
2022-01-24 03:14:09,164 Epoch[020/050], Step[0950/1252], Avg Loss: 2.8971, Avg Acc: 0.4817
2022-01-24 03:15:36,464 Epoch[020/050], Step[1000/1252], Avg Loss: 2.8953, Avg Acc: 0.4827
2022-01-24 03:17:04,406 Epoch[020/050], Step[1050/1252], Avg Loss: 2.8957, Avg Acc: 0.4820
2022-01-24 03:18:31,579 Epoch[020/050], Step[1100/1252], Avg Loss: 2.8939, Avg Acc: 0.4829
2022-01-24 03:19:58,797 Epoch[020/050], Step[1150/1252], Avg Loss: 2.8926, Avg Acc: 0.4846
2022-01-24 03:21:26,860 Epoch[020/050], Step[1200/1252], Avg Loss: 2.8937, Avg Acc: 0.4842
2022-01-24 03:22:53,905 Epoch[020/050], Step[1250/1252], Avg Loss: 2.8926, Avg Acc: 0.4845
2022-01-24 03:23:01,029 ----- Epoch[020/050], Train Loss: 2.8926, Train Acc: 0.4845, time: 2288.07, Best Val(epoch14) Acc@1: 0.7757
2022-01-24 03:23:01,029 ----- Validation after Epoch: 20
2022-01-24 03:24:11,172 Val Step[0000/1563], Avg Loss: 0.8312, Avg Acc@1: 0.7812, Avg Acc@5: 1.0000
2022-01-24 03:24:13,170 Val Step[0050/1563], Avg Loss: 1.0008, Avg Acc@1: 0.7800, Avg Acc@5: 0.9418
2022-01-24 03:24:15,001 Val Step[0100/1563], Avg Loss: 1.0313, Avg Acc@1: 0.7822, Avg Acc@5: 0.9381
2022-01-24 03:24:16,941 Val Step[0150/1563], Avg Loss: 1.0340, Avg Acc@1: 0.7819, Avg Acc@5: 0.9363
2022-01-24 03:24:18,787 Val Step[0200/1563], Avg Loss: 1.0346, Avg Acc@1: 0.7820, Avg Acc@5: 0.9358
2022-01-24 03:24:20,733 Val Step[0250/1563], Avg Loss: 1.0245, Avg Acc@1: 0.7816, Avg Acc@5: 0.9376
2022-01-24 03:24:22,659 Val Step[0300/1563], Avg Loss: 1.0244, Avg Acc@1: 0.7820, Avg Acc@5: 0.9366
2022-01-24 03:24:24,559 Val Step[0350/1563], Avg Loss: 1.0287, Avg Acc@1: 0.7815, Avg Acc@5: 0.9363
2022-01-24 03:24:26,450 Val Step[0400/1563], Avg Loss: 1.0282, Avg Acc@1: 0.7823, Avg Acc@5: 0.9361
2022-01-24 03:24:28,392 Val Step[0450/1563], Avg Loss: 1.0329, Avg Acc@1: 0.7794, Avg Acc@5: 0.9360
2022-01-24 03:24:30,331 Val Step[0500/1563], Avg Loss: 1.0358, Avg Acc@1: 0.7788, Avg Acc@5: 0.9364
2022-01-24 03:24:32,230 Val Step[0550/1563], Avg Loss: 1.0348, Avg Acc@1: 0.7780, Avg Acc@5: 0.9366
2022-01-24 03:24:34,110 Val Step[0600/1563], Avg Loss: 1.0335, Avg Acc@1: 0.7782, Avg Acc@5: 0.9367
2022-01-24 03:24:35,964 Val Step[0650/1563], Avg Loss: 1.0338, Avg Acc@1: 0.7781, Avg Acc@5: 0.9369
2022-01-24 03:24:37,925 Val Step[0700/1563], Avg Loss: 1.0317, Avg Acc@1: 0.7784, Avg Acc@5: 0.9375
2022-01-24 03:24:40,010 Val Step[0750/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7763, Avg Acc@5: 0.9371
2022-01-24 03:24:42,076 Val Step[0800/1563], Avg Loss: 1.0379, Avg Acc@1: 0.7770, Avg Acc@5: 0.9368
2022-01-24 03:24:44,094 Val Step[0850/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7768, Avg Acc@5: 0.9366
2022-01-24 03:24:46,092 Val Step[0900/1563], Avg Loss: 1.0363, Avg Acc@1: 0.7773, Avg Acc@5: 0.9370
2022-01-24 03:24:48,104 Val Step[0950/1563], Avg Loss: 1.0359, Avg Acc@1: 0.7778, Avg Acc@5: 0.9371
2022-01-24 03:24:50,168 Val Step[1000/1563], Avg Loss: 1.0376, Avg Acc@1: 0.7773, Avg Acc@5: 0.9369
2022-01-24 03:24:52,257 Val Step[1050/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7768, Avg Acc@5: 0.9365
2022-01-24 03:24:54,189 Val Step[1100/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7762, Avg Acc@5: 0.9366
2022-01-24 03:24:56,022 Val Step[1150/1563], Avg Loss: 1.0374, Avg Acc@1: 0.7766, Avg Acc@5: 0.9370
2022-01-24 03:24:57,929 Val Step[1200/1563], Avg Loss: 1.0364, Avg Acc@1: 0.7772, Avg Acc@5: 0.9370
2022-01-24 03:24:59,808 Val Step[1250/1563], Avg Loss: 1.0361, Avg Acc@1: 0.7768, Avg Acc@5: 0.9373
2022-01-24 03:25:01,622 Val Step[1300/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7766, Avg Acc@5: 0.9369
2022-01-24 03:25:03,468 Val Step[1350/1563], Avg Loss: 1.0407, Avg Acc@1: 0.7762, Avg Acc@5: 0.9369
2022-01-24 03:25:05,371 Val Step[1400/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7760, Avg Acc@5: 0.9368
2022-01-24 03:25:07,174 Val Step[1450/1563], Avg Loss: 1.0389, Avg Acc@1: 0.7762, Avg Acc@5: 0.9369
2022-01-24 03:25:08,989 Val Step[1500/1563], Avg Loss: 1.0388, Avg Acc@1: 0.7763, Avg Acc@5: 0.9372
2022-01-24 03:25:10,777 Val Step[1550/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7761, Avg Acc@5: 0.9371
2022-01-24 03:25:12,620 ----- Epoch[020/050], Validation Loss: 1.0389, Validation Acc@1: 0.7761, Validation Acc@5: 0.9372, time: 131.59
2022-01-24 03:25:13,864 the pre best model acc:0.7757, at epoch 14
2022-01-24 03:25:13,865 current best model acc:0.7761, at epoch 20
2022-01-24 03:25:13,865 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 03:25:13,865 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 03:25:13,865 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 03:25:13,865 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 03:25:13,866 Now training epoch 21. LR=0.000007
2022-01-24 03:26:59,660 Epoch[021/050], Step[0000/1252], Avg Loss: 2.8585, Avg Acc: 0.6855
2022-01-24 03:28:27,072 Epoch[021/050], Step[0050/1252], Avg Loss: 2.8893, Avg Acc: 0.4662
2022-01-24 03:29:54,234 Epoch[021/050], Step[0100/1252], Avg Loss: 2.8824, Avg Acc: 0.4999
2022-01-24 03:31:20,926 Epoch[021/050], Step[0150/1252], Avg Loss: 2.8783, Avg Acc: 0.4968
2022-01-24 03:32:47,356 Epoch[021/050], Step[0200/1252], Avg Loss: 2.9080, Avg Acc: 0.4926
2022-01-24 03:34:15,343 Epoch[021/050], Step[0250/1252], Avg Loss: 2.9043, Avg Acc: 0.4987
2022-01-24 03:35:42,548 Epoch[021/050], Step[0300/1252], Avg Loss: 2.9091, Avg Acc: 0.5018
2022-01-24 03:37:08,570 Epoch[021/050], Step[0350/1252], Avg Loss: 2.9016, Avg Acc: 0.5017
2022-01-24 03:38:35,997 Epoch[021/050], Step[0400/1252], Avg Loss: 2.9038, Avg Acc: 0.5038
2022-01-24 03:40:02,628 Epoch[021/050], Step[0450/1252], Avg Loss: 2.9008, Avg Acc: 0.5020
2022-01-24 03:41:29,236 Epoch[021/050], Step[0500/1252], Avg Loss: 2.8932, Avg Acc: 0.5003
2022-01-24 03:42:55,982 Epoch[021/050], Step[0550/1252], Avg Loss: 2.8916, Avg Acc: 0.5014
2022-01-24 03:44:23,070 Epoch[021/050], Step[0600/1252], Avg Loss: 2.8881, Avg Acc: 0.5001
2022-01-24 03:45:50,417 Epoch[021/050], Step[0650/1252], Avg Loss: 2.8916, Avg Acc: 0.4984
2022-01-24 03:47:18,068 Epoch[021/050], Step[0700/1252], Avg Loss: 2.8903, Avg Acc: 0.4974
2022-01-24 03:48:45,312 Epoch[021/050], Step[0750/1252], Avg Loss: 2.8926, Avg Acc: 0.4975
2022-01-24 03:50:12,603 Epoch[021/050], Step[0800/1252], Avg Loss: 2.8928, Avg Acc: 0.4982
2022-01-24 03:51:39,154 Epoch[021/050], Step[0850/1252], Avg Loss: 2.8895, Avg Acc: 0.4990
2022-01-24 03:53:05,612 Epoch[021/050], Step[0900/1252], Avg Loss: 2.8881, Avg Acc: 0.4977
2022-01-24 03:54:29,906 Epoch[021/050], Step[0950/1252], Avg Loss: 2.8874, Avg Acc: 0.4983
2022-01-24 03:55:56,735 Epoch[021/050], Step[1000/1252], Avg Loss: 2.8873, Avg Acc: 0.4969
2022-01-24 03:57:23,749 Epoch[021/050], Step[1050/1252], Avg Loss: 2.8883, Avg Acc: 0.4969
2022-01-24 03:58:51,600 Epoch[021/050], Step[1100/1252], Avg Loss: 2.8897, Avg Acc: 0.4963
2022-01-24 04:00:18,329 Epoch[021/050], Step[1150/1252], Avg Loss: 2.8910, Avg Acc: 0.4954
2022-01-24 04:01:45,249 Epoch[021/050], Step[1200/1252], Avg Loss: 2.8880, Avg Acc: 0.4952
2022-01-24 04:03:12,342 Epoch[021/050], Step[1250/1252], Avg Loss: 2.8867, Avg Acc: 0.4939
2022-01-24 04:03:19,469 ----- Epoch[021/050], Train Loss: 2.8867, Train Acc: 0.4939, time: 2285.60, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 04:03:19,469 Now training epoch 22. LR=0.000007
2022-01-24 04:05:20,224 Epoch[022/050], Step[0000/1252], Avg Loss: 2.4551, Avg Acc: 0.7090
2022-01-24 04:06:46,081 Epoch[022/050], Step[0050/1252], Avg Loss: 2.8344, Avg Acc: 0.4989
2022-01-24 04:08:11,509 Epoch[022/050], Step[0100/1252], Avg Loss: 2.8693, Avg Acc: 0.5122
2022-01-24 04:09:37,210 Epoch[022/050], Step[0150/1252], Avg Loss: 2.8665, Avg Acc: 0.4987
2022-01-24 04:11:04,091 Epoch[022/050], Step[0200/1252], Avg Loss: 2.8712, Avg Acc: 0.4998
2022-01-24 04:12:30,139 Epoch[022/050], Step[0250/1252], Avg Loss: 2.8858, Avg Acc: 0.4983
2022-01-24 04:13:55,821 Epoch[022/050], Step[0300/1252], Avg Loss: 2.8866, Avg Acc: 0.5021
2022-01-24 04:15:23,144 Epoch[022/050], Step[0350/1252], Avg Loss: 2.8864, Avg Acc: 0.4993
2022-01-24 04:16:49,240 Epoch[022/050], Step[0400/1252], Avg Loss: 2.8972, Avg Acc: 0.4960
2022-01-24 04:18:16,035 Epoch[022/050], Step[0450/1252], Avg Loss: 2.8994, Avg Acc: 0.4962
2022-01-24 04:19:42,736 Epoch[022/050], Step[0500/1252], Avg Loss: 2.8965, Avg Acc: 0.4957
2022-01-24 04:21:10,160 Epoch[022/050], Step[0550/1252], Avg Loss: 2.9011, Avg Acc: 0.4952
2022-01-24 04:22:36,628 Epoch[022/050], Step[0600/1252], Avg Loss: 2.8997, Avg Acc: 0.4928
2022-01-24 04:24:04,284 Epoch[022/050], Step[0650/1252], Avg Loss: 2.8999, Avg Acc: 0.4931
2022-01-24 04:25:31,637 Epoch[022/050], Step[0700/1252], Avg Loss: 2.8926, Avg Acc: 0.4927
2022-01-24 04:26:56,841 Epoch[022/050], Step[0750/1252], Avg Loss: 2.8926, Avg Acc: 0.4918
2022-01-24 04:28:23,964 Epoch[022/050], Step[0800/1252], Avg Loss: 2.8890, Avg Acc: 0.4919
2022-01-24 04:29:52,556 Epoch[022/050], Step[0850/1252], Avg Loss: 2.8911, Avg Acc: 0.4910
2022-01-24 04:31:19,735 Epoch[022/050], Step[0900/1252], Avg Loss: 2.8931, Avg Acc: 0.4903
2022-01-24 04:32:47,802 Epoch[022/050], Step[0950/1252], Avg Loss: 2.8915, Avg Acc: 0.4905
2022-01-24 04:34:14,930 Epoch[022/050], Step[1000/1252], Avg Loss: 2.8924, Avg Acc: 0.4890
2022-01-24 04:35:42,365 Epoch[022/050], Step[1050/1252], Avg Loss: 2.8925, Avg Acc: 0.4894
2022-01-24 04:37:10,884 Epoch[022/050], Step[1100/1252], Avg Loss: 2.8919, Avg Acc: 0.4908
2022-01-24 04:38:38,701 Epoch[022/050], Step[1150/1252], Avg Loss: 2.8894, Avg Acc: 0.4912
2022-01-24 04:40:06,826 Epoch[022/050], Step[1200/1252], Avg Loss: 2.8885, Avg Acc: 0.4914
2022-01-24 04:41:35,760 Epoch[022/050], Step[1250/1252], Avg Loss: 2.8911, Avg Acc: 0.4909
2022-01-24 04:41:42,948 ----- Epoch[022/050], Train Loss: 2.8911, Train Acc: 0.4909, time: 2303.48, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 04:41:42,949 ----- Validation after Epoch: 22
2022-01-24 04:42:48,978 Val Step[0000/1563], Avg Loss: 0.8208, Avg Acc@1: 0.8438, Avg Acc@5: 1.0000
2022-01-24 04:42:51,122 Val Step[0050/1563], Avg Loss: 1.0151, Avg Acc@1: 0.7794, Avg Acc@5: 0.9430
2022-01-24 04:42:52,901 Val Step[0100/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7834, Avg Acc@5: 0.9390
2022-01-24 04:42:54,684 Val Step[0150/1563], Avg Loss: 1.0497, Avg Acc@1: 0.7833, Avg Acc@5: 0.9363
2022-01-24 04:42:56,492 Val Step[0200/1563], Avg Loss: 1.0499, Avg Acc@1: 0.7831, Avg Acc@5: 0.9367
2022-01-24 04:42:58,283 Val Step[0250/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7819, Avg Acc@5: 0.9381
2022-01-24 04:43:00,079 Val Step[0300/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7820, Avg Acc@5: 0.9367
2022-01-24 04:43:01,879 Val Step[0350/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7805, Avg Acc@5: 0.9363
2022-01-24 04:43:03,669 Val Step[0400/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7809, Avg Acc@5: 0.9363
2022-01-24 04:43:05,491 Val Step[0450/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7784, Avg Acc@5: 0.9358
2022-01-24 04:43:07,390 Val Step[0500/1563], Avg Loss: 1.0514, Avg Acc@1: 0.7778, Avg Acc@5: 0.9362
2022-01-24 04:43:09,223 Val Step[0550/1563], Avg Loss: 1.0503, Avg Acc@1: 0.7772, Avg Acc@5: 0.9364
2022-01-24 04:43:11,042 Val Step[0600/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7773, Avg Acc@5: 0.9365
2022-01-24 04:43:12,840 Val Step[0650/1563], Avg Loss: 1.0488, Avg Acc@1: 0.7771, Avg Acc@5: 0.9369
2022-01-24 04:43:14,687 Val Step[0700/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7773, Avg Acc@5: 0.9374
2022-01-24 04:43:16,556 Val Step[0750/1563], Avg Loss: 1.0528, Avg Acc@1: 0.7755, Avg Acc@5: 0.9370
2022-01-24 04:43:18,388 Val Step[0800/1563], Avg Loss: 1.0527, Avg Acc@1: 0.7761, Avg Acc@5: 0.9370
2022-01-24 04:43:20,242 Val Step[0850/1563], Avg Loss: 1.0543, Avg Acc@1: 0.7759, Avg Acc@5: 0.9369
2022-01-24 04:43:22,086 Val Step[0900/1563], Avg Loss: 1.0514, Avg Acc@1: 0.7762, Avg Acc@5: 0.9372
2022-01-24 04:43:23,961 Val Step[0950/1563], Avg Loss: 1.0511, Avg Acc@1: 0.7768, Avg Acc@5: 0.9373
2022-01-24 04:43:25,787 Val Step[1000/1563], Avg Loss: 1.0528, Avg Acc@1: 0.7765, Avg Acc@5: 0.9370
2022-01-24 04:43:27,592 Val Step[1050/1563], Avg Loss: 1.0546, Avg Acc@1: 0.7757, Avg Acc@5: 0.9368
2022-01-24 04:43:29,389 Val Step[1100/1563], Avg Loss: 1.0548, Avg Acc@1: 0.7751, Avg Acc@5: 0.9369
2022-01-24 04:43:31,227 Val Step[1150/1563], Avg Loss: 1.0522, Avg Acc@1: 0.7756, Avg Acc@5: 0.9372
2022-01-24 04:43:33,115 Val Step[1200/1563], Avg Loss: 1.0513, Avg Acc@1: 0.7763, Avg Acc@5: 0.9372
2022-01-24 04:43:35,032 Val Step[1250/1563], Avg Loss: 1.0512, Avg Acc@1: 0.7758, Avg Acc@5: 0.9375
2022-01-24 04:43:36,897 Val Step[1300/1563], Avg Loss: 1.0543, Avg Acc@1: 0.7757, Avg Acc@5: 0.9371
2022-01-24 04:43:38,719 Val Step[1350/1563], Avg Loss: 1.0557, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-24 04:43:40,567 Val Step[1400/1563], Avg Loss: 1.0553, Avg Acc@1: 0.7747, Avg Acc@5: 0.9370
2022-01-24 04:43:42,368 Val Step[1450/1563], Avg Loss: 1.0543, Avg Acc@1: 0.7751, Avg Acc@5: 0.9370
2022-01-24 04:43:44,262 Val Step[1500/1563], Avg Loss: 1.0543, Avg Acc@1: 0.7753, Avg Acc@5: 0.9372
2022-01-24 04:43:46,285 Val Step[1550/1563], Avg Loss: 1.0547, Avg Acc@1: 0.7749, Avg Acc@5: 0.9373
2022-01-24 04:43:48,313 ----- Epoch[022/050], Validation Loss: 1.0545, Validation Acc@1: 0.7750, Validation Acc@5: 0.9373, time: 125.36
2022-01-24 04:43:48,313 Now training epoch 23. LR=0.000006
2022-01-24 04:45:36,959 Epoch[023/050], Step[0000/1252], Avg Loss: 2.6163, Avg Acc: 0.6289
2022-01-24 04:47:04,236 Epoch[023/050], Step[0050/1252], Avg Loss: 2.8460, Avg Acc: 0.4777
2022-01-24 04:48:31,305 Epoch[023/050], Step[0100/1252], Avg Loss: 2.8799, Avg Acc: 0.4755
2022-01-24 04:49:59,813 Epoch[023/050], Step[0150/1252], Avg Loss: 2.8627, Avg Acc: 0.4817
2022-01-24 04:51:27,525 Epoch[023/050], Step[0200/1252], Avg Loss: 2.8765, Avg Acc: 0.4830
2022-01-24 04:52:55,876 Epoch[023/050], Step[0250/1252], Avg Loss: 2.8769, Avg Acc: 0.4804
2022-01-24 04:54:23,074 Epoch[023/050], Step[0300/1252], Avg Loss: 2.8890, Avg Acc: 0.4821
2022-01-24 04:55:51,342 Epoch[023/050], Step[0350/1252], Avg Loss: 2.8829, Avg Acc: 0.4818
2022-01-24 04:57:18,752 Epoch[023/050], Step[0400/1252], Avg Loss: 2.8780, Avg Acc: 0.4832
2022-01-24 04:58:46,972 Epoch[023/050], Step[0450/1252], Avg Loss: 2.8809, Avg Acc: 0.4827
2022-01-24 05:00:14,756 Epoch[023/050], Step[0500/1252], Avg Loss: 2.8855, Avg Acc: 0.4856
2022-01-24 05:01:41,750 Epoch[023/050], Step[0550/1252], Avg Loss: 2.8870, Avg Acc: 0.4886
2022-01-24 05:03:09,800 Epoch[023/050], Step[0600/1252], Avg Loss: 2.8844, Avg Acc: 0.4862
2022-01-24 05:04:37,933 Epoch[023/050], Step[0650/1252], Avg Loss: 2.8865, Avg Acc: 0.4850
2022-01-24 05:06:05,614 Epoch[023/050], Step[0700/1252], Avg Loss: 2.8847, Avg Acc: 0.4876
2022-01-24 05:07:32,336 Epoch[023/050], Step[0750/1252], Avg Loss: 2.8827, Avg Acc: 0.4892
2022-01-24 05:08:58,777 Epoch[023/050], Step[0800/1252], Avg Loss: 2.8837, Avg Acc: 0.4894
2022-01-24 05:10:25,280 Epoch[023/050], Step[0850/1252], Avg Loss: 2.8822, Avg Acc: 0.4909
2022-01-24 05:11:52,822 Epoch[023/050], Step[0900/1252], Avg Loss: 2.8781, Avg Acc: 0.4928
2022-01-24 05:13:20,444 Epoch[023/050], Step[0950/1252], Avg Loss: 2.8782, Avg Acc: 0.4920
2022-01-24 05:14:48,676 Epoch[023/050], Step[1000/1252], Avg Loss: 2.8782, Avg Acc: 0.4915
2022-01-24 05:16:16,681 Epoch[023/050], Step[1050/1252], Avg Loss: 2.8797, Avg Acc: 0.4896
2022-01-24 05:17:43,990 Epoch[023/050], Step[1100/1252], Avg Loss: 2.8814, Avg Acc: 0.4876
2022-01-24 05:19:11,269 Epoch[023/050], Step[1150/1252], Avg Loss: 2.8845, Avg Acc: 0.4872
2022-01-24 05:20:39,695 Epoch[023/050], Step[1200/1252], Avg Loss: 2.8855, Avg Acc: 0.4872
2022-01-24 05:22:08,370 Epoch[023/050], Step[1250/1252], Avg Loss: 2.8870, Avg Acc: 0.4868
2022-01-24 05:22:15,477 ----- Epoch[023/050], Train Loss: 2.8870, Train Acc: 0.4868, time: 2307.16, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 05:22:15,477 Now training epoch 24. LR=0.000006
2022-01-24 05:24:01,537 Epoch[024/050], Step[0000/1252], Avg Loss: 2.3434, Avg Acc: 0.1621
2022-01-24 05:25:29,876 Epoch[024/050], Step[0050/1252], Avg Loss: 2.8946, Avg Acc: 0.4957
2022-01-24 05:26:57,137 Epoch[024/050], Step[0100/1252], Avg Loss: 2.8865, Avg Acc: 0.4773
2022-01-24 05:28:24,570 Epoch[024/050], Step[0150/1252], Avg Loss: 2.8733, Avg Acc: 0.4938
2022-01-24 05:29:51,747 Epoch[024/050], Step[0200/1252], Avg Loss: 2.8674, Avg Acc: 0.4948
2022-01-24 05:31:19,472 Epoch[024/050], Step[0250/1252], Avg Loss: 2.8684, Avg Acc: 0.4826
2022-01-24 05:32:47,108 Epoch[024/050], Step[0300/1252], Avg Loss: 2.8784, Avg Acc: 0.4812
2022-01-24 05:34:13,841 Epoch[024/050], Step[0350/1252], Avg Loss: 2.8717, Avg Acc: 0.4882
2022-01-24 05:35:42,065 Epoch[024/050], Step[0400/1252], Avg Loss: 2.8698, Avg Acc: 0.4930
2022-01-24 05:37:10,732 Epoch[024/050], Step[0450/1252], Avg Loss: 2.8733, Avg Acc: 0.4917
2022-01-24 05:38:37,619 Epoch[024/050], Step[0500/1252], Avg Loss: 2.8787, Avg Acc: 0.4901
2022-01-24 05:40:05,386 Epoch[024/050], Step[0550/1252], Avg Loss: 2.8799, Avg Acc: 0.4910
2022-01-24 05:41:32,470 Epoch[024/050], Step[0600/1252], Avg Loss: 2.8782, Avg Acc: 0.4920
2022-01-24 05:43:00,014 Epoch[024/050], Step[0650/1252], Avg Loss: 2.8751, Avg Acc: 0.4908
2022-01-24 05:44:27,395 Epoch[024/050], Step[0700/1252], Avg Loss: 2.8778, Avg Acc: 0.4918
2022-01-24 05:45:55,175 Epoch[024/050], Step[0750/1252], Avg Loss: 2.8753, Avg Acc: 0.4919
2022-01-24 05:47:22,004 Epoch[024/050], Step[0800/1252], Avg Loss: 2.8740, Avg Acc: 0.4895
2022-01-24 05:48:49,049 Epoch[024/050], Step[0850/1252], Avg Loss: 2.8739, Avg Acc: 0.4900
2022-01-24 05:50:16,228 Epoch[024/050], Step[0900/1252], Avg Loss: 2.8765, Avg Acc: 0.4869
2022-01-24 05:51:43,357 Epoch[024/050], Step[0950/1252], Avg Loss: 2.8784, Avg Acc: 0.4869
2022-01-24 05:53:11,426 Epoch[024/050], Step[1000/1252], Avg Loss: 2.8759, Avg Acc: 0.4871
2022-01-24 05:54:38,869 Epoch[024/050], Step[1050/1252], Avg Loss: 2.8784, Avg Acc: 0.4848
2022-01-24 05:56:07,384 Epoch[024/050], Step[1100/1252], Avg Loss: 2.8765, Avg Acc: 0.4880
2022-01-24 05:57:33,373 Epoch[024/050], Step[1150/1252], Avg Loss: 2.8770, Avg Acc: 0.4896
2022-01-24 05:59:00,914 Epoch[024/050], Step[1200/1252], Avg Loss: 2.8796, Avg Acc: 0.4880
2022-01-24 06:00:29,492 Epoch[024/050], Step[1250/1252], Avg Loss: 2.8819, Avg Acc: 0.4884
2022-01-24 06:00:36,797 ----- Epoch[024/050], Train Loss: 2.8819, Train Acc: 0.4884, time: 2301.32, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 06:00:36,797 ----- Validation after Epoch: 24
2022-01-24 06:01:49,708 Val Step[0000/1563], Avg Loss: 0.8334, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 06:01:51,586 Val Step[0050/1563], Avg Loss: 1.0090, Avg Acc@1: 0.7819, Avg Acc@5: 0.9387
2022-01-24 06:01:53,373 Val Step[0100/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7816, Avg Acc@5: 0.9372
2022-01-24 06:01:55,155 Val Step[0150/1563], Avg Loss: 1.0446, Avg Acc@1: 0.7804, Avg Acc@5: 0.9358
2022-01-24 06:01:56,954 Val Step[0200/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7819, Avg Acc@5: 0.9364
2022-01-24 06:01:58,824 Val Step[0250/1563], Avg Loss: 1.0343, Avg Acc@1: 0.7801, Avg Acc@5: 0.9380
2022-01-24 06:02:01,021 Val Step[0300/1563], Avg Loss: 1.0343, Avg Acc@1: 0.7800, Avg Acc@5: 0.9372
2022-01-24 06:02:03,071 Val Step[0350/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7796, Avg Acc@5: 0.9368
2022-01-24 06:02:05,141 Val Step[0400/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7802, Avg Acc@5: 0.9365
2022-01-24 06:02:07,191 Val Step[0450/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7782, Avg Acc@5: 0.9360
2022-01-24 06:02:09,215 Val Step[0500/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7773, Avg Acc@5: 0.9364
2022-01-24 06:02:11,245 Val Step[0550/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7763, Avg Acc@5: 0.9366
2022-01-24 06:02:13,242 Val Step[0600/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7766, Avg Acc@5: 0.9368
2022-01-24 06:02:15,247 Val Step[0650/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7764, Avg Acc@5: 0.9371
2022-01-24 06:02:17,266 Val Step[0700/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7771, Avg Acc@5: 0.9376
2022-01-24 06:02:19,334 Val Step[0750/1563], Avg Loss: 1.0472, Avg Acc@1: 0.7748, Avg Acc@5: 0.9373
2022-01-24 06:02:21,408 Val Step[0800/1563], Avg Loss: 1.0470, Avg Acc@1: 0.7757, Avg Acc@5: 0.9373
2022-01-24 06:02:23,453 Val Step[0850/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7757, Avg Acc@5: 0.9372
2022-01-24 06:02:25,483 Val Step[0900/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7761, Avg Acc@5: 0.9375
2022-01-24 06:02:27,503 Val Step[0950/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7769, Avg Acc@5: 0.9378
2022-01-24 06:02:29,514 Val Step[1000/1563], Avg Loss: 1.0467, Avg Acc@1: 0.7767, Avg Acc@5: 0.9374
2022-01-24 06:02:31,550 Val Step[1050/1563], Avg Loss: 1.0486, Avg Acc@1: 0.7759, Avg Acc@5: 0.9371
2022-01-24 06:02:33,554 Val Step[1100/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7754, Avg Acc@5: 0.9372
2022-01-24 06:02:35,570 Val Step[1150/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7757, Avg Acc@5: 0.9375
2022-01-24 06:02:37,600 Val Step[1200/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7764, Avg Acc@5: 0.9375
2022-01-24 06:02:39,643 Val Step[1250/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7762, Avg Acc@5: 0.9378
2022-01-24 06:02:41,709 Val Step[1300/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7763, Avg Acc@5: 0.9374
2022-01-24 06:02:43,766 Val Step[1350/1563], Avg Loss: 1.0496, Avg Acc@1: 0.7758, Avg Acc@5: 0.9373
2022-01-24 06:02:45,809 Val Step[1400/1563], Avg Loss: 1.0492, Avg Acc@1: 0.7755, Avg Acc@5: 0.9373
2022-01-24 06:02:47,855 Val Step[1450/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7760, Avg Acc@5: 0.9373
2022-01-24 06:02:49,893 Val Step[1500/1563], Avg Loss: 1.0480, Avg Acc@1: 0.7761, Avg Acc@5: 0.9375
2022-01-24 06:02:51,905 Val Step[1550/1563], Avg Loss: 1.0484, Avg Acc@1: 0.7759, Avg Acc@5: 0.9375
2022-01-24 06:02:53,749 ----- Epoch[024/050], Validation Loss: 1.0482, Validation Acc@1: 0.7758, Validation Acc@5: 0.9375, time: 136.95
2022-01-24 06:02:53,750 Now training epoch 25. LR=0.000006
2022-01-24 06:04:54,065 Epoch[025/050], Step[0000/1252], Avg Loss: 3.0690, Avg Acc: 0.4629
2022-01-24 06:06:20,851 Epoch[025/050], Step[0050/1252], Avg Loss: 2.8588, Avg Acc: 0.4798
2022-01-24 06:07:46,940 Epoch[025/050], Step[0100/1252], Avg Loss: 2.9035, Avg Acc: 0.4761
2022-01-24 06:09:14,975 Epoch[025/050], Step[0150/1252], Avg Loss: 2.9139, Avg Acc: 0.4807
2022-01-24 06:10:41,016 Epoch[025/050], Step[0200/1252], Avg Loss: 2.9145, Avg Acc: 0.4828
2022-01-24 06:12:08,177 Epoch[025/050], Step[0250/1252], Avg Loss: 2.9134, Avg Acc: 0.4801
2022-01-24 06:13:35,676 Epoch[025/050], Step[0300/1252], Avg Loss: 2.9080, Avg Acc: 0.4801
2022-01-24 06:15:02,791 Epoch[025/050], Step[0350/1252], Avg Loss: 2.9068, Avg Acc: 0.4809
2022-01-24 06:16:30,474 Epoch[025/050], Step[0400/1252], Avg Loss: 2.9095, Avg Acc: 0.4845
2022-01-24 06:17:57,910 Epoch[025/050], Step[0450/1252], Avg Loss: 2.9130, Avg Acc: 0.4870
2022-01-24 06:19:26,059 Epoch[025/050], Step[0500/1252], Avg Loss: 2.9074, Avg Acc: 0.4848
2022-01-24 06:20:53,788 Epoch[025/050], Step[0550/1252], Avg Loss: 2.8999, Avg Acc: 0.4862
2022-01-24 06:22:20,338 Epoch[025/050], Step[0600/1252], Avg Loss: 2.8965, Avg Acc: 0.4863
2022-01-24 06:23:47,417 Epoch[025/050], Step[0650/1252], Avg Loss: 2.8940, Avg Acc: 0.4857
2022-01-24 06:25:13,314 Epoch[025/050], Step[0700/1252], Avg Loss: 2.8936, Avg Acc: 0.4836
2022-01-24 06:26:40,030 Epoch[025/050], Step[0750/1252], Avg Loss: 2.8935, Avg Acc: 0.4833
2022-01-24 06:28:06,001 Epoch[025/050], Step[0800/1252], Avg Loss: 2.8986, Avg Acc: 0.4833
2022-01-24 06:29:33,007 Epoch[025/050], Step[0850/1252], Avg Loss: 2.9013, Avg Acc: 0.4826
2022-01-24 06:30:59,435 Epoch[025/050], Step[0900/1252], Avg Loss: 2.8994, Avg Acc: 0.4832
2022-01-24 06:32:26,718 Epoch[025/050], Step[0950/1252], Avg Loss: 2.8974, Avg Acc: 0.4834
2022-01-24 06:33:53,402 Epoch[025/050], Step[1000/1252], Avg Loss: 2.8956, Avg Acc: 0.4842
2022-01-24 06:35:19,576 Epoch[025/050], Step[1050/1252], Avg Loss: 2.8942, Avg Acc: 0.4843
2022-01-24 06:36:46,096 Epoch[025/050], Step[1100/1252], Avg Loss: 2.8979, Avg Acc: 0.4833
2022-01-24 06:38:12,017 Epoch[025/050], Step[1150/1252], Avg Loss: 2.8992, Avg Acc: 0.4843
2022-01-24 06:39:39,777 Epoch[025/050], Step[1200/1252], Avg Loss: 2.8985, Avg Acc: 0.4838
2022-01-24 06:41:08,420 Epoch[025/050], Step[1250/1252], Avg Loss: 2.9007, Avg Acc: 0.4841
2022-01-24 06:41:15,562 ----- Epoch[025/050], Train Loss: 2.9006, Train Acc: 0.4841, time: 2301.81, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 06:41:15,562 Now training epoch 26. LR=0.000005
2022-01-24 06:43:02,782 Epoch[026/050], Step[0000/1252], Avg Loss: 3.2572, Avg Acc: 0.5283
2022-01-24 06:44:29,439 Epoch[026/050], Step[0050/1252], Avg Loss: 2.9010, Avg Acc: 0.4996
2022-01-24 06:45:54,890 Epoch[026/050], Step[0100/1252], Avg Loss: 2.8854, Avg Acc: 0.4976
2022-01-24 06:47:20,970 Epoch[026/050], Step[0150/1252], Avg Loss: 2.8890, Avg Acc: 0.4829
2022-01-24 06:48:48,156 Epoch[026/050], Step[0200/1252], Avg Loss: 2.8880, Avg Acc: 0.4813
2022-01-24 06:50:13,959 Epoch[026/050], Step[0250/1252], Avg Loss: 2.8773, Avg Acc: 0.4842
2022-01-24 06:51:41,049 Epoch[026/050], Step[0300/1252], Avg Loss: 2.8781, Avg Acc: 0.4853
2022-01-24 06:53:07,838 Epoch[026/050], Step[0350/1252], Avg Loss: 2.8759, Avg Acc: 0.4878
2022-01-24 06:54:34,817 Epoch[026/050], Step[0400/1252], Avg Loss: 2.8851, Avg Acc: 0.4861
2022-01-24 06:56:01,779 Epoch[026/050], Step[0450/1252], Avg Loss: 2.8893, Avg Acc: 0.4838
2022-01-24 06:57:29,771 Epoch[026/050], Step[0500/1252], Avg Loss: 2.8923, Avg Acc: 0.4796
2022-01-24 06:58:55,924 Epoch[026/050], Step[0550/1252], Avg Loss: 2.8914, Avg Acc: 0.4818
2022-01-24 07:00:23,316 Epoch[026/050], Step[0600/1252], Avg Loss: 2.8918, Avg Acc: 0.4799
2022-01-24 07:01:50,432 Epoch[026/050], Step[0650/1252], Avg Loss: 2.8892, Avg Acc: 0.4787
2022-01-24 07:03:17,435 Epoch[026/050], Step[0700/1252], Avg Loss: 2.8883, Avg Acc: 0.4799
2022-01-24 07:04:44,852 Epoch[026/050], Step[0750/1252], Avg Loss: 2.8879, Avg Acc: 0.4813
2022-01-24 07:06:11,339 Epoch[026/050], Step[0800/1252], Avg Loss: 2.8904, Avg Acc: 0.4827
2022-01-24 07:07:39,143 Epoch[026/050], Step[0850/1252], Avg Loss: 2.8917, Avg Acc: 0.4819
2022-01-24 07:09:06,170 Epoch[026/050], Step[0900/1252], Avg Loss: 2.8962, Avg Acc: 0.4818
2022-01-24 07:10:33,287 Epoch[026/050], Step[0950/1252], Avg Loss: 2.8947, Avg Acc: 0.4802
2022-01-24 07:12:00,555 Epoch[026/050], Step[1000/1252], Avg Loss: 2.8957, Avg Acc: 0.4790
2022-01-24 07:13:28,296 Epoch[026/050], Step[1050/1252], Avg Loss: 2.8966, Avg Acc: 0.4790
2022-01-24 07:14:56,017 Epoch[026/050], Step[1100/1252], Avg Loss: 2.8970, Avg Acc: 0.4790
2022-01-24 07:16:23,604 Epoch[026/050], Step[1150/1252], Avg Loss: 2.8963, Avg Acc: 0.4802
2022-01-24 07:17:50,257 Epoch[026/050], Step[1200/1252], Avg Loss: 2.8930, Avg Acc: 0.4820
2022-01-24 07:19:18,588 Epoch[026/050], Step[1250/1252], Avg Loss: 2.8923, Avg Acc: 0.4832
2022-01-24 07:19:25,910 ----- Epoch[026/050], Train Loss: 2.8923, Train Acc: 0.4832, time: 2290.34, Best Val(epoch20) Acc@1: 0.7761
2022-01-24 07:19:25,910 ----- Validation after Epoch: 26
2022-01-24 07:20:30,659 Val Step[0000/1563], Avg Loss: 0.8272, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 07:20:32,522 Val Step[0050/1563], Avg Loss: 1.0009, Avg Acc@1: 0.7800, Avg Acc@5: 0.9424
2022-01-24 07:20:34,339 Val Step[0100/1563], Avg Loss: 1.0333, Avg Acc@1: 0.7828, Avg Acc@5: 0.9387
2022-01-24 07:20:36,176 Val Step[0150/1563], Avg Loss: 1.0366, Avg Acc@1: 0.7833, Avg Acc@5: 0.9371
2022-01-24 07:20:38,079 Val Step[0200/1563], Avg Loss: 1.0370, Avg Acc@1: 0.7844, Avg Acc@5: 0.9372
2022-01-24 07:20:39,894 Val Step[0250/1563], Avg Loss: 1.0268, Avg Acc@1: 0.7829, Avg Acc@5: 0.9384
2022-01-24 07:20:41,712 Val Step[0300/1563], Avg Loss: 1.0263, Avg Acc@1: 0.7829, Avg Acc@5: 0.9372
2022-01-24 07:20:43,514 Val Step[0350/1563], Avg Loss: 1.0313, Avg Acc@1: 0.7819, Avg Acc@5: 0.9363
2022-01-24 07:20:45,318 Val Step[0400/1563], Avg Loss: 1.0312, Avg Acc@1: 0.7827, Avg Acc@5: 0.9358
2022-01-24 07:20:47,123 Val Step[0450/1563], Avg Loss: 1.0358, Avg Acc@1: 0.7799, Avg Acc@5: 0.9357
2022-01-24 07:20:49,032 Val Step[0500/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7795, Avg Acc@5: 0.9361
2022-01-24 07:20:50,837 Val Step[0550/1563], Avg Loss: 1.0376, Avg Acc@1: 0.7786, Avg Acc@5: 0.9361
2022-01-24 07:20:52,628 Val Step[0600/1563], Avg Loss: 1.0361, Avg Acc@1: 0.7782, Avg Acc@5: 0.9363
2022-01-24 07:20:54,458 Val Step[0650/1563], Avg Loss: 1.0367, Avg Acc@1: 0.7782, Avg Acc@5: 0.9367
2022-01-24 07:20:56,290 Val Step[0700/1563], Avg Loss: 1.0345, Avg Acc@1: 0.7788, Avg Acc@5: 0.9374
2022-01-24 07:20:58,208 Val Step[0750/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7763, Avg Acc@5: 0.9369
2022-01-24 07:21:00,138 Val Step[0800/1563], Avg Loss: 1.0407, Avg Acc@1: 0.7771, Avg Acc@5: 0.9369
2022-01-24 07:21:01,968 Val Step[0850/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7769, Avg Acc@5: 0.9368
2022-01-24 07:21:03,748 Val Step[0900/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7772, Avg Acc@5: 0.9373
2022-01-24 07:21:05,528 Val Step[0950/1563], Avg Loss: 1.0386, Avg Acc@1: 0.7780, Avg Acc@5: 0.9374
2022-01-24 07:21:07,330 Val Step[1000/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7777, Avg Acc@5: 0.9371
2022-01-24 07:21:09,106 Val Step[1050/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7770, Avg Acc@5: 0.9367
2022-01-24 07:21:11,155 Val Step[1100/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7766, Avg Acc@5: 0.9370
2022-01-24 07:21:13,357 Val Step[1150/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7768, Avg Acc@5: 0.9373
2022-01-24 07:21:15,395 Val Step[1200/1563], Avg Loss: 1.0389, Avg Acc@1: 0.7774, Avg Acc@5: 0.9374
2022-01-24 07:21:17,283 Val Step[1250/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7770, Avg Acc@5: 0.9376
2022-01-24 07:21:19,065 Val Step[1300/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7767, Avg Acc@5: 0.9373
2022-01-24 07:21:20,906 Val Step[1350/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7761, Avg Acc@5: 0.9372
2022-01-24 07:21:22,733 Val Step[1400/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7759, Avg Acc@5: 0.9372
2022-01-24 07:21:24,558 Val Step[1450/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7762, Avg Acc@5: 0.9373
2022-01-24 07:21:26,383 Val Step[1500/1563], Avg Loss: 1.0412, Avg Acc@1: 0.7765, Avg Acc@5: 0.9374
2022-01-24 07:21:28,106 Val Step[1550/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7762, Avg Acc@5: 0.9372
2022-01-24 07:21:30,021 ----- Epoch[026/050], Validation Loss: 1.0416, Validation Acc@1: 0.7761, Validation Acc@5: 0.9373, time: 124.11
2022-01-24 07:21:31,277 the pre best model acc:0.7761, at epoch 20
2022-01-24 07:21:31,277 current best model acc:0.7761, at epoch 26
2022-01-24 07:21:31,278 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 07:21:31,278 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 07:21:31,278 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 07:21:31,278 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 07:21:31,278 Now training epoch 27. LR=0.000005
2022-01-24 07:23:18,658 Epoch[027/050], Step[0000/1252], Avg Loss: 3.3919, Avg Acc: 0.4443
2022-01-24 07:24:47,146 Epoch[027/050], Step[0050/1252], Avg Loss: 2.9311, Avg Acc: 0.5038
2022-01-24 07:26:13,835 Epoch[027/050], Step[0100/1252], Avg Loss: 2.9226, Avg Acc: 0.5086
2022-01-24 07:27:41,206 Epoch[027/050], Step[0150/1252], Avg Loss: 2.9088, Avg Acc: 0.5007
2022-01-24 07:29:08,172 Epoch[027/050], Step[0200/1252], Avg Loss: 2.8982, Avg Acc: 0.4907
2022-01-24 07:30:35,691 Epoch[027/050], Step[0250/1252], Avg Loss: 2.8970, Avg Acc: 0.4910
2022-01-24 07:32:03,108 Epoch[027/050], Step[0300/1252], Avg Loss: 2.9033, Avg Acc: 0.4912
2022-01-24 07:33:30,506 Epoch[027/050], Step[0350/1252], Avg Loss: 2.8948, Avg Acc: 0.4912
2022-01-24 07:34:57,145 Epoch[027/050], Step[0400/1252], Avg Loss: 2.8939, Avg Acc: 0.4885
2022-01-24 07:36:25,335 Epoch[027/050], Step[0450/1252], Avg Loss: 2.8878, Avg Acc: 0.4895
2022-01-24 07:37:52,975 Epoch[027/050], Step[0500/1252], Avg Loss: 2.8956, Avg Acc: 0.4874
2022-01-24 07:39:20,592 Epoch[027/050], Step[0550/1252], Avg Loss: 2.8958, Avg Acc: 0.4868
2022-01-24 07:40:48,567 Epoch[027/050], Step[0600/1252], Avg Loss: 2.8951, Avg Acc: 0.4851
2022-01-24 07:42:15,996 Epoch[027/050], Step[0650/1252], Avg Loss: 2.8980, Avg Acc: 0.4840
2022-01-24 07:43:42,876 Epoch[027/050], Step[0700/1252], Avg Loss: 2.8978, Avg Acc: 0.4862
2022-01-24 07:45:10,757 Epoch[027/050], Step[0750/1252], Avg Loss: 2.8984, Avg Acc: 0.4839
2022-01-24 07:46:38,975 Epoch[027/050], Step[0800/1252], Avg Loss: 2.9004, Avg Acc: 0.4812
2022-01-24 07:48:06,408 Epoch[027/050], Step[0850/1252], Avg Loss: 2.8989, Avg Acc: 0.4831
2022-01-24 07:49:34,634 Epoch[027/050], Step[0900/1252], Avg Loss: 2.8959, Avg Acc: 0.4844
2022-01-24 07:51:01,658 Epoch[027/050], Step[0950/1252], Avg Loss: 2.8971, Avg Acc: 0.4850
2022-01-24 07:52:28,170 Epoch[027/050], Step[1000/1252], Avg Loss: 2.8979, Avg Acc: 0.4857
2022-01-24 07:53:56,395 Epoch[027/050], Step[1050/1252], Avg Loss: 2.8973, Avg Acc: 0.4853
2022-01-24 07:55:24,628 Epoch[027/050], Step[1100/1252], Avg Loss: 2.8963, Avg Acc: 0.4865
2022-01-24 07:56:53,337 Epoch[027/050], Step[1150/1252], Avg Loss: 2.8942, Avg Acc: 0.4874
2022-01-24 07:58:20,394 Epoch[027/050], Step[1200/1252], Avg Loss: 2.8956, Avg Acc: 0.4878
2022-01-24 07:59:49,570 Epoch[027/050], Step[1250/1252], Avg Loss: 2.8930, Avg Acc: 0.4883
2022-01-24 07:59:56,850 ----- Epoch[027/050], Train Loss: 2.8930, Train Acc: 0.4883, time: 2305.57, Best Val(epoch26) Acc@1: 0.7761
2022-01-24 07:59:56,851 Now training epoch 28. LR=0.000005
2022-01-24 08:01:38,649 Epoch[028/050], Step[0000/1252], Avg Loss: 3.1307, Avg Acc: 0.5000
2022-01-24 08:03:05,683 Epoch[028/050], Step[0050/1252], Avg Loss: 2.9229, Avg Acc: 0.4829
2022-01-24 08:04:31,138 Epoch[028/050], Step[0100/1252], Avg Loss: 2.9038, Avg Acc: 0.4717
2022-01-24 08:05:57,777 Epoch[028/050], Step[0150/1252], Avg Loss: 2.8984, Avg Acc: 0.4710
2022-01-24 08:07:25,685 Epoch[028/050], Step[0200/1252], Avg Loss: 2.8949, Avg Acc: 0.4803
2022-01-24 08:08:52,991 Epoch[028/050], Step[0250/1252], Avg Loss: 2.8885, Avg Acc: 0.4821
2022-01-24 08:10:20,944 Epoch[028/050], Step[0300/1252], Avg Loss: 2.8887, Avg Acc: 0.4808
2022-01-24 08:11:48,234 Epoch[028/050], Step[0350/1252], Avg Loss: 2.8843, Avg Acc: 0.4840
2022-01-24 08:13:14,739 Epoch[028/050], Step[0400/1252], Avg Loss: 2.8778, Avg Acc: 0.4847
2022-01-24 08:14:41,957 Epoch[028/050], Step[0450/1252], Avg Loss: 2.8788, Avg Acc: 0.4836
2022-01-24 08:16:09,231 Epoch[028/050], Step[0500/1252], Avg Loss: 2.8759, Avg Acc: 0.4860
2022-01-24 08:17:35,682 Epoch[028/050], Step[0550/1252], Avg Loss: 2.8778, Avg Acc: 0.4889
2022-01-24 08:19:01,543 Epoch[028/050], Step[0600/1252], Avg Loss: 2.8845, Avg Acc: 0.4885
2022-01-24 08:20:28,220 Epoch[028/050], Step[0650/1252], Avg Loss: 2.8801, Avg Acc: 0.4889
2022-01-24 08:21:55,403 Epoch[028/050], Step[0700/1252], Avg Loss: 2.8804, Avg Acc: 0.4872
2022-01-24 08:23:22,638 Epoch[028/050], Step[0750/1252], Avg Loss: 2.8818, Avg Acc: 0.4882
2022-01-24 08:24:47,305 Epoch[028/050], Step[0800/1252], Avg Loss: 2.8811, Avg Acc: 0.4883
2022-01-24 08:26:14,428 Epoch[028/050], Step[0850/1252], Avg Loss: 2.8775, Avg Acc: 0.4890
2022-01-24 08:27:42,060 Epoch[028/050], Step[0900/1252], Avg Loss: 2.8812, Avg Acc: 0.4886
2022-01-24 08:29:08,965 Epoch[028/050], Step[0950/1252], Avg Loss: 2.8829, Avg Acc: 0.4887
2022-01-24 08:30:36,983 Epoch[028/050], Step[1000/1252], Avg Loss: 2.8846, Avg Acc: 0.4893
2022-01-24 08:32:04,104 Epoch[028/050], Step[1050/1252], Avg Loss: 2.8846, Avg Acc: 0.4895
2022-01-24 08:33:31,335 Epoch[028/050], Step[1100/1252], Avg Loss: 2.8837, Avg Acc: 0.4887
2022-01-24 08:34:57,712 Epoch[028/050], Step[1150/1252], Avg Loss: 2.8863, Avg Acc: 0.4878
2022-01-24 08:36:26,167 Epoch[028/050], Step[1200/1252], Avg Loss: 2.8850, Avg Acc: 0.4897
2022-01-24 08:37:54,696 Epoch[028/050], Step[1250/1252], Avg Loss: 2.8828, Avg Acc: 0.4896
2022-01-24 08:38:01,851 ----- Epoch[028/050], Train Loss: 2.8827, Train Acc: 0.4896, time: 2285.00, Best Val(epoch26) Acc@1: 0.7761
2022-01-24 08:38:01,851 ----- Validation after Epoch: 28
2022-01-24 08:39:10,452 Val Step[0000/1563], Avg Loss: 0.8289, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 08:39:12,387 Val Step[0050/1563], Avg Loss: 1.0033, Avg Acc@1: 0.7831, Avg Acc@5: 0.9430
2022-01-24 08:39:14,306 Val Step[0100/1563], Avg Loss: 1.0367, Avg Acc@1: 0.7843, Avg Acc@5: 0.9384
2022-01-24 08:39:16,115 Val Step[0150/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7833, Avg Acc@5: 0.9361
2022-01-24 08:39:17,959 Val Step[0200/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7836, Avg Acc@5: 0.9370
2022-01-24 08:39:19,808 Val Step[0250/1563], Avg Loss: 1.0298, Avg Acc@1: 0.7829, Avg Acc@5: 0.9384
2022-01-24 08:39:21,631 Val Step[0300/1563], Avg Loss: 1.0294, Avg Acc@1: 0.7827, Avg Acc@5: 0.9371
2022-01-24 08:39:23,402 Val Step[0350/1563], Avg Loss: 1.0344, Avg Acc@1: 0.7818, Avg Acc@5: 0.9365
2022-01-24 08:39:25,236 Val Step[0400/1563], Avg Loss: 1.0345, Avg Acc@1: 0.7824, Avg Acc@5: 0.9366
2022-01-24 08:39:27,102 Val Step[0450/1563], Avg Loss: 1.0388, Avg Acc@1: 0.7799, Avg Acc@5: 0.9364
2022-01-24 08:39:28,905 Val Step[0500/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7796, Avg Acc@5: 0.9368
2022-01-24 08:39:30,704 Val Step[0550/1563], Avg Loss: 1.0405, Avg Acc@1: 0.7788, Avg Acc@5: 0.9368
2022-01-24 08:39:32,504 Val Step[0600/1563], Avg Loss: 1.0389, Avg Acc@1: 0.7784, Avg Acc@5: 0.9369
2022-01-24 08:39:34,362 Val Step[0650/1563], Avg Loss: 1.0395, Avg Acc@1: 0.7780, Avg Acc@5: 0.9371
2022-01-24 08:39:36,523 Val Step[0700/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7781, Avg Acc@5: 0.9374
2022-01-24 08:39:38,640 Val Step[0750/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7761, Avg Acc@5: 0.9372
2022-01-24 08:39:40,553 Val Step[0800/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7768, Avg Acc@5: 0.9371
2022-01-24 08:39:42,320 Val Step[0850/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7766, Avg Acc@5: 0.9369
2022-01-24 08:39:44,198 Val Step[0900/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7771, Avg Acc@5: 0.9373
2022-01-24 08:39:46,315 Val Step[0950/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7777, Avg Acc@5: 0.9375
2022-01-24 08:39:48,096 Val Step[1000/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7775, Avg Acc@5: 0.9372
2022-01-24 08:39:50,111 Val Step[1050/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7769, Avg Acc@5: 0.9367
2022-01-24 08:39:51,983 Val Step[1100/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7763, Avg Acc@5: 0.9369
2022-01-24 08:39:53,766 Val Step[1150/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7766, Avg Acc@5: 0.9373
2022-01-24 08:39:55,612 Val Step[1200/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7773, Avg Acc@5: 0.9372
2022-01-24 08:39:57,407 Val Step[1250/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-24 08:39:59,188 Val Step[1300/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7767, Avg Acc@5: 0.9371
2022-01-24 08:40:00,992 Val Step[1350/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7762, Avg Acc@5: 0.9372
2022-01-24 08:40:02,800 Val Step[1400/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7759, Avg Acc@5: 0.9372
2022-01-24 08:40:04,610 Val Step[1450/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7764, Avg Acc@5: 0.9372
2022-01-24 08:40:06,410 Val Step[1500/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7765, Avg Acc@5: 0.9375
2022-01-24 08:40:08,154 Val Step[1550/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7763, Avg Acc@5: 0.9374
2022-01-24 08:40:10,046 ----- Epoch[028/050], Validation Loss: 1.0452, Validation Acc@1: 0.7762, Validation Acc@5: 0.9375, time: 128.19
2022-01-24 08:40:11,304 the pre best model acc:0.7761, at epoch 26
2022-01-24 08:40:11,579 current best model acc:0.7762, at epoch 28
2022-01-24 08:40:11,579 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 08:40:11,579 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 08:40:11,579 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 08:40:11,579 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 08:40:11,579 Now training epoch 29. LR=0.000004
2022-01-24 08:41:55,431 Epoch[029/050], Step[0000/1252], Avg Loss: 2.9128, Avg Acc: 0.3584
2022-01-24 08:43:20,357 Epoch[029/050], Step[0050/1252], Avg Loss: 2.8828, Avg Acc: 0.5159
2022-01-24 08:44:46,353 Epoch[029/050], Step[0100/1252], Avg Loss: 2.9421, Avg Acc: 0.4861
2022-01-24 08:46:13,522 Epoch[029/050], Step[0150/1252], Avg Loss: 2.9318, Avg Acc: 0.4819
2022-01-24 08:47:40,037 Epoch[029/050], Step[0200/1252], Avg Loss: 2.9323, Avg Acc: 0.4855
2022-01-24 08:49:07,738 Epoch[029/050], Step[0250/1252], Avg Loss: 2.9188, Avg Acc: 0.4778
2022-01-24 08:50:33,636 Epoch[029/050], Step[0300/1252], Avg Loss: 2.9112, Avg Acc: 0.4773
2022-01-24 08:52:01,206 Epoch[029/050], Step[0350/1252], Avg Loss: 2.9083, Avg Acc: 0.4770
2022-01-24 08:53:28,662 Epoch[029/050], Step[0400/1252], Avg Loss: 2.9050, Avg Acc: 0.4776
2022-01-24 08:54:55,685 Epoch[029/050], Step[0450/1252], Avg Loss: 2.9008, Avg Acc: 0.4769
2022-01-24 08:56:23,576 Epoch[029/050], Step[0500/1252], Avg Loss: 2.8971, Avg Acc: 0.4764
2022-01-24 08:57:50,389 Epoch[029/050], Step[0550/1252], Avg Loss: 2.8962, Avg Acc: 0.4771
2022-01-24 08:59:17,421 Epoch[029/050], Step[0600/1252], Avg Loss: 2.8891, Avg Acc: 0.4772
2022-01-24 09:00:43,229 Epoch[029/050], Step[0650/1252], Avg Loss: 2.8895, Avg Acc: 0.4775
2022-01-24 09:02:09,622 Epoch[029/050], Step[0700/1252], Avg Loss: 2.8843, Avg Acc: 0.4790
2022-01-24 09:03:35,733 Epoch[029/050], Step[0750/1252], Avg Loss: 2.8819, Avg Acc: 0.4775
2022-01-24 09:05:00,466 Epoch[029/050], Step[0800/1252], Avg Loss: 2.8831, Avg Acc: 0.4797
2022-01-24 09:06:25,209 Epoch[029/050], Step[0850/1252], Avg Loss: 2.8794, Avg Acc: 0.4812
2022-01-24 09:07:51,781 Epoch[029/050], Step[0900/1252], Avg Loss: 2.8789, Avg Acc: 0.4807
2022-01-24 09:09:19,130 Epoch[029/050], Step[0950/1252], Avg Loss: 2.8785, Avg Acc: 0.4823
2022-01-24 09:10:46,596 Epoch[029/050], Step[1000/1252], Avg Loss: 2.8791, Avg Acc: 0.4837
2022-01-24 09:12:13,977 Epoch[029/050], Step[1050/1252], Avg Loss: 2.8793, Avg Acc: 0.4834
2022-01-24 09:13:41,728 Epoch[029/050], Step[1100/1252], Avg Loss: 2.8787, Avg Acc: 0.4824
2022-01-24 09:15:07,970 Epoch[029/050], Step[1150/1252], Avg Loss: 2.8784, Avg Acc: 0.4823
2022-01-24 09:16:35,415 Epoch[029/050], Step[1200/1252], Avg Loss: 2.8787, Avg Acc: 0.4833
2022-01-24 09:18:03,418 Epoch[029/050], Step[1250/1252], Avg Loss: 2.8792, Avg Acc: 0.4825
2022-01-24 09:18:10,723 ----- Epoch[029/050], Train Loss: 2.8792, Train Acc: 0.4825, time: 2279.14, Best Val(epoch28) Acc@1: 0.7762
2022-01-24 09:18:10,723 Now training epoch 30. LR=0.000004
2022-01-24 09:19:55,022 Epoch[030/050], Step[0000/1252], Avg Loss: 3.0795, Avg Acc: 0.3682
2022-01-24 09:21:21,276 Epoch[030/050], Step[0050/1252], Avg Loss: 2.8559, Avg Acc: 0.4916
2022-01-24 09:22:47,995 Epoch[030/050], Step[0100/1252], Avg Loss: 2.8882, Avg Acc: 0.4839
2022-01-24 09:24:14,518 Epoch[030/050], Step[0150/1252], Avg Loss: 2.8784, Avg Acc: 0.4804
2022-01-24 09:25:41,085 Epoch[030/050], Step[0200/1252], Avg Loss: 2.8602, Avg Acc: 0.4855
2022-01-24 09:27:07,270 Epoch[030/050], Step[0250/1252], Avg Loss: 2.8694, Avg Acc: 0.4855
2022-01-24 09:28:33,183 Epoch[030/050], Step[0300/1252], Avg Loss: 2.8741, Avg Acc: 0.4879
2022-01-24 09:30:00,360 Epoch[030/050], Step[0350/1252], Avg Loss: 2.8730, Avg Acc: 0.4911
2022-01-24 09:31:27,288 Epoch[030/050], Step[0400/1252], Avg Loss: 2.8758, Avg Acc: 0.4885
2022-01-24 09:32:53,587 Epoch[030/050], Step[0450/1252], Avg Loss: 2.8774, Avg Acc: 0.4896
2022-01-24 09:34:20,572 Epoch[030/050], Step[0500/1252], Avg Loss: 2.8757, Avg Acc: 0.4887
2022-01-24 09:35:47,904 Epoch[030/050], Step[0550/1252], Avg Loss: 2.8722, Avg Acc: 0.4855
2022-01-24 09:37:15,708 Epoch[030/050], Step[0600/1252], Avg Loss: 2.8752, Avg Acc: 0.4843
2022-01-24 09:38:41,488 Epoch[030/050], Step[0650/1252], Avg Loss: 2.8763, Avg Acc: 0.4856
2022-01-24 09:40:09,433 Epoch[030/050], Step[0700/1252], Avg Loss: 2.8810, Avg Acc: 0.4833
2022-01-24 09:41:36,429 Epoch[030/050], Step[0750/1252], Avg Loss: 2.8805, Avg Acc: 0.4820
2022-01-24 09:43:04,167 Epoch[030/050], Step[0800/1252], Avg Loss: 2.8820, Avg Acc: 0.4824
2022-01-24 09:44:30,971 Epoch[030/050], Step[0850/1252], Avg Loss: 2.8827, Avg Acc: 0.4815
2022-01-24 09:45:57,395 Epoch[030/050], Step[0900/1252], Avg Loss: 2.8802, Avg Acc: 0.4828
2022-01-24 09:47:22,543 Epoch[030/050], Step[0950/1252], Avg Loss: 2.8801, Avg Acc: 0.4848
2022-01-24 09:48:49,472 Epoch[030/050], Step[1000/1252], Avg Loss: 2.8816, Avg Acc: 0.4844
2022-01-24 09:50:16,271 Epoch[030/050], Step[1050/1252], Avg Loss: 2.8793, Avg Acc: 0.4852
2022-01-24 09:51:43,668 Epoch[030/050], Step[1100/1252], Avg Loss: 2.8811, Avg Acc: 0.4846
2022-01-24 09:53:10,665 Epoch[030/050], Step[1150/1252], Avg Loss: 2.8812, Avg Acc: 0.4841
2022-01-24 09:54:36,578 Epoch[030/050], Step[1200/1252], Avg Loss: 2.8805, Avg Acc: 0.4852
2022-01-24 09:56:04,637 Epoch[030/050], Step[1250/1252], Avg Loss: 2.8804, Avg Acc: 0.4843
2022-01-24 09:56:11,787 ----- Epoch[030/050], Train Loss: 2.8804, Train Acc: 0.4843, time: 2281.06, Best Val(epoch28) Acc@1: 0.7762
2022-01-24 09:56:11,787 ----- Validation after Epoch: 30
2022-01-24 09:57:25,190 Val Step[0000/1563], Avg Loss: 0.8297, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 09:57:27,179 Val Step[0050/1563], Avg Loss: 1.0035, Avg Acc@1: 0.7794, Avg Acc@5: 0.9418
2022-01-24 09:57:28,974 Val Step[0100/1563], Avg Loss: 1.0377, Avg Acc@1: 0.7831, Avg Acc@5: 0.9369
2022-01-24 09:57:30,777 Val Step[0150/1563], Avg Loss: 1.0412, Avg Acc@1: 0.7827, Avg Acc@5: 0.9348
2022-01-24 09:57:32,598 Val Step[0200/1563], Avg Loss: 1.0409, Avg Acc@1: 0.7844, Avg Acc@5: 0.9358
2022-01-24 09:57:34,387 Val Step[0250/1563], Avg Loss: 1.0309, Avg Acc@1: 0.7829, Avg Acc@5: 0.9376
2022-01-24 09:57:36,206 Val Step[0300/1563], Avg Loss: 1.0313, Avg Acc@1: 0.7826, Avg Acc@5: 0.9365
2022-01-24 09:57:38,035 Val Step[0350/1563], Avg Loss: 1.0363, Avg Acc@1: 0.7825, Avg Acc@5: 0.9358
2022-01-24 09:57:39,928 Val Step[0400/1563], Avg Loss: 1.0357, Avg Acc@1: 0.7831, Avg Acc@5: 0.9356
2022-01-24 09:57:41,782 Val Step[0450/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7810, Avg Acc@5: 0.9352
2022-01-24 09:57:43,607 Val Step[0500/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7804, Avg Acc@5: 0.9359
2022-01-24 09:57:45,400 Val Step[0550/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7799, Avg Acc@5: 0.9361
2022-01-24 09:57:47,251 Val Step[0600/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7795, Avg Acc@5: 0.9361
2022-01-24 09:57:49,138 Val Step[0650/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7792, Avg Acc@5: 0.9364
2022-01-24 09:57:51,041 Val Step[0700/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7795, Avg Acc@5: 0.9371
2022-01-24 09:57:52,884 Val Step[0750/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7771, Avg Acc@5: 0.9368
2022-01-24 09:57:54,736 Val Step[0800/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7777, Avg Acc@5: 0.9366
2022-01-24 09:57:56,522 Val Step[0850/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7775, Avg Acc@5: 0.9365
2022-01-24 09:57:58,325 Val Step[0900/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7781, Avg Acc@5: 0.9369
2022-01-24 09:58:00,119 Val Step[0950/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7787, Avg Acc@5: 0.9371
2022-01-24 09:58:02,081 Val Step[1000/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7783, Avg Acc@5: 0.9369
2022-01-24 09:58:03,905 Val Step[1050/1563], Avg Loss: 1.0463, Avg Acc@1: 0.7776, Avg Acc@5: 0.9365
2022-01-24 09:58:05,711 Val Step[1100/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7770, Avg Acc@5: 0.9367
2022-01-24 09:58:07,499 Val Step[1150/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7772, Avg Acc@5: 0.9370
2022-01-24 09:58:09,335 Val Step[1200/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7778, Avg Acc@5: 0.9371
2022-01-24 09:58:11,253 Val Step[1250/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7775, Avg Acc@5: 0.9374
2022-01-24 09:58:13,166 Val Step[1300/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7773, Avg Acc@5: 0.9371
2022-01-24 09:58:14,938 Val Step[1350/1563], Avg Loss: 1.0470, Avg Acc@1: 0.7767, Avg Acc@5: 0.9370
2022-01-24 09:58:16,748 Val Step[1400/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7764, Avg Acc@5: 0.9370
2022-01-24 09:58:18,555 Val Step[1450/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7767, Avg Acc@5: 0.9371
2022-01-24 09:58:20,331 Val Step[1500/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7770, Avg Acc@5: 0.9373
2022-01-24 09:58:22,072 Val Step[1550/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7767, Avg Acc@5: 0.9372
2022-01-24 09:58:24,053 ----- Epoch[030/050], Validation Loss: 1.0458, Validation Acc@1: 0.7766, Validation Acc@5: 0.9372, time: 132.26
2022-01-24 09:58:25,526 the pre best model acc:0.7762, at epoch 28
2022-01-24 09:58:25,585 current best model acc:0.7766, at epoch 30
2022-01-24 09:58:25,585 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 09:58:25,585 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 09:58:25,586 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 09:58:25,586 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 09:58:25,586 Now training epoch 31. LR=0.000004
2022-01-24 10:00:08,639 Epoch[031/050], Step[0000/1252], Avg Loss: 3.1807, Avg Acc: 0.5869
2022-01-24 10:01:34,963 Epoch[031/050], Step[0050/1252], Avg Loss: 2.8668, Avg Acc: 0.5129
2022-01-24 10:03:00,508 Epoch[031/050], Step[0100/1252], Avg Loss: 2.9004, Avg Acc: 0.4969
2022-01-24 10:04:25,586 Epoch[031/050], Step[0150/1252], Avg Loss: 2.8900, Avg Acc: 0.5029
2022-01-24 10:05:51,072 Epoch[031/050], Step[0200/1252], Avg Loss: 2.8747, Avg Acc: 0.5057
2022-01-24 10:07:17,559 Epoch[031/050], Step[0250/1252], Avg Loss: 2.8751, Avg Acc: 0.4985
2022-01-24 10:08:44,595 Epoch[031/050], Step[0300/1252], Avg Loss: 2.8737, Avg Acc: 0.5012
2022-01-24 10:10:11,455 Epoch[031/050], Step[0350/1252], Avg Loss: 2.8708, Avg Acc: 0.5007
2022-01-24 10:11:38,623 Epoch[031/050], Step[0400/1252], Avg Loss: 2.8629, Avg Acc: 0.5004
2022-01-24 10:13:06,140 Epoch[031/050], Step[0450/1252], Avg Loss: 2.8558, Avg Acc: 0.5003
2022-01-24 10:14:33,489 Epoch[031/050], Step[0500/1252], Avg Loss: 2.8521, Avg Acc: 0.4996
2022-01-24 10:16:01,481 Epoch[031/050], Step[0550/1252], Avg Loss: 2.8536, Avg Acc: 0.4995
2022-01-24 10:17:29,957 Epoch[031/050], Step[0600/1252], Avg Loss: 2.8592, Avg Acc: 0.4953
2022-01-24 10:18:57,086 Epoch[031/050], Step[0650/1252], Avg Loss: 2.8647, Avg Acc: 0.4979
2022-01-24 10:20:24,132 Epoch[031/050], Step[0700/1252], Avg Loss: 2.8723, Avg Acc: 0.4976
2022-01-24 10:21:50,841 Epoch[031/050], Step[0750/1252], Avg Loss: 2.8750, Avg Acc: 0.4984
2022-01-24 10:23:18,235 Epoch[031/050], Step[0800/1252], Avg Loss: 2.8760, Avg Acc: 0.4980
2022-01-24 10:24:45,621 Epoch[031/050], Step[0850/1252], Avg Loss: 2.8755, Avg Acc: 0.4977
2022-01-24 10:26:11,934 Epoch[031/050], Step[0900/1252], Avg Loss: 2.8743, Avg Acc: 0.4999
2022-01-24 10:27:38,244 Epoch[031/050], Step[0950/1252], Avg Loss: 2.8766, Avg Acc: 0.5017
2022-01-24 10:29:05,293 Epoch[031/050], Step[1000/1252], Avg Loss: 2.8763, Avg Acc: 0.5000
2022-01-24 10:30:32,600 Epoch[031/050], Step[1050/1252], Avg Loss: 2.8761, Avg Acc: 0.5001
2022-01-24 10:32:00,530 Epoch[031/050], Step[1100/1252], Avg Loss: 2.8740, Avg Acc: 0.4994
2022-01-24 10:33:28,083 Epoch[031/050], Step[1150/1252], Avg Loss: 2.8743, Avg Acc: 0.4997
2022-01-24 10:34:56,250 Epoch[031/050], Step[1200/1252], Avg Loss: 2.8749, Avg Acc: 0.5003
2022-01-24 10:36:25,300 Epoch[031/050], Step[1250/1252], Avg Loss: 2.8734, Avg Acc: 0.4994
2022-01-24 10:36:32,544 ----- Epoch[031/050], Train Loss: 2.8734, Train Acc: 0.4994, time: 2286.95, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 10:36:32,544 Now training epoch 32. LR=0.000003
2022-01-24 10:38:20,839 Epoch[032/050], Step[0000/1252], Avg Loss: 2.7426, Avg Acc: 0.5283
2022-01-24 10:39:48,661 Epoch[032/050], Step[0050/1252], Avg Loss: 2.8334, Avg Acc: 0.5139
2022-01-24 10:41:15,527 Epoch[032/050], Step[0100/1252], Avg Loss: 2.8616, Avg Acc: 0.5077
2022-01-24 10:42:42,293 Epoch[032/050], Step[0150/1252], Avg Loss: 2.8713, Avg Acc: 0.4916
2022-01-24 10:44:09,341 Epoch[032/050], Step[0200/1252], Avg Loss: 2.8724, Avg Acc: 0.4918
2022-01-24 10:45:37,048 Epoch[032/050], Step[0250/1252], Avg Loss: 2.8718, Avg Acc: 0.4924
2022-01-24 10:47:05,358 Epoch[032/050], Step[0300/1252], Avg Loss: 2.8771, Avg Acc: 0.4932
2022-01-24 10:48:32,194 Epoch[032/050], Step[0350/1252], Avg Loss: 2.8846, Avg Acc: 0.4913
2022-01-24 10:50:00,518 Epoch[032/050], Step[0400/1252], Avg Loss: 2.8867, Avg Acc: 0.4920
2022-01-24 10:51:27,242 Epoch[032/050], Step[0450/1252], Avg Loss: 2.8903, Avg Acc: 0.4934
2022-01-24 10:52:54,071 Epoch[032/050], Step[0500/1252], Avg Loss: 2.8895, Avg Acc: 0.4949
2022-01-24 10:54:21,983 Epoch[032/050], Step[0550/1252], Avg Loss: 2.8906, Avg Acc: 0.4907
2022-01-24 10:55:50,259 Epoch[032/050], Step[0600/1252], Avg Loss: 2.8916, Avg Acc: 0.4900
2022-01-24 10:57:18,138 Epoch[032/050], Step[0650/1252], Avg Loss: 2.8911, Avg Acc: 0.4917
2022-01-24 10:58:46,144 Epoch[032/050], Step[0700/1252], Avg Loss: 2.8938, Avg Acc: 0.4906
2022-01-24 11:00:13,646 Epoch[032/050], Step[0750/1252], Avg Loss: 2.8914, Avg Acc: 0.4909
2022-01-24 11:01:40,228 Epoch[032/050], Step[0800/1252], Avg Loss: 2.8971, Avg Acc: 0.4914
2022-01-24 11:03:07,540 Epoch[032/050], Step[0850/1252], Avg Loss: 2.8988, Avg Acc: 0.4918
2022-01-24 11:04:34,286 Epoch[032/050], Step[0900/1252], Avg Loss: 2.8969, Avg Acc: 0.4928
2022-01-24 11:06:02,720 Epoch[032/050], Step[0950/1252], Avg Loss: 2.8969, Avg Acc: 0.4925
2022-01-24 11:07:29,713 Epoch[032/050], Step[1000/1252], Avg Loss: 2.8937, Avg Acc: 0.4932
2022-01-24 11:08:56,363 Epoch[032/050], Step[1050/1252], Avg Loss: 2.8921, Avg Acc: 0.4946
2022-01-24 11:10:23,318 Epoch[032/050], Step[1100/1252], Avg Loss: 2.8902, Avg Acc: 0.4946
2022-01-24 11:11:51,114 Epoch[032/050], Step[1150/1252], Avg Loss: 2.8898, Avg Acc: 0.4949
2022-01-24 11:13:19,100 Epoch[032/050], Step[1200/1252], Avg Loss: 2.8900, Avg Acc: 0.4951
2022-01-24 11:14:46,509 Epoch[032/050], Step[1250/1252], Avg Loss: 2.8873, Avg Acc: 0.4966
2022-01-24 11:14:53,654 ----- Epoch[032/050], Train Loss: 2.8873, Train Acc: 0.4966, time: 2301.11, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 11:14:53,654 ----- Validation after Epoch: 32
2022-01-24 11:16:07,124 Val Step[0000/1563], Avg Loss: 0.8310, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 11:16:08,920 Val Step[0050/1563], Avg Loss: 1.0051, Avg Acc@1: 0.7806, Avg Acc@5: 0.9400
2022-01-24 11:16:11,054 Val Step[0100/1563], Avg Loss: 1.0370, Avg Acc@1: 0.7834, Avg Acc@5: 0.9360
2022-01-24 11:16:13,061 Val Step[0150/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7831, Avg Acc@5: 0.9344
2022-01-24 11:16:15,035 Val Step[0200/1563], Avg Loss: 1.0405, Avg Acc@1: 0.7834, Avg Acc@5: 0.9349
2022-01-24 11:16:17,022 Val Step[0250/1563], Avg Loss: 1.0307, Avg Acc@1: 0.7824, Avg Acc@5: 0.9368
2022-01-24 11:16:19,031 Val Step[0300/1563], Avg Loss: 1.0306, Avg Acc@1: 0.7824, Avg Acc@5: 0.9357
2022-01-24 11:16:21,060 Val Step[0350/1563], Avg Loss: 1.0355, Avg Acc@1: 0.7815, Avg Acc@5: 0.9355
2022-01-24 11:16:23,089 Val Step[0400/1563], Avg Loss: 1.0350, Avg Acc@1: 0.7822, Avg Acc@5: 0.9357
2022-01-24 11:16:25,112 Val Step[0450/1563], Avg Loss: 1.0393, Avg Acc@1: 0.7794, Avg Acc@5: 0.9355
2022-01-24 11:16:27,153 Val Step[0500/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7788, Avg Acc@5: 0.9359
2022-01-24 11:16:29,204 Val Step[0550/1563], Avg Loss: 1.0405, Avg Acc@1: 0.7778, Avg Acc@5: 0.9362
2022-01-24 11:16:31,254 Val Step[0600/1563], Avg Loss: 1.0391, Avg Acc@1: 0.7776, Avg Acc@5: 0.9363
2022-01-24 11:16:33,301 Val Step[0650/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7772, Avg Acc@5: 0.9365
2022-01-24 11:16:35,349 Val Step[0700/1563], Avg Loss: 1.0372, Avg Acc@1: 0.7775, Avg Acc@5: 0.9370
2022-01-24 11:16:37,414 Val Step[0750/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7756, Avg Acc@5: 0.9368
2022-01-24 11:16:39,501 Val Step[0800/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7761, Avg Acc@5: 0.9367
2022-01-24 11:16:41,301 Val Step[0850/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7762, Avg Acc@5: 0.9364
2022-01-24 11:16:43,062 Val Step[0900/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7765, Avg Acc@5: 0.9369
2022-01-24 11:16:44,906 Val Step[0950/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7771, Avg Acc@5: 0.9370
2022-01-24 11:16:46,825 Val Step[1000/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7769, Avg Acc@5: 0.9368
2022-01-24 11:16:48,678 Val Step[1050/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7762, Avg Acc@5: 0.9365
2022-01-24 11:16:50,581 Val Step[1100/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7755, Avg Acc@5: 0.9367
2022-01-24 11:16:52,680 Val Step[1150/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7760, Avg Acc@5: 0.9370
2022-01-24 11:16:54,741 Val Step[1200/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7767, Avg Acc@5: 0.9370
2022-01-24 11:16:56,781 Val Step[1250/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7762, Avg Acc@5: 0.9373
2022-01-24 11:16:58,803 Val Step[1300/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7760, Avg Acc@5: 0.9370
2022-01-24 11:17:00,585 Val Step[1350/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7754, Avg Acc@5: 0.9369
2022-01-24 11:17:02,368 Val Step[1400/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7751, Avg Acc@5: 0.9369
2022-01-24 11:17:04,204 Val Step[1450/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7755, Avg Acc@5: 0.9370
2022-01-24 11:17:06,054 Val Step[1500/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7758, Avg Acc@5: 0.9373
2022-01-24 11:17:07,859 Val Step[1550/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7755, Avg Acc@5: 0.9372
2022-01-24 11:17:09,754 ----- Epoch[032/050], Validation Loss: 1.0447, Validation Acc@1: 0.7754, Validation Acc@5: 0.9372, time: 136.10
2022-01-24 11:17:09,754 Now training epoch 33. LR=0.000003
2022-01-24 11:18:56,134 Epoch[033/050], Step[0000/1252], Avg Loss: 2.8997, Avg Acc: 0.7236
2022-01-24 11:20:24,214 Epoch[033/050], Step[0050/1252], Avg Loss: 2.9082, Avg Acc: 0.4916
2022-01-24 11:21:50,799 Epoch[033/050], Step[0100/1252], Avg Loss: 2.9116, Avg Acc: 0.4953
2022-01-24 11:23:18,534 Epoch[033/050], Step[0150/1252], Avg Loss: 2.8972, Avg Acc: 0.4965
2022-01-24 11:24:45,948 Epoch[033/050], Step[0200/1252], Avg Loss: 2.8892, Avg Acc: 0.4872
2022-01-24 11:26:11,927 Epoch[033/050], Step[0250/1252], Avg Loss: 2.8921, Avg Acc: 0.4837
2022-01-24 11:27:38,622 Epoch[033/050], Step[0300/1252], Avg Loss: 2.8874, Avg Acc: 0.4890
2022-01-24 11:29:05,342 Epoch[033/050], Step[0350/1252], Avg Loss: 2.8843, Avg Acc: 0.4911
2022-01-24 11:30:32,495 Epoch[033/050], Step[0400/1252], Avg Loss: 2.8901, Avg Acc: 0.4877
2022-01-24 11:31:59,812 Epoch[033/050], Step[0450/1252], Avg Loss: 2.8996, Avg Acc: 0.4868
2022-01-24 11:33:27,488 Epoch[033/050], Step[0500/1252], Avg Loss: 2.8960, Avg Acc: 0.4883
2022-01-24 11:34:54,290 Epoch[033/050], Step[0550/1252], Avg Loss: 2.8948, Avg Acc: 0.4900
2022-01-24 11:36:20,773 Epoch[033/050], Step[0600/1252], Avg Loss: 2.8937, Avg Acc: 0.4932
2022-01-24 11:37:49,500 Epoch[033/050], Step[0650/1252], Avg Loss: 2.8934, Avg Acc: 0.4920
2022-01-24 11:39:17,731 Epoch[033/050], Step[0700/1252], Avg Loss: 2.8907, Avg Acc: 0.4931
2022-01-24 11:40:44,715 Epoch[033/050], Step[0750/1252], Avg Loss: 2.8915, Avg Acc: 0.4922
2022-01-24 11:42:12,038 Epoch[033/050], Step[0800/1252], Avg Loss: 2.8880, Avg Acc: 0.4903
2022-01-24 11:43:39,900 Epoch[033/050], Step[0850/1252], Avg Loss: 2.8887, Avg Acc: 0.4903
2022-01-24 11:45:07,641 Epoch[033/050], Step[0900/1252], Avg Loss: 2.8887, Avg Acc: 0.4904
2022-01-24 11:46:34,768 Epoch[033/050], Step[0950/1252], Avg Loss: 2.8877, Avg Acc: 0.4898
2022-01-24 11:48:02,023 Epoch[033/050], Step[1000/1252], Avg Loss: 2.8864, Avg Acc: 0.4911
2022-01-24 11:49:29,105 Epoch[033/050], Step[1050/1252], Avg Loss: 2.8885, Avg Acc: 0.4906
2022-01-24 11:50:56,998 Epoch[033/050], Step[1100/1252], Avg Loss: 2.8890, Avg Acc: 0.4897
2022-01-24 11:52:22,619 Epoch[033/050], Step[1150/1252], Avg Loss: 2.8900, Avg Acc: 0.4901
2022-01-24 11:53:49,333 Epoch[033/050], Step[1200/1252], Avg Loss: 2.8897, Avg Acc: 0.4910
2022-01-24 11:55:16,586 Epoch[033/050], Step[1250/1252], Avg Loss: 2.8920, Avg Acc: 0.4907
2022-01-24 11:55:23,703 ----- Epoch[033/050], Train Loss: 2.8920, Train Acc: 0.4907, time: 2293.94, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 11:55:23,704 Now training epoch 34. LR=0.000003
2022-01-24 11:57:09,829 Epoch[034/050], Step[0000/1252], Avg Loss: 2.6055, Avg Acc: 0.3721
2022-01-24 11:58:36,806 Epoch[034/050], Step[0050/1252], Avg Loss: 2.8281, Avg Acc: 0.4805
2022-01-24 12:00:04,812 Epoch[034/050], Step[0100/1252], Avg Loss: 2.8623, Avg Acc: 0.4793
2022-01-24 12:01:31,240 Epoch[034/050], Step[0150/1252], Avg Loss: 2.8736, Avg Acc: 0.4871
2022-01-24 12:02:59,148 Epoch[034/050], Step[0200/1252], Avg Loss: 2.8666, Avg Acc: 0.4919
2022-01-24 12:04:23,892 Epoch[034/050], Step[0250/1252], Avg Loss: 2.8598, Avg Acc: 0.4993
2022-01-24 12:05:51,325 Epoch[034/050], Step[0300/1252], Avg Loss: 2.8585, Avg Acc: 0.4994
2022-01-24 12:07:17,621 Epoch[034/050], Step[0350/1252], Avg Loss: 2.8515, Avg Acc: 0.5024
2022-01-24 12:08:44,118 Epoch[034/050], Step[0400/1252], Avg Loss: 2.8525, Avg Acc: 0.4993
2022-01-24 12:10:11,669 Epoch[034/050], Step[0450/1252], Avg Loss: 2.8528, Avg Acc: 0.4964
2022-01-24 12:11:38,914 Epoch[034/050], Step[0500/1252], Avg Loss: 2.8572, Avg Acc: 0.4962
2022-01-24 12:13:05,809 Epoch[034/050], Step[0550/1252], Avg Loss: 2.8586, Avg Acc: 0.4975
2022-01-24 12:14:32,587 Epoch[034/050], Step[0600/1252], Avg Loss: 2.8630, Avg Acc: 0.4959
2022-01-24 12:15:59,343 Epoch[034/050], Step[0650/1252], Avg Loss: 2.8647, Avg Acc: 0.4957
2022-01-24 12:17:25,924 Epoch[034/050], Step[0700/1252], Avg Loss: 2.8712, Avg Acc: 0.4945
2022-01-24 12:18:52,843 Epoch[034/050], Step[0750/1252], Avg Loss: 2.8714, Avg Acc: 0.4938
2022-01-24 12:20:20,042 Epoch[034/050], Step[0800/1252], Avg Loss: 2.8685, Avg Acc: 0.4944
2022-01-24 12:21:46,169 Epoch[034/050], Step[0850/1252], Avg Loss: 2.8683, Avg Acc: 0.4948
2022-01-24 12:23:13,631 Epoch[034/050], Step[0900/1252], Avg Loss: 2.8704, Avg Acc: 0.4954
2022-01-24 12:24:39,502 Epoch[034/050], Step[0950/1252], Avg Loss: 2.8709, Avg Acc: 0.4955
2022-01-24 12:26:05,968 Epoch[034/050], Step[1000/1252], Avg Loss: 2.8677, Avg Acc: 0.4958
2022-01-24 12:27:32,272 Epoch[034/050], Step[1050/1252], Avg Loss: 2.8687, Avg Acc: 0.4954
2022-01-24 12:28:58,122 Epoch[034/050], Step[1100/1252], Avg Loss: 2.8686, Avg Acc: 0.4948
2022-01-24 12:30:25,596 Epoch[034/050], Step[1150/1252], Avg Loss: 2.8710, Avg Acc: 0.4935
2022-01-24 12:31:52,210 Epoch[034/050], Step[1200/1252], Avg Loss: 2.8719, Avg Acc: 0.4933
2022-01-24 12:33:19,314 Epoch[034/050], Step[1250/1252], Avg Loss: 2.8696, Avg Acc: 0.4938
2022-01-24 12:33:26,454 ----- Epoch[034/050], Train Loss: 2.8696, Train Acc: 0.4938, time: 2282.75, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 12:33:26,454 ----- Validation after Epoch: 34
2022-01-24 12:34:35,975 Val Step[0000/1563], Avg Loss: 0.7983, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 12:34:37,931 Val Step[0050/1563], Avg Loss: 1.0018, Avg Acc@1: 0.7855, Avg Acc@5: 0.9430
2022-01-24 12:34:40,059 Val Step[0100/1563], Avg Loss: 1.0336, Avg Acc@1: 0.7856, Avg Acc@5: 0.9394
2022-01-24 12:34:42,199 Val Step[0150/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7850, Avg Acc@5: 0.9369
2022-01-24 12:34:44,305 Val Step[0200/1563], Avg Loss: 1.0385, Avg Acc@1: 0.7848, Avg Acc@5: 0.9370
2022-01-24 12:34:46,400 Val Step[0250/1563], Avg Loss: 1.0289, Avg Acc@1: 0.7839, Avg Acc@5: 0.9381
2022-01-24 12:34:48,376 Val Step[0300/1563], Avg Loss: 1.0291, Avg Acc@1: 0.7831, Avg Acc@5: 0.9367
2022-01-24 12:34:50,302 Val Step[0350/1563], Avg Loss: 1.0338, Avg Acc@1: 0.7820, Avg Acc@5: 0.9363
2022-01-24 12:34:52,243 Val Step[0400/1563], Avg Loss: 1.0332, Avg Acc@1: 0.7823, Avg Acc@5: 0.9365
2022-01-24 12:34:54,068 Val Step[0450/1563], Avg Loss: 1.0376, Avg Acc@1: 0.7800, Avg Acc@5: 0.9365
2022-01-24 12:34:55,885 Val Step[0500/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7793, Avg Acc@5: 0.9368
2022-01-24 12:34:57,691 Val Step[0550/1563], Avg Loss: 1.0395, Avg Acc@1: 0.7782, Avg Acc@5: 0.9369
2022-01-24 12:34:59,491 Val Step[0600/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7781, Avg Acc@5: 0.9368
2022-01-24 12:35:01,390 Val Step[0650/1563], Avg Loss: 1.0383, Avg Acc@1: 0.7780, Avg Acc@5: 0.9370
2022-01-24 12:35:03,425 Val Step[0700/1563], Avg Loss: 1.0360, Avg Acc@1: 0.7782, Avg Acc@5: 0.9378
2022-01-24 12:35:05,471 Val Step[0750/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7763, Avg Acc@5: 0.9375
2022-01-24 12:35:07,564 Val Step[0800/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7771, Avg Acc@5: 0.9375
2022-01-24 12:35:09,656 Val Step[0850/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7769, Avg Acc@5: 0.9373
2022-01-24 12:35:11,697 Val Step[0900/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7773, Avg Acc@5: 0.9376
2022-01-24 12:35:13,771 Val Step[0950/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7780, Avg Acc@5: 0.9376
2022-01-24 12:35:15,775 Val Step[1000/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7778, Avg Acc@5: 0.9373
2022-01-24 12:35:17,575 Val Step[1050/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7772, Avg Acc@5: 0.9369
2022-01-24 12:35:19,565 Val Step[1100/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7767, Avg Acc@5: 0.9372
2022-01-24 12:35:21,529 Val Step[1150/1563], Avg Loss: 1.0415, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-24 12:35:23,386 Val Step[1200/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7775, Avg Acc@5: 0.9374
2022-01-24 12:35:25,191 Val Step[1250/1563], Avg Loss: 1.0400, Avg Acc@1: 0.7771, Avg Acc@5: 0.9376
2022-01-24 12:35:26,989 Val Step[1300/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7769, Avg Acc@5: 0.9373
2022-01-24 12:35:28,794 Val Step[1350/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7763, Avg Acc@5: 0.9372
2022-01-24 12:35:30,707 Val Step[1400/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7758, Avg Acc@5: 0.9372
2022-01-24 12:35:32,578 Val Step[1450/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7761, Avg Acc@5: 0.9372
2022-01-24 12:35:34,392 Val Step[1500/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7763, Avg Acc@5: 0.9373
2022-01-24 12:35:36,127 Val Step[1550/1563], Avg Loss: 1.0431, Avg Acc@1: 0.7761, Avg Acc@5: 0.9373
2022-01-24 12:35:38,116 ----- Epoch[034/050], Validation Loss: 1.0430, Validation Acc@1: 0.7760, Validation Acc@5: 0.9373, time: 131.66
2022-01-24 12:35:38,116 Now training epoch 35. LR=0.000002
2022-01-24 12:37:25,880 Epoch[035/050], Step[0000/1252], Avg Loss: 3.4297, Avg Acc: 0.4512
2022-01-24 12:38:52,202 Epoch[035/050], Step[0050/1252], Avg Loss: 2.8185, Avg Acc: 0.4925
2022-01-24 12:40:17,843 Epoch[035/050], Step[0100/1252], Avg Loss: 2.8779, Avg Acc: 0.4944
2022-01-24 12:41:44,087 Epoch[035/050], Step[0150/1252], Avg Loss: 2.8687, Avg Acc: 0.4979
2022-01-24 12:43:09,436 Epoch[035/050], Step[0200/1252], Avg Loss: 2.8747, Avg Acc: 0.4941
2022-01-24 12:44:36,898 Epoch[035/050], Step[0250/1252], Avg Loss: 2.8753, Avg Acc: 0.4868
2022-01-24 12:46:04,051 Epoch[035/050], Step[0300/1252], Avg Loss: 2.8747, Avg Acc: 0.4843
2022-01-24 12:47:31,234 Epoch[035/050], Step[0350/1252], Avg Loss: 2.8735, Avg Acc: 0.4903
2022-01-24 12:48:58,691 Epoch[035/050], Step[0400/1252], Avg Loss: 2.8752, Avg Acc: 0.4890
2022-01-24 12:50:25,544 Epoch[035/050], Step[0450/1252], Avg Loss: 2.8776, Avg Acc: 0.4875
2022-01-24 12:51:52,895 Epoch[035/050], Step[0500/1252], Avg Loss: 2.8803, Avg Acc: 0.4865
2022-01-24 12:53:20,277 Epoch[035/050], Step[0550/1252], Avg Loss: 2.8842, Avg Acc: 0.4868
2022-01-24 12:54:46,750 Epoch[035/050], Step[0600/1252], Avg Loss: 2.8826, Avg Acc: 0.4896
2022-01-24 12:56:13,569 Epoch[035/050], Step[0650/1252], Avg Loss: 2.8858, Avg Acc: 0.4878
2022-01-24 12:57:41,285 Epoch[035/050], Step[0700/1252], Avg Loss: 2.8890, Avg Acc: 0.4881
2022-01-24 12:59:08,349 Epoch[035/050], Step[0750/1252], Avg Loss: 2.8915, Avg Acc: 0.4868
2022-01-24 13:00:35,728 Epoch[035/050], Step[0800/1252], Avg Loss: 2.8884, Avg Acc: 0.4889
2022-01-24 13:02:03,123 Epoch[035/050], Step[0850/1252], Avg Loss: 2.8882, Avg Acc: 0.4892
2022-01-24 13:03:30,335 Epoch[035/050], Step[0900/1252], Avg Loss: 2.8872, Avg Acc: 0.4894
2022-01-24 13:04:57,730 Epoch[035/050], Step[0950/1252], Avg Loss: 2.8875, Avg Acc: 0.4889
2022-01-24 13:06:23,526 Epoch[035/050], Step[1000/1252], Avg Loss: 2.8873, Avg Acc: 0.4877
2022-01-24 13:07:52,061 Epoch[035/050], Step[1050/1252], Avg Loss: 2.8883, Avg Acc: 0.4883
2022-01-24 13:09:20,012 Epoch[035/050], Step[1100/1252], Avg Loss: 2.8868, Avg Acc: 0.4879
2022-01-24 13:10:47,883 Epoch[035/050], Step[1150/1252], Avg Loss: 2.8890, Avg Acc: 0.4878
2022-01-24 13:12:14,802 Epoch[035/050], Step[1200/1252], Avg Loss: 2.8891, Avg Acc: 0.4880
2022-01-24 13:13:43,230 Epoch[035/050], Step[1250/1252], Avg Loss: 2.8870, Avg Acc: 0.4879
2022-01-24 13:13:50,297 ----- Epoch[035/050], Train Loss: 2.8871, Train Acc: 0.4879, time: 2292.18, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 13:13:50,297 Now training epoch 36. LR=0.000002
2022-01-24 13:15:38,464 Epoch[036/050], Step[0000/1252], Avg Loss: 3.2687, Avg Acc: 0.5078
2022-01-24 13:17:05,660 Epoch[036/050], Step[0050/1252], Avg Loss: 2.9587, Avg Acc: 0.4834
2022-01-24 13:18:32,610 Epoch[036/050], Step[0100/1252], Avg Loss: 2.9138, Avg Acc: 0.4939
2022-01-24 13:19:59,761 Epoch[036/050], Step[0150/1252], Avg Loss: 2.9090, Avg Acc: 0.4935
2022-01-24 13:21:25,055 Epoch[036/050], Step[0200/1252], Avg Loss: 2.9084, Avg Acc: 0.4880
2022-01-24 13:22:50,595 Epoch[036/050], Step[0250/1252], Avg Loss: 2.9161, Avg Acc: 0.4918
2022-01-24 13:24:15,965 Epoch[036/050], Step[0300/1252], Avg Loss: 2.9173, Avg Acc: 0.4840
2022-01-24 13:25:42,622 Epoch[036/050], Step[0350/1252], Avg Loss: 2.9134, Avg Acc: 0.4833
2022-01-24 13:27:09,726 Epoch[036/050], Step[0400/1252], Avg Loss: 2.9108, Avg Acc: 0.4796
2022-01-24 13:28:35,476 Epoch[036/050], Step[0450/1252], Avg Loss: 2.9118, Avg Acc: 0.4837
2022-01-24 13:30:01,098 Epoch[036/050], Step[0500/1252], Avg Loss: 2.9059, Avg Acc: 0.4837
2022-01-24 13:31:27,213 Epoch[036/050], Step[0550/1252], Avg Loss: 2.9072, Avg Acc: 0.4841
2022-01-24 13:32:53,783 Epoch[036/050], Step[0600/1252], Avg Loss: 2.9061, Avg Acc: 0.4859
2022-01-24 13:34:19,095 Epoch[036/050], Step[0650/1252], Avg Loss: 2.9063, Avg Acc: 0.4865
2022-01-24 13:35:45,463 Epoch[036/050], Step[0700/1252], Avg Loss: 2.9045, Avg Acc: 0.4869
2022-01-24 13:37:13,214 Epoch[036/050], Step[0750/1252], Avg Loss: 2.8996, Avg Acc: 0.4835
2022-01-24 13:38:39,570 Epoch[036/050], Step[0800/1252], Avg Loss: 2.9007, Avg Acc: 0.4841
2022-01-24 13:40:07,946 Epoch[036/050], Step[0850/1252], Avg Loss: 2.8990, Avg Acc: 0.4827
2022-01-24 13:41:36,242 Epoch[036/050], Step[0900/1252], Avg Loss: 2.8981, Avg Acc: 0.4844
2022-01-24 13:43:03,181 Epoch[036/050], Step[0950/1252], Avg Loss: 2.8998, Avg Acc: 0.4841
2022-01-24 13:44:29,379 Epoch[036/050], Step[1000/1252], Avg Loss: 2.9003, Avg Acc: 0.4843
2022-01-24 13:45:56,278 Epoch[036/050], Step[1050/1252], Avg Loss: 2.8954, Avg Acc: 0.4836
2022-01-24 13:47:23,396 Epoch[036/050], Step[1100/1252], Avg Loss: 2.8939, Avg Acc: 0.4846
2022-01-24 13:48:48,332 Epoch[036/050], Step[1150/1252], Avg Loss: 2.8915, Avg Acc: 0.4857
2022-01-24 13:50:14,792 Epoch[036/050], Step[1200/1252], Avg Loss: 2.8918, Avg Acc: 0.4853
2022-01-24 13:51:41,334 Epoch[036/050], Step[1250/1252], Avg Loss: 2.8896, Avg Acc: 0.4850
2022-01-24 13:51:48,379 ----- Epoch[036/050], Train Loss: 2.8896, Train Acc: 0.4850, time: 2278.08, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 13:51:48,379 ----- Validation after Epoch: 36
2022-01-24 13:53:01,688 Val Step[0000/1563], Avg Loss: 0.8024, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 13:53:03,509 Val Step[0050/1563], Avg Loss: 1.0016, Avg Acc@1: 0.7837, Avg Acc@5: 0.9412
2022-01-24 13:53:05,450 Val Step[0100/1563], Avg Loss: 1.0343, Avg Acc@1: 0.7850, Avg Acc@5: 0.9372
2022-01-24 13:53:07,240 Val Step[0150/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7852, Avg Acc@5: 0.9352
2022-01-24 13:53:09,154 Val Step[0200/1563], Avg Loss: 1.0382, Avg Acc@1: 0.7858, Avg Acc@5: 0.9356
2022-01-24 13:53:10,954 Val Step[0250/1563], Avg Loss: 1.0286, Avg Acc@1: 0.7842, Avg Acc@5: 0.9379
2022-01-24 13:53:12,840 Val Step[0300/1563], Avg Loss: 1.0288, Avg Acc@1: 0.7842, Avg Acc@5: 0.9367
2022-01-24 13:53:14,774 Val Step[0350/1563], Avg Loss: 1.0335, Avg Acc@1: 0.7835, Avg Acc@5: 0.9363
2022-01-24 13:53:16,586 Val Step[0400/1563], Avg Loss: 1.0330, Avg Acc@1: 0.7837, Avg Acc@5: 0.9359
2022-01-24 13:53:18,431 Val Step[0450/1563], Avg Loss: 1.0374, Avg Acc@1: 0.7815, Avg Acc@5: 0.9358
2022-01-24 13:53:20,366 Val Step[0500/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7805, Avg Acc@5: 0.9361
2022-01-24 13:53:22,281 Val Step[0550/1563], Avg Loss: 1.0389, Avg Acc@1: 0.7794, Avg Acc@5: 0.9362
2022-01-24 13:53:24,183 Val Step[0600/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7790, Avg Acc@5: 0.9363
2022-01-24 13:53:26,052 Val Step[0650/1563], Avg Loss: 1.0380, Avg Acc@1: 0.7784, Avg Acc@5: 0.9365
2022-01-24 13:53:27,966 Val Step[0700/1563], Avg Loss: 1.0356, Avg Acc@1: 0.7789, Avg Acc@5: 0.9371
2022-01-24 13:53:29,808 Val Step[0750/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7769, Avg Acc@5: 0.9370
2022-01-24 13:53:31,623 Val Step[0800/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7774, Avg Acc@5: 0.9370
2022-01-24 13:53:33,452 Val Step[0850/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7772, Avg Acc@5: 0.9368
2022-01-24 13:53:35,361 Val Step[0900/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7776, Avg Acc@5: 0.9373
2022-01-24 13:53:37,289 Val Step[0950/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7782, Avg Acc@5: 0.9373
2022-01-24 13:53:39,068 Val Step[1000/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7780, Avg Acc@5: 0.9370
2022-01-24 13:53:40,838 Val Step[1050/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7772, Avg Acc@5: 0.9366
2022-01-24 13:53:42,654 Val Step[1100/1563], Avg Loss: 1.0438, Avg Acc@1: 0.7767, Avg Acc@5: 0.9368
2022-01-24 13:53:44,510 Val Step[1150/1563], Avg Loss: 1.0415, Avg Acc@1: 0.7768, Avg Acc@5: 0.9372
2022-01-24 13:53:46,401 Val Step[1200/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7776, Avg Acc@5: 0.9372
2022-01-24 13:53:48,356 Val Step[1250/1563], Avg Loss: 1.0400, Avg Acc@1: 0.7772, Avg Acc@5: 0.9374
2022-01-24 13:53:50,173 Val Step[1300/1563], Avg Loss: 1.0430, Avg Acc@1: 0.7770, Avg Acc@5: 0.9372
2022-01-24 13:53:51,981 Val Step[1350/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7764, Avg Acc@5: 0.9372
2022-01-24 13:53:53,781 Val Step[1400/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7759, Avg Acc@5: 0.9372
2022-01-24 13:53:55,728 Val Step[1450/1563], Avg Loss: 1.0428, Avg Acc@1: 0.7764, Avg Acc@5: 0.9373
2022-01-24 13:53:57,868 Val Step[1500/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7766, Avg Acc@5: 0.9374
2022-01-24 13:53:59,920 Val Step[1550/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7763, Avg Acc@5: 0.9374
2022-01-24 13:54:01,929 ----- Epoch[036/050], Validation Loss: 1.0431, Validation Acc@1: 0.7763, Validation Acc@5: 0.9374, time: 133.55
2022-01-24 13:54:01,929 Now training epoch 37. LR=0.000002
2022-01-24 13:55:53,507 Epoch[037/050], Step[0000/1252], Avg Loss: 2.5636, Avg Acc: 0.7100
2022-01-24 13:57:21,896 Epoch[037/050], Step[0050/1252], Avg Loss: 2.8656, Avg Acc: 0.4501
2022-01-24 13:58:47,701 Epoch[037/050], Step[0100/1252], Avg Loss: 2.8623, Avg Acc: 0.4811
2022-01-24 14:00:15,461 Epoch[037/050], Step[0150/1252], Avg Loss: 2.8657, Avg Acc: 0.4818
2022-01-24 14:01:43,154 Epoch[037/050], Step[0200/1252], Avg Loss: 2.8691, Avg Acc: 0.4865
2022-01-24 14:03:10,602 Epoch[037/050], Step[0250/1252], Avg Loss: 2.8801, Avg Acc: 0.4846
2022-01-24 14:04:37,302 Epoch[037/050], Step[0300/1252], Avg Loss: 2.8782, Avg Acc: 0.4859
2022-01-24 14:06:05,497 Epoch[037/050], Step[0350/1252], Avg Loss: 2.8877, Avg Acc: 0.4847
2022-01-24 14:07:33,444 Epoch[037/050], Step[0400/1252], Avg Loss: 2.8882, Avg Acc: 0.4884
2022-01-24 14:09:01,160 Epoch[037/050], Step[0450/1252], Avg Loss: 2.8828, Avg Acc: 0.4873
2022-01-24 14:10:28,330 Epoch[037/050], Step[0500/1252], Avg Loss: 2.8826, Avg Acc: 0.4872
2022-01-24 14:11:56,838 Epoch[037/050], Step[0550/1252], Avg Loss: 2.8837, Avg Acc: 0.4868
2022-01-24 14:13:24,583 Epoch[037/050], Step[0600/1252], Avg Loss: 2.8844, Avg Acc: 0.4885
2022-01-24 14:14:52,172 Epoch[037/050], Step[0650/1252], Avg Loss: 2.8885, Avg Acc: 0.4898
2022-01-24 14:16:19,734 Epoch[037/050], Step[0700/1252], Avg Loss: 2.8816, Avg Acc: 0.4910
2022-01-24 14:17:46,899 Epoch[037/050], Step[0750/1252], Avg Loss: 2.8802, Avg Acc: 0.4936
2022-01-24 14:19:13,951 Epoch[037/050], Step[0800/1252], Avg Loss: 2.8781, Avg Acc: 0.4946
2022-01-24 14:20:41,067 Epoch[037/050], Step[0850/1252], Avg Loss: 2.8795, Avg Acc: 0.4947
2022-01-24 14:22:08,457 Epoch[037/050], Step[0900/1252], Avg Loss: 2.8820, Avg Acc: 0.4941
2022-01-24 14:23:35,672 Epoch[037/050], Step[0950/1252], Avg Loss: 2.8833, Avg Acc: 0.4931
2022-01-24 14:25:03,110 Epoch[037/050], Step[1000/1252], Avg Loss: 2.8850, Avg Acc: 0.4935
2022-01-24 14:26:30,876 Epoch[037/050], Step[1050/1252], Avg Loss: 2.8847, Avg Acc: 0.4941
2022-01-24 14:27:59,696 Epoch[037/050], Step[1100/1252], Avg Loss: 2.8856, Avg Acc: 0.4953
2022-01-24 14:29:28,328 Epoch[037/050], Step[1150/1252], Avg Loss: 2.8860, Avg Acc: 0.4952
2022-01-24 14:30:55,496 Epoch[037/050], Step[1200/1252], Avg Loss: 2.8857, Avg Acc: 0.4973
2022-01-24 14:32:22,452 Epoch[037/050], Step[1250/1252], Avg Loss: 2.8850, Avg Acc: 0.4969
2022-01-24 14:32:29,653 ----- Epoch[037/050], Train Loss: 2.8850, Train Acc: 0.4969, time: 2307.72, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 14:32:29,653 Now training epoch 38. LR=0.000002
2022-01-24 14:34:21,377 Epoch[038/050], Step[0000/1252], Avg Loss: 2.5266, Avg Acc: 0.7520
2022-01-24 14:35:48,959 Epoch[038/050], Step[0050/1252], Avg Loss: 2.9014, Avg Acc: 0.5058
2022-01-24 14:37:16,327 Epoch[038/050], Step[0100/1252], Avg Loss: 2.9122, Avg Acc: 0.4909
2022-01-24 14:38:42,323 Epoch[038/050], Step[0150/1252], Avg Loss: 2.8959, Avg Acc: 0.4852
2022-01-24 14:40:08,913 Epoch[038/050], Step[0200/1252], Avg Loss: 2.8855, Avg Acc: 0.4885
2022-01-24 14:41:35,907 Epoch[038/050], Step[0250/1252], Avg Loss: 2.8872, Avg Acc: 0.4917
2022-01-24 14:43:02,569 Epoch[038/050], Step[0300/1252], Avg Loss: 2.8813, Avg Acc: 0.4947
2022-01-24 14:44:30,265 Epoch[038/050], Step[0350/1252], Avg Loss: 2.8776, Avg Acc: 0.4953
2022-01-24 14:45:56,190 Epoch[038/050], Step[0400/1252], Avg Loss: 2.8775, Avg Acc: 0.4951
2022-01-24 14:47:23,101 Epoch[038/050], Step[0450/1252], Avg Loss: 2.8792, Avg Acc: 0.4909
2022-01-24 14:48:48,625 Epoch[038/050], Step[0500/1252], Avg Loss: 2.8846, Avg Acc: 0.4921
2022-01-24 14:50:15,066 Epoch[038/050], Step[0550/1252], Avg Loss: 2.8830, Avg Acc: 0.4938
2022-01-24 14:51:42,991 Epoch[038/050], Step[0600/1252], Avg Loss: 2.8761, Avg Acc: 0.4925
2022-01-24 14:53:10,050 Epoch[038/050], Step[0650/1252], Avg Loss: 2.8803, Avg Acc: 0.4918
2022-01-24 14:54:37,266 Epoch[038/050], Step[0700/1252], Avg Loss: 2.8816, Avg Acc: 0.4900
2022-01-24 14:56:04,530 Epoch[038/050], Step[0750/1252], Avg Loss: 2.8792, Avg Acc: 0.4933
2022-01-24 14:57:32,713 Epoch[038/050], Step[0800/1252], Avg Loss: 2.8836, Avg Acc: 0.4932
2022-01-24 14:59:00,268 Epoch[038/050], Step[0850/1252], Avg Loss: 2.8819, Avg Acc: 0.4929
2022-01-24 15:00:27,655 Epoch[038/050], Step[0900/1252], Avg Loss: 2.8866, Avg Acc: 0.4923
2022-01-24 15:01:55,544 Epoch[038/050], Step[0950/1252], Avg Loss: 2.8874, Avg Acc: 0.4919
2022-01-24 15:03:24,250 Epoch[038/050], Step[1000/1252], Avg Loss: 2.8862, Avg Acc: 0.4909
2022-01-24 15:04:52,362 Epoch[038/050], Step[1050/1252], Avg Loss: 2.8873, Avg Acc: 0.4897
2022-01-24 15:06:21,098 Epoch[038/050], Step[1100/1252], Avg Loss: 2.8910, Avg Acc: 0.4899
2022-01-24 15:07:49,067 Epoch[038/050], Step[1150/1252], Avg Loss: 2.8891, Avg Acc: 0.4899
2022-01-24 15:09:17,306 Epoch[038/050], Step[1200/1252], Avg Loss: 2.8885, Avg Acc: 0.4890
2022-01-24 15:10:44,543 Epoch[038/050], Step[1250/1252], Avg Loss: 2.8887, Avg Acc: 0.4900
2022-01-24 15:10:51,709 ----- Epoch[038/050], Train Loss: 2.8887, Train Acc: 0.4900, time: 2302.05, Best Val(epoch30) Acc@1: 0.7766
2022-01-24 15:10:51,709 ----- Validation after Epoch: 38
2022-01-24 15:12:04,752 Val Step[0000/1563], Avg Loss: 0.8025, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 15:12:06,773 Val Step[0050/1563], Avg Loss: 1.0044, Avg Acc@1: 0.7831, Avg Acc@5: 0.9418
2022-01-24 15:12:08,855 Val Step[0100/1563], Avg Loss: 1.0368, Avg Acc@1: 0.7822, Avg Acc@5: 0.9381
2022-01-24 15:12:10,736 Val Step[0150/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7817, Avg Acc@5: 0.9358
2022-01-24 15:12:12,638 Val Step[0200/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7833, Avg Acc@5: 0.9367
2022-01-24 15:12:14,545 Val Step[0250/1563], Avg Loss: 1.0305, Avg Acc@1: 0.7824, Avg Acc@5: 0.9389
2022-01-24 15:12:16,404 Val Step[0300/1563], Avg Loss: 1.0304, Avg Acc@1: 0.7818, Avg Acc@5: 0.9374
2022-01-24 15:12:18,283 Val Step[0350/1563], Avg Loss: 1.0353, Avg Acc@1: 0.7812, Avg Acc@5: 0.9369
2022-01-24 15:12:20,165 Val Step[0400/1563], Avg Loss: 1.0349, Avg Acc@1: 0.7821, Avg Acc@5: 0.9366
2022-01-24 15:12:21,929 Val Step[0450/1563], Avg Loss: 1.0392, Avg Acc@1: 0.7794, Avg Acc@5: 0.9365
2022-01-24 15:12:23,755 Val Step[0500/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7791, Avg Acc@5: 0.9369
2022-01-24 15:12:25,537 Val Step[0550/1563], Avg Loss: 1.0407, Avg Acc@1: 0.7784, Avg Acc@5: 0.9369
2022-01-24 15:12:27,314 Val Step[0600/1563], Avg Loss: 1.0392, Avg Acc@1: 0.7784, Avg Acc@5: 0.9370
2022-01-24 15:12:29,134 Val Step[0650/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7781, Avg Acc@5: 0.9370
2022-01-24 15:12:31,048 Val Step[0700/1563], Avg Loss: 1.0371, Avg Acc@1: 0.7788, Avg Acc@5: 0.9375
2022-01-24 15:12:32,943 Val Step[0750/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7769, Avg Acc@5: 0.9373
2022-01-24 15:12:34,773 Val Step[0800/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7775, Avg Acc@5: 0.9373
2022-01-24 15:12:36,562 Val Step[0850/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7775, Avg Acc@5: 0.9370
2022-01-24 15:12:38,331 Val Step[0900/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7779, Avg Acc@5: 0.9374
2022-01-24 15:12:40,115 Val Step[0950/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7785, Avg Acc@5: 0.9376
2022-01-24 15:12:41,954 Val Step[1000/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7783, Avg Acc@5: 0.9373
2022-01-24 15:12:43,736 Val Step[1050/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7776, Avg Acc@5: 0.9370
2022-01-24 15:12:45,560 Val Step[1100/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7770, Avg Acc@5: 0.9372
2022-01-24 15:12:47,415 Val Step[1150/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7774, Avg Acc@5: 0.9376
2022-01-24 15:12:49,187 Val Step[1200/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7781, Avg Acc@5: 0.9376
2022-01-24 15:12:51,003 Val Step[1250/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7777, Avg Acc@5: 0.9378
2022-01-24 15:12:52,874 Val Step[1300/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7776, Avg Acc@5: 0.9376
2022-01-24 15:12:54,655 Val Step[1350/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7770, Avg Acc@5: 0.9375
2022-01-24 15:12:56,526 Val Step[1400/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7766, Avg Acc@5: 0.9375
2022-01-24 15:12:58,316 Val Step[1450/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-24 15:13:00,129 Val Step[1500/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7771, Avg Acc@5: 0.9376
2022-01-24 15:13:01,892 Val Step[1550/1563], Avg Loss: 1.0446, Avg Acc@1: 0.7769, Avg Acc@5: 0.9376
2022-01-24 15:13:03,793 ----- Epoch[038/050], Validation Loss: 1.0445, Validation Acc@1: 0.7769, Validation Acc@5: 0.9376, time: 132.08
2022-01-24 15:13:05,043 the pre best model acc:0.7766, at epoch 30
2022-01-24 15:13:05,322 current best model acc:0.7769, at epoch 38
2022-01-24 15:13:05,322 ----- Save BEST model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 15:13:05,322 ----- Save BEST optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 15:13:05,322 ----- Save model: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdparams
2022-01-24 15:13:05,322 ----- Save optim: /root/paddlejob/workspace/output//train/Best_CycleMLP.pdopt
2022-01-24 15:13:05,322 Now training epoch 39. LR=0.000001
2022-01-24 15:14:46,673 Epoch[039/050], Step[0000/1252], Avg Loss: 3.1197, Avg Acc: 0.4785
2022-01-24 15:16:15,128 Epoch[039/050], Step[0050/1252], Avg Loss: 2.9219, Avg Acc: 0.4860
2022-01-24 15:17:42,388 Epoch[039/050], Step[0100/1252], Avg Loss: 2.9005, Avg Acc: 0.4770
2022-01-24 15:19:09,985 Epoch[039/050], Step[0150/1252], Avg Loss: 2.9141, Avg Acc: 0.4802
2022-01-24 15:20:35,965 Epoch[039/050], Step[0200/1252], Avg Loss: 2.9156, Avg Acc: 0.4858
2022-01-24 15:22:03,284 Epoch[039/050], Step[0250/1252], Avg Loss: 2.9144, Avg Acc: 0.4844
2022-01-24 15:23:30,030 Epoch[039/050], Step[0300/1252], Avg Loss: 2.9091, Avg Acc: 0.4871
2022-01-24 15:24:56,541 Epoch[039/050], Step[0350/1252], Avg Loss: 2.9069, Avg Acc: 0.4935
2022-01-24 15:26:24,446 Epoch[039/050], Step[0400/1252], Avg Loss: 2.9025, Avg Acc: 0.4938
2022-01-24 15:27:51,971 Epoch[039/050], Step[0450/1252], Avg Loss: 2.8984, Avg Acc: 0.4935
2022-01-24 15:29:20,440 Epoch[039/050], Step[0500/1252], Avg Loss: 2.8980, Avg Acc: 0.4952
2022-01-24 15:30:47,716 Epoch[039/050], Step[0550/1252], Avg Loss: 2.8940, Avg Acc: 0.4948
2022-01-24 15:32:13,984 Epoch[039/050], Step[0600/1252], Avg Loss: 2.8981, Avg Acc: 0.4941
2022-01-24 15:33:42,009 Epoch[039/050], Step[0650/1252], Avg Loss: 2.8974, Avg Acc: 0.4944
2022-01-24 15:35:08,718 Epoch[039/050], Step[0700/1252], Avg Loss: 2.8951, Avg Acc: 0.4944
2022-01-24 15:36:36,708 Epoch[039/050], Step[0750/1252], Avg Loss: 2.8951, Avg Acc: 0.4915
2022-01-24 15:38:04,567 Epoch[039/050], Step[0800/1252], Avg Loss: 2.8948, Avg Acc: 0.4900
2022-01-24 15:39:31,855 Epoch[039/050], Step[0850/1252], Avg Loss: 2.8930, Avg Acc: 0.4902
2022-01-24 15:40:59,914 Epoch[039/050], Step[0900/1252], Avg Loss: 2.8961, Avg Acc: 0.4895
2022-01-24 15:42:27,658 Epoch[039/050], Step[0950/1252], Avg Loss: 2.8969, Avg Acc: 0.4884
2022-01-24 15:43:55,428 Epoch[039/050], Step[1000/1252], Avg Loss: 2.8956, Avg Acc: 0.4889
2022-01-24 15:45:23,105 Epoch[039/050], Step[1050/1252], Avg Loss: 2.8974, Avg Acc: 0.4884
2022-01-24 15:46:50,676 Epoch[039/050], Step[1100/1252], Avg Loss: 2.8942, Avg Acc: 0.4888
2022-01-24 15:48:19,075 Epoch[039/050], Step[1150/1252], Avg Loss: 2.8903, Avg Acc: 0.4899
2022-01-24 15:49:46,166 Epoch[039/050], Step[1200/1252], Avg Loss: 2.8917, Avg Acc: 0.4903
2022-01-24 15:51:13,830 Epoch[039/050], Step[1250/1252], Avg Loss: 2.8903, Avg Acc: 0.4917
2022-01-24 15:51:21,058 ----- Epoch[039/050], Train Loss: 2.8903, Train Acc: 0.4917, time: 2295.73, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 15:51:21,058 Now training epoch 40. LR=0.000001
2022-01-24 15:53:07,673 Epoch[040/050], Step[0000/1252], Avg Loss: 2.8924, Avg Acc: 0.4844
2022-01-24 15:54:33,868 Epoch[040/050], Step[0050/1252], Avg Loss: 2.8878, Avg Acc: 0.5073
2022-01-24 15:55:59,728 Epoch[040/050], Step[0100/1252], Avg Loss: 2.9253, Avg Acc: 0.4855
2022-01-24 15:57:26,192 Epoch[040/050], Step[0150/1252], Avg Loss: 2.9155, Avg Acc: 0.4889
2022-01-24 15:58:52,705 Epoch[040/050], Step[0200/1252], Avg Loss: 2.8996, Avg Acc: 0.4935
2022-01-24 16:00:19,420 Epoch[040/050], Step[0250/1252], Avg Loss: 2.8975, Avg Acc: 0.4893
2022-01-24 16:01:44,328 Epoch[040/050], Step[0300/1252], Avg Loss: 2.8991, Avg Acc: 0.4864
2022-01-24 16:03:10,671 Epoch[040/050], Step[0350/1252], Avg Loss: 2.8974, Avg Acc: 0.4885
2022-01-24 16:04:37,628 Epoch[040/050], Step[0400/1252], Avg Loss: 2.9006, Avg Acc: 0.4892
2022-01-24 16:06:05,785 Epoch[040/050], Step[0450/1252], Avg Loss: 2.8971, Avg Acc: 0.4861
2022-01-24 16:07:32,731 Epoch[040/050], Step[0500/1252], Avg Loss: 2.8930, Avg Acc: 0.4890
2022-01-24 16:09:01,217 Epoch[040/050], Step[0550/1252], Avg Loss: 2.8980, Avg Acc: 0.4888
2022-01-24 16:10:29,412 Epoch[040/050], Step[0600/1252], Avg Loss: 2.8976, Avg Acc: 0.4895
2022-01-24 16:11:57,191 Epoch[040/050], Step[0650/1252], Avg Loss: 2.8928, Avg Acc: 0.4909
2022-01-24 16:13:24,568 Epoch[040/050], Step[0700/1252], Avg Loss: 2.8850, Avg Acc: 0.4914
2022-01-24 16:14:52,016 Epoch[040/050], Step[0750/1252], Avg Loss: 2.8838, Avg Acc: 0.4913
2022-01-24 16:16:18,649 Epoch[040/050], Step[0800/1252], Avg Loss: 2.8824, Avg Acc: 0.4891
2022-01-24 16:17:46,709 Epoch[040/050], Step[0850/1252], Avg Loss: 2.8833, Avg Acc: 0.4890
2022-01-24 16:19:15,457 Epoch[040/050], Step[0900/1252], Avg Loss: 2.8808, Avg Acc: 0.4881
2022-01-24 16:20:43,777 Epoch[040/050], Step[0950/1252], Avg Loss: 2.8804, Avg Acc: 0.4846
2022-01-24 16:22:10,920 Epoch[040/050], Step[1000/1252], Avg Loss: 2.8822, Avg Acc: 0.4834
2022-01-24 16:23:37,680 Epoch[040/050], Step[1050/1252], Avg Loss: 2.8857, Avg Acc: 0.4830
2022-01-24 16:25:05,418 Epoch[040/050], Step[1100/1252], Avg Loss: 2.8871, Avg Acc: 0.4825
2022-01-24 16:26:32,808 Epoch[040/050], Step[1150/1252], Avg Loss: 2.8882, Avg Acc: 0.4829
2022-01-24 16:28:00,389 Epoch[040/050], Step[1200/1252], Avg Loss: 2.8859, Avg Acc: 0.4833
2022-01-24 16:29:26,451 Epoch[040/050], Step[1250/1252], Avg Loss: 2.8861, Avg Acc: 0.4838
2022-01-24 16:29:33,543 ----- Epoch[040/050], Train Loss: 2.8860, Train Acc: 0.4838, time: 2292.48, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 16:29:33,543 ----- Validation after Epoch: 40
2022-01-24 16:30:46,368 Val Step[0000/1563], Avg Loss: 0.8175, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 16:30:48,529 Val Step[0050/1563], Avg Loss: 1.0068, Avg Acc@1: 0.7819, Avg Acc@5: 0.9412
2022-01-24 16:30:50,627 Val Step[0100/1563], Avg Loss: 1.0387, Avg Acc@1: 0.7828, Avg Acc@5: 0.9378
2022-01-24 16:30:52,479 Val Step[0150/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7833, Avg Acc@5: 0.9361
2022-01-24 16:30:54,287 Val Step[0200/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7833, Avg Acc@5: 0.9367
2022-01-24 16:30:56,056 Val Step[0250/1563], Avg Loss: 1.0332, Avg Acc@1: 0.7819, Avg Acc@5: 0.9382
2022-01-24 16:30:57,844 Val Step[0300/1563], Avg Loss: 1.0332, Avg Acc@1: 0.7811, Avg Acc@5: 0.9370
2022-01-24 16:30:59,684 Val Step[0350/1563], Avg Loss: 1.0381, Avg Acc@1: 0.7810, Avg Acc@5: 0.9364
2022-01-24 16:31:01,481 Val Step[0400/1563], Avg Loss: 1.0375, Avg Acc@1: 0.7820, Avg Acc@5: 0.9366
2022-01-24 16:31:03,279 Val Step[0450/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7794, Avg Acc@5: 0.9365
2022-01-24 16:31:05,191 Val Step[0500/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7787, Avg Acc@5: 0.9368
2022-01-24 16:31:07,123 Val Step[0550/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7780, Avg Acc@5: 0.9368
2022-01-24 16:31:09,041 Val Step[0600/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7777, Avg Acc@5: 0.9370
2022-01-24 16:31:10,976 Val Step[0650/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7774, Avg Acc@5: 0.9370
2022-01-24 16:31:12,851 Val Step[0700/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7779, Avg Acc@5: 0.9376
2022-01-24 16:31:14,679 Val Step[0750/1563], Avg Loss: 1.0465, Avg Acc@1: 0.7761, Avg Acc@5: 0.9374
2022-01-24 16:31:16,481 Val Step[0800/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7769, Avg Acc@5: 0.9373
2022-01-24 16:31:18,288 Val Step[0850/1563], Avg Loss: 1.0478, Avg Acc@1: 0.7769, Avg Acc@5: 0.9371
2022-01-24 16:31:20,078 Val Step[0900/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7775, Avg Acc@5: 0.9375
2022-01-24 16:31:21,862 Val Step[0950/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7780, Avg Acc@5: 0.9378
2022-01-24 16:31:23,648 Val Step[1000/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7778, Avg Acc@5: 0.9375
2022-01-24 16:31:25,499 Val Step[1050/1563], Avg Loss: 1.0481, Avg Acc@1: 0.7772, Avg Acc@5: 0.9372
2022-01-24 16:31:27,367 Val Step[1100/1563], Avg Loss: 1.0482, Avg Acc@1: 0.7767, Avg Acc@5: 0.9374
2022-01-24 16:31:29,151 Val Step[1150/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7768, Avg Acc@5: 0.9378
2022-01-24 16:31:30,954 Val Step[1200/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7776, Avg Acc@5: 0.9378
2022-01-24 16:31:32,846 Val Step[1250/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7771, Avg Acc@5: 0.9380
2022-01-24 16:31:34,660 Val Step[1300/1563], Avg Loss: 1.0474, Avg Acc@1: 0.7770, Avg Acc@5: 0.9377
2022-01-24 16:31:36,500 Val Step[1350/1563], Avg Loss: 1.0487, Avg Acc@1: 0.7765, Avg Acc@5: 0.9376
2022-01-24 16:31:38,295 Val Step[1400/1563], Avg Loss: 1.0483, Avg Acc@1: 0.7761, Avg Acc@5: 0.9376
2022-01-24 16:31:40,092 Val Step[1450/1563], Avg Loss: 1.0472, Avg Acc@1: 0.7765, Avg Acc@5: 0.9376
2022-01-24 16:31:41,948 Val Step[1500/1563], Avg Loss: 1.0471, Avg Acc@1: 0.7766, Avg Acc@5: 0.9378
2022-01-24 16:31:43,694 Val Step[1550/1563], Avg Loss: 1.0476, Avg Acc@1: 0.7764, Avg Acc@5: 0.9378
2022-01-24 16:31:45,529 ----- Epoch[040/050], Validation Loss: 1.0475, Validation Acc@1: 0.7764, Validation Acc@5: 0.9378, time: 131.98
2022-01-24 16:31:45,530 Now training epoch 41. LR=0.000001
2022-01-24 16:33:29,083 Epoch[041/050], Step[0000/1252], Avg Loss: 2.9504, Avg Acc: 0.5059
2022-01-24 16:34:56,336 Epoch[041/050], Step[0050/1252], Avg Loss: 2.7881, Avg Acc: 0.5111
2022-01-24 16:36:23,029 Epoch[041/050], Step[0100/1252], Avg Loss: 2.8387, Avg Acc: 0.4935
2022-01-24 16:37:49,369 Epoch[041/050], Step[0150/1252], Avg Loss: 2.8476, Avg Acc: 0.5000
2022-01-24 16:39:15,472 Epoch[041/050], Step[0200/1252], Avg Loss: 2.8539, Avg Acc: 0.4896
2022-01-24 16:40:42,282 Epoch[041/050], Step[0250/1252], Avg Loss: 2.8699, Avg Acc: 0.4893
2022-01-24 16:42:09,758 Epoch[041/050], Step[0300/1252], Avg Loss: 2.8754, Avg Acc: 0.4903
2022-01-24 16:43:36,981 Epoch[041/050], Step[0350/1252], Avg Loss: 2.8768, Avg Acc: 0.4931
2022-01-24 16:45:04,572 Epoch[041/050], Step[0400/1252], Avg Loss: 2.8888, Avg Acc: 0.4907
2022-01-24 16:46:31,329 Epoch[041/050], Step[0450/1252], Avg Loss: 2.8799, Avg Acc: 0.4929
2022-01-24 16:47:58,793 Epoch[041/050], Step[0500/1252], Avg Loss: 2.8863, Avg Acc: 0.4882
2022-01-24 16:49:25,247 Epoch[041/050], Step[0550/1252], Avg Loss: 2.8797, Avg Acc: 0.4866
2022-01-24 16:50:50,913 Epoch[041/050], Step[0600/1252], Avg Loss: 2.8798, Avg Acc: 0.4859
2022-01-24 16:52:18,516 Epoch[041/050], Step[0650/1252], Avg Loss: 2.8828, Avg Acc: 0.4853
2022-01-24 16:53:44,325 Epoch[041/050], Step[0700/1252], Avg Loss: 2.8812, Avg Acc: 0.4864
2022-01-24 16:55:10,678 Epoch[041/050], Step[0750/1252], Avg Loss: 2.8840, Avg Acc: 0.4870
2022-01-24 16:56:37,459 Epoch[041/050], Step[0800/1252], Avg Loss: 2.8851, Avg Acc: 0.4879
2022-01-24 16:58:05,294 Epoch[041/050], Step[0850/1252], Avg Loss: 2.8856, Avg Acc: 0.4877
2022-01-24 16:59:33,345 Epoch[041/050], Step[0900/1252], Avg Loss: 2.8842, Avg Acc: 0.4887
2022-01-24 17:01:01,352 Epoch[041/050], Step[0950/1252], Avg Loss: 2.8829, Avg Acc: 0.4890
2022-01-24 17:02:28,518 Epoch[041/050], Step[1000/1252], Avg Loss: 2.8829, Avg Acc: 0.4889
2022-01-24 17:03:55,943 Epoch[041/050], Step[1050/1252], Avg Loss: 2.8814, Avg Acc: 0.4888
2022-01-24 17:05:22,627 Epoch[041/050], Step[1100/1252], Avg Loss: 2.8842, Avg Acc: 0.4892
2022-01-24 17:06:48,763 Epoch[041/050], Step[1150/1252], Avg Loss: 2.8834, Avg Acc: 0.4897
2022-01-24 17:08:16,296 Epoch[041/050], Step[1200/1252], Avg Loss: 2.8806, Avg Acc: 0.4892
2022-01-24 17:09:43,066 Epoch[041/050], Step[1250/1252], Avg Loss: 2.8820, Avg Acc: 0.4883
2022-01-24 17:09:50,290 ----- Epoch[041/050], Train Loss: 2.8821, Train Acc: 0.4883, time: 2284.76, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 17:09:50,290 Now training epoch 42. LR=0.000001
2022-01-24 17:11:33,855 Epoch[042/050], Step[0000/1252], Avg Loss: 3.1927, Avg Acc: 0.4219
2022-01-24 17:13:00,113 Epoch[042/050], Step[0050/1252], Avg Loss: 2.9327, Avg Acc: 0.4955
2022-01-24 17:14:26,846 Epoch[042/050], Step[0100/1252], Avg Loss: 2.9305, Avg Acc: 0.4839
2022-01-24 17:15:53,757 Epoch[042/050], Step[0150/1252], Avg Loss: 2.9082, Avg Acc: 0.4815
2022-01-24 17:17:20,821 Epoch[042/050], Step[0200/1252], Avg Loss: 2.9143, Avg Acc: 0.4873
2022-01-24 17:18:48,161 Epoch[042/050], Step[0250/1252], Avg Loss: 2.9084, Avg Acc: 0.4928
2022-01-24 17:20:15,301 Epoch[042/050], Step[0300/1252], Avg Loss: 2.9095, Avg Acc: 0.4931
2022-01-24 17:21:42,087 Epoch[042/050], Step[0350/1252], Avg Loss: 2.9079, Avg Acc: 0.4937
2022-01-24 17:23:09,273 Epoch[042/050], Step[0400/1252], Avg Loss: 2.9043, Avg Acc: 0.4896
2022-01-24 17:24:36,702 Epoch[042/050], Step[0450/1252], Avg Loss: 2.9017, Avg Acc: 0.4868
2022-01-24 17:26:03,655 Epoch[042/050], Step[0500/1252], Avg Loss: 2.9001, Avg Acc: 0.4858
2022-01-24 17:27:30,369 Epoch[042/050], Step[0550/1252], Avg Loss: 2.8968, Avg Acc: 0.4868
2022-01-24 17:28:57,165 Epoch[042/050], Step[0600/1252], Avg Loss: 2.9034, Avg Acc: 0.4857
2022-01-24 17:30:23,210 Epoch[042/050], Step[0650/1252], Avg Loss: 2.9021, Avg Acc: 0.4869
2022-01-24 17:31:48,838 Epoch[042/050], Step[0700/1252], Avg Loss: 2.8962, Avg Acc: 0.4898
2022-01-24 17:33:15,254 Epoch[042/050], Step[0750/1252], Avg Loss: 2.8922, Avg Acc: 0.4909
2022-01-24 17:34:42,045 Epoch[042/050], Step[0800/1252], Avg Loss: 2.8938, Avg Acc: 0.4906
2022-01-24 17:36:09,040 Epoch[042/050], Step[0850/1252], Avg Loss: 2.8965, Avg Acc: 0.4897
2022-01-24 17:37:34,867 Epoch[042/050], Step[0900/1252], Avg Loss: 2.8960, Avg Acc: 0.4895
2022-01-24 17:39:03,029 Epoch[042/050], Step[0950/1252], Avg Loss: 2.8967, Avg Acc: 0.4892
2022-01-24 17:40:31,391 Epoch[042/050], Step[1000/1252], Avg Loss: 2.8949, Avg Acc: 0.4892
2022-01-24 17:41:58,747 Epoch[042/050], Step[1050/1252], Avg Loss: 2.8966, Avg Acc: 0.4888
2022-01-24 17:43:25,498 Epoch[042/050], Step[1100/1252], Avg Loss: 2.8948, Avg Acc: 0.4889
2022-01-24 17:44:52,388 Epoch[042/050], Step[1150/1252], Avg Loss: 2.8953, Avg Acc: 0.4885
2022-01-24 17:46:18,933 Epoch[042/050], Step[1200/1252], Avg Loss: 2.8913, Avg Acc: 0.4894
2022-01-24 17:47:46,597 Epoch[042/050], Step[1250/1252], Avg Loss: 2.8932, Avg Acc: 0.4881
2022-01-24 17:47:53,682 ----- Epoch[042/050], Train Loss: 2.8932, Train Acc: 0.4881, time: 2283.39, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 17:47:53,683 ----- Validation after Epoch: 42
2022-01-24 17:48:57,773 Val Step[0000/1563], Avg Loss: 0.8193, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 17:48:59,735 Val Step[0050/1563], Avg Loss: 1.0079, Avg Acc@1: 0.7843, Avg Acc@5: 0.9412
2022-01-24 17:49:01,526 Val Step[0100/1563], Avg Loss: 1.0400, Avg Acc@1: 0.7834, Avg Acc@5: 0.9378
2022-01-24 17:49:03,338 Val Step[0150/1563], Avg Loss: 1.0433, Avg Acc@1: 0.7839, Avg Acc@5: 0.9354
2022-01-24 17:49:05,129 Val Step[0200/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7842, Avg Acc@5: 0.9361
2022-01-24 17:49:06,908 Val Step[0250/1563], Avg Loss: 1.0337, Avg Acc@1: 0.7821, Avg Acc@5: 0.9379
2022-01-24 17:49:08,750 Val Step[0300/1563], Avg Loss: 1.0336, Avg Acc@1: 0.7819, Avg Acc@5: 0.9365
2022-01-24 17:49:10,538 Val Step[0350/1563], Avg Loss: 1.0384, Avg Acc@1: 0.7812, Avg Acc@5: 0.9359
2022-01-24 17:49:12,323 Val Step[0400/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7822, Avg Acc@5: 0.9359
2022-01-24 17:49:14,116 Val Step[0450/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7797, Avg Acc@5: 0.9357
2022-01-24 17:49:15,976 Val Step[0500/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7793, Avg Acc@5: 0.9360
2022-01-24 17:49:17,788 Val Step[0550/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7786, Avg Acc@5: 0.9362
2022-01-24 17:49:19,576 Val Step[0600/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7782, Avg Acc@5: 0.9361
2022-01-24 17:49:21,399 Val Step[0650/1563], Avg Loss: 1.0427, Avg Acc@1: 0.7779, Avg Acc@5: 0.9363
2022-01-24 17:49:23,246 Val Step[0700/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7783, Avg Acc@5: 0.9370
2022-01-24 17:49:25,087 Val Step[0750/1563], Avg Loss: 1.0467, Avg Acc@1: 0.7763, Avg Acc@5: 0.9368
2022-01-24 17:49:26,924 Val Step[0800/1563], Avg Loss: 1.0466, Avg Acc@1: 0.7769, Avg Acc@5: 0.9367
2022-01-24 17:49:28,701 Val Step[0850/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7766, Avg Acc@5: 0.9364
2022-01-24 17:49:30,497 Val Step[0900/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7772, Avg Acc@5: 0.9369
2022-01-24 17:49:32,291 Val Step[0950/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7778, Avg Acc@5: 0.9371
2022-01-24 17:49:34,070 Val Step[1000/1563], Avg Loss: 1.0463, Avg Acc@1: 0.7775, Avg Acc@5: 0.9368
2022-01-24 17:49:35,860 Val Step[1050/1563], Avg Loss: 1.0482, Avg Acc@1: 0.7770, Avg Acc@5: 0.9365
2022-01-24 17:49:37,676 Val Step[1100/1563], Avg Loss: 1.0483, Avg Acc@1: 0.7765, Avg Acc@5: 0.9368
2022-01-24 17:49:39,624 Val Step[1150/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7767, Avg Acc@5: 0.9372
2022-01-24 17:49:41,521 Val Step[1200/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7774, Avg Acc@5: 0.9372
2022-01-24 17:49:43,394 Val Step[1250/1563], Avg Loss: 1.0446, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-24 17:49:45,218 Val Step[1300/1563], Avg Loss: 1.0476, Avg Acc@1: 0.7767, Avg Acc@5: 0.9372
2022-01-24 17:49:47,058 Val Step[1350/1563], Avg Loss: 1.0489, Avg Acc@1: 0.7762, Avg Acc@5: 0.9372
2022-01-24 17:49:48,903 Val Step[1400/1563], Avg Loss: 1.0485, Avg Acc@1: 0.7759, Avg Acc@5: 0.9372
2022-01-24 17:49:50,826 Val Step[1450/1563], Avg Loss: 1.0474, Avg Acc@1: 0.7763, Avg Acc@5: 0.9373
2022-01-24 17:49:52,784 Val Step[1500/1563], Avg Loss: 1.0474, Avg Acc@1: 0.7764, Avg Acc@5: 0.9375
2022-01-24 17:49:54,618 Val Step[1550/1563], Avg Loss: 1.0479, Avg Acc@1: 0.7762, Avg Acc@5: 0.9375
2022-01-24 17:49:56,539 ----- Epoch[042/050], Validation Loss: 1.0478, Validation Acc@1: 0.7762, Validation Acc@5: 0.9375, time: 122.85
2022-01-24 17:49:56,539 Now training epoch 43. LR=0.000001
2022-01-24 17:51:39,037 Epoch[043/050], Step[0000/1252], Avg Loss: 3.0577, Avg Acc: 0.3926
2022-01-24 17:53:07,355 Epoch[043/050], Step[0050/1252], Avg Loss: 2.8998, Avg Acc: 0.4857
2022-01-24 17:54:34,829 Epoch[043/050], Step[0100/1252], Avg Loss: 2.8687, Avg Acc: 0.4781
2022-01-24 17:56:01,959 Epoch[043/050], Step[0150/1252], Avg Loss: 2.8594, Avg Acc: 0.4813
2022-01-24 17:57:30,283 Epoch[043/050], Step[0200/1252], Avg Loss: 2.8559, Avg Acc: 0.4840
2022-01-24 17:58:57,963 Epoch[043/050], Step[0250/1252], Avg Loss: 2.8634, Avg Acc: 0.4875
2022-01-24 18:00:25,544 Epoch[043/050], Step[0300/1252], Avg Loss: 2.8732, Avg Acc: 0.4916
2022-01-24 18:01:52,590 Epoch[043/050], Step[0350/1252], Avg Loss: 2.8686, Avg Acc: 0.4957
2022-01-24 18:03:19,543 Epoch[043/050], Step[0400/1252], Avg Loss: 2.8637, Avg Acc: 0.4958
2022-01-24 18:04:46,937 Epoch[043/050], Step[0450/1252], Avg Loss: 2.8656, Avg Acc: 0.4920
2022-01-24 18:06:15,298 Epoch[043/050], Step[0500/1252], Avg Loss: 2.8708, Avg Acc: 0.4949
2022-01-24 18:07:42,688 Epoch[043/050], Step[0550/1252], Avg Loss: 2.8665, Avg Acc: 0.4972
2022-01-24 18:09:11,213 Epoch[043/050], Step[0600/1252], Avg Loss: 2.8669, Avg Acc: 0.4968
2022-01-24 18:10:40,024 Epoch[043/050], Step[0650/1252], Avg Loss: 2.8712, Avg Acc: 0.4952
2022-01-24 18:12:08,288 Epoch[043/050], Step[0700/1252], Avg Loss: 2.8715, Avg Acc: 0.4939
2022-01-24 18:13:35,979 Epoch[043/050], Step[0750/1252], Avg Loss: 2.8740, Avg Acc: 0.4950
2022-01-24 18:15:03,205 Epoch[043/050], Step[0800/1252], Avg Loss: 2.8790, Avg Acc: 0.4945
2022-01-24 18:16:31,313 Epoch[043/050], Step[0850/1252], Avg Loss: 2.8829, Avg Acc: 0.4943
2022-01-24 18:17:58,489 Epoch[043/050], Step[0900/1252], Avg Loss: 2.8796, Avg Acc: 0.4966
2022-01-24 18:19:25,893 Epoch[043/050], Step[0950/1252], Avg Loss: 2.8845, Avg Acc: 0.4966
2022-01-24 18:20:54,033 Epoch[043/050], Step[1000/1252], Avg Loss: 2.8837, Avg Acc: 0.4967
2022-01-24 18:22:22,105 Epoch[043/050], Step[1050/1252], Avg Loss: 2.8857, Avg Acc: 0.4978
2022-01-24 18:23:49,147 Epoch[043/050], Step[1100/1252], Avg Loss: 2.8842, Avg Acc: 0.4975
2022-01-24 18:25:16,440 Epoch[043/050], Step[1150/1252], Avg Loss: 2.8851, Avg Acc: 0.4978
2022-01-24 18:26:44,457 Epoch[043/050], Step[1200/1252], Avg Loss: 2.8846, Avg Acc: 0.4973
2022-01-24 18:28:11,636 Epoch[043/050], Step[1250/1252], Avg Loss: 2.8834, Avg Acc: 0.4968
2022-01-24 18:28:18,750 ----- Epoch[043/050], Train Loss: 2.8834, Train Acc: 0.4968, time: 2302.21, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 18:28:18,750 Now training epoch 44. LR=0.000000
2022-01-24 18:30:03,429 Epoch[044/050], Step[0000/1252], Avg Loss: 3.0924, Avg Acc: 0.1221
2022-01-24 18:31:29,817 Epoch[044/050], Step[0050/1252], Avg Loss: 2.9292, Avg Acc: 0.4678
2022-01-24 18:32:57,204 Epoch[044/050], Step[0100/1252], Avg Loss: 2.8932, Avg Acc: 0.4800
2022-01-24 18:34:25,314 Epoch[044/050], Step[0150/1252], Avg Loss: 2.8901, Avg Acc: 0.4786
2022-01-24 18:35:51,662 Epoch[044/050], Step[0200/1252], Avg Loss: 2.8852, Avg Acc: 0.4852
2022-01-24 18:37:19,204 Epoch[044/050], Step[0250/1252], Avg Loss: 2.9044, Avg Acc: 0.4837
2022-01-24 18:38:47,231 Epoch[044/050], Step[0300/1252], Avg Loss: 2.8930, Avg Acc: 0.4826
2022-01-24 18:40:14,343 Epoch[044/050], Step[0350/1252], Avg Loss: 2.8881, Avg Acc: 0.4892
2022-01-24 18:41:41,095 Epoch[044/050], Step[0400/1252], Avg Loss: 2.8909, Avg Acc: 0.4883
2022-01-24 18:43:08,235 Epoch[044/050], Step[0450/1252], Avg Loss: 2.8909, Avg Acc: 0.4874
2022-01-24 18:44:34,881 Epoch[044/050], Step[0500/1252], Avg Loss: 2.8900, Avg Acc: 0.4906
2022-01-24 18:46:01,872 Epoch[044/050], Step[0550/1252], Avg Loss: 2.8867, Avg Acc: 0.4925
2022-01-24 18:47:29,798 Epoch[044/050], Step[0600/1252], Avg Loss: 2.8847, Avg Acc: 0.4952
2022-01-24 18:48:58,071 Epoch[044/050], Step[0650/1252], Avg Loss: 2.8854, Avg Acc: 0.4939
2022-01-24 18:50:26,466 Epoch[044/050], Step[0700/1252], Avg Loss: 2.8846, Avg Acc: 0.4929
2022-01-24 18:51:54,506 Epoch[044/050], Step[0750/1252], Avg Loss: 2.8848, Avg Acc: 0.4922
2022-01-24 18:53:22,994 Epoch[044/050], Step[0800/1252], Avg Loss: 2.8850, Avg Acc: 0.4903
2022-01-24 18:54:50,168 Epoch[044/050], Step[0850/1252], Avg Loss: 2.8855, Avg Acc: 0.4907
2022-01-24 18:56:17,723 Epoch[044/050], Step[0900/1252], Avg Loss: 2.8829, Avg Acc: 0.4913
2022-01-24 18:57:46,000 Epoch[044/050], Step[0950/1252], Avg Loss: 2.8811, Avg Acc: 0.4915
2022-01-24 18:59:13,671 Epoch[044/050], Step[1000/1252], Avg Loss: 2.8836, Avg Acc: 0.4906
2022-01-24 19:00:41,635 Epoch[044/050], Step[1050/1252], Avg Loss: 2.8877, Avg Acc: 0.4895
2022-01-24 19:02:09,283 Epoch[044/050], Step[1100/1252], Avg Loss: 2.8867, Avg Acc: 0.4917
2022-01-24 19:03:36,516 Epoch[044/050], Step[1150/1252], Avg Loss: 2.8851, Avg Acc: 0.4914
2022-01-24 19:05:04,241 Epoch[044/050], Step[1200/1252], Avg Loss: 2.8867, Avg Acc: 0.4911
2022-01-24 19:06:32,012 Epoch[044/050], Step[1250/1252], Avg Loss: 2.8861, Avg Acc: 0.4917
2022-01-24 19:06:39,279 ----- Epoch[044/050], Train Loss: 2.8861, Train Acc: 0.4917, time: 2300.52, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 19:06:39,279 ----- Validation after Epoch: 44
2022-01-24 19:07:56,453 Val Step[0000/1563], Avg Loss: 0.8173, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 19:07:58,475 Val Step[0050/1563], Avg Loss: 1.0051, Avg Acc@1: 0.7831, Avg Acc@5: 0.9418
2022-01-24 19:08:00,477 Val Step[0100/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7840, Avg Acc@5: 0.9378
2022-01-24 19:08:02,419 Val Step[0150/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7839, Avg Acc@5: 0.9361
2022-01-24 19:08:04,222 Val Step[0200/1563], Avg Loss: 1.0408, Avg Acc@1: 0.7844, Avg Acc@5: 0.9361
2022-01-24 19:08:06,010 Val Step[0250/1563], Avg Loss: 1.0311, Avg Acc@1: 0.7825, Avg Acc@5: 0.9376
2022-01-24 19:08:07,828 Val Step[0300/1563], Avg Loss: 1.0311, Avg Acc@1: 0.7820, Avg Acc@5: 0.9367
2022-01-24 19:08:09,665 Val Step[0350/1563], Avg Loss: 1.0358, Avg Acc@1: 0.7812, Avg Acc@5: 0.9363
2022-01-24 19:08:11,498 Val Step[0400/1563], Avg Loss: 1.0352, Avg Acc@1: 0.7823, Avg Acc@5: 0.9363
2022-01-24 19:08:13,386 Val Step[0450/1563], Avg Loss: 1.0396, Avg Acc@1: 0.7798, Avg Acc@5: 0.9363
2022-01-24 19:08:15,201 Val Step[0500/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7791, Avg Acc@5: 0.9367
2022-01-24 19:08:16,998 Val Step[0550/1563], Avg Loss: 1.0411, Avg Acc@1: 0.7783, Avg Acc@5: 0.9368
2022-01-24 19:08:18,878 Val Step[0600/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7780, Avg Acc@5: 0.9368
2022-01-24 19:08:20,761 Val Step[0650/1563], Avg Loss: 1.0402, Avg Acc@1: 0.7779, Avg Acc@5: 0.9369
2022-01-24 19:08:22,564 Val Step[0700/1563], Avg Loss: 1.0379, Avg Acc@1: 0.7784, Avg Acc@5: 0.9374
2022-01-24 19:08:24,364 Val Step[0750/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7764, Avg Acc@5: 0.9373
2022-01-24 19:08:26,168 Val Step[0800/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7770, Avg Acc@5: 0.9373
2022-01-24 19:08:27,996 Val Step[0850/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7770, Avg Acc@5: 0.9370
2022-01-24 19:08:29,897 Val Step[0900/1563], Avg Loss: 1.0425, Avg Acc@1: 0.7776, Avg Acc@5: 0.9374
2022-01-24 19:08:31,776 Val Step[0950/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7782, Avg Acc@5: 0.9377
2022-01-24 19:08:33,684 Val Step[1000/1563], Avg Loss: 1.0437, Avg Acc@1: 0.7781, Avg Acc@5: 0.9373
2022-01-24 19:08:35,532 Val Step[1050/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7774, Avg Acc@5: 0.9370
2022-01-24 19:08:37,512 Val Step[1100/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7768, Avg Acc@5: 0.9372
2022-01-24 19:08:39,374 Val Step[1150/1563], Avg Loss: 1.0434, Avg Acc@1: 0.7769, Avg Acc@5: 0.9376
2022-01-24 19:08:41,164 Val Step[1200/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7777, Avg Acc@5: 0.9376
2022-01-24 19:08:43,042 Val Step[1250/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7773, Avg Acc@5: 0.9377
2022-01-24 19:08:44,840 Val Step[1300/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7771, Avg Acc@5: 0.9375
2022-01-24 19:08:46,640 Val Step[1350/1563], Avg Loss: 1.0462, Avg Acc@1: 0.7765, Avg Acc@5: 0.9375
2022-01-24 19:08:48,425 Val Step[1400/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7762, Avg Acc@5: 0.9374
2022-01-24 19:08:50,263 Val Step[1450/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7767, Avg Acc@5: 0.9375
2022-01-24 19:08:52,212 Val Step[1500/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7768, Avg Acc@5: 0.9376
2022-01-24 19:08:54,069 Val Step[1550/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7765, Avg Acc@5: 0.9376
2022-01-24 19:08:56,021 ----- Epoch[044/050], Validation Loss: 1.0450, Validation Acc@1: 0.7764, Validation Acc@5: 0.9377, time: 136.74
2022-01-24 19:08:56,021 Now training epoch 45. LR=0.000000
2022-01-24 19:10:43,870 Epoch[045/050], Step[0000/1252], Avg Loss: 2.8988, Avg Acc: 0.6074
2022-01-24 19:12:09,693 Epoch[045/050], Step[0050/1252], Avg Loss: 2.8739, Avg Acc: 0.4855
2022-01-24 19:13:33,254 Epoch[045/050], Step[0100/1252], Avg Loss: 2.8490, Avg Acc: 0.5040
2022-01-24 19:14:59,043 Epoch[045/050], Step[0150/1252], Avg Loss: 2.8574, Avg Acc: 0.5043
2022-01-24 19:16:24,468 Epoch[045/050], Step[0200/1252], Avg Loss: 2.8470, Avg Acc: 0.5081
2022-01-24 19:17:49,586 Epoch[045/050], Step[0250/1252], Avg Loss: 2.8482, Avg Acc: 0.5043
2022-01-24 19:19:16,016 Epoch[045/050], Step[0300/1252], Avg Loss: 2.8651, Avg Acc: 0.5001
2022-01-24 19:20:41,945 Epoch[045/050], Step[0350/1252], Avg Loss: 2.8626, Avg Acc: 0.4999
2022-01-24 19:22:07,929 Epoch[045/050], Step[0400/1252], Avg Loss: 2.8705, Avg Acc: 0.4953
2022-01-24 19:23:35,050 Epoch[045/050], Step[0450/1252], Avg Loss: 2.8706, Avg Acc: 0.4924
2022-01-24 19:25:00,211 Epoch[045/050], Step[0500/1252], Avg Loss: 2.8742, Avg Acc: 0.4932
2022-01-24 19:26:25,982 Epoch[045/050], Step[0550/1252], Avg Loss: 2.8737, Avg Acc: 0.4889
2022-01-24 19:27:53,042 Epoch[045/050], Step[0600/1252], Avg Loss: 2.8743, Avg Acc: 0.4875
2022-01-24 19:29:19,208 Epoch[045/050], Step[0650/1252], Avg Loss: 2.8748, Avg Acc: 0.4871
2022-01-24 19:30:44,172 Epoch[045/050], Step[0700/1252], Avg Loss: 2.8742, Avg Acc: 0.4869
2022-01-24 19:32:09,944 Epoch[045/050], Step[0750/1252], Avg Loss: 2.8737, Avg Acc: 0.4881
2022-01-24 19:33:36,619 Epoch[045/050], Step[0800/1252], Avg Loss: 2.8736, Avg Acc: 0.4886
2022-01-24 19:35:02,846 Epoch[045/050], Step[0850/1252], Avg Loss: 2.8749, Avg Acc: 0.4884
2022-01-24 19:36:30,536 Epoch[045/050], Step[0900/1252], Avg Loss: 2.8760, Avg Acc: 0.4884
2022-01-24 19:37:58,040 Epoch[045/050], Step[0950/1252], Avg Loss: 2.8768, Avg Acc: 0.4885
2022-01-24 19:39:24,673 Epoch[045/050], Step[1000/1252], Avg Loss: 2.8799, Avg Acc: 0.4896
2022-01-24 19:40:52,030 Epoch[045/050], Step[1050/1252], Avg Loss: 2.8805, Avg Acc: 0.4882
2022-01-24 19:42:19,220 Epoch[045/050], Step[1100/1252], Avg Loss: 2.8776, Avg Acc: 0.4878
2022-01-24 19:43:46,672 Epoch[045/050], Step[1150/1252], Avg Loss: 2.8767, Avg Acc: 0.4884
2022-01-24 19:45:14,244 Epoch[045/050], Step[1200/1252], Avg Loss: 2.8752, Avg Acc: 0.4901
2022-01-24 19:46:41,343 Epoch[045/050], Step[1250/1252], Avg Loss: 2.8774, Avg Acc: 0.4901
2022-01-24 19:46:48,558 ----- Epoch[045/050], Train Loss: 2.8774, Train Acc: 0.4901, time: 2272.53, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 19:46:48,558 Now training epoch 46. LR=0.000000
2022-01-24 19:48:35,625 Epoch[046/050], Step[0000/1252], Avg Loss: 3.0808, Avg Acc: 0.3369
2022-01-24 19:50:03,955 Epoch[046/050], Step[0050/1252], Avg Loss: 2.8918, Avg Acc: 0.4890
2022-01-24 19:51:29,826 Epoch[046/050], Step[0100/1252], Avg Loss: 2.8849, Avg Acc: 0.5041
2022-01-24 19:52:57,814 Epoch[046/050], Step[0150/1252], Avg Loss: 2.8841, Avg Acc: 0.4887
2022-01-24 19:54:25,396 Epoch[046/050], Step[0200/1252], Avg Loss: 2.8797, Avg Acc: 0.4973
2022-01-24 19:55:51,687 Epoch[046/050], Step[0250/1252], Avg Loss: 2.8751, Avg Acc: 0.4932
2022-01-24 19:57:18,114 Epoch[046/050], Step[0300/1252], Avg Loss: 2.8742, Avg Acc: 0.4922
2022-01-24 19:58:45,805 Epoch[046/050], Step[0350/1252], Avg Loss: 2.8729, Avg Acc: 0.4921
2022-01-24 20:00:13,053 Epoch[046/050], Step[0400/1252], Avg Loss: 2.8818, Avg Acc: 0.4903
2022-01-24 20:01:39,223 Epoch[046/050], Step[0450/1252], Avg Loss: 2.8846, Avg Acc: 0.4904
2022-01-24 20:03:07,148 Epoch[046/050], Step[0500/1252], Avg Loss: 2.8835, Avg Acc: 0.4897
2022-01-24 20:04:33,264 Epoch[046/050], Step[0550/1252], Avg Loss: 2.8807, Avg Acc: 0.4926
2022-01-24 20:06:00,161 Epoch[046/050], Step[0600/1252], Avg Loss: 2.8819, Avg Acc: 0.4922
2022-01-24 20:07:27,749 Epoch[046/050], Step[0650/1252], Avg Loss: 2.8836, Avg Acc: 0.4920
2022-01-24 20:08:55,836 Epoch[046/050], Step[0700/1252], Avg Loss: 2.8840, Avg Acc: 0.4893
2022-01-24 20:10:23,372 Epoch[046/050], Step[0750/1252], Avg Loss: 2.8843, Avg Acc: 0.4910
2022-01-24 20:11:51,196 Epoch[046/050], Step[0800/1252], Avg Loss: 2.8874, Avg Acc: 0.4898
2022-01-24 20:13:18,510 Epoch[046/050], Step[0850/1252], Avg Loss: 2.8873, Avg Acc: 0.4902
2022-01-24 20:14:45,768 Epoch[046/050], Step[0900/1252], Avg Loss: 2.8863, Avg Acc: 0.4921
2022-01-24 20:16:13,249 Epoch[046/050], Step[0950/1252], Avg Loss: 2.8816, Avg Acc: 0.4920
2022-01-24 20:17:40,819 Epoch[046/050], Step[1000/1252], Avg Loss: 2.8819, Avg Acc: 0.4918
2022-01-24 20:19:09,045 Epoch[046/050], Step[1050/1252], Avg Loss: 2.8825, Avg Acc: 0.4906
2022-01-24 20:20:36,782 Epoch[046/050], Step[1100/1252], Avg Loss: 2.8813, Avg Acc: 0.4898
2022-01-24 20:22:05,019 Epoch[046/050], Step[1150/1252], Avg Loss: 2.8781, Avg Acc: 0.4892
2022-01-24 20:23:32,094 Epoch[046/050], Step[1200/1252], Avg Loss: 2.8773, Avg Acc: 0.4899
2022-01-24 20:25:00,880 Epoch[046/050], Step[1250/1252], Avg Loss: 2.8787, Avg Acc: 0.4891
2022-01-24 20:25:07,955 ----- Epoch[046/050], Train Loss: 2.8787, Train Acc: 0.4891, time: 2299.39, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 20:25:07,955 ----- Validation after Epoch: 46
2022-01-24 20:26:17,108 Val Step[0000/1563], Avg Loss: 0.8147, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 20:26:19,104 Val Step[0050/1563], Avg Loss: 1.0046, Avg Acc@1: 0.7837, Avg Acc@5: 0.9418
2022-01-24 20:26:21,203 Val Step[0100/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7847, Avg Acc@5: 0.9378
2022-01-24 20:26:23,030 Val Step[0150/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7852, Avg Acc@5: 0.9363
2022-01-24 20:26:25,040 Val Step[0200/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7851, Avg Acc@5: 0.9364
2022-01-24 20:26:27,093 Val Step[0250/1563], Avg Loss: 1.0306, Avg Acc@1: 0.7832, Avg Acc@5: 0.9382
2022-01-24 20:26:29,162 Val Step[0300/1563], Avg Loss: 1.0306, Avg Acc@1: 0.7828, Avg Acc@5: 0.9368
2022-01-24 20:26:31,268 Val Step[0350/1563], Avg Loss: 1.0353, Avg Acc@1: 0.7821, Avg Acc@5: 0.9363
2022-01-24 20:26:33,402 Val Step[0400/1563], Avg Loss: 1.0346, Avg Acc@1: 0.7830, Avg Acc@5: 0.9366
2022-01-24 20:26:35,415 Val Step[0450/1563], Avg Loss: 1.0390, Avg Acc@1: 0.7804, Avg Acc@5: 0.9364
2022-01-24 20:26:37,437 Val Step[0500/1563], Avg Loss: 1.0416, Avg Acc@1: 0.7799, Avg Acc@5: 0.9367
2022-01-24 20:26:39,468 Val Step[0550/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7792, Avg Acc@5: 0.9368
2022-01-24 20:26:41,511 Val Step[0600/1563], Avg Loss: 1.0392, Avg Acc@1: 0.7787, Avg Acc@5: 0.9368
2022-01-24 20:26:43,590 Val Step[0650/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7784, Avg Acc@5: 0.9369
2022-01-24 20:26:45,679 Val Step[0700/1563], Avg Loss: 1.0374, Avg Acc@1: 0.7788, Avg Acc@5: 0.9374
2022-01-24 20:26:47,730 Val Step[0750/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7768, Avg Acc@5: 0.9373
2022-01-24 20:26:49,790 Val Step[0800/1563], Avg Loss: 1.0435, Avg Acc@1: 0.7775, Avg Acc@5: 0.9373
2022-01-24 20:26:51,807 Val Step[0850/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7774, Avg Acc@5: 0.9370
2022-01-24 20:26:53,831 Val Step[0900/1563], Avg Loss: 1.0419, Avg Acc@1: 0.7780, Avg Acc@5: 0.9374
2022-01-24 20:26:55,940 Val Step[0950/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7785, Avg Acc@5: 0.9377
2022-01-24 20:26:58,035 Val Step[1000/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7783, Avg Acc@5: 0.9374
2022-01-24 20:27:00,081 Val Step[1050/1563], Avg Loss: 1.0451, Avg Acc@1: 0.7777, Avg Acc@5: 0.9371
2022-01-24 20:27:02,109 Val Step[1100/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7770, Avg Acc@5: 0.9373
2022-01-24 20:27:04,137 Val Step[1150/1563], Avg Loss: 1.0429, Avg Acc@1: 0.7772, Avg Acc@5: 0.9376
2022-01-24 20:27:06,152 Val Step[1200/1563], Avg Loss: 1.0417, Avg Acc@1: 0.7780, Avg Acc@5: 0.9376
2022-01-24 20:27:07,978 Val Step[1250/1563], Avg Loss: 1.0414, Avg Acc@1: 0.7775, Avg Acc@5: 0.9378
2022-01-24 20:27:09,799 Val Step[1300/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7773, Avg Acc@5: 0.9376
2022-01-24 20:27:11,756 Val Step[1350/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7767, Avg Acc@5: 0.9376
2022-01-24 20:27:13,626 Val Step[1400/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7763, Avg Acc@5: 0.9375
2022-01-24 20:27:15,466 Val Step[1450/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7769, Avg Acc@5: 0.9375
2022-01-24 20:27:17,449 Val Step[1500/1563], Avg Loss: 1.0442, Avg Acc@1: 0.7769, Avg Acc@5: 0.9377
2022-01-24 20:27:19,295 Val Step[1550/1563], Avg Loss: 1.0447, Avg Acc@1: 0.7766, Avg Acc@5: 0.9377
2022-01-24 20:27:21,251 ----- Epoch[046/050], Validation Loss: 1.0445, Validation Acc@1: 0.7765, Validation Acc@5: 0.9378, time: 133.29
2022-01-24 20:27:21,252 Now training epoch 47. LR=0.000000
2022-01-24 20:29:16,785 Epoch[047/050], Step[0000/1252], Avg Loss: 2.4027, Avg Acc: 0.5850
2022-01-24 20:30:43,634 Epoch[047/050], Step[0050/1252], Avg Loss: 2.8926, Avg Acc: 0.4565
2022-01-24 20:32:11,427 Epoch[047/050], Step[0100/1252], Avg Loss: 2.8835, Avg Acc: 0.4754
2022-01-24 20:33:36,637 Epoch[047/050], Step[0150/1252], Avg Loss: 2.8856, Avg Acc: 0.4849
2022-01-24 20:35:04,175 Epoch[047/050], Step[0200/1252], Avg Loss: 2.8769, Avg Acc: 0.4825
2022-01-24 20:36:31,423 Epoch[047/050], Step[0250/1252], Avg Loss: 2.8599, Avg Acc: 0.4887
2022-01-24 20:37:58,082 Epoch[047/050], Step[0300/1252], Avg Loss: 2.8550, Avg Acc: 0.4900
2022-01-24 20:39:25,781 Epoch[047/050], Step[0350/1252], Avg Loss: 2.8631, Avg Acc: 0.4840
2022-01-24 20:40:53,378 Epoch[047/050], Step[0400/1252], Avg Loss: 2.8682, Avg Acc: 0.4845
2022-01-24 20:42:18,413 Epoch[047/050], Step[0450/1252], Avg Loss: 2.8756, Avg Acc: 0.4832
2022-01-24 20:43:45,127 Epoch[047/050], Step[0500/1252], Avg Loss: 2.8783, Avg Acc: 0.4864
2022-01-24 20:45:11,558 Epoch[047/050], Step[0550/1252], Avg Loss: 2.8760, Avg Acc: 0.4852
2022-01-24 20:46:37,834 Epoch[047/050], Step[0600/1252], Avg Loss: 2.8737, Avg Acc: 0.4866
2022-01-24 20:48:05,371 Epoch[047/050], Step[0650/1252], Avg Loss: 2.8787, Avg Acc: 0.4856
2022-01-24 20:49:33,306 Epoch[047/050], Step[0700/1252], Avg Loss: 2.8777, Avg Acc: 0.4862
2022-01-24 20:51:01,379 Epoch[047/050], Step[0750/1252], Avg Loss: 2.8727, Avg Acc: 0.4873
2022-01-24 20:52:28,663 Epoch[047/050], Step[0800/1252], Avg Loss: 2.8697, Avg Acc: 0.4891
2022-01-24 20:53:56,987 Epoch[047/050], Step[0850/1252], Avg Loss: 2.8734, Avg Acc: 0.4889
2022-01-24 20:55:25,277 Epoch[047/050], Step[0900/1252], Avg Loss: 2.8757, Avg Acc: 0.4874
2022-01-24 20:56:52,150 Epoch[047/050], Step[0950/1252], Avg Loss: 2.8758, Avg Acc: 0.4882
2022-01-24 20:58:19,022 Epoch[047/050], Step[1000/1252], Avg Loss: 2.8754, Avg Acc: 0.4904
2022-01-24 20:59:47,152 Epoch[047/050], Step[1050/1252], Avg Loss: 2.8740, Avg Acc: 0.4902
2022-01-24 21:01:15,322 Epoch[047/050], Step[1100/1252], Avg Loss: 2.8772, Avg Acc: 0.4907
2022-01-24 21:02:42,648 Epoch[047/050], Step[1150/1252], Avg Loss: 2.8788, Avg Acc: 0.4888
2022-01-24 21:04:10,817 Epoch[047/050], Step[1200/1252], Avg Loss: 2.8822, Avg Acc: 0.4886
2022-01-24 21:05:39,535 Epoch[047/050], Step[1250/1252], Avg Loss: 2.8818, Avg Acc: 0.4885
2022-01-24 21:05:46,626 ----- Epoch[047/050], Train Loss: 2.8817, Train Acc: 0.4885, time: 2305.37, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 21:05:46,626 Now training epoch 48. LR=0.000000
2022-01-24 21:07:36,764 Epoch[048/050], Step[0000/1252], Avg Loss: 2.3881, Avg Acc: 0.5820
2022-01-24 21:09:02,734 Epoch[048/050], Step[0050/1252], Avg Loss: 2.8847, Avg Acc: 0.5032
2022-01-24 21:10:29,308 Epoch[048/050], Step[0100/1252], Avg Loss: 2.8696, Avg Acc: 0.5005
2022-01-24 21:11:55,639 Epoch[048/050], Step[0150/1252], Avg Loss: 2.8876, Avg Acc: 0.4970
2022-01-24 21:13:22,532 Epoch[048/050], Step[0200/1252], Avg Loss: 2.8800, Avg Acc: 0.5021
2022-01-24 21:14:49,733 Epoch[048/050], Step[0250/1252], Avg Loss: 2.8843, Avg Acc: 0.4967
2022-01-24 21:16:17,348 Epoch[048/050], Step[0300/1252], Avg Loss: 2.8783, Avg Acc: 0.4982
2022-01-24 21:17:44,935 Epoch[048/050], Step[0350/1252], Avg Loss: 2.8794, Avg Acc: 0.4945
2022-01-24 21:19:12,471 Epoch[048/050], Step[0400/1252], Avg Loss: 2.8832, Avg Acc: 0.4939
2022-01-24 21:20:40,387 Epoch[048/050], Step[0450/1252], Avg Loss: 2.8862, Avg Acc: 0.4926
2022-01-24 21:22:07,609 Epoch[048/050], Step[0500/1252], Avg Loss: 2.8863, Avg Acc: 0.4910
2022-01-24 21:23:34,120 Epoch[048/050], Step[0550/1252], Avg Loss: 2.8852, Avg Acc: 0.4927
2022-01-24 21:25:00,914 Epoch[048/050], Step[0600/1252], Avg Loss: 2.8902, Avg Acc: 0.4904
2022-01-24 21:26:26,555 Epoch[048/050], Step[0650/1252], Avg Loss: 2.8852, Avg Acc: 0.4904
2022-01-24 21:27:53,501 Epoch[048/050], Step[0700/1252], Avg Loss: 2.8842, Avg Acc: 0.4927
2022-01-24 21:29:20,032 Epoch[048/050], Step[0750/1252], Avg Loss: 2.8844, Avg Acc: 0.4910
2022-01-24 21:30:49,111 Epoch[048/050], Step[0800/1252], Avg Loss: 2.8832, Avg Acc: 0.4901
2022-01-24 21:32:17,649 Epoch[048/050], Step[0850/1252], Avg Loss: 2.8803, Avg Acc: 0.4884
2022-01-24 21:33:44,834 Epoch[048/050], Step[0900/1252], Avg Loss: 2.8788, Avg Acc: 0.4884
2022-01-24 21:35:13,119 Epoch[048/050], Step[0950/1252], Avg Loss: 2.8749, Avg Acc: 0.4872
2022-01-24 21:36:41,096 Epoch[048/050], Step[1000/1252], Avg Loss: 2.8752, Avg Acc: 0.4874
2022-01-24 21:38:09,758 Epoch[048/050], Step[1050/1252], Avg Loss: 2.8773, Avg Acc: 0.4859
2022-01-24 21:39:38,406 Epoch[048/050], Step[1100/1252], Avg Loss: 2.8756, Avg Acc: 0.4868
2022-01-24 21:41:05,970 Epoch[048/050], Step[1150/1252], Avg Loss: 2.8763, Avg Acc: 0.4868
2022-01-24 21:42:33,437 Epoch[048/050], Step[1200/1252], Avg Loss: 2.8781, Avg Acc: 0.4878
2022-01-24 21:44:01,954 Epoch[048/050], Step[1250/1252], Avg Loss: 2.8785, Avg Acc: 0.4877
2022-01-24 21:44:09,130 ----- Epoch[048/050], Train Loss: 2.8785, Train Acc: 0.4877, time: 2302.50, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 21:44:09,131 ----- Validation after Epoch: 48
2022-01-24 21:45:23,685 Val Step[0000/1563], Avg Loss: 0.8117, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 21:45:25,628 Val Step[0050/1563], Avg Loss: 1.0048, Avg Acc@1: 0.7831, Avg Acc@5: 0.9430
2022-01-24 21:45:27,417 Val Step[0100/1563], Avg Loss: 1.0369, Avg Acc@1: 0.7837, Avg Acc@5: 0.9381
2022-01-24 21:45:29,200 Val Step[0150/1563], Avg Loss: 1.0403, Avg Acc@1: 0.7848, Avg Acc@5: 0.9361
2022-01-24 21:45:31,025 Val Step[0200/1563], Avg Loss: 1.0406, Avg Acc@1: 0.7853, Avg Acc@5: 0.9364
2022-01-24 21:45:32,908 Val Step[0250/1563], Avg Loss: 1.0309, Avg Acc@1: 0.7834, Avg Acc@5: 0.9381
2022-01-24 21:45:34,695 Val Step[0300/1563], Avg Loss: 1.0308, Avg Acc@1: 0.7830, Avg Acc@5: 0.9366
2022-01-24 21:45:36,470 Val Step[0350/1563], Avg Loss: 1.0355, Avg Acc@1: 0.7821, Avg Acc@5: 0.9362
2022-01-24 21:45:38,302 Val Step[0400/1563], Avg Loss: 1.0349, Avg Acc@1: 0.7830, Avg Acc@5: 0.9363
2022-01-24 21:45:40,249 Val Step[0450/1563], Avg Loss: 1.0394, Avg Acc@1: 0.7802, Avg Acc@5: 0.9362
2022-01-24 21:45:42,084 Val Step[0500/1563], Avg Loss: 1.0420, Avg Acc@1: 0.7796, Avg Acc@5: 0.9365
2022-01-24 21:45:43,859 Val Step[0550/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7788, Avg Acc@5: 0.9366
2022-01-24 21:45:45,755 Val Step[0600/1563], Avg Loss: 1.0397, Avg Acc@1: 0.7783, Avg Acc@5: 0.9366
2022-01-24 21:45:47,666 Val Step[0650/1563], Avg Loss: 1.0401, Avg Acc@1: 0.7780, Avg Acc@5: 0.9367
2022-01-24 21:45:49,438 Val Step[0700/1563], Avg Loss: 1.0378, Avg Acc@1: 0.7784, Avg Acc@5: 0.9372
2022-01-24 21:45:51,246 Val Step[0750/1563], Avg Loss: 1.0441, Avg Acc@1: 0.7765, Avg Acc@5: 0.9370
2022-01-24 21:45:53,179 Val Step[0800/1563], Avg Loss: 1.0440, Avg Acc@1: 0.7772, Avg Acc@5: 0.9371
2022-01-24 21:45:55,157 Val Step[0850/1563], Avg Loss: 1.0454, Avg Acc@1: 0.7771, Avg Acc@5: 0.9368
2022-01-24 21:45:57,097 Val Step[0900/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7776, Avg Acc@5: 0.9372
2022-01-24 21:45:58,985 Val Step[0950/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7782, Avg Acc@5: 0.9375
2022-01-24 21:46:00,777 Val Step[1000/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7779, Avg Acc@5: 0.9372
2022-01-24 21:46:02,667 Val Step[1050/1563], Avg Loss: 1.0455, Avg Acc@1: 0.7773, Avg Acc@5: 0.9369
2022-01-24 21:46:04,608 Val Step[1100/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7768, Avg Acc@5: 0.9371
2022-01-24 21:46:06,634 Val Step[1150/1563], Avg Loss: 1.0432, Avg Acc@1: 0.7770, Avg Acc@5: 0.9375
2022-01-24 21:46:08,715 Val Step[1200/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7778, Avg Acc@5: 0.9375
2022-01-24 21:46:10,817 Val Step[1250/1563], Avg Loss: 1.0418, Avg Acc@1: 0.7773, Avg Acc@5: 0.9376
2022-01-24 21:46:12,861 Val Step[1300/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7771, Avg Acc@5: 0.9374
2022-01-24 21:46:14,943 Val Step[1350/1563], Avg Loss: 1.0461, Avg Acc@1: 0.7765, Avg Acc@5: 0.9373
2022-01-24 21:46:16,965 Val Step[1400/1563], Avg Loss: 1.0457, Avg Acc@1: 0.7761, Avg Acc@5: 0.9373
2022-01-24 21:46:18,999 Val Step[1450/1563], Avg Loss: 1.0446, Avg Acc@1: 0.7767, Avg Acc@5: 0.9373
2022-01-24 21:46:21,035 Val Step[1500/1563], Avg Loss: 1.0445, Avg Acc@1: 0.7768, Avg Acc@5: 0.9375
2022-01-24 21:46:23,054 Val Step[1550/1563], Avg Loss: 1.0450, Avg Acc@1: 0.7764, Avg Acc@5: 0.9375
2022-01-24 21:46:25,129 ----- Epoch[048/050], Validation Loss: 1.0449, Validation Acc@1: 0.7763, Validation Acc@5: 0.9376, time: 136.00
2022-01-24 21:46:25,130 Now training epoch 49. LR=0.000000
2022-01-24 21:48:10,689 Epoch[049/050], Step[0000/1252], Avg Loss: 2.7480, Avg Acc: 0.5479
2022-01-24 21:49:37,641 Epoch[049/050], Step[0050/1252], Avg Loss: 2.8935, Avg Acc: 0.5041
2022-01-24 21:51:03,727 Epoch[049/050], Step[0100/1252], Avg Loss: 2.8829, Avg Acc: 0.5013
2022-01-24 21:52:30,848 Epoch[049/050], Step[0150/1252], Avg Loss: 2.8809, Avg Acc: 0.5007
2022-01-24 21:53:57,031 Epoch[049/050], Step[0200/1252], Avg Loss: 2.8932, Avg Acc: 0.4946
2022-01-24 21:55:23,611 Epoch[049/050], Step[0250/1252], Avg Loss: 2.8786, Avg Acc: 0.4992
2022-01-24 21:56:50,804 Epoch[049/050], Step[0300/1252], Avg Loss: 2.8833, Avg Acc: 0.4991
2022-01-24 21:58:18,336 Epoch[049/050], Step[0350/1252], Avg Loss: 2.8810, Avg Acc: 0.4913
2022-01-24 21:59:46,113 Epoch[049/050], Step[0400/1252], Avg Loss: 2.8753, Avg Acc: 0.4927
2022-01-24 22:01:13,848 Epoch[049/050], Step[0450/1252], Avg Loss: 2.8764, Avg Acc: 0.4937
2022-01-24 22:02:40,479 Epoch[049/050], Step[0500/1252], Avg Loss: 2.8794, Avg Acc: 0.4919
2022-01-24 22:04:07,645 Epoch[049/050], Step[0550/1252], Avg Loss: 2.8841, Avg Acc: 0.4898
2022-01-24 22:05:34,277 Epoch[049/050], Step[0600/1252], Avg Loss: 2.8862, Avg Acc: 0.4897
2022-01-24 22:07:01,736 Epoch[049/050], Step[0650/1252], Avg Loss: 2.8837, Avg Acc: 0.4882
2022-01-24 22:08:29,054 Epoch[049/050], Step[0700/1252], Avg Loss: 2.8851, Avg Acc: 0.4883
2022-01-24 22:09:56,197 Epoch[049/050], Step[0750/1252], Avg Loss: 2.8886, Avg Acc: 0.4874
2022-01-24 22:11:23,359 Epoch[049/050], Step[0800/1252], Avg Loss: 2.8874, Avg Acc: 0.4886
2022-01-24 22:12:50,669 Epoch[049/050], Step[0850/1252], Avg Loss: 2.8855, Avg Acc: 0.4879
2022-01-24 22:14:17,377 Epoch[049/050], Step[0900/1252], Avg Loss: 2.8887, Avg Acc: 0.4882
2022-01-24 22:15:43,772 Epoch[049/050], Step[0950/1252], Avg Loss: 2.8917, Avg Acc: 0.4882
2022-01-24 22:17:11,478 Epoch[049/050], Step[1000/1252], Avg Loss: 2.8905, Avg Acc: 0.4866
2022-01-24 22:18:37,661 Epoch[049/050], Step[1050/1252], Avg Loss: 2.8906, Avg Acc: 0.4878
2022-01-24 22:20:05,766 Epoch[049/050], Step[1100/1252], Avg Loss: 2.8884, Avg Acc: 0.4879
2022-01-24 22:21:33,909 Epoch[049/050], Step[1150/1252], Avg Loss: 2.8888, Avg Acc: 0.4871
2022-01-24 22:23:01,581 Epoch[049/050], Step[1200/1252], Avg Loss: 2.8899, Avg Acc: 0.4868
2022-01-24 22:24:29,851 Epoch[049/050], Step[1250/1252], Avg Loss: 2.8918, Avg Acc: 0.4848
2022-01-24 22:24:37,094 ----- Epoch[049/050], Train Loss: 2.8918, Train Acc: 0.4848, time: 2291.96, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 22:24:37,094 Now training epoch 50. LR=0.000000
2022-01-24 22:26:27,139 Epoch[050/050], Step[0000/1252], Avg Loss: 2.3641, Avg Acc: 0.7705
2022-01-24 22:27:53,252 Epoch[050/050], Step[0050/1252], Avg Loss: 2.7764, Avg Acc: 0.5055
2022-01-24 22:29:19,865 Epoch[050/050], Step[0100/1252], Avg Loss: 2.7996, Avg Acc: 0.5142
2022-01-24 22:30:47,468 Epoch[050/050], Step[0150/1252], Avg Loss: 2.8057, Avg Acc: 0.5010
2022-01-24 22:32:13,335 Epoch[050/050], Step[0200/1252], Avg Loss: 2.8148, Avg Acc: 0.5030
2022-01-24 22:33:40,428 Epoch[050/050], Step[0250/1252], Avg Loss: 2.8322, Avg Acc: 0.4971
2022-01-24 22:35:07,316 Epoch[050/050], Step[0300/1252], Avg Loss: 2.8331, Avg Acc: 0.4954
2022-01-24 22:36:33,979 Epoch[050/050], Step[0350/1252], Avg Loss: 2.8478, Avg Acc: 0.4985
2022-01-24 22:38:00,233 Epoch[050/050], Step[0400/1252], Avg Loss: 2.8515, Avg Acc: 0.5007
2022-01-24 22:39:27,577 Epoch[050/050], Step[0450/1252], Avg Loss: 2.8527, Avg Acc: 0.4972
2022-01-24 22:40:54,114 Epoch[050/050], Step[0500/1252], Avg Loss: 2.8556, Avg Acc: 0.4938
2022-01-24 22:42:21,254 Epoch[050/050], Step[0550/1252], Avg Loss: 2.8583, Avg Acc: 0.4947
2022-01-24 22:43:48,950 Epoch[050/050], Step[0600/1252], Avg Loss: 2.8632, Avg Acc: 0.4932
2022-01-24 22:45:14,378 Epoch[050/050], Step[0650/1252], Avg Loss: 2.8618, Avg Acc: 0.4944
2022-01-24 22:46:41,569 Epoch[050/050], Step[0700/1252], Avg Loss: 2.8635, Avg Acc: 0.4925
2022-01-24 22:48:08,886 Epoch[050/050], Step[0750/1252], Avg Loss: 2.8608, Avg Acc: 0.4926
2022-01-24 22:49:35,668 Epoch[050/050], Step[0800/1252], Avg Loss: 2.8637, Avg Acc: 0.4927
2022-01-24 22:51:02,318 Epoch[050/050], Step[0850/1252], Avg Loss: 2.8663, Avg Acc: 0.4908
2022-01-24 22:52:29,361 Epoch[050/050], Step[0900/1252], Avg Loss: 2.8649, Avg Acc: 0.4900
2022-01-24 22:53:55,591 Epoch[050/050], Step[0950/1252], Avg Loss: 2.8651, Avg Acc: 0.4912
2022-01-24 22:55:23,265 Epoch[050/050], Step[1000/1252], Avg Loss: 2.8666, Avg Acc: 0.4920
2022-01-24 22:56:50,837 Epoch[050/050], Step[1050/1252], Avg Loss: 2.8672, Avg Acc: 0.4907
2022-01-24 22:58:16,465 Epoch[050/050], Step[1100/1252], Avg Loss: 2.8665, Avg Acc: 0.4920
2022-01-24 22:59:42,201 Epoch[050/050], Step[1150/1252], Avg Loss: 2.8672, Avg Acc: 0.4913
2022-01-24 23:01:10,583 Epoch[050/050], Step[1200/1252], Avg Loss: 2.8697, Avg Acc: 0.4914
2022-01-24 23:02:38,549 Epoch[050/050], Step[1250/1252], Avg Loss: 2.8707, Avg Acc: 0.4896
2022-01-24 23:02:45,715 ----- Epoch[050/050], Train Loss: 2.8706, Train Acc: 0.4896, time: 2288.62, Best Val(epoch38) Acc@1: 0.7769
2022-01-24 23:02:45,715 ----- Validation after Epoch: 50
2022-01-24 23:04:05,491 Val Step[0000/1563], Avg Loss: 0.8152, Avg Acc@1: 0.8125, Avg Acc@5: 1.0000
2022-01-24 23:04:07,309 Val Step[0050/1563], Avg Loss: 1.0053, Avg Acc@1: 0.7831, Avg Acc@5: 0.9430
2022-01-24 23:04:09,208 Val Step[0100/1563], Avg Loss: 1.0373, Avg Acc@1: 0.7840, Avg Acc@5: 0.9378
2022-01-24 23:04:11,008 Val Step[0150/1563], Avg Loss: 1.0407, Avg Acc@1: 0.7846, Avg Acc@5: 0.9358
2022-01-24 23:04:12,893 Val Step[0200/1563], Avg Loss: 1.0410, Avg Acc@1: 0.7848, Avg Acc@5: 0.9363
2022-01-24 23:04:14,770 Val Step[0250/1563], Avg Loss: 1.0313, Avg Acc@1: 0.7829, Avg Acc@5: 0.9380
2022-01-24 23:04:16,612 Val Step[0300/1563], Avg Loss: 1.0313, Avg Acc@1: 0.7825, Avg Acc@5: 0.9367
2022-01-24 23:04:18,548 Val Step[0350/1563], Avg Loss: 1.0360, Avg Acc@1: 0.7818, Avg Acc@5: 0.9363
2022-01-24 23:04:20,464 Val Step[0400/1563], Avg Loss: 1.0353, Avg Acc@1: 0.7827, Avg Acc@5: 0.9363
2022-01-24 23:04:22,251 Val Step[0450/1563], Avg Loss: 1.0398, Avg Acc@1: 0.7801, Avg Acc@5: 0.9363
2022-01-24 23:04:24,023 Val Step[0500/1563], Avg Loss: 1.0423, Avg Acc@1: 0.7796, Avg Acc@5: 0.9366
2022-01-24 23:04:25,804 Val Step[0550/1563], Avg Loss: 1.0413, Avg Acc@1: 0.7788, Avg Acc@5: 0.9366
2022-01-24 23:04:27,681 Val Step[0600/1563], Avg Loss: 1.0399, Avg Acc@1: 0.7783, Avg Acc@5: 0.9366
2022-01-24 23:04:29,570 Val Step[0650/1563], Avg Loss: 1.0404, Avg Acc@1: 0.7781, Avg Acc@5: 0.9367
2022-01-24 23:04:31,460 Val Step[0700/1563], Avg Loss: 1.0381, Avg Acc@1: 0.7784, Avg Acc@5: 0.9372
2022-01-24 23:04:33,277 Val Step[0750/1563], Avg Loss: 1.0444, Avg Acc@1: 0.7765, Avg Acc@5: 0.9370
2022-01-24 23:04:35,082 Val Step[0800/1563], Avg Loss: 1.0443, Avg Acc@1: 0.7772, Avg Acc@5: 0.9371
2022-01-24 23:04:36,964 Val Step[0850/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7771, Avg Acc@5: 0.9368
2022-01-24 23:04:38,860 Val Step[0900/1563], Avg Loss: 1.0426, Avg Acc@1: 0.7776, Avg Acc@5: 0.9372
2022-01-24 23:04:40,820 Val Step[0950/1563], Avg Loss: 1.0421, Avg Acc@1: 0.7783, Avg Acc@5: 0.9375
2022-01-24 23:04:42,827 Val Step[1000/1563], Avg Loss: 1.0439, Avg Acc@1: 0.7780, Avg Acc@5: 0.9371
2022-01-24 23:04:44,632 Val Step[1050/1563], Avg Loss: 1.0458, Avg Acc@1: 0.7774, Avg Acc@5: 0.9368
2022-01-24 23:04:46,410 Val Step[1100/1563], Avg Loss: 1.0459, Avg Acc@1: 0.7768, Avg Acc@5: 0.9371
2022-01-24 23:04:48,394 Val Step[1150/1563], Avg Loss: 1.0436, Avg Acc@1: 0.7770, Avg Acc@5: 0.9375
2022-01-24 23:04:50,423 Val Step[1200/1563], Avg Loss: 1.0424, Avg Acc@1: 0.7777, Avg Acc@5: 0.9374
2022-01-24 23:04:52,447 Val Step[1250/1563], Avg Loss: 1.0422, Avg Acc@1: 0.7772, Avg Acc@5: 0.9376
2022-01-24 23:04:54,472 Val Step[1300/1563], Avg Loss: 1.0452, Avg Acc@1: 0.7771, Avg Acc@5: 0.9374
2022-01-24 23:04:56,502 Val Step[1350/1563], Avg Loss: 1.0464, Avg Acc@1: 0.7765, Avg Acc@5: 0.9373
2022-01-24 23:04:58,537 Val Step[1400/1563], Avg Loss: 1.0460, Avg Acc@1: 0.7761, Avg Acc@5: 0.9373
2022-01-24 23:05:00,577 Val Step[1450/1563], Avg Loss: 1.0449, Avg Acc@1: 0.7767, Avg Acc@5: 0.9373
2022-01-24 23:05:02,648 Val Step[1500/1563], Avg Loss: 1.0448, Avg Acc@1: 0.7768, Avg Acc@5: 0.9375
2022-01-24 23:05:04,685 Val Step[1550/1563], Avg Loss: 1.0453, Avg Acc@1: 0.7764, Avg Acc@5: 0.9375
2022-01-24 23:05:06,717 ----- Epoch[050/050], Validation Loss: 1.0452, Validation Acc@1: 0.7763, Validation Acc@5: 0.9375, time: 141.00
2022-01-24 23:05:07,273 ----- Save model: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-50-Loss-2.8542775166655066.pdparams
2022-01-24 23:05:07,273 ----- Save optim: /root/paddlejob/workspace/output//train/CycleMLP-Epoch-50-Loss-2.8542775166655066.pdopt
