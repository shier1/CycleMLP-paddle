2022-01-14 19:32:21,355 ----- world_size = 4, local_rank = 3
2022-01-14 19:32:22,132 ----- Total # of train batch (single gpu): 1252
2022-01-14 19:32:22,132 ----- Total # of val batch (single gpu): 1563
2022-01-14 19:32:23,426 ----- Resume Training: Load model and optmizer from Best_CycleMLP
2022-01-14 19:32:23,426 Start training from epoch 53.
2022-01-14 19:32:23,426 Now training epoch 53. LR=0.000966
2022-01-14 19:34:22,272 Epoch[053/300], Step[0000/1252], Avg Loss: 4.4353, Avg Acc: 0.0703
2022-01-14 19:35:50,183 Epoch[053/300], Step[0050/1252], Avg Loss: 3.7800, Avg Acc: 0.2907
2022-01-14 19:37:17,242 Epoch[053/300], Step[0100/1252], Avg Loss: 3.7648, Avg Acc: 0.3144
2022-01-14 19:38:44,161 Epoch[053/300], Step[0150/1252], Avg Loss: 3.7995, Avg Acc: 0.3182
2022-01-14 19:40:11,621 Epoch[053/300], Step[0200/1252], Avg Loss: 3.7703, Avg Acc: 0.3326
2022-01-14 19:41:39,507 Epoch[053/300], Step[0250/1252], Avg Loss: 3.7504, Avg Acc: 0.3396
2022-01-14 19:43:06,769 Epoch[053/300], Step[0300/1252], Avg Loss: 3.7564, Avg Acc: 0.3430
2022-01-14 19:44:35,498 Epoch[053/300], Step[0350/1252], Avg Loss: 3.7852, Avg Acc: 0.3429
2022-01-14 19:46:03,997 Epoch[053/300], Step[0400/1252], Avg Loss: 3.7685, Avg Acc: 0.3454
2022-01-14 19:47:32,271 Epoch[053/300], Step[0450/1252], Avg Loss: 3.7777, Avg Acc: 0.3386
2022-01-14 19:49:00,470 Epoch[053/300], Step[0500/1252], Avg Loss: 3.7837, Avg Acc: 0.3379
2022-01-14 19:50:27,813 Epoch[053/300], Step[0550/1252], Avg Loss: 3.7797, Avg Acc: 0.3316
2022-01-14 19:51:56,702 Epoch[053/300], Step[0600/1252], Avg Loss: 3.7707, Avg Acc: 0.3364
2022-01-14 19:53:26,061 Epoch[053/300], Step[0650/1252], Avg Loss: 3.7723, Avg Acc: 0.3355
2022-01-14 19:54:54,918 Epoch[053/300], Step[0700/1252], Avg Loss: 3.7702, Avg Acc: 0.3336
2022-01-14 19:56:24,572 Epoch[053/300], Step[0750/1252], Avg Loss: 3.7672, Avg Acc: 0.3369
2022-01-14 19:57:52,821 Epoch[053/300], Step[0800/1252], Avg Loss: 3.7745, Avg Acc: 0.3369
2022-01-14 19:59:21,927 Epoch[053/300], Step[0850/1252], Avg Loss: 3.7703, Avg Acc: 0.3387
2022-01-14 20:00:51,085 Epoch[053/300], Step[0900/1252], Avg Loss: 3.7742, Avg Acc: 0.3397
2022-01-14 20:02:20,946 Epoch[053/300], Step[0950/1252], Avg Loss: 3.7769, Avg Acc: 0.3406
2022-01-14 20:03:50,244 Epoch[053/300], Step[1000/1252], Avg Loss: 3.7725, Avg Acc: 0.3398
2022-01-14 20:05:18,553 Epoch[053/300], Step[1050/1252], Avg Loss: 3.7734, Avg Acc: 0.3384
2022-01-14 20:06:46,729 Epoch[053/300], Step[1100/1252], Avg Loss: 3.7758, Avg Acc: 0.3369
2022-01-14 20:08:14,434 Epoch[053/300], Step[1150/1252], Avg Loss: 3.7789, Avg Acc: 0.3369
2022-01-14 20:09:43,650 Epoch[053/300], Step[1200/1252], Avg Loss: 3.7740, Avg Acc: 0.3376
2022-01-14 20:11:11,702 Epoch[053/300], Step[1250/1252], Avg Loss: 3.7741, Avg Acc: 0.3380
2022-01-14 20:11:18,169 ----- Epoch[053/300], Train Loss: 3.7740, Train Acc: 0.3380, time: 2334.74
2022-01-14 20:11:18,171 Now training epoch 54. LR=0.000964
2022-01-14 20:13:26,874 Epoch[054/300], Step[0000/1252], Avg Loss: 4.5843, Avg Acc: 0.2539
2022-01-14 20:14:53,040 Epoch[054/300], Step[0050/1252], Avg Loss: 3.7980, Avg Acc: 0.3898
2022-01-14 20:16:18,942 Epoch[054/300], Step[0100/1252], Avg Loss: 3.8058, Avg Acc: 0.3455
2022-01-14 20:17:44,546 Epoch[054/300], Step[0150/1252], Avg Loss: 3.7873, Avg Acc: 0.3479
2022-01-14 20:19:10,986 Epoch[054/300], Step[0200/1252], Avg Loss: 3.7700, Avg Acc: 0.3534
2022-01-14 20:20:38,579 Epoch[054/300], Step[0250/1252], Avg Loss: 3.7770, Avg Acc: 0.3575
2022-01-14 20:22:04,076 Epoch[054/300], Step[0300/1252], Avg Loss: 3.7728, Avg Acc: 0.3656
2022-01-14 20:23:31,889 Epoch[054/300], Step[0350/1252], Avg Loss: 3.7748, Avg Acc: 0.3604
2022-01-14 20:24:59,300 Epoch[054/300], Step[0400/1252], Avg Loss: 3.7680, Avg Acc: 0.3605
2022-01-14 20:26:26,860 Epoch[054/300], Step[0450/1252], Avg Loss: 3.7576, Avg Acc: 0.3566
2022-01-14 20:27:54,139 Epoch[054/300], Step[0500/1252], Avg Loss: 3.7742, Avg Acc: 0.3502
2022-01-14 20:29:20,738 Epoch[054/300], Step[0550/1252], Avg Loss: 3.7784, Avg Acc: 0.3503
2022-01-14 20:30:47,624 Epoch[054/300], Step[0600/1252], Avg Loss: 3.7766, Avg Acc: 0.3539
2022-01-14 20:32:15,934 Epoch[054/300], Step[0650/1252], Avg Loss: 3.7675, Avg Acc: 0.3564
2022-01-14 20:33:41,975 Epoch[054/300], Step[0700/1252], Avg Loss: 3.7644, Avg Acc: 0.3560
2022-01-14 20:35:09,289 Epoch[054/300], Step[0750/1252], Avg Loss: 3.7600, Avg Acc: 0.3611
2022-01-14 20:36:35,990 Epoch[054/300], Step[0800/1252], Avg Loss: 3.7654, Avg Acc: 0.3586
2022-01-14 20:38:04,168 Epoch[054/300], Step[0850/1252], Avg Loss: 3.7666, Avg Acc: 0.3556
2022-01-14 20:39:31,332 Epoch[054/300], Step[0900/1252], Avg Loss: 3.7677, Avg Acc: 0.3548
2022-01-14 20:40:57,985 Epoch[054/300], Step[0950/1252], Avg Loss: 3.7764, Avg Acc: 0.3550
2022-01-14 20:42:25,390 Epoch[054/300], Step[1000/1252], Avg Loss: 3.7708, Avg Acc: 0.3552
2022-01-14 20:43:53,788 Epoch[054/300], Step[1050/1252], Avg Loss: 3.7679, Avg Acc: 0.3545
2022-01-14 20:45:21,922 Epoch[054/300], Step[1100/1252], Avg Loss: 3.7683, Avg Acc: 0.3533
2022-01-14 20:46:49,493 Epoch[054/300], Step[1150/1252], Avg Loss: 3.7747, Avg Acc: 0.3511
2022-01-14 20:48:17,644 Epoch[054/300], Step[1200/1252], Avg Loss: 3.7733, Avg Acc: 0.3524
2022-01-14 20:49:44,695 Epoch[054/300], Step[1250/1252], Avg Loss: 3.7774, Avg Acc: 0.3526
2022-01-14 20:49:51,744 ----- Epoch[054/300], Train Loss: 3.7774, Train Acc: 0.3525, time: 2313.57
2022-01-14 20:49:51,746 ----- Validation after Epoch: 54
2022-01-14 20:51:22,509 Val Step[0000/1563], Avg Loss: 1.1072, Avg Acc@1: 0.5000, Avg Acc@5: 1.0000
2022-01-14 20:51:24,427 Val Step[0050/1563], Avg Loss: 1.3657, Avg Acc@1: 0.6765, Avg Acc@5: 0.9093
2022-01-14 20:51:26,279 Val Step[0100/1563], Avg Loss: 1.3424, Avg Acc@1: 0.6980, Avg Acc@5: 0.8998
2022-01-14 20:51:28,161 Val Step[0150/1563], Avg Loss: 1.4095, Avg Acc@1: 0.6879, Avg Acc@5: 0.8849
2022-01-14 20:51:29,992 Val Step[0200/1563], Avg Loss: 1.3971, Avg Acc@1: 0.6928, Avg Acc@5: 0.8837
2022-01-14 20:51:31,875 Val Step[0250/1563], Avg Loss: 1.4039, Avg Acc@1: 0.6942, Avg Acc@5: 0.8850
2022-01-14 20:51:33,849 Val Step[0300/1563], Avg Loss: 1.4131, Avg Acc@1: 0.6910, Avg Acc@5: 0.8837
2022-01-14 20:51:35,853 Val Step[0350/1563], Avg Loss: 1.4410, Avg Acc@1: 0.6848, Avg Acc@5: 0.8793
2022-01-14 20:51:37,891 Val Step[0400/1563], Avg Loss: 1.4320, Avg Acc@1: 0.6870, Avg Acc@5: 0.8819
2022-01-14 20:51:39,985 Val Step[0450/1563], Avg Loss: 1.4376, Avg Acc@1: 0.6843, Avg Acc@5: 0.8803
2022-01-14 20:51:42,059 Val Step[0500/1563], Avg Loss: 1.4433, Avg Acc@1: 0.6814, Avg Acc@5: 0.8802
2022-01-14 20:51:44,111 Val Step[0550/1563], Avg Loss: 1.4401, Avg Acc@1: 0.6835, Avg Acc@5: 0.8818
2022-01-14 20:51:46,106 Val Step[0600/1563], Avg Loss: 1.4394, Avg Acc@1: 0.6830, Avg Acc@5: 0.8814
2022-01-14 20:51:48,064 Val Step[0650/1563], Avg Loss: 1.4407, Avg Acc@1: 0.6830, Avg Acc@5: 0.8823
2022-01-14 20:51:49,924 Val Step[0700/1563], Avg Loss: 1.4382, Avg Acc@1: 0.6831, Avg Acc@5: 0.8827
2022-01-14 20:51:51,805 Val Step[0750/1563], Avg Loss: 1.4431, Avg Acc@1: 0.6829, Avg Acc@5: 0.8827
2022-01-14 20:51:53,667 Val Step[0800/1563], Avg Loss: 1.4467, Avg Acc@1: 0.6838, Avg Acc@5: 0.8822
2022-01-14 20:51:55,548 Val Step[0850/1563], Avg Loss: 1.4512, Avg Acc@1: 0.6832, Avg Acc@5: 0.8815
2022-01-14 20:51:57,459 Val Step[0900/1563], Avg Loss: 1.4423, Avg Acc@1: 0.6863, Avg Acc@5: 0.8826
2022-01-14 20:51:59,378 Val Step[0950/1563], Avg Loss: 1.4373, Avg Acc@1: 0.6868, Avg Acc@5: 0.8839
2022-01-14 20:52:01,286 Val Step[1000/1563], Avg Loss: 1.4377, Avg Acc@1: 0.6864, Avg Acc@5: 0.8839
2022-01-14 20:52:03,201 Val Step[1050/1563], Avg Loss: 1.4429, Avg Acc@1: 0.6860, Avg Acc@5: 0.8823
2022-01-14 20:52:05,103 Val Step[1100/1563], Avg Loss: 1.4489, Avg Acc@1: 0.6842, Avg Acc@5: 0.8818
2022-01-14 20:52:07,030 Val Step[1150/1563], Avg Loss: 1.4508, Avg Acc@1: 0.6842, Avg Acc@5: 0.8809
2022-01-14 20:52:09,004 Val Step[1200/1563], Avg Loss: 1.4442, Avg Acc@1: 0.6848, Avg Acc@5: 0.8820
2022-01-14 20:52:10,960 Val Step[1250/1563], Avg Loss: 1.4423, Avg Acc@1: 0.6845, Avg Acc@5: 0.8816
2022-01-14 20:52:12,791 Val Step[1300/1563], Avg Loss: 1.4480, Avg Acc@1: 0.6838, Avg Acc@5: 0.8806
2022-01-14 20:52:14,667 Val Step[1350/1563], Avg Loss: 1.4544, Avg Acc@1: 0.6823, Avg Acc@5: 0.8800
2022-01-14 20:52:16,493 Val Step[1400/1563], Avg Loss: 1.4541, Avg Acc@1: 0.6824, Avg Acc@5: 0.8805
2022-01-14 20:52:18,353 Val Step[1450/1563], Avg Loss: 1.4513, Avg Acc@1: 0.6819, Avg Acc@5: 0.8815
2022-01-14 20:52:20,174 Val Step[1500/1563], Avg Loss: 1.4512, Avg Acc@1: 0.6822, Avg Acc@5: 0.8813
2022-01-14 20:52:22,084 Val Step[1550/1563], Avg Loss: 1.4509, Avg Acc@1: 0.6827, Avg Acc@5: 0.8817
2022-01-14 20:52:24,028 ----- Epoch[054/300], Validation Loss: 1.4535, Validation Acc@1: 0.6819, Validation Acc@5: 0.8814, time: 152.28
2022-01-14 20:52:24,029 Now training epoch 55. LR=0.000962
2022-01-14 20:54:28,603 Epoch[055/300], Step[0000/1252], Avg Loss: 2.6736, Avg Acc: 0.6250
2022-01-14 20:55:54,228 Epoch[055/300], Step[0050/1252], Avg Loss: 3.5863, Avg Acc: 0.3683
2022-01-14 20:57:19,036 Epoch[055/300], Step[0100/1252], Avg Loss: 3.6334, Avg Acc: 0.3762
2022-01-14 20:58:43,926 Epoch[055/300], Step[0150/1252], Avg Loss: 3.6494, Avg Acc: 0.3604
2022-01-14 21:00:09,725 Epoch[055/300], Step[0200/1252], Avg Loss: 3.6664, Avg Acc: 0.3601
2022-01-14 21:01:37,115 Epoch[055/300], Step[0250/1252], Avg Loss: 3.6621, Avg Acc: 0.3566
2022-01-14 21:03:04,562 Epoch[055/300], Step[0300/1252], Avg Loss: 3.6587, Avg Acc: 0.3580
2022-01-14 21:04:31,585 Epoch[055/300], Step[0350/1252], Avg Loss: 3.6655, Avg Acc: 0.3573
2022-01-14 21:05:57,421 Epoch[055/300], Step[0400/1252], Avg Loss: 3.6747, Avg Acc: 0.3595
2022-01-14 21:07:24,922 Epoch[055/300], Step[0450/1252], Avg Loss: 3.6723, Avg Acc: 0.3626
2022-01-14 21:08:51,841 Epoch[055/300], Step[0500/1252], Avg Loss: 3.6729, Avg Acc: 0.3625
2022-01-14 21:10:18,575 Epoch[055/300], Step[0550/1252], Avg Loss: 3.6923, Avg Acc: 0.3598
2022-01-14 21:11:45,884 Epoch[055/300], Step[0600/1252], Avg Loss: 3.6981, Avg Acc: 0.3629
2022-01-14 21:13:13,339 Epoch[055/300], Step[0650/1252], Avg Loss: 3.6913, Avg Acc: 0.3640
2022-01-14 21:14:39,940 Epoch[055/300], Step[0700/1252], Avg Loss: 3.6928, Avg Acc: 0.3604
2022-01-14 21:16:07,358 Epoch[055/300], Step[0750/1252], Avg Loss: 3.6966, Avg Acc: 0.3600
2022-01-14 21:17:34,909 Epoch[055/300], Step[0800/1252], Avg Loss: 3.7088, Avg Acc: 0.3600
2022-01-14 21:19:01,330 Epoch[055/300], Step[0850/1252], Avg Loss: 3.7166, Avg Acc: 0.3589
2022-01-14 21:20:28,135 Epoch[055/300], Step[0900/1252], Avg Loss: 3.7228, Avg Acc: 0.3564
2022-01-14 21:21:54,779 Epoch[055/300], Step[0950/1252], Avg Loss: 3.7226, Avg Acc: 0.3549
2022-01-14 21:23:21,620 Epoch[055/300], Step[1000/1252], Avg Loss: 3.7223, Avg Acc: 0.3553
2022-01-14 21:24:49,262 Epoch[055/300], Step[1050/1252], Avg Loss: 3.7181, Avg Acc: 0.3550
2022-01-14 21:26:16,655 Epoch[055/300], Step[1100/1252], Avg Loss: 3.7178, Avg Acc: 0.3556
2022-01-14 21:27:43,450 Epoch[055/300], Step[1150/1252], Avg Loss: 3.7181, Avg Acc: 0.3552
2022-01-14 21:29:09,745 Epoch[055/300], Step[1200/1252], Avg Loss: 3.7169, Avg Acc: 0.3543
2022-01-14 21:30:36,415 Epoch[055/300], Step[1250/1252], Avg Loss: 3.7219, Avg Acc: 0.3510
2022-01-14 21:30:42,610 ----- Epoch[055/300], Train Loss: 3.7220, Train Acc: 0.3510, time: 2298.58
2022-01-14 21:30:42,612 Now training epoch 56. LR=0.000960
2022-01-14 21:35:44,895 Epoch[056/300], Step[0000/1252], Avg Loss: 2.6821, Avg Acc: 0.6445
2022-01-14 21:37:13,346 Epoch[056/300], Step[0050/1252], Avg Loss: 3.7271, Avg Acc: 0.3758
2022-01-14 21:38:40,105 Epoch[056/300], Step[0100/1252], Avg Loss: 3.7901, Avg Acc: 0.3824
2022-01-14 21:40:07,660 Epoch[056/300], Step[0150/1252], Avg Loss: 3.7717, Avg Acc: 0.3947
2022-01-14 21:41:35,601 Epoch[056/300], Step[0200/1252], Avg Loss: 3.7973, Avg Acc: 0.3772
2022-01-14 21:43:03,543 Epoch[056/300], Step[0250/1252], Avg Loss: 3.7654, Avg Acc: 0.3646
2022-01-14 21:44:33,698 Epoch[056/300], Step[0300/1252], Avg Loss: 3.7658, Avg Acc: 0.3628
2022-01-14 21:46:02,525 Epoch[056/300], Step[0350/1252], Avg Loss: 3.7557, Avg Acc: 0.3690
2022-01-14 21:47:31,741 Epoch[056/300], Step[0400/1252], Avg Loss: 3.7493, Avg Acc: 0.3700
2022-01-14 21:49:00,611 Epoch[056/300], Step[0450/1252], Avg Loss: 3.7529, Avg Acc: 0.3708
2022-01-14 21:50:29,767 Epoch[056/300], Step[0500/1252], Avg Loss: 3.7566, Avg Acc: 0.3698
2022-01-14 21:51:58,775 Epoch[056/300], Step[0550/1252], Avg Loss: 3.7610, Avg Acc: 0.3624
2022-01-14 21:53:29,162 Epoch[056/300], Step[0600/1252], Avg Loss: 3.7599, Avg Acc: 0.3620
2022-01-14 21:54:56,935 Epoch[056/300], Step[0650/1252], Avg Loss: 3.7562, Avg Acc: 0.3579
2022-01-14 21:56:25,513 Epoch[056/300], Step[0700/1252], Avg Loss: 3.7622, Avg Acc: 0.3536
2022-01-14 21:57:54,995 Epoch[056/300], Step[0750/1252], Avg Loss: 3.7774, Avg Acc: 0.3499
2022-01-14 21:59:24,823 Epoch[056/300], Step[0800/1252], Avg Loss: 3.7774, Avg Acc: 0.3493
2022-01-14 22:00:53,819 Epoch[056/300], Step[0850/1252], Avg Loss: 3.7850, Avg Acc: 0.3494
2022-01-14 22:02:24,153 Epoch[056/300], Step[0900/1252], Avg Loss: 3.7859, Avg Acc: 0.3505
2022-01-14 22:03:54,829 Epoch[056/300], Step[0950/1252], Avg Loss: 3.7839, Avg Acc: 0.3540
2022-01-14 22:05:23,489 Epoch[056/300], Step[1000/1252], Avg Loss: 3.7794, Avg Acc: 0.3558
2022-01-14 22:06:52,937 Epoch[056/300], Step[1050/1252], Avg Loss: 3.7827, Avg Acc: 0.3544
2022-01-14 22:08:23,056 Epoch[056/300], Step[1100/1252], Avg Loss: 3.7783, Avg Acc: 0.3553
2022-01-14 22:09:51,143 Epoch[056/300], Step[1150/1252], Avg Loss: 3.7775, Avg Acc: 0.3561
2022-01-14 22:11:21,585 Epoch[056/300], Step[1200/1252], Avg Loss: 3.7806, Avg Acc: 0.3551
2022-01-14 22:12:51,622 Epoch[056/300], Step[1250/1252], Avg Loss: 3.7785, Avg Acc: 0.3531
2022-01-14 22:12:58,862 ----- Epoch[056/300], Train Loss: 3.7785, Train Acc: 0.3531, time: 2536.25
2022-01-14 22:12:58,863 ----- Validation after Epoch: 56
2022-01-14 22:14:20,762 Val Step[0000/1563], Avg Loss: 1.0131, Avg Acc@1: 0.6250, Avg Acc@5: 1.0000
2022-01-14 22:14:22,658 Val Step[0050/1563], Avg Loss: 1.3410, Avg Acc@1: 0.7034, Avg Acc@5: 0.9020
2022-01-14 22:14:24,435 Val Step[0100/1563], Avg Loss: 1.3598, Avg Acc@1: 0.6832, Avg Acc@5: 0.9059
2022-01-14 22:14:26,231 Val Step[0150/1563], Avg Loss: 1.4484, Avg Acc@1: 0.6705, Avg Acc@5: 0.8866
2022-01-14 22:14:28,136 Val Step[0200/1563], Avg Loss: 1.4344, Avg Acc@1: 0.6810, Avg Acc@5: 0.8887
2022-01-14 22:14:29,948 Val Step[0250/1563], Avg Loss: 1.4385, Avg Acc@1: 0.6823, Avg Acc@5: 0.8889
2022-01-14 22:14:31,832 Val Step[0300/1563], Avg Loss: 1.4355, Avg Acc@1: 0.6823, Avg Acc@5: 0.8895
2022-01-14 22:14:33,698 Val Step[0350/1563], Avg Loss: 1.4596, Avg Acc@1: 0.6806, Avg Acc@5: 0.8850
2022-01-14 22:14:35,820 Val Step[0400/1563], Avg Loss: 1.4525, Avg Acc@1: 0.6802, Avg Acc@5: 0.8856
2022-01-14 22:14:37,826 Val Step[0450/1563], Avg Loss: 1.4617, Avg Acc@1: 0.6766, Avg Acc@5: 0.8830
2022-01-14 22:14:39,649 Val Step[0500/1563], Avg Loss: 1.4664, Avg Acc@1: 0.6756, Avg Acc@5: 0.8812
2022-01-14 22:14:41,525 Val Step[0550/1563], Avg Loss: 1.4628, Avg Acc@1: 0.6776, Avg Acc@5: 0.8814
2022-01-14 22:14:43,402 Val Step[0600/1563], Avg Loss: 1.4581, Avg Acc@1: 0.6772, Avg Acc@5: 0.8827
2022-01-14 22:14:45,178 Val Step[0650/1563], Avg Loss: 1.4598, Avg Acc@1: 0.6776, Avg Acc@5: 0.8831
2022-01-14 22:14:47,062 Val Step[0700/1563], Avg Loss: 1.4569, Avg Acc@1: 0.6799, Avg Acc@5: 0.8830
2022-01-14 22:14:49,146 Val Step[0750/1563], Avg Loss: 1.4632, Avg Acc@1: 0.6774, Avg Acc@5: 0.8827
2022-01-14 22:14:51,206 Val Step[0800/1563], Avg Loss: 1.4629, Avg Acc@1: 0.6801, Avg Acc@5: 0.8822
2022-01-14 22:14:52,977 Val Step[0850/1563], Avg Loss: 1.4669, Avg Acc@1: 0.6782, Avg Acc@5: 0.8826
2022-01-14 22:14:54,830 Val Step[0900/1563], Avg Loss: 1.4582, Avg Acc@1: 0.6804, Avg Acc@5: 0.8837
2022-01-14 22:14:56,634 Val Step[0950/1563], Avg Loss: 1.4503, Avg Acc@1: 0.6820, Avg Acc@5: 0.8843
2022-01-14 22:14:58,437 Val Step[1000/1563], Avg Loss: 1.4527, Avg Acc@1: 0.6806, Avg Acc@5: 0.8844
2022-01-14 22:15:00,263 Val Step[1050/1563], Avg Loss: 1.4538, Avg Acc@1: 0.6803, Avg Acc@5: 0.8837
2022-01-14 22:15:02,125 Val Step[1100/1563], Avg Loss: 1.4599, Avg Acc@1: 0.6792, Avg Acc@5: 0.8828
2022-01-14 22:15:03,983 Val Step[1150/1563], Avg Loss: 1.4598, Avg Acc@1: 0.6788, Avg Acc@5: 0.8818
2022-01-14 22:15:05,844 Val Step[1200/1563], Avg Loss: 1.4539, Avg Acc@1: 0.6804, Avg Acc@5: 0.8823
2022-01-14 22:15:07,655 Val Step[1250/1563], Avg Loss: 1.4534, Avg Acc@1: 0.6806, Avg Acc@5: 0.8823
2022-01-14 22:15:09,486 Val Step[1300/1563], Avg Loss: 1.4559, Avg Acc@1: 0.6796, Avg Acc@5: 0.8821
2022-01-14 22:15:11,269 Val Step[1350/1563], Avg Loss: 1.4588, Avg Acc@1: 0.6784, Avg Acc@5: 0.8813
2022-01-14 22:15:13,047 Val Step[1400/1563], Avg Loss: 1.4583, Avg Acc@1: 0.6787, Avg Acc@5: 0.8812
2022-01-14 22:15:14,820 Val Step[1450/1563], Avg Loss: 1.4568, Avg Acc@1: 0.6791, Avg Acc@5: 0.8820
2022-01-14 22:15:16,687 Val Step[1500/1563], Avg Loss: 1.4549, Avg Acc@1: 0.6791, Avg Acc@5: 0.8827
2022-01-14 22:15:18,471 Val Step[1550/1563], Avg Loss: 1.4551, Avg Acc@1: 0.6792, Avg Acc@5: 0.8827
2022-01-14 22:15:20,370 ----- Epoch[056/300], Validation Loss: 1.4591, Validation Acc@1: 0.6782, Validation Acc@5: 0.8822, time: 141.51
2022-01-14 22:15:20,371 Now training epoch 57. LR=0.000958
2022-01-14 22:17:14,019 Epoch[057/300], Step[0000/1252], Avg Loss: 2.7594, Avg Acc: 0.6367
2022-01-14 22:18:41,455 Epoch[057/300], Step[0050/1252], Avg Loss: 3.7993, Avg Acc: 0.3843
2022-01-14 22:20:07,198 Epoch[057/300], Step[0100/1252], Avg Loss: 3.7428, Avg Acc: 0.4060
2022-01-14 22:21:33,921 Epoch[057/300], Step[0150/1252], Avg Loss: 3.7146, Avg Acc: 0.3984
2022-01-14 22:23:00,254 Epoch[057/300], Step[0200/1252], Avg Loss: 3.6870, Avg Acc: 0.3819
2022-01-14 22:24:28,059 Epoch[057/300], Step[0250/1252], Avg Loss: 3.6994, Avg Acc: 0.3680
2022-01-14 22:25:56,702 Epoch[057/300], Step[0300/1252], Avg Loss: 3.6916, Avg Acc: 0.3696
2022-01-14 22:27:24,846 Epoch[057/300], Step[0350/1252], Avg Loss: 3.7126, Avg Acc: 0.3659
2022-01-14 22:28:53,350 Epoch[057/300], Step[0400/1252], Avg Loss: 3.7208, Avg Acc: 0.3678
2022-01-14 22:30:21,985 Epoch[057/300], Step[0450/1252], Avg Loss: 3.7274, Avg Acc: 0.3661
2022-01-14 22:31:48,958 Epoch[057/300], Step[0500/1252], Avg Loss: 3.7222, Avg Acc: 0.3656
2022-01-14 22:33:15,997 Epoch[057/300], Step[0550/1252], Avg Loss: 3.7214, Avg Acc: 0.3674
2022-01-14 22:34:44,948 Epoch[057/300], Step[0600/1252], Avg Loss: 3.7213, Avg Acc: 0.3621
2022-01-14 22:36:11,860 Epoch[057/300], Step[0650/1252], Avg Loss: 3.7225, Avg Acc: 0.3600
2022-01-14 22:37:40,583 Epoch[057/300], Step[0700/1252], Avg Loss: 3.7255, Avg Acc: 0.3583
2022-01-14 22:39:08,509 Epoch[057/300], Step[0750/1252], Avg Loss: 3.7179, Avg Acc: 0.3606
2022-01-14 22:40:36,574 Epoch[057/300], Step[0800/1252], Avg Loss: 3.7084, Avg Acc: 0.3576
2022-01-14 22:42:05,072 Epoch[057/300], Step[0850/1252], Avg Loss: 3.7184, Avg Acc: 0.3583
2022-01-14 22:43:33,077 Epoch[057/300], Step[0900/1252], Avg Loss: 3.7233, Avg Acc: 0.3571
2022-01-14 22:45:00,811 Epoch[057/300], Step[0950/1252], Avg Loss: 3.7185, Avg Acc: 0.3578
2022-01-14 22:46:28,572 Epoch[057/300], Step[1000/1252], Avg Loss: 3.7171, Avg Acc: 0.3574
2022-01-14 22:47:56,832 Epoch[057/300], Step[1050/1252], Avg Loss: 3.7132, Avg Acc: 0.3572
2022-01-14 22:49:25,304 Epoch[057/300], Step[1100/1252], Avg Loss: 3.7146, Avg Acc: 0.3569
2022-01-14 22:50:53,253 Epoch[057/300], Step[1150/1252], Avg Loss: 3.7212, Avg Acc: 0.3549
2022-01-14 22:52:21,224 Epoch[057/300], Step[1200/1252], Avg Loss: 3.7196, Avg Acc: 0.3548
2022-01-14 22:53:50,268 Epoch[057/300], Step[1250/1252], Avg Loss: 3.7238, Avg Acc: 0.3543
2022-01-14 22:53:57,364 ----- Epoch[057/300], Train Loss: 3.7238, Train Acc: 0.3543, time: 2316.99
2022-01-14 22:53:57,365 Now training epoch 58. LR=0.000956
2022-01-14 22:55:46,684 Epoch[058/300], Step[0000/1252], Avg Loss: 4.3971, Avg Acc: 0.1094
2022-01-14 22:57:15,280 Epoch[058/300], Step[0050/1252], Avg Loss: 3.8819, Avg Acc: 0.4036
2022-01-14 22:58:43,421 Epoch[058/300], Step[0100/1252], Avg Loss: 3.7982, Avg Acc: 0.3873
2022-01-14 23:00:12,338 Epoch[058/300], Step[0150/1252], Avg Loss: 3.8091, Avg Acc: 0.3729
2022-01-14 23:01:40,691 Epoch[058/300], Step[0200/1252], Avg Loss: 3.8130, Avg Acc: 0.3569
2022-01-14 23:03:09,507 Epoch[058/300], Step[0250/1252], Avg Loss: 3.7907, Avg Acc: 0.3605
2022-01-14 23:04:37,017 Epoch[058/300], Step[0300/1252], Avg Loss: 3.7934, Avg Acc: 0.3583
2022-01-14 23:06:03,868 Epoch[058/300], Step[0350/1252], Avg Loss: 3.7914, Avg Acc: 0.3596
2022-01-14 23:07:30,538 Epoch[058/300], Step[0400/1252], Avg Loss: 3.7910, Avg Acc: 0.3606
2022-01-14 23:08:57,625 Epoch[058/300], Step[0450/1252], Avg Loss: 3.7712, Avg Acc: 0.3661
2022-01-14 23:10:25,125 Epoch[058/300], Step[0500/1252], Avg Loss: 3.7604, Avg Acc: 0.3670
2022-01-14 23:11:50,765 Epoch[058/300], Step[0550/1252], Avg Loss: 3.7553, Avg Acc: 0.3677
2022-01-14 23:13:17,502 Epoch[058/300], Step[0600/1252], Avg Loss: 3.7498, Avg Acc: 0.3669
2022-01-14 23:14:44,021 Epoch[058/300], Step[0650/1252], Avg Loss: 3.7482, Avg Acc: 0.3662
2022-01-14 23:16:11,986 Epoch[058/300], Step[0700/1252], Avg Loss: 3.7453, Avg Acc: 0.3634
2022-01-14 23:17:39,617 Epoch[058/300], Step[0750/1252], Avg Loss: 3.7447, Avg Acc: 0.3628
2022-01-14 23:19:04,688 Epoch[058/300], Step[0800/1252], Avg Loss: 3.7429, Avg Acc: 0.3655
2022-01-14 23:20:31,852 Epoch[058/300], Step[0850/1252], Avg Loss: 3.7428, Avg Acc: 0.3663
2022-01-14 23:22:00,117 Epoch[058/300], Step[0900/1252], Avg Loss: 3.7381, Avg Acc: 0.3651
2022-01-14 23:23:28,791 Epoch[058/300], Step[0950/1252], Avg Loss: 3.7386, Avg Acc: 0.3654
2022-01-14 23:24:56,947 Epoch[058/300], Step[1000/1252], Avg Loss: 3.7407, Avg Acc: 0.3626
2022-01-14 23:26:25,207 Epoch[058/300], Step[1050/1252], Avg Loss: 3.7373, Avg Acc: 0.3600
2022-01-14 23:27:53,479 Epoch[058/300], Step[1100/1252], Avg Loss: 3.7349, Avg Acc: 0.3614
2022-01-14 23:29:20,590 Epoch[058/300], Step[1150/1252], Avg Loss: 3.7327, Avg Acc: 0.3608
2022-01-14 23:30:49,129 Epoch[058/300], Step[1200/1252], Avg Loss: 3.7339, Avg Acc: 0.3601
2022-01-14 23:32:17,580 Epoch[058/300], Step[1250/1252], Avg Loss: 3.7360, Avg Acc: 0.3636
2022-01-14 23:32:24,874 ----- Epoch[058/300], Train Loss: 3.7360, Train Acc: 0.3636, time: 2307.51
2022-01-14 23:32:24,876 ----- Validation after Epoch: 58
2022-01-14 23:33:43,337 Val Step[0000/1563], Avg Loss: 1.3904, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-14 23:33:45,170 Val Step[0050/1563], Avg Loss: 1.3777, Avg Acc@1: 0.7132, Avg Acc@5: 0.9020
2022-01-14 23:33:46,948 Val Step[0100/1563], Avg Loss: 1.4203, Avg Acc@1: 0.6968, Avg Acc@5: 0.8923
2022-01-14 23:33:48,738 Val Step[0150/1563], Avg Loss: 1.5070, Avg Acc@1: 0.6788, Avg Acc@5: 0.8791
2022-01-14 23:33:50,518 Val Step[0200/1563], Avg Loss: 1.4955, Avg Acc@1: 0.6816, Avg Acc@5: 0.8781
2022-01-14 23:33:52,309 Val Step[0250/1563], Avg Loss: 1.4986, Avg Acc@1: 0.6833, Avg Acc@5: 0.8805
2022-01-14 23:33:54,234 Val Step[0300/1563], Avg Loss: 1.5025, Avg Acc@1: 0.6819, Avg Acc@5: 0.8800
2022-01-14 23:33:56,020 Val Step[0350/1563], Avg Loss: 1.5247, Avg Acc@1: 0.6766, Avg Acc@5: 0.8796
2022-01-14 23:33:57,851 Val Step[0400/1563], Avg Loss: 1.5186, Avg Acc@1: 0.6746, Avg Acc@5: 0.8800
2022-01-14 23:33:59,655 Val Step[0450/1563], Avg Loss: 1.5278, Avg Acc@1: 0.6718, Avg Acc@5: 0.8786
2022-01-14 23:34:01,559 Val Step[0500/1563], Avg Loss: 1.5312, Avg Acc@1: 0.6719, Avg Acc@5: 0.8765
2022-01-14 23:34:03,373 Val Step[0550/1563], Avg Loss: 1.5287, Avg Acc@1: 0.6735, Avg Acc@5: 0.8764
2022-01-14 23:34:05,179 Val Step[0600/1563], Avg Loss: 1.5262, Avg Acc@1: 0.6716, Avg Acc@5: 0.8758
2022-01-14 23:34:06,978 Val Step[0650/1563], Avg Loss: 1.5271, Avg Acc@1: 0.6699, Avg Acc@5: 0.8765
2022-01-14 23:34:08,997 Val Step[0700/1563], Avg Loss: 1.5250, Avg Acc@1: 0.6699, Avg Acc@5: 0.8779
2022-01-14 23:34:11,042 Val Step[0750/1563], Avg Loss: 1.5297, Avg Acc@1: 0.6699, Avg Acc@5: 0.8783
2022-01-14 23:34:13,087 Val Step[0800/1563], Avg Loss: 1.5291, Avg Acc@1: 0.6721, Avg Acc@5: 0.8780
2022-01-14 23:34:15,066 Val Step[0850/1563], Avg Loss: 1.5317, Avg Acc@1: 0.6714, Avg Acc@5: 0.8782
2022-01-14 23:34:16,975 Val Step[0900/1563], Avg Loss: 1.5255, Avg Acc@1: 0.6741, Avg Acc@5: 0.8790
2022-01-14 23:34:19,059 Val Step[0950/1563], Avg Loss: 1.5171, Avg Acc@1: 0.6761, Avg Acc@5: 0.8814
2022-01-14 23:34:21,151 Val Step[1000/1563], Avg Loss: 1.5180, Avg Acc@1: 0.6763, Avg Acc@5: 0.8817
2022-01-14 23:34:22,985 Val Step[1050/1563], Avg Loss: 1.5210, Avg Acc@1: 0.6755, Avg Acc@5: 0.8812
2022-01-14 23:34:24,840 Val Step[1100/1563], Avg Loss: 1.5266, Avg Acc@1: 0.6736, Avg Acc@5: 0.8794
2022-01-14 23:34:26,617 Val Step[1150/1563], Avg Loss: 1.5274, Avg Acc@1: 0.6720, Avg Acc@5: 0.8791
2022-01-14 23:34:28,449 Val Step[1200/1563], Avg Loss: 1.5206, Avg Acc@1: 0.6745, Avg Acc@5: 0.8801
2022-01-14 23:34:30,259 Val Step[1250/1563], Avg Loss: 1.5208, Avg Acc@1: 0.6739, Avg Acc@5: 0.8798
2022-01-14 23:34:32,047 Val Step[1300/1563], Avg Loss: 1.5259, Avg Acc@1: 0.6722, Avg Acc@5: 0.8792
2022-01-14 23:34:33,870 Val Step[1350/1563], Avg Loss: 1.5303, Avg Acc@1: 0.6706, Avg Acc@5: 0.8788
2022-01-14 23:34:35,811 Val Step[1400/1563], Avg Loss: 1.5266, Avg Acc@1: 0.6711, Avg Acc@5: 0.8796
2022-01-14 23:34:37,698 Val Step[1450/1563], Avg Loss: 1.5251, Avg Acc@1: 0.6711, Avg Acc@5: 0.8800
2022-01-14 23:34:39,501 Val Step[1500/1563], Avg Loss: 1.5238, Avg Acc@1: 0.6706, Avg Acc@5: 0.8804
2022-01-14 23:34:41,248 Val Step[1550/1563], Avg Loss: 1.5247, Avg Acc@1: 0.6700, Avg Acc@5: 0.8803
2022-01-14 23:34:43,172 ----- Epoch[058/300], Validation Loss: 1.5275, Validation Acc@1: 0.6690, Validation Acc@5: 0.8805, time: 138.29
2022-01-14 23:34:43,173 Now training epoch 59. LR=0.000953
2022-01-14 23:36:32,771 Epoch[059/300], Step[0000/1252], Avg Loss: 3.7212, Avg Acc: 0.5117
2022-01-14 23:38:00,485 Epoch[059/300], Step[0050/1252], Avg Loss: 3.7568, Avg Acc: 0.3720
2022-01-14 23:39:28,665 Epoch[059/300], Step[0100/1252], Avg Loss: 3.7501, Avg Acc: 0.3716
2022-01-14 23:40:55,473 Epoch[059/300], Step[0150/1252], Avg Loss: 3.7331, Avg Acc: 0.3629
2022-01-14 23:42:22,640 Epoch[059/300], Step[0200/1252], Avg Loss: 3.7109, Avg Acc: 0.3678
2022-01-14 23:43:50,267 Epoch[059/300], Step[0250/1252], Avg Loss: 3.7280, Avg Acc: 0.3584
2022-01-14 23:45:19,581 Epoch[059/300], Step[0300/1252], Avg Loss: 3.7478, Avg Acc: 0.3527
2022-01-14 23:46:48,648 Epoch[059/300], Step[0350/1252], Avg Loss: 3.7420, Avg Acc: 0.3543
2022-01-14 23:48:16,749 Epoch[059/300], Step[0400/1252], Avg Loss: 3.7604, Avg Acc: 0.3556
2022-01-14 23:49:45,958 Epoch[059/300], Step[0450/1252], Avg Loss: 3.7537, Avg Acc: 0.3616
2022-01-14 23:51:15,476 Epoch[059/300], Step[0500/1252], Avg Loss: 3.7589, Avg Acc: 0.3613
2022-01-14 23:52:42,867 Epoch[059/300], Step[0550/1252], Avg Loss: 3.7639, Avg Acc: 0.3574
2022-01-14 23:54:13,204 Epoch[059/300], Step[0600/1252], Avg Loss: 3.7699, Avg Acc: 0.3596
2022-01-14 23:55:44,403 Epoch[059/300], Step[0650/1252], Avg Loss: 3.7591, Avg Acc: 0.3607
2022-01-14 23:57:14,827 Epoch[059/300], Step[0700/1252], Avg Loss: 3.7549, Avg Acc: 0.3584
2022-01-14 23:58:45,947 Epoch[059/300], Step[0750/1252], Avg Loss: 3.7589, Avg Acc: 0.3569
2022-01-15 00:00:17,378 Epoch[059/300], Step[0800/1252], Avg Loss: 3.7642, Avg Acc: 0.3528
2022-01-15 00:01:48,488 Epoch[059/300], Step[0850/1252], Avg Loss: 3.7667, Avg Acc: 0.3560
2022-01-15 00:03:18,608 Epoch[059/300], Step[0900/1252], Avg Loss: 3.7634, Avg Acc: 0.3551
2022-01-15 00:04:50,782 Epoch[059/300], Step[0950/1252], Avg Loss: 3.7574, Avg Acc: 0.3574
2022-01-15 00:06:20,114 Epoch[059/300], Step[1000/1252], Avg Loss: 3.7540, Avg Acc: 0.3571
2022-01-15 00:07:50,208 Epoch[059/300], Step[1050/1252], Avg Loss: 3.7590, Avg Acc: 0.3564
2022-01-15 00:09:20,135 Epoch[059/300], Step[1100/1252], Avg Loss: 3.7642, Avg Acc: 0.3561
2022-01-15 00:10:51,055 Epoch[059/300], Step[1150/1252], Avg Loss: 3.7725, Avg Acc: 0.3548
2022-01-15 00:12:20,574 Epoch[059/300], Step[1200/1252], Avg Loss: 3.7694, Avg Acc: 0.3566
2022-01-15 00:13:52,154 Epoch[059/300], Step[1250/1252], Avg Loss: 3.7710, Avg Acc: 0.3576
2022-01-15 00:13:58,814 ----- Epoch[059/300], Train Loss: 3.7709, Train Acc: 0.3576, time: 2355.64
2022-01-15 00:13:58,816 Now training epoch 60. LR=0.000951
2022-01-15 00:16:00,466 Epoch[060/300], Step[0000/1252], Avg Loss: 4.2341, Avg Acc: 0.0586
2022-01-15 00:17:28,066 Epoch[060/300], Step[0050/1252], Avg Loss: 3.7309, Avg Acc: 0.4203
2022-01-15 00:18:57,206 Epoch[060/300], Step[0100/1252], Avg Loss: 3.7724, Avg Acc: 0.3787
2022-01-15 00:20:26,061 Epoch[060/300], Step[0150/1252], Avg Loss: 3.7368, Avg Acc: 0.3620
2022-01-15 00:21:56,514 Epoch[060/300], Step[0200/1252], Avg Loss: 3.7043, Avg Acc: 0.3603
2022-01-15 00:23:27,142 Epoch[060/300], Step[0250/1252], Avg Loss: 3.7074, Avg Acc: 0.3555
2022-01-15 00:24:58,980 Epoch[060/300], Step[0300/1252], Avg Loss: 3.7041, Avg Acc: 0.3606
2022-01-15 00:26:30,975 Epoch[060/300], Step[0350/1252], Avg Loss: 3.7116, Avg Acc: 0.3599
2022-01-15 00:28:02,765 Epoch[060/300], Step[0400/1252], Avg Loss: 3.7207, Avg Acc: 0.3591
2022-01-15 00:29:33,446 Epoch[060/300], Step[0450/1252], Avg Loss: 3.7272, Avg Acc: 0.3642
2022-01-15 00:31:03,969 Epoch[060/300], Step[0500/1252], Avg Loss: 3.7209, Avg Acc: 0.3660
2022-01-15 00:32:35,215 Epoch[060/300], Step[0550/1252], Avg Loss: 3.7222, Avg Acc: 0.3654
2022-01-15 00:34:04,632 Epoch[060/300], Step[0600/1252], Avg Loss: 3.7219, Avg Acc: 0.3640
2022-01-15 00:35:34,784 Epoch[060/300], Step[0650/1252], Avg Loss: 3.7274, Avg Acc: 0.3638
2022-01-15 00:37:06,400 Epoch[060/300], Step[0700/1252], Avg Loss: 3.7289, Avg Acc: 0.3645
2022-01-15 00:38:37,841 Epoch[060/300], Step[0750/1252], Avg Loss: 3.7385, Avg Acc: 0.3674
2022-01-15 00:40:07,844 Epoch[060/300], Step[0800/1252], Avg Loss: 3.7372, Avg Acc: 0.3666
2022-01-15 00:41:38,530 Epoch[060/300], Step[0850/1252], Avg Loss: 3.7404, Avg Acc: 0.3633
2022-01-15 00:43:09,956 Epoch[060/300], Step[0900/1252], Avg Loss: 3.7335, Avg Acc: 0.3640
2022-01-15 00:44:42,635 Epoch[060/300], Step[0950/1252], Avg Loss: 3.7343, Avg Acc: 0.3614
2022-01-15 00:46:13,091 Epoch[060/300], Step[1000/1252], Avg Loss: 3.7364, Avg Acc: 0.3596
2022-01-15 00:47:44,997 Epoch[060/300], Step[1050/1252], Avg Loss: 3.7327, Avg Acc: 0.3580
2022-01-15 00:49:16,310 Epoch[060/300], Step[1100/1252], Avg Loss: 3.7280, Avg Acc: 0.3616
2022-01-15 00:50:46,864 Epoch[060/300], Step[1150/1252], Avg Loss: 3.7265, Avg Acc: 0.3599
2022-01-15 00:52:17,829 Epoch[060/300], Step[1200/1252], Avg Loss: 3.7233, Avg Acc: 0.3594
2022-01-15 00:53:48,775 Epoch[060/300], Step[1250/1252], Avg Loss: 3.7221, Avg Acc: 0.3594
2022-01-15 00:53:55,285 ----- Epoch[060/300], Train Loss: 3.7221, Train Acc: 0.3594, time: 2396.47
2022-01-15 00:53:55,286 ----- Validation after Epoch: 60
2022-01-15 00:55:13,377 Val Step[0000/1563], Avg Loss: 1.0456, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 00:55:15,498 Val Step[0050/1563], Avg Loss: 1.3185, Avg Acc@1: 0.6985, Avg Acc@5: 0.9142
2022-01-15 00:55:17,518 Val Step[0100/1563], Avg Loss: 1.3464, Avg Acc@1: 0.6943, Avg Acc@5: 0.9084
2022-01-15 00:55:19,599 Val Step[0150/1563], Avg Loss: 1.4403, Avg Acc@1: 0.6730, Avg Acc@5: 0.8858
2022-01-15 00:55:21,634 Val Step[0200/1563], Avg Loss: 1.4242, Avg Acc@1: 0.6785, Avg Acc@5: 0.8812
2022-01-15 00:55:23,567 Val Step[0250/1563], Avg Loss: 1.4179, Avg Acc@1: 0.6808, Avg Acc@5: 0.8820
2022-01-15 00:55:25,620 Val Step[0300/1563], Avg Loss: 1.4267, Avg Acc@1: 0.6790, Avg Acc@5: 0.8796
2022-01-15 00:55:27,567 Val Step[0350/1563], Avg Loss: 1.4514, Avg Acc@1: 0.6731, Avg Acc@5: 0.8793
2022-01-15 00:55:29,491 Val Step[0400/1563], Avg Loss: 1.4425, Avg Acc@1: 0.6752, Avg Acc@5: 0.8809
2022-01-15 00:55:31,518 Val Step[0450/1563], Avg Loss: 1.4484, Avg Acc@1: 0.6735, Avg Acc@5: 0.8805
2022-01-15 00:55:33,509 Val Step[0500/1563], Avg Loss: 1.4571, Avg Acc@1: 0.6707, Avg Acc@5: 0.8785
2022-01-15 00:55:35,492 Val Step[0550/1563], Avg Loss: 1.4514, Avg Acc@1: 0.6735, Avg Acc@5: 0.8793
2022-01-15 00:55:37,493 Val Step[0600/1563], Avg Loss: 1.4462, Avg Acc@1: 0.6722, Avg Acc@5: 0.8806
2022-01-15 00:55:39,592 Val Step[0650/1563], Avg Loss: 1.4452, Avg Acc@1: 0.6728, Avg Acc@5: 0.8813
2022-01-15 00:55:41,592 Val Step[0700/1563], Avg Loss: 1.4454, Avg Acc@1: 0.6737, Avg Acc@5: 0.8814
2022-01-15 00:55:43,614 Val Step[0750/1563], Avg Loss: 1.4546, Avg Acc@1: 0.6721, Avg Acc@5: 0.8812
2022-01-15 00:55:45,634 Val Step[0800/1563], Avg Loss: 1.4529, Avg Acc@1: 0.6738, Avg Acc@5: 0.8806
2022-01-15 00:55:47,648 Val Step[0850/1563], Avg Loss: 1.4533, Avg Acc@1: 0.6720, Avg Acc@5: 0.8816
2022-01-15 00:55:49,692 Val Step[0900/1563], Avg Loss: 1.4421, Avg Acc@1: 0.6770, Avg Acc@5: 0.8830
2022-01-15 00:55:51,674 Val Step[0950/1563], Avg Loss: 1.4362, Avg Acc@1: 0.6789, Avg Acc@5: 0.8831
2022-01-15 00:55:53,728 Val Step[1000/1563], Avg Loss: 1.4335, Avg Acc@1: 0.6796, Avg Acc@5: 0.8839
2022-01-15 00:55:55,947 Val Step[1050/1563], Avg Loss: 1.4381, Avg Acc@1: 0.6792, Avg Acc@5: 0.8831
2022-01-15 00:55:57,907 Val Step[1100/1563], Avg Loss: 1.4452, Avg Acc@1: 0.6768, Avg Acc@5: 0.8820
2022-01-15 00:55:59,908 Val Step[1150/1563], Avg Loss: 1.4456, Avg Acc@1: 0.6768, Avg Acc@5: 0.8816
2022-01-15 00:56:02,006 Val Step[1200/1563], Avg Loss: 1.4400, Avg Acc@1: 0.6783, Avg Acc@5: 0.8820
2022-01-15 00:56:04,063 Val Step[1250/1563], Avg Loss: 1.4416, Avg Acc@1: 0.6781, Avg Acc@5: 0.8818
2022-01-15 00:56:06,241 Val Step[1300/1563], Avg Loss: 1.4471, Avg Acc@1: 0.6765, Avg Acc@5: 0.8810
2022-01-15 00:56:08,404 Val Step[1350/1563], Avg Loss: 1.4520, Avg Acc@1: 0.6760, Avg Acc@5: 0.8801
2022-01-15 00:56:10,672 Val Step[1400/1563], Avg Loss: 1.4510, Avg Acc@1: 0.6765, Avg Acc@5: 0.8801
2022-01-15 00:56:12,889 Val Step[1450/1563], Avg Loss: 1.4480, Avg Acc@1: 0.6775, Avg Acc@5: 0.8809
2022-01-15 00:56:14,849 Val Step[1500/1563], Avg Loss: 1.4468, Avg Acc@1: 0.6782, Avg Acc@5: 0.8811
2022-01-15 00:56:16,917 Val Step[1550/1563], Avg Loss: 1.4466, Avg Acc@1: 0.6780, Avg Acc@5: 0.8814
2022-01-15 00:56:18,833 ----- Epoch[060/300], Validation Loss: 1.4501, Validation Acc@1: 0.6767, Validation Acc@5: 0.8811, time: 143.54
2022-01-15 00:56:18,834 Now training epoch 61. LR=0.000949
2022-01-15 00:58:08,408 Epoch[061/300], Step[0000/1252], Avg Loss: 4.5660, Avg Acc: 0.1523
2022-01-15 00:59:38,066 Epoch[061/300], Step[0050/1252], Avg Loss: 3.7175, Avg Acc: 0.4013
2022-01-15 01:01:07,460 Epoch[061/300], Step[0100/1252], Avg Loss: 3.7032, Avg Acc: 0.3668
2022-01-15 01:02:38,032 Epoch[061/300], Step[0150/1252], Avg Loss: 3.6950, Avg Acc: 0.3652
2022-01-15 01:04:05,807 Epoch[061/300], Step[0200/1252], Avg Loss: 3.6824, Avg Acc: 0.3639
2022-01-15 01:05:36,115 Epoch[061/300], Step[0250/1252], Avg Loss: 3.6667, Avg Acc: 0.3760
2022-01-15 01:07:06,113 Epoch[061/300], Step[0300/1252], Avg Loss: 3.6686, Avg Acc: 0.3770
2022-01-15 01:08:38,188 Epoch[061/300], Step[0350/1252], Avg Loss: 3.6619, Avg Acc: 0.3688
2022-01-15 01:10:09,019 Epoch[061/300], Step[0400/1252], Avg Loss: 3.6816, Avg Acc: 0.3715
2022-01-15 01:11:38,023 Epoch[061/300], Step[0450/1252], Avg Loss: 3.6769, Avg Acc: 0.3726
2022-01-15 01:13:05,828 Epoch[061/300], Step[0500/1252], Avg Loss: 3.6781, Avg Acc: 0.3689
2022-01-15 01:14:34,854 Epoch[061/300], Step[0550/1252], Avg Loss: 3.6802, Avg Acc: 0.3679
2022-01-15 01:16:03,196 Epoch[061/300], Step[0600/1252], Avg Loss: 3.6863, Avg Acc: 0.3686
2022-01-15 01:17:32,321 Epoch[061/300], Step[0650/1252], Avg Loss: 3.6887, Avg Acc: 0.3662
2022-01-15 01:18:59,520 Epoch[061/300], Step[0700/1252], Avg Loss: 3.6954, Avg Acc: 0.3633
2022-01-15 01:20:30,007 Epoch[061/300], Step[0750/1252], Avg Loss: 3.6906, Avg Acc: 0.3636
2022-01-15 01:21:58,591 Epoch[061/300], Step[0800/1252], Avg Loss: 3.6970, Avg Acc: 0.3652
2022-01-15 01:23:28,354 Epoch[061/300], Step[0850/1252], Avg Loss: 3.7024, Avg Acc: 0.3647
2022-01-15 01:24:58,651 Epoch[061/300], Step[0900/1252], Avg Loss: 3.7068, Avg Acc: 0.3645
2022-01-15 01:26:30,368 Epoch[061/300], Step[0950/1252], Avg Loss: 3.7033, Avg Acc: 0.3661
2022-01-15 01:28:01,674 Epoch[061/300], Step[1000/1252], Avg Loss: 3.7113, Avg Acc: 0.3649
2022-01-15 01:29:32,277 Epoch[061/300], Step[1050/1252], Avg Loss: 3.7062, Avg Acc: 0.3656
2022-01-15 01:31:03,107 Epoch[061/300], Step[1100/1252], Avg Loss: 3.7025, Avg Acc: 0.3651
2022-01-15 01:32:34,011 Epoch[061/300], Step[1150/1252], Avg Loss: 3.7006, Avg Acc: 0.3645
2022-01-15 01:34:03,486 Epoch[061/300], Step[1200/1252], Avg Loss: 3.7017, Avg Acc: 0.3658
2022-01-15 01:35:35,264 Epoch[061/300], Step[1250/1252], Avg Loss: 3.7038, Avg Acc: 0.3650
2022-01-15 01:35:42,078 ----- Epoch[061/300], Train Loss: 3.7037, Train Acc: 0.3651, time: 2363.24
2022-01-15 01:35:42,079 Now training epoch 62. LR=0.000946
2022-01-15 01:37:34,131 Epoch[062/300], Step[0000/1252], Avg Loss: 3.6071, Avg Acc: 0.5820
2022-01-15 01:39:03,361 Epoch[062/300], Step[0050/1252], Avg Loss: 3.8505, Avg Acc: 0.2633
2022-01-15 01:40:33,588 Epoch[062/300], Step[0100/1252], Avg Loss: 3.8125, Avg Acc: 0.3457
2022-01-15 01:42:05,054 Epoch[062/300], Step[0150/1252], Avg Loss: 3.7860, Avg Acc: 0.3594
2022-01-15 01:43:37,305 Epoch[062/300], Step[0200/1252], Avg Loss: 3.7790, Avg Acc: 0.3504
2022-01-15 01:45:07,923 Epoch[062/300], Step[0250/1252], Avg Loss: 3.7588, Avg Acc: 0.3469
2022-01-15 01:46:38,528 Epoch[062/300], Step[0300/1252], Avg Loss: 3.7603, Avg Acc: 0.3540
2022-01-15 01:48:10,199 Epoch[062/300], Step[0350/1252], Avg Loss: 3.7623, Avg Acc: 0.3634
2022-01-15 01:49:42,000 Epoch[062/300], Step[0400/1252], Avg Loss: 3.7545, Avg Acc: 0.3652
2022-01-15 01:51:13,648 Epoch[062/300], Step[0450/1252], Avg Loss: 3.7479, Avg Acc: 0.3660
2022-01-15 01:52:45,048 Epoch[062/300], Step[0500/1252], Avg Loss: 3.7432, Avg Acc: 0.3651
2022-01-15 01:54:15,497 Epoch[062/300], Step[0550/1252], Avg Loss: 3.7398, Avg Acc: 0.3676
2022-01-15 01:55:46,942 Epoch[062/300], Step[0600/1252], Avg Loss: 3.7499, Avg Acc: 0.3669
2022-01-15 01:57:18,271 Epoch[062/300], Step[0650/1252], Avg Loss: 3.7466, Avg Acc: 0.3675
2022-01-15 01:58:49,608 Epoch[062/300], Step[0700/1252], Avg Loss: 3.7519, Avg Acc: 0.3660
2022-01-15 02:00:21,096 Epoch[062/300], Step[0750/1252], Avg Loss: 3.7509, Avg Acc: 0.3661
2022-01-15 02:01:51,500 Epoch[062/300], Step[0800/1252], Avg Loss: 3.7489, Avg Acc: 0.3671
2022-01-15 02:03:21,234 Epoch[062/300], Step[0850/1252], Avg Loss: 3.7440, Avg Acc: 0.3682
2022-01-15 02:04:52,926 Epoch[062/300], Step[0900/1252], Avg Loss: 3.7438, Avg Acc: 0.3692
2022-01-15 02:06:25,127 Epoch[062/300], Step[0950/1252], Avg Loss: 3.7534, Avg Acc: 0.3681
2022-01-15 02:07:57,359 Epoch[062/300], Step[1000/1252], Avg Loss: 3.7470, Avg Acc: 0.3662
2022-01-15 02:09:28,743 Epoch[062/300], Step[1050/1252], Avg Loss: 3.7476, Avg Acc: 0.3659
2022-01-15 02:11:00,029 Epoch[062/300], Step[1100/1252], Avg Loss: 3.7528, Avg Acc: 0.3649
2022-01-15 02:12:31,349 Epoch[062/300], Step[1150/1252], Avg Loss: 3.7503, Avg Acc: 0.3648
2022-01-15 02:14:02,104 Epoch[062/300], Step[1200/1252], Avg Loss: 3.7508, Avg Acc: 0.3651
2022-01-15 02:15:34,076 Epoch[062/300], Step[1250/1252], Avg Loss: 3.7466, Avg Acc: 0.3651
2022-01-15 02:15:41,134 ----- Epoch[062/300], Train Loss: 3.7466, Train Acc: 0.3652, time: 2399.05
2022-01-15 02:15:41,136 ----- Validation after Epoch: 62
2022-01-15 02:17:02,457 Val Step[0000/1563], Avg Loss: 1.3589, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 02:17:04,852 Val Step[0050/1563], Avg Loss: 1.3366, Avg Acc@1: 0.7181, Avg Acc@5: 0.9216
2022-01-15 02:17:06,861 Val Step[0100/1563], Avg Loss: 1.3731, Avg Acc@1: 0.6931, Avg Acc@5: 0.9146
2022-01-15 02:17:08,762 Val Step[0150/1563], Avg Loss: 1.4545, Avg Acc@1: 0.6829, Avg Acc@5: 0.8949
2022-01-15 02:17:10,677 Val Step[0200/1563], Avg Loss: 1.4375, Avg Acc@1: 0.6909, Avg Acc@5: 0.8912
2022-01-15 02:17:12,528 Val Step[0250/1563], Avg Loss: 1.4466, Avg Acc@1: 0.6897, Avg Acc@5: 0.8884
2022-01-15 02:17:14,526 Val Step[0300/1563], Avg Loss: 1.4604, Avg Acc@1: 0.6898, Avg Acc@5: 0.8854
2022-01-15 02:17:16,705 Val Step[0350/1563], Avg Loss: 1.4868, Avg Acc@1: 0.6838, Avg Acc@5: 0.8843
2022-01-15 02:17:18,711 Val Step[0400/1563], Avg Loss: 1.4690, Avg Acc@1: 0.6861, Avg Acc@5: 0.8868
2022-01-15 02:17:20,746 Val Step[0450/1563], Avg Loss: 1.4795, Avg Acc@1: 0.6843, Avg Acc@5: 0.8853
2022-01-15 02:17:22,933 Val Step[0500/1563], Avg Loss: 1.4768, Avg Acc@1: 0.6826, Avg Acc@5: 0.8860
2022-01-15 02:17:25,043 Val Step[0550/1563], Avg Loss: 1.4728, Avg Acc@1: 0.6831, Avg Acc@5: 0.8857
2022-01-15 02:17:27,016 Val Step[0600/1563], Avg Loss: 1.4714, Avg Acc@1: 0.6822, Avg Acc@5: 0.8848
2022-01-15 02:17:29,150 Val Step[0650/1563], Avg Loss: 1.4704, Avg Acc@1: 0.6818, Avg Acc@5: 0.8848
2022-01-15 02:17:31,102 Val Step[0700/1563], Avg Loss: 1.4656, Avg Acc@1: 0.6815, Avg Acc@5: 0.8853
2022-01-15 02:17:33,101 Val Step[0750/1563], Avg Loss: 1.4716, Avg Acc@1: 0.6794, Avg Acc@5: 0.8850
2022-01-15 02:17:35,246 Val Step[0800/1563], Avg Loss: 1.4706, Avg Acc@1: 0.6818, Avg Acc@5: 0.8844
2022-01-15 02:17:37,436 Val Step[0850/1563], Avg Loss: 1.4743, Avg Acc@1: 0.6793, Avg Acc@5: 0.8835
2022-01-15 02:17:39,401 Val Step[0900/1563], Avg Loss: 1.4689, Avg Acc@1: 0.6819, Avg Acc@5: 0.8839
2022-01-15 02:17:41,360 Val Step[0950/1563], Avg Loss: 1.4636, Avg Acc@1: 0.6824, Avg Acc@5: 0.8846
2022-01-15 02:17:43,518 Val Step[1000/1563], Avg Loss: 1.4619, Avg Acc@1: 0.6826, Avg Acc@5: 0.8859
2022-01-15 02:17:45,577 Val Step[1050/1563], Avg Loss: 1.4636, Avg Acc@1: 0.6820, Avg Acc@5: 0.8853
2022-01-15 02:17:47,487 Val Step[1100/1563], Avg Loss: 1.4705, Avg Acc@1: 0.6797, Avg Acc@5: 0.8845
2022-01-15 02:17:49,519 Val Step[1150/1563], Avg Loss: 1.4730, Avg Acc@1: 0.6798, Avg Acc@5: 0.8835
2022-01-15 02:17:51,481 Val Step[1200/1563], Avg Loss: 1.4669, Avg Acc@1: 0.6814, Avg Acc@5: 0.8849
2022-01-15 02:17:53,577 Val Step[1250/1563], Avg Loss: 1.4690, Avg Acc@1: 0.6812, Avg Acc@5: 0.8848
2022-01-15 02:17:55,534 Val Step[1300/1563], Avg Loss: 1.4721, Avg Acc@1: 0.6801, Avg Acc@5: 0.8844
2022-01-15 02:17:57,454 Val Step[1350/1563], Avg Loss: 1.4739, Avg Acc@1: 0.6793, Avg Acc@5: 0.8844
2022-01-15 02:17:59,480 Val Step[1400/1563], Avg Loss: 1.4741, Avg Acc@1: 0.6781, Avg Acc@5: 0.8850
2022-01-15 02:18:01,500 Val Step[1450/1563], Avg Loss: 1.4735, Avg Acc@1: 0.6775, Avg Acc@5: 0.8851
2022-01-15 02:18:03,432 Val Step[1500/1563], Avg Loss: 1.4725, Avg Acc@1: 0.6775, Avg Acc@5: 0.8848
2022-01-15 02:18:05,535 Val Step[1550/1563], Avg Loss: 1.4732, Avg Acc@1: 0.6772, Avg Acc@5: 0.8848
2022-01-15 02:18:07,344 ----- Epoch[062/300], Validation Loss: 1.4759, Validation Acc@1: 0.6762, Validation Acc@5: 0.8848, time: 146.21
2022-01-15 02:18:07,344 Now training epoch 63. LR=0.000943
2022-01-15 02:20:06,141 Epoch[063/300], Step[0000/1252], Avg Loss: 4.6023, Avg Acc: 0.2539
2022-01-15 02:21:36,375 Epoch[063/300], Step[0050/1252], Avg Loss: 3.7555, Avg Acc: 0.3900
2022-01-15 02:23:06,668 Epoch[063/300], Step[0100/1252], Avg Loss: 3.7601, Avg Acc: 0.3621
2022-01-15 02:24:36,968 Epoch[063/300], Step[0150/1252], Avg Loss: 3.7387, Avg Acc: 0.3501
2022-01-15 02:26:07,324 Epoch[063/300], Step[0200/1252], Avg Loss: 3.7435, Avg Acc: 0.3559
2022-01-15 02:27:37,981 Epoch[063/300], Step[0250/1252], Avg Loss: 3.7136, Avg Acc: 0.3466
2022-01-15 02:29:08,135 Epoch[063/300], Step[0300/1252], Avg Loss: 3.7145, Avg Acc: 0.3527
2022-01-15 02:30:38,005 Epoch[063/300], Step[0350/1252], Avg Loss: 3.7061, Avg Acc: 0.3561
2022-01-15 02:32:07,915 Epoch[063/300], Step[0400/1252], Avg Loss: 3.7088, Avg Acc: 0.3569
2022-01-15 02:33:38,523 Epoch[063/300], Step[0450/1252], Avg Loss: 3.7029, Avg Acc: 0.3605
2022-01-15 02:35:10,205 Epoch[063/300], Step[0500/1252], Avg Loss: 3.7080, Avg Acc: 0.3622
2022-01-15 02:36:40,557 Epoch[063/300], Step[0550/1252], Avg Loss: 3.7138, Avg Acc: 0.3667
2022-01-15 02:38:13,056 Epoch[063/300], Step[0600/1252], Avg Loss: 3.7032, Avg Acc: 0.3681
2022-01-15 02:39:44,033 Epoch[063/300], Step[0650/1252], Avg Loss: 3.7056, Avg Acc: 0.3696
2022-01-15 02:41:14,578 Epoch[063/300], Step[0700/1252], Avg Loss: 3.7034, Avg Acc: 0.3685
2022-01-15 02:42:45,768 Epoch[063/300], Step[0750/1252], Avg Loss: 3.7103, Avg Acc: 0.3654
2022-01-15 02:44:16,225 Epoch[063/300], Step[0800/1252], Avg Loss: 3.7043, Avg Acc: 0.3648
2022-01-15 02:45:47,568 Epoch[063/300], Step[0850/1252], Avg Loss: 3.7050, Avg Acc: 0.3666
2022-01-15 02:47:17,256 Epoch[063/300], Step[0900/1252], Avg Loss: 3.7086, Avg Acc: 0.3663
2022-01-15 02:48:46,652 Epoch[063/300], Step[0950/1252], Avg Loss: 3.7141, Avg Acc: 0.3625
2022-01-15 02:50:15,434 Epoch[063/300], Step[1000/1252], Avg Loss: 3.7164, Avg Acc: 0.3616
2022-01-15 02:51:43,882 Epoch[063/300], Step[1050/1252], Avg Loss: 3.7128, Avg Acc: 0.3646
2022-01-15 02:53:13,187 Epoch[063/300], Step[1100/1252], Avg Loss: 3.7105, Avg Acc: 0.3653
2022-01-15 02:54:40,370 Epoch[063/300], Step[1150/1252], Avg Loss: 3.7170, Avg Acc: 0.3646
2022-01-15 02:56:10,997 Epoch[063/300], Step[1200/1252], Avg Loss: 3.7185, Avg Acc: 0.3658
2022-01-15 02:57:42,046 Epoch[063/300], Step[1250/1252], Avg Loss: 3.7173, Avg Acc: 0.3679
2022-01-15 02:57:48,818 ----- Epoch[063/300], Train Loss: 3.7174, Train Acc: 0.3679, time: 2381.47
2022-01-15 02:57:48,819 Now training epoch 64. LR=0.000941
2022-01-15 02:59:46,040 Epoch[064/300], Step[0000/1252], Avg Loss: 2.6858, Avg Acc: 0.6523
2022-01-15 03:01:16,650 Epoch[064/300], Step[0050/1252], Avg Loss: 3.6630, Avg Acc: 0.3513
2022-01-15 03:02:47,544 Epoch[064/300], Step[0100/1252], Avg Loss: 3.6406, Avg Acc: 0.3605
2022-01-15 03:04:19,580 Epoch[064/300], Step[0150/1252], Avg Loss: 3.6543, Avg Acc: 0.3620
2022-01-15 03:05:51,952 Epoch[064/300], Step[0200/1252], Avg Loss: 3.6607, Avg Acc: 0.3637
2022-01-15 03:07:22,946 Epoch[064/300], Step[0250/1252], Avg Loss: 3.6586, Avg Acc: 0.3670
2022-01-15 03:08:53,313 Epoch[064/300], Step[0300/1252], Avg Loss: 3.6629, Avg Acc: 0.3707
2022-01-15 03:10:25,420 Epoch[064/300], Step[0350/1252], Avg Loss: 3.6673, Avg Acc: 0.3707
2022-01-15 03:11:57,131 Epoch[064/300], Step[0400/1252], Avg Loss: 3.6846, Avg Acc: 0.3627
2022-01-15 03:13:29,147 Epoch[064/300], Step[0450/1252], Avg Loss: 3.6920, Avg Acc: 0.3606
2022-01-15 03:15:00,463 Epoch[064/300], Step[0500/1252], Avg Loss: 3.6789, Avg Acc: 0.3582
2022-01-15 03:16:31,296 Epoch[064/300], Step[0550/1252], Avg Loss: 3.6708, Avg Acc: 0.3639
2022-01-15 03:18:01,006 Epoch[064/300], Step[0600/1252], Avg Loss: 3.6692, Avg Acc: 0.3668
2022-01-15 03:19:30,034 Epoch[064/300], Step[0650/1252], Avg Loss: 3.6587, Avg Acc: 0.3690
2022-01-15 03:21:01,419 Epoch[064/300], Step[0700/1252], Avg Loss: 3.6664, Avg Acc: 0.3684
2022-01-15 03:22:32,845 Epoch[064/300], Step[0750/1252], Avg Loss: 3.6674, Avg Acc: 0.3680
2022-01-15 03:24:04,175 Epoch[064/300], Step[0800/1252], Avg Loss: 3.6731, Avg Acc: 0.3667
2022-01-15 03:25:34,808 Epoch[064/300], Step[0850/1252], Avg Loss: 3.6709, Avg Acc: 0.3679
2022-01-15 03:27:05,585 Epoch[064/300], Step[0900/1252], Avg Loss: 3.6781, Avg Acc: 0.3657
2022-01-15 03:28:37,154 Epoch[064/300], Step[0950/1252], Avg Loss: 3.6754, Avg Acc: 0.3661
2022-01-15 03:30:09,244 Epoch[064/300], Step[1000/1252], Avg Loss: 3.6822, Avg Acc: 0.3661
2022-01-15 03:31:40,494 Epoch[064/300], Step[1050/1252], Avg Loss: 3.6833, Avg Acc: 0.3648
2022-01-15 03:33:12,593 Epoch[064/300], Step[1100/1252], Avg Loss: 3.6875, Avg Acc: 0.3633
2022-01-15 03:34:43,878 Epoch[064/300], Step[1150/1252], Avg Loss: 3.6883, Avg Acc: 0.3623
2022-01-15 03:36:14,254 Epoch[064/300], Step[1200/1252], Avg Loss: 3.6852, Avg Acc: 0.3635
2022-01-15 03:37:46,288 Epoch[064/300], Step[1250/1252], Avg Loss: 3.6874, Avg Acc: 0.3657
2022-01-15 03:37:53,423 ----- Epoch[064/300], Train Loss: 3.6874, Train Acc: 0.3657, time: 2404.60
2022-01-15 03:37:53,424 ----- Validation after Epoch: 64
2022-01-15 03:39:09,370 Val Step[0000/1563], Avg Loss: 1.2718, Avg Acc@1: 0.8750, Avg Acc@5: 0.8750
2022-01-15 03:39:11,368 Val Step[0050/1563], Avg Loss: 1.3623, Avg Acc@1: 0.7157, Avg Acc@5: 0.9069
2022-01-15 03:39:13,403 Val Step[0100/1563], Avg Loss: 1.4160, Avg Acc@1: 0.6943, Avg Acc@5: 0.8960
2022-01-15 03:39:15,303 Val Step[0150/1563], Avg Loss: 1.5017, Avg Acc@1: 0.6755, Avg Acc@5: 0.8791
2022-01-15 03:39:17,254 Val Step[0200/1563], Avg Loss: 1.4825, Avg Acc@1: 0.6803, Avg Acc@5: 0.8831
2022-01-15 03:39:19,185 Val Step[0250/1563], Avg Loss: 1.4859, Avg Acc@1: 0.6853, Avg Acc@5: 0.8825
2022-01-15 03:39:21,238 Val Step[0300/1563], Avg Loss: 1.4839, Avg Acc@1: 0.6848, Avg Acc@5: 0.8825
2022-01-15 03:39:23,233 Val Step[0350/1563], Avg Loss: 1.5028, Avg Acc@1: 0.6816, Avg Acc@5: 0.8811
2022-01-15 03:39:25,222 Val Step[0400/1563], Avg Loss: 1.4953, Avg Acc@1: 0.6824, Avg Acc@5: 0.8828
2022-01-15 03:39:27,304 Val Step[0450/1563], Avg Loss: 1.5014, Avg Acc@1: 0.6793, Avg Acc@5: 0.8803
2022-01-15 03:39:29,404 Val Step[0500/1563], Avg Loss: 1.5053, Avg Acc@1: 0.6759, Avg Acc@5: 0.8812
2022-01-15 03:39:31,472 Val Step[0550/1563], Avg Loss: 1.4956, Avg Acc@1: 0.6799, Avg Acc@5: 0.8827
2022-01-15 03:39:33,466 Val Step[0600/1563], Avg Loss: 1.4939, Avg Acc@1: 0.6807, Avg Acc@5: 0.8821
2022-01-15 03:39:35,604 Val Step[0650/1563], Avg Loss: 1.4947, Avg Acc@1: 0.6795, Avg Acc@5: 0.8833
2022-01-15 03:39:37,563 Val Step[0700/1563], Avg Loss: 1.4903, Avg Acc@1: 0.6806, Avg Acc@5: 0.8836
2022-01-15 03:39:39,492 Val Step[0750/1563], Avg Loss: 1.4964, Avg Acc@1: 0.6796, Avg Acc@5: 0.8838
2022-01-15 03:39:41,543 Val Step[0800/1563], Avg Loss: 1.4998, Avg Acc@1: 0.6807, Avg Acc@5: 0.8833
2022-01-15 03:39:43,648 Val Step[0850/1563], Avg Loss: 1.5049, Avg Acc@1: 0.6783, Avg Acc@5: 0.8832
2022-01-15 03:39:45,570 Val Step[0900/1563], Avg Loss: 1.4962, Avg Acc@1: 0.6810, Avg Acc@5: 0.8837
2022-01-15 03:39:47,549 Val Step[0950/1563], Avg Loss: 1.4886, Avg Acc@1: 0.6835, Avg Acc@5: 0.8843
2022-01-15 03:39:49,550 Val Step[1000/1563], Avg Loss: 1.4896, Avg Acc@1: 0.6838, Avg Acc@5: 0.8845
2022-01-15 03:39:51,456 Val Step[1050/1563], Avg Loss: 1.4915, Avg Acc@1: 0.6829, Avg Acc@5: 0.8837
2022-01-15 03:39:53,429 Val Step[1100/1563], Avg Loss: 1.5017, Avg Acc@1: 0.6805, Avg Acc@5: 0.8822
2022-01-15 03:39:55,406 Val Step[1150/1563], Avg Loss: 1.5039, Avg Acc@1: 0.6797, Avg Acc@5: 0.8814
2022-01-15 03:39:57,411 Val Step[1200/1563], Avg Loss: 1.4988, Avg Acc@1: 0.6807, Avg Acc@5: 0.8826
2022-01-15 03:39:59,367 Val Step[1250/1563], Avg Loss: 1.4997, Avg Acc@1: 0.6806, Avg Acc@5: 0.8821
2022-01-15 03:40:01,423 Val Step[1300/1563], Avg Loss: 1.5029, Avg Acc@1: 0.6800, Avg Acc@5: 0.8821
2022-01-15 03:40:03,405 Val Step[1350/1563], Avg Loss: 1.5074, Avg Acc@1: 0.6794, Avg Acc@5: 0.8822
2022-01-15 03:40:05,388 Val Step[1400/1563], Avg Loss: 1.5066, Avg Acc@1: 0.6788, Avg Acc@5: 0.8826
2022-01-15 03:40:07,428 Val Step[1450/1563], Avg Loss: 1.5060, Avg Acc@1: 0.6785, Avg Acc@5: 0.8831
2022-01-15 03:40:09,399 Val Step[1500/1563], Avg Loss: 1.5029, Avg Acc@1: 0.6787, Avg Acc@5: 0.8832
2022-01-15 03:40:11,291 Val Step[1550/1563], Avg Loss: 1.5040, Avg Acc@1: 0.6787, Avg Acc@5: 0.8832
2022-01-15 03:40:13,264 ----- Epoch[064/300], Validation Loss: 1.5072, Validation Acc@1: 0.6772, Validation Acc@5: 0.8832, time: 139.84
2022-01-15 03:40:13,264 Now training epoch 65. LR=0.000938
2022-01-15 03:42:06,824 Epoch[065/300], Step[0000/1252], Avg Loss: 3.6249, Avg Acc: 0.5430
2022-01-15 03:43:37,527 Epoch[065/300], Step[0050/1252], Avg Loss: 3.6907, Avg Acc: 0.4220
2022-01-15 03:45:08,763 Epoch[065/300], Step[0100/1252], Avg Loss: 3.7777, Avg Acc: 0.3757
2022-01-15 03:46:39,926 Epoch[065/300], Step[0150/1252], Avg Loss: 3.7579, Avg Acc: 0.3775
2022-01-15 03:48:10,122 Epoch[065/300], Step[0200/1252], Avg Loss: 3.7395, Avg Acc: 0.3640
2022-01-15 03:49:40,567 Epoch[065/300], Step[0250/1252], Avg Loss: 3.7384, Avg Acc: 0.3484
2022-01-15 03:51:12,963 Epoch[065/300], Step[0300/1252], Avg Loss: 3.7388, Avg Acc: 0.3477
2022-01-15 03:52:43,910 Epoch[065/300], Step[0350/1252], Avg Loss: 3.7410, Avg Acc: 0.3537
2022-01-15 03:54:14,937 Epoch[065/300], Step[0400/1252], Avg Loss: 3.7363, Avg Acc: 0.3572
2022-01-15 03:55:46,812 Epoch[065/300], Step[0450/1252], Avg Loss: 3.7223, Avg Acc: 0.3572
2022-01-15 03:57:17,715 Epoch[065/300], Step[0500/1252], Avg Loss: 3.7132, Avg Acc: 0.3585
2022-01-15 03:58:48,927 Epoch[065/300], Step[0550/1252], Avg Loss: 3.7114, Avg Acc: 0.3545
2022-01-15 04:00:20,159 Epoch[065/300], Step[0600/1252], Avg Loss: 3.7192, Avg Acc: 0.3498
2022-01-15 04:01:51,041 Epoch[065/300], Step[0650/1252], Avg Loss: 3.7129, Avg Acc: 0.3513
2022-01-15 04:03:21,734 Epoch[065/300], Step[0700/1252], Avg Loss: 3.7190, Avg Acc: 0.3536
2022-01-15 04:04:50,763 Epoch[065/300], Step[0750/1252], Avg Loss: 3.7317, Avg Acc: 0.3534
2022-01-15 04:06:21,669 Epoch[065/300], Step[0800/1252], Avg Loss: 3.7251, Avg Acc: 0.3548
2022-01-15 04:07:53,195 Epoch[065/300], Step[0850/1252], Avg Loss: 3.7120, Avg Acc: 0.3554
2022-01-15 04:09:24,914 Epoch[065/300], Step[0900/1252], Avg Loss: 3.7153, Avg Acc: 0.3539
2022-01-15 04:10:56,629 Epoch[065/300], Step[0950/1252], Avg Loss: 3.7177, Avg Acc: 0.3538
2022-01-15 04:12:27,235 Epoch[065/300], Step[1000/1252], Avg Loss: 3.7167, Avg Acc: 0.3574
2022-01-15 04:13:58,423 Epoch[065/300], Step[1050/1252], Avg Loss: 3.7195, Avg Acc: 0.3551
2022-01-15 04:15:28,378 Epoch[065/300], Step[1100/1252], Avg Loss: 3.7203, Avg Acc: 0.3520
2022-01-15 04:16:59,893 Epoch[065/300], Step[1150/1252], Avg Loss: 3.7208, Avg Acc: 0.3522
2022-01-15 04:18:32,252 Epoch[065/300], Step[1200/1252], Avg Loss: 3.7226, Avg Acc: 0.3520
2022-01-15 04:20:02,202 Epoch[065/300], Step[1250/1252], Avg Loss: 3.7183, Avg Acc: 0.3519
2022-01-15 04:20:09,014 ----- Epoch[065/300], Train Loss: 3.7183, Train Acc: 0.3519, time: 2395.75
2022-01-15 04:20:09,016 Now training epoch 66. LR=0.000936
2022-01-15 04:22:09,839 Epoch[066/300], Step[0000/1252], Avg Loss: 4.5640, Avg Acc: 0.2148
2022-01-15 04:23:38,618 Epoch[066/300], Step[0050/1252], Avg Loss: 3.6714, Avg Acc: 0.4281
2022-01-15 04:25:07,132 Epoch[066/300], Step[0100/1252], Avg Loss: 3.6552, Avg Acc: 0.4083
2022-01-15 04:26:35,220 Epoch[066/300], Step[0150/1252], Avg Loss: 3.6449, Avg Acc: 0.3753
2022-01-15 04:28:03,237 Epoch[066/300], Step[0200/1252], Avg Loss: 3.6358, Avg Acc: 0.3831
2022-01-15 04:29:31,515 Epoch[066/300], Step[0250/1252], Avg Loss: 3.6432, Avg Acc: 0.3778
2022-01-15 04:30:58,694 Epoch[066/300], Step[0300/1252], Avg Loss: 3.6540, Avg Acc: 0.3717
2022-01-15 04:32:27,498 Epoch[066/300], Step[0350/1252], Avg Loss: 3.6692, Avg Acc: 0.3695
2022-01-15 04:33:56,706 Epoch[066/300], Step[0400/1252], Avg Loss: 3.6791, Avg Acc: 0.3733
2022-01-15 04:35:25,433 Epoch[066/300], Step[0450/1252], Avg Loss: 3.6882, Avg Acc: 0.3644
2022-01-15 04:36:54,846 Epoch[066/300], Step[0500/1252], Avg Loss: 3.6864, Avg Acc: 0.3662
2022-01-15 04:38:26,099 Epoch[066/300], Step[0550/1252], Avg Loss: 3.6793, Avg Acc: 0.3694
2022-01-15 04:39:57,040 Epoch[066/300], Step[0600/1252], Avg Loss: 3.6810, Avg Acc: 0.3663
2022-01-15 04:41:28,124 Epoch[066/300], Step[0650/1252], Avg Loss: 3.6867, Avg Acc: 0.3663
2022-01-15 04:43:00,422 Epoch[066/300], Step[0700/1252], Avg Loss: 3.7030, Avg Acc: 0.3633
2022-01-15 04:44:30,680 Epoch[066/300], Step[0750/1252], Avg Loss: 3.7061, Avg Acc: 0.3639
2022-01-15 04:46:01,599 Epoch[066/300], Step[0800/1252], Avg Loss: 3.7179, Avg Acc: 0.3606
2022-01-15 04:47:33,112 Epoch[066/300], Step[0850/1252], Avg Loss: 3.7174, Avg Acc: 0.3597
2022-01-15 04:49:04,796 Epoch[066/300], Step[0900/1252], Avg Loss: 3.7248, Avg Acc: 0.3586
2022-01-15 04:50:37,006 Epoch[066/300], Step[0950/1252], Avg Loss: 3.7239, Avg Acc: 0.3580
2022-01-15 04:52:09,700 Epoch[066/300], Step[1000/1252], Avg Loss: 3.7217, Avg Acc: 0.3582
2022-01-15 04:53:41,255 Epoch[066/300], Step[1050/1252], Avg Loss: 3.7249, Avg Acc: 0.3601
2022-01-15 04:55:11,307 Epoch[066/300], Step[1100/1252], Avg Loss: 3.7197, Avg Acc: 0.3600
2022-01-15 04:56:43,058 Epoch[066/300], Step[1150/1252], Avg Loss: 3.7129, Avg Acc: 0.3625
2022-01-15 04:58:14,491 Epoch[066/300], Step[1200/1252], Avg Loss: 3.7155, Avg Acc: 0.3619
2022-01-15 04:59:46,208 Epoch[066/300], Step[1250/1252], Avg Loss: 3.7112, Avg Acc: 0.3637
2022-01-15 04:59:53,150 ----- Epoch[066/300], Train Loss: 3.7111, Train Acc: 0.3637, time: 2384.13
2022-01-15 04:59:53,152 ----- Validation after Epoch: 66
2022-01-15 05:01:12,721 Val Step[0000/1563], Avg Loss: 0.9016, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-15 05:01:14,708 Val Step[0050/1563], Avg Loss: 1.2783, Avg Acc@1: 0.7206, Avg Acc@5: 0.9069
2022-01-15 05:01:16,622 Val Step[0100/1563], Avg Loss: 1.3053, Avg Acc@1: 0.7079, Avg Acc@5: 0.9084
2022-01-15 05:01:18,717 Val Step[0150/1563], Avg Loss: 1.3998, Avg Acc@1: 0.6854, Avg Acc@5: 0.8891
2022-01-15 05:01:20,711 Val Step[0200/1563], Avg Loss: 1.3784, Avg Acc@1: 0.6891, Avg Acc@5: 0.8943
2022-01-15 05:01:22,776 Val Step[0250/1563], Avg Loss: 1.3928, Avg Acc@1: 0.6907, Avg Acc@5: 0.8919
2022-01-15 05:01:24,711 Val Step[0300/1563], Avg Loss: 1.4037, Avg Acc@1: 0.6894, Avg Acc@5: 0.8870
2022-01-15 05:01:26,677 Val Step[0350/1563], Avg Loss: 1.4284, Avg Acc@1: 0.6845, Avg Acc@5: 0.8853
2022-01-15 05:01:28,631 Val Step[0400/1563], Avg Loss: 1.4216, Avg Acc@1: 0.6849, Avg Acc@5: 0.8872
2022-01-15 05:01:30,533 Val Step[0450/1563], Avg Loss: 1.4357, Avg Acc@1: 0.6793, Avg Acc@5: 0.8844
2022-01-15 05:01:32,497 Val Step[0500/1563], Avg Loss: 1.4444, Avg Acc@1: 0.6764, Avg Acc@5: 0.8822
2022-01-15 05:01:34,456 Val Step[0550/1563], Avg Loss: 1.4378, Avg Acc@1: 0.6797, Avg Acc@5: 0.8816
2022-01-15 05:01:36,398 Val Step[0600/1563], Avg Loss: 1.4335, Avg Acc@1: 0.6803, Avg Acc@5: 0.8819
2022-01-15 05:01:38,470 Val Step[0650/1563], Avg Loss: 1.4317, Avg Acc@1: 0.6797, Avg Acc@5: 0.8827
2022-01-15 05:01:40,646 Val Step[0700/1563], Avg Loss: 1.4297, Avg Acc@1: 0.6801, Avg Acc@5: 0.8830
2022-01-15 05:01:42,694 Val Step[0750/1563], Avg Loss: 1.4401, Avg Acc@1: 0.6784, Avg Acc@5: 0.8830
2022-01-15 05:01:44,719 Val Step[0800/1563], Avg Loss: 1.4399, Avg Acc@1: 0.6798, Avg Acc@5: 0.8820
2022-01-15 05:01:46,690 Val Step[0850/1563], Avg Loss: 1.4449, Avg Acc@1: 0.6752, Avg Acc@5: 0.8825
2022-01-15 05:01:48,602 Val Step[0900/1563], Avg Loss: 1.4362, Avg Acc@1: 0.6773, Avg Acc@5: 0.8836
2022-01-15 05:01:50,530 Val Step[0950/1563], Avg Loss: 1.4300, Avg Acc@1: 0.6777, Avg Acc@5: 0.8847
2022-01-15 05:01:52,458 Val Step[1000/1563], Avg Loss: 1.4304, Avg Acc@1: 0.6778, Avg Acc@5: 0.8849
2022-01-15 05:01:54,335 Val Step[1050/1563], Avg Loss: 1.4341, Avg Acc@1: 0.6773, Avg Acc@5: 0.8830
2022-01-15 05:01:56,223 Val Step[1100/1563], Avg Loss: 1.4428, Avg Acc@1: 0.6748, Avg Acc@5: 0.8812
2022-01-15 05:01:58,219 Val Step[1150/1563], Avg Loss: 1.4438, Avg Acc@1: 0.6753, Avg Acc@5: 0.8804
2022-01-15 05:02:00,092 Val Step[1200/1563], Avg Loss: 1.4376, Avg Acc@1: 0.6774, Avg Acc@5: 0.8818
2022-01-15 05:02:02,138 Val Step[1250/1563], Avg Loss: 1.4383, Avg Acc@1: 0.6775, Avg Acc@5: 0.8821
2022-01-15 05:02:04,179 Val Step[1300/1563], Avg Loss: 1.4418, Avg Acc@1: 0.6765, Avg Acc@5: 0.8813
2022-01-15 05:02:06,069 Val Step[1350/1563], Avg Loss: 1.4458, Avg Acc@1: 0.6760, Avg Acc@5: 0.8808
2022-01-15 05:02:08,077 Val Step[1400/1563], Avg Loss: 1.4441, Avg Acc@1: 0.6764, Avg Acc@5: 0.8812
2022-01-15 05:02:10,050 Val Step[1450/1563], Avg Loss: 1.4405, Avg Acc@1: 0.6770, Avg Acc@5: 0.8815
2022-01-15 05:02:12,049 Val Step[1500/1563], Avg Loss: 1.4371, Avg Acc@1: 0.6773, Avg Acc@5: 0.8821
2022-01-15 05:02:13,937 Val Step[1550/1563], Avg Loss: 1.4367, Avg Acc@1: 0.6767, Avg Acc@5: 0.8824
2022-01-15 05:02:15,923 ----- Epoch[066/300], Validation Loss: 1.4388, Validation Acc@1: 0.6759, Validation Acc@5: 0.8824, time: 142.77
2022-01-15 05:02:15,924 Now training epoch 67. LR=0.000933
2022-01-15 05:04:17,229 Epoch[067/300], Step[0000/1252], Avg Loss: 4.0113, Avg Acc: 0.3750
2022-01-15 05:05:47,313 Epoch[067/300], Step[0050/1252], Avg Loss: 3.7196, Avg Acc: 0.3225
2022-01-15 05:07:17,684 Epoch[067/300], Step[0100/1252], Avg Loss: 3.5961, Avg Acc: 0.3406
2022-01-15 05:08:48,067 Epoch[067/300], Step[0150/1252], Avg Loss: 3.5999, Avg Acc: 0.3671
2022-01-15 05:10:19,323 Epoch[067/300], Step[0200/1252], Avg Loss: 3.6426, Avg Acc: 0.3688
2022-01-15 05:11:50,749 Epoch[067/300], Step[0250/1252], Avg Loss: 3.6632, Avg Acc: 0.3629
2022-01-15 05:13:21,700 Epoch[067/300], Step[0300/1252], Avg Loss: 3.6384, Avg Acc: 0.3683
2022-01-15 05:14:52,289 Epoch[067/300], Step[0350/1252], Avg Loss: 3.6513, Avg Acc: 0.3748
2022-01-15 05:16:23,582 Epoch[067/300], Step[0400/1252], Avg Loss: 3.6569, Avg Acc: 0.3685
2022-01-15 05:17:52,497 Epoch[067/300], Step[0450/1252], Avg Loss: 3.6677, Avg Acc: 0.3665
2022-01-15 05:19:21,737 Epoch[067/300], Step[0500/1252], Avg Loss: 3.6672, Avg Acc: 0.3680
2022-01-15 05:20:52,700 Epoch[067/300], Step[0550/1252], Avg Loss: 3.6812, Avg Acc: 0.3665
2022-01-15 05:22:24,380 Epoch[067/300], Step[0600/1252], Avg Loss: 3.6849, Avg Acc: 0.3670
2022-01-15 05:23:56,303 Epoch[067/300], Step[0650/1252], Avg Loss: 3.6878, Avg Acc: 0.3664
2022-01-15 05:25:26,314 Epoch[067/300], Step[0700/1252], Avg Loss: 3.6896, Avg Acc: 0.3677
2022-01-15 05:26:56,605 Epoch[067/300], Step[0750/1252], Avg Loss: 3.6945, Avg Acc: 0.3697
2022-01-15 05:28:26,953 Epoch[067/300], Step[0800/1252], Avg Loss: 3.6896, Avg Acc: 0.3703
2022-01-15 05:29:57,986 Epoch[067/300], Step[0850/1252], Avg Loss: 3.6831, Avg Acc: 0.3722
2022-01-15 05:31:27,755 Epoch[067/300], Step[0900/1252], Avg Loss: 3.6837, Avg Acc: 0.3752
2022-01-15 05:32:59,778 Epoch[067/300], Step[0950/1252], Avg Loss: 3.6835, Avg Acc: 0.3736
2022-01-15 05:34:31,430 Epoch[067/300], Step[1000/1252], Avg Loss: 3.6850, Avg Acc: 0.3739
2022-01-15 05:36:03,212 Epoch[067/300], Step[1050/1252], Avg Loss: 3.6846, Avg Acc: 0.3722
2022-01-15 05:37:34,712 Epoch[067/300], Step[1100/1252], Avg Loss: 3.6799, Avg Acc: 0.3722
2022-01-15 05:39:06,449 Epoch[067/300], Step[1150/1252], Avg Loss: 3.6806, Avg Acc: 0.3731
2022-01-15 05:40:37,275 Epoch[067/300], Step[1200/1252], Avg Loss: 3.6869, Avg Acc: 0.3734
2022-01-15 05:42:04,950 Epoch[067/300], Step[1250/1252], Avg Loss: 3.6963, Avg Acc: 0.3717
2022-01-15 05:42:11,896 ----- Epoch[067/300], Train Loss: 3.6962, Train Acc: 0.3717, time: 2395.97
2022-01-15 05:42:11,898 Now training epoch 68. LR=0.000930
2022-01-15 05:44:10,335 Epoch[068/300], Step[0000/1252], Avg Loss: 3.7184, Avg Acc: 0.0234
2022-01-15 05:45:40,729 Epoch[068/300], Step[0050/1252], Avg Loss: 3.6652, Avg Acc: 0.3469
2022-01-15 05:47:10,958 Epoch[068/300], Step[0100/1252], Avg Loss: 3.6652, Avg Acc: 0.3513
2022-01-15 05:48:42,406 Epoch[068/300], Step[0150/1252], Avg Loss: 3.6434, Avg Acc: 0.3572
2022-01-15 05:50:13,301 Epoch[068/300], Step[0200/1252], Avg Loss: 3.6243, Avg Acc: 0.3687
2022-01-15 05:51:43,832 Epoch[068/300], Step[0250/1252], Avg Loss: 3.6497, Avg Acc: 0.3787
2022-01-15 05:53:15,746 Epoch[068/300], Step[0300/1252], Avg Loss: 3.6479, Avg Acc: 0.3623
2022-01-15 05:54:47,288 Epoch[068/300], Step[0350/1252], Avg Loss: 3.6530, Avg Acc: 0.3613
2022-01-15 05:56:19,730 Epoch[068/300], Step[0400/1252], Avg Loss: 3.6630, Avg Acc: 0.3566
2022-01-15 05:57:49,720 Epoch[068/300], Step[0450/1252], Avg Loss: 3.6652, Avg Acc: 0.3616
2022-01-15 05:59:20,798 Epoch[068/300], Step[0500/1252], Avg Loss: 3.6794, Avg Acc: 0.3551
2022-01-15 06:00:50,893 Epoch[068/300], Step[0550/1252], Avg Loss: 3.6801, Avg Acc: 0.3548
2022-01-15 06:02:20,589 Epoch[068/300], Step[0600/1252], Avg Loss: 3.6875, Avg Acc: 0.3584
2022-01-15 06:03:49,507 Epoch[068/300], Step[0650/1252], Avg Loss: 3.6869, Avg Acc: 0.3561
2022-01-15 06:05:18,714 Epoch[068/300], Step[0700/1252], Avg Loss: 3.6911, Avg Acc: 0.3587
2022-01-15 06:06:48,945 Epoch[068/300], Step[0750/1252], Avg Loss: 3.6942, Avg Acc: 0.3616
2022-01-15 06:08:18,659 Epoch[068/300], Step[0800/1252], Avg Loss: 3.6925, Avg Acc: 0.3642
2022-01-15 06:09:51,113 Epoch[068/300], Step[0850/1252], Avg Loss: 3.6941, Avg Acc: 0.3638
2022-01-15 06:11:22,916 Epoch[068/300], Step[0900/1252], Avg Loss: 3.6867, Avg Acc: 0.3658
2022-01-15 06:12:54,072 Epoch[068/300], Step[0950/1252], Avg Loss: 3.6907, Avg Acc: 0.3652
2022-01-15 06:14:25,780 Epoch[068/300], Step[1000/1252], Avg Loss: 3.6837, Avg Acc: 0.3682
2022-01-15 06:15:56,235 Epoch[068/300], Step[1050/1252], Avg Loss: 3.6824, Avg Acc: 0.3674
2022-01-15 06:17:25,353 Epoch[068/300], Step[1100/1252], Avg Loss: 3.6800, Avg Acc: 0.3655
2022-01-15 06:18:56,963 Epoch[068/300], Step[1150/1252], Avg Loss: 3.6860, Avg Acc: 0.3668
2022-01-15 06:20:26,761 Epoch[068/300], Step[1200/1252], Avg Loss: 3.6877, Avg Acc: 0.3688
2022-01-15 06:21:57,261 Epoch[068/300], Step[1250/1252], Avg Loss: 3.6906, Avg Acc: 0.3676
2022-01-15 06:22:04,300 ----- Epoch[068/300], Train Loss: 3.6906, Train Acc: 0.3676, time: 2392.40
2022-01-15 06:22:04,302 ----- Validation after Epoch: 68
2022-01-15 06:23:20,709 Val Step[0000/1563], Avg Loss: 0.9056, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 06:23:23,379 Val Step[0050/1563], Avg Loss: 1.4305, Avg Acc@1: 0.6789, Avg Acc@5: 0.9093
2022-01-15 06:23:25,373 Val Step[0100/1563], Avg Loss: 1.4198, Avg Acc@1: 0.6869, Avg Acc@5: 0.9084
2022-01-15 06:23:27,333 Val Step[0150/1563], Avg Loss: 1.4994, Avg Acc@1: 0.6788, Avg Acc@5: 0.8866
2022-01-15 06:23:29,304 Val Step[0200/1563], Avg Loss: 1.4914, Avg Acc@1: 0.6803, Avg Acc@5: 0.8843
2022-01-15 06:23:31,514 Val Step[0250/1563], Avg Loss: 1.4888, Avg Acc@1: 0.6833, Avg Acc@5: 0.8899
2022-01-15 06:23:33,532 Val Step[0300/1563], Avg Loss: 1.4974, Avg Acc@1: 0.6827, Avg Acc@5: 0.8858
2022-01-15 06:23:35,509 Val Step[0350/1563], Avg Loss: 1.5220, Avg Acc@1: 0.6777, Avg Acc@5: 0.8825
2022-01-15 06:23:37,552 Val Step[0400/1563], Avg Loss: 1.5072, Avg Acc@1: 0.6811, Avg Acc@5: 0.8840
2022-01-15 06:23:39,660 Val Step[0450/1563], Avg Loss: 1.5125, Avg Acc@1: 0.6779, Avg Acc@5: 0.8830
2022-01-15 06:23:41,640 Val Step[0500/1563], Avg Loss: 1.5165, Avg Acc@1: 0.6751, Avg Acc@5: 0.8827
2022-01-15 06:23:43,623 Val Step[0550/1563], Avg Loss: 1.5146, Avg Acc@1: 0.6760, Avg Acc@5: 0.8825
2022-01-15 06:23:45,571 Val Step[0600/1563], Avg Loss: 1.5116, Avg Acc@1: 0.6751, Avg Acc@5: 0.8823
2022-01-15 06:23:47,762 Val Step[0650/1563], Avg Loss: 1.5130, Avg Acc@1: 0.6747, Avg Acc@5: 0.8831
2022-01-15 06:23:49,886 Val Step[0700/1563], Avg Loss: 1.5090, Avg Acc@1: 0.6778, Avg Acc@5: 0.8828
2022-01-15 06:23:52,065 Val Step[0750/1563], Avg Loss: 1.5145, Avg Acc@1: 0.6763, Avg Acc@5: 0.8833
2022-01-15 06:23:54,130 Val Step[0800/1563], Avg Loss: 1.5141, Avg Acc@1: 0.6787, Avg Acc@5: 0.8830
2022-01-15 06:23:56,178 Val Step[0850/1563], Avg Loss: 1.5184, Avg Acc@1: 0.6774, Avg Acc@5: 0.8823
2022-01-15 06:23:58,213 Val Step[0900/1563], Avg Loss: 1.5105, Avg Acc@1: 0.6813, Avg Acc@5: 0.8828
2022-01-15 06:24:00,196 Val Step[0950/1563], Avg Loss: 1.5045, Avg Acc@1: 0.6831, Avg Acc@5: 0.8837
2022-01-15 06:24:02,217 Val Step[1000/1563], Avg Loss: 1.5059, Avg Acc@1: 0.6832, Avg Acc@5: 0.8840
2022-01-15 06:24:04,328 Val Step[1050/1563], Avg Loss: 1.5067, Avg Acc@1: 0.6828, Avg Acc@5: 0.8836
2022-01-15 06:24:06,300 Val Step[1100/1563], Avg Loss: 1.5127, Avg Acc@1: 0.6814, Avg Acc@5: 0.8824
2022-01-15 06:24:08,333 Val Step[1150/1563], Avg Loss: 1.5131, Avg Acc@1: 0.6807, Avg Acc@5: 0.8827
2022-01-15 06:24:10,246 Val Step[1200/1563], Avg Loss: 1.5090, Avg Acc@1: 0.6821, Avg Acc@5: 0.8835
2022-01-15 06:24:12,248 Val Step[1250/1563], Avg Loss: 1.5109, Avg Acc@1: 0.6821, Avg Acc@5: 0.8826
2022-01-15 06:24:14,307 Val Step[1300/1563], Avg Loss: 1.5145, Avg Acc@1: 0.6819, Avg Acc@5: 0.8819
2022-01-15 06:24:16,271 Val Step[1350/1563], Avg Loss: 1.5165, Avg Acc@1: 0.6811, Avg Acc@5: 0.8819
2022-01-15 06:24:18,277 Val Step[1400/1563], Avg Loss: 1.5163, Avg Acc@1: 0.6807, Avg Acc@5: 0.8820
2022-01-15 06:24:20,261 Val Step[1450/1563], Avg Loss: 1.5145, Avg Acc@1: 0.6813, Avg Acc@5: 0.8824
2022-01-15 06:24:22,467 Val Step[1500/1563], Avg Loss: 1.5123, Avg Acc@1: 0.6810, Avg Acc@5: 0.8822
2022-01-15 06:24:24,412 Val Step[1550/1563], Avg Loss: 1.5133, Avg Acc@1: 0.6811, Avg Acc@5: 0.8823
2022-01-15 06:24:26,123 ----- Epoch[068/300], Validation Loss: 1.5163, Validation Acc@1: 0.6802, Validation Acc@5: 0.8822, time: 141.82
2022-01-15 06:24:26,123 Now training epoch 69. LR=0.000927
2022-01-15 06:26:18,530 Epoch[069/300], Step[0000/1252], Avg Loss: 2.7553, Avg Acc: 0.0039
2022-01-15 06:27:49,061 Epoch[069/300], Step[0050/1252], Avg Loss: 3.6025, Avg Acc: 0.4351
2022-01-15 06:29:19,531 Epoch[069/300], Step[0100/1252], Avg Loss: 3.6345, Avg Acc: 0.3901
2022-01-15 06:30:49,350 Epoch[069/300], Step[0150/1252], Avg Loss: 3.6197, Avg Acc: 0.4014
2022-01-15 06:32:21,777 Epoch[069/300], Step[0200/1252], Avg Loss: 3.6333, Avg Acc: 0.4065
2022-01-15 06:33:54,313 Epoch[069/300], Step[0250/1252], Avg Loss: 3.6167, Avg Acc: 0.3996
2022-01-15 06:35:24,271 Epoch[069/300], Step[0300/1252], Avg Loss: 3.5997, Avg Acc: 0.4028
2022-01-15 06:36:55,149 Epoch[069/300], Step[0350/1252], Avg Loss: 3.6085, Avg Acc: 0.4065
2022-01-15 06:38:26,940 Epoch[069/300], Step[0400/1252], Avg Loss: 3.6202, Avg Acc: 0.4014
2022-01-15 06:39:57,253 Epoch[069/300], Step[0450/1252], Avg Loss: 3.6319, Avg Acc: 0.3932
2022-01-15 06:41:28,554 Epoch[069/300], Step[0500/1252], Avg Loss: 3.6454, Avg Acc: 0.3918
2022-01-15 06:43:00,413 Epoch[069/300], Step[0550/1252], Avg Loss: 3.6317, Avg Acc: 0.3934
2022-01-15 06:44:30,704 Epoch[069/300], Step[0600/1252], Avg Loss: 3.6344, Avg Acc: 0.3923
2022-01-15 06:46:02,075 Epoch[069/300], Step[0650/1252], Avg Loss: 3.6549, Avg Acc: 0.3854
2022-01-15 06:47:33,167 Epoch[069/300], Step[0700/1252], Avg Loss: 3.6592, Avg Acc: 0.3807
2022-01-15 06:49:03,974 Epoch[069/300], Step[0750/1252], Avg Loss: 3.6629, Avg Acc: 0.3765
2022-01-15 06:50:36,274 Epoch[069/300], Step[0800/1252], Avg Loss: 3.6628, Avg Acc: 0.3759
2022-01-15 06:52:07,518 Epoch[069/300], Step[0850/1252], Avg Loss: 3.6615, Avg Acc: 0.3735
2022-01-15 06:53:39,276 Epoch[069/300], Step[0900/1252], Avg Loss: 3.6691, Avg Acc: 0.3716
2022-01-15 06:55:09,632 Epoch[069/300], Step[0950/1252], Avg Loss: 3.6720, Avg Acc: 0.3715
2022-01-15 06:56:41,448 Epoch[069/300], Step[1000/1252], Avg Loss: 3.6778, Avg Acc: 0.3696
2022-01-15 06:58:13,187 Epoch[069/300], Step[1050/1252], Avg Loss: 3.6779, Avg Acc: 0.3677
2022-01-15 06:59:43,754 Epoch[069/300], Step[1100/1252], Avg Loss: 3.6773, Avg Acc: 0.3679
2022-01-15 07:01:13,564 Epoch[069/300], Step[1150/1252], Avg Loss: 3.6850, Avg Acc: 0.3678
2022-01-15 07:02:44,293 Epoch[069/300], Step[1200/1252], Avg Loss: 3.6839, Avg Acc: 0.3679
2022-01-15 07:04:13,839 Epoch[069/300], Step[1250/1252], Avg Loss: 3.6895, Avg Acc: 0.3677
2022-01-15 07:04:20,891 ----- Epoch[069/300], Train Loss: 3.6895, Train Acc: 0.3677, time: 2394.76
2022-01-15 07:04:20,893 Now training epoch 70. LR=0.000924
2022-01-15 07:06:13,115 Epoch[070/300], Step[0000/1252], Avg Loss: 2.4971, Avg Acc: 0.6484
2022-01-15 07:07:44,026 Epoch[070/300], Step[0050/1252], Avg Loss: 3.6677, Avg Acc: 0.3594
2022-01-15 07:09:14,814 Epoch[070/300], Step[0100/1252], Avg Loss: 3.6900, Avg Acc: 0.3739
2022-01-15 07:10:46,223 Epoch[070/300], Step[0150/1252], Avg Loss: 3.7241, Avg Acc: 0.3736
2022-01-15 07:12:18,340 Epoch[070/300], Step[0200/1252], Avg Loss: 3.6902, Avg Acc: 0.3794
2022-01-15 07:13:49,712 Epoch[070/300], Step[0250/1252], Avg Loss: 3.7117, Avg Acc: 0.3826
2022-01-15 07:15:20,477 Epoch[070/300], Step[0300/1252], Avg Loss: 3.7052, Avg Acc: 0.3796
2022-01-15 07:16:50,192 Epoch[070/300], Step[0350/1252], Avg Loss: 3.7122, Avg Acc: 0.3837
2022-01-15 07:18:21,258 Epoch[070/300], Step[0400/1252], Avg Loss: 3.7019, Avg Acc: 0.3700
2022-01-15 07:19:51,429 Epoch[070/300], Step[0450/1252], Avg Loss: 3.6885, Avg Acc: 0.3715
2022-01-15 07:21:23,280 Epoch[070/300], Step[0500/1252], Avg Loss: 3.6923, Avg Acc: 0.3691
2022-01-15 07:22:54,363 Epoch[070/300], Step[0550/1252], Avg Loss: 3.6878, Avg Acc: 0.3684
2022-01-15 07:24:26,460 Epoch[070/300], Step[0600/1252], Avg Loss: 3.6864, Avg Acc: 0.3676
2022-01-15 07:25:57,469 Epoch[070/300], Step[0650/1252], Avg Loss: 3.6913, Avg Acc: 0.3656
2022-01-15 07:27:27,846 Epoch[070/300], Step[0700/1252], Avg Loss: 3.6876, Avg Acc: 0.3674
2022-01-15 07:28:58,476 Epoch[070/300], Step[0750/1252], Avg Loss: 3.6927, Avg Acc: 0.3638
2022-01-15 07:30:30,290 Epoch[070/300], Step[0800/1252], Avg Loss: 3.6948, Avg Acc: 0.3639
2022-01-15 07:32:00,897 Epoch[070/300], Step[0850/1252], Avg Loss: 3.6886, Avg Acc: 0.3641
2022-01-15 07:33:32,453 Epoch[070/300], Step[0900/1252], Avg Loss: 3.6915, Avg Acc: 0.3610
2022-01-15 07:35:02,630 Epoch[070/300], Step[0950/1252], Avg Loss: 3.7023, Avg Acc: 0.3588
2022-01-15 07:36:32,769 Epoch[070/300], Step[1000/1252], Avg Loss: 3.6990, Avg Acc: 0.3569
2022-01-15 07:38:01,101 Epoch[070/300], Step[1050/1252], Avg Loss: 3.6981, Avg Acc: 0.3544
2022-01-15 07:39:29,972 Epoch[070/300], Step[1100/1252], Avg Loss: 3.6971, Avg Acc: 0.3556
2022-01-15 07:40:59,832 Epoch[070/300], Step[1150/1252], Avg Loss: 3.6924, Avg Acc: 0.3578
2022-01-15 07:42:28,888 Epoch[070/300], Step[1200/1252], Avg Loss: 3.6966, Avg Acc: 0.3565
2022-01-15 07:43:57,668 Epoch[070/300], Step[1250/1252], Avg Loss: 3.6939, Avg Acc: 0.3567
2022-01-15 07:44:04,260 ----- Epoch[070/300], Train Loss: 3.6939, Train Acc: 0.3567, time: 2383.36
2022-01-15 07:44:04,261 ----- Validation after Epoch: 70
2022-01-15 07:45:15,390 Val Step[0000/1563], Avg Loss: 1.0654, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 07:45:17,428 Val Step[0050/1563], Avg Loss: 1.3389, Avg Acc@1: 0.7108, Avg Acc@5: 0.9044
2022-01-15 07:45:19,514 Val Step[0100/1563], Avg Loss: 1.3617, Avg Acc@1: 0.6955, Avg Acc@5: 0.9010
2022-01-15 07:45:21,621 Val Step[0150/1563], Avg Loss: 1.4496, Avg Acc@1: 0.6838, Avg Acc@5: 0.8841
2022-01-15 07:45:23,661 Val Step[0200/1563], Avg Loss: 1.4292, Avg Acc@1: 0.6878, Avg Acc@5: 0.8881
2022-01-15 07:45:25,708 Val Step[0250/1563], Avg Loss: 1.4320, Avg Acc@1: 0.6877, Avg Acc@5: 0.8889
2022-01-15 07:45:27,840 Val Step[0300/1563], Avg Loss: 1.4405, Avg Acc@1: 0.6902, Avg Acc@5: 0.8833
2022-01-15 07:45:30,003 Val Step[0350/1563], Avg Loss: 1.4665, Avg Acc@1: 0.6852, Avg Acc@5: 0.8793
2022-01-15 07:45:32,170 Val Step[0400/1563], Avg Loss: 1.4606, Avg Acc@1: 0.6830, Avg Acc@5: 0.8819
2022-01-15 07:45:34,350 Val Step[0450/1563], Avg Loss: 1.4679, Avg Acc@1: 0.6793, Avg Acc@5: 0.8783
2022-01-15 07:45:36,518 Val Step[0500/1563], Avg Loss: 1.4771, Avg Acc@1: 0.6761, Avg Acc@5: 0.8772
2022-01-15 07:45:38,601 Val Step[0550/1563], Avg Loss: 1.4713, Avg Acc@1: 0.6804, Avg Acc@5: 0.8779
2022-01-15 07:45:40,725 Val Step[0600/1563], Avg Loss: 1.4654, Avg Acc@1: 0.6818, Avg Acc@5: 0.8783
2022-01-15 07:45:42,841 Val Step[0650/1563], Avg Loss: 1.4669, Avg Acc@1: 0.6799, Avg Acc@5: 0.8786
2022-01-15 07:45:44,885 Val Step[0700/1563], Avg Loss: 1.4630, Avg Acc@1: 0.6792, Avg Acc@5: 0.8795
2022-01-15 07:45:46,883 Val Step[0750/1563], Avg Loss: 1.4718, Avg Acc@1: 0.6781, Avg Acc@5: 0.8787
2022-01-15 07:45:48,863 Val Step[0800/1563], Avg Loss: 1.4730, Avg Acc@1: 0.6799, Avg Acc@5: 0.8773
2022-01-15 07:45:50,924 Val Step[0850/1563], Avg Loss: 1.4741, Avg Acc@1: 0.6783, Avg Acc@5: 0.8776
2022-01-15 07:45:52,903 Val Step[0900/1563], Avg Loss: 1.4637, Avg Acc@1: 0.6816, Avg Acc@5: 0.8790
2022-01-15 07:45:54,832 Val Step[0950/1563], Avg Loss: 1.4573, Avg Acc@1: 0.6824, Avg Acc@5: 0.8800
2022-01-15 07:45:56,799 Val Step[1000/1563], Avg Loss: 1.4565, Avg Acc@1: 0.6831, Avg Acc@5: 0.8805
2022-01-15 07:45:58,744 Val Step[1050/1563], Avg Loss: 1.4565, Avg Acc@1: 0.6834, Avg Acc@5: 0.8798
2022-01-15 07:46:00,683 Val Step[1100/1563], Avg Loss: 1.4634, Avg Acc@1: 0.6819, Avg Acc@5: 0.8790
2022-01-15 07:46:02,607 Val Step[1150/1563], Avg Loss: 1.4648, Avg Acc@1: 0.6819, Avg Acc@5: 0.8785
2022-01-15 07:46:04,489 Val Step[1200/1563], Avg Loss: 1.4600, Avg Acc@1: 0.6827, Avg Acc@5: 0.8792
2022-01-15 07:46:06,421 Val Step[1250/1563], Avg Loss: 1.4624, Avg Acc@1: 0.6831, Avg Acc@5: 0.8791
2022-01-15 07:46:08,530 Val Step[1300/1563], Avg Loss: 1.4652, Avg Acc@1: 0.6821, Avg Acc@5: 0.8787
2022-01-15 07:46:10,791 Val Step[1350/1563], Avg Loss: 1.4681, Avg Acc@1: 0.6815, Avg Acc@5: 0.8784
2022-01-15 07:46:12,803 Val Step[1400/1563], Avg Loss: 1.4688, Avg Acc@1: 0.6811, Avg Acc@5: 0.8786
2022-01-15 07:46:14,733 Val Step[1450/1563], Avg Loss: 1.4667, Avg Acc@1: 0.6815, Avg Acc@5: 0.8793
2022-01-15 07:46:16,717 Val Step[1500/1563], Avg Loss: 1.4658, Avg Acc@1: 0.6812, Avg Acc@5: 0.8796
2022-01-15 07:46:18,582 Val Step[1550/1563], Avg Loss: 1.4654, Avg Acc@1: 0.6801, Avg Acc@5: 0.8797
2022-01-15 07:46:20,537 ----- Epoch[070/300], Validation Loss: 1.4681, Validation Acc@1: 0.6796, Validation Acc@5: 0.8795, time: 136.27
2022-01-15 07:46:20,538 Now training epoch 71. LR=0.000921
2022-01-15 07:48:11,217 Epoch[071/300], Step[0000/1252], Avg Loss: 3.9870, Avg Acc: 0.4492
2022-01-15 07:49:40,956 Epoch[071/300], Step[0050/1252], Avg Loss: 3.7646, Avg Acc: 0.3237
2022-01-15 07:51:11,378 Epoch[071/300], Step[0100/1252], Avg Loss: 3.6769, Avg Acc: 0.3761
2022-01-15 07:52:44,112 Epoch[071/300], Step[0150/1252], Avg Loss: 3.6816, Avg Acc: 0.3824
2022-01-15 07:54:14,277 Epoch[071/300], Step[0200/1252], Avg Loss: 3.7171, Avg Acc: 0.3838
2022-01-15 07:55:46,254 Epoch[071/300], Step[0250/1252], Avg Loss: 3.7324, Avg Acc: 0.3765
2022-01-15 07:57:16,632 Epoch[071/300], Step[0300/1252], Avg Loss: 3.7286, Avg Acc: 0.3774
2022-01-15 07:58:47,957 Epoch[071/300], Step[0350/1252], Avg Loss: 3.6992, Avg Acc: 0.3752
2022-01-15 08:00:17,266 Epoch[071/300], Step[0400/1252], Avg Loss: 3.7019, Avg Acc: 0.3791
2022-01-15 08:01:48,104 Epoch[071/300], Step[0450/1252], Avg Loss: 3.6934, Avg Acc: 0.3812
2022-01-15 08:03:17,845 Epoch[071/300], Step[0500/1252], Avg Loss: 3.7042, Avg Acc: 0.3800
2022-01-15 08:04:49,632 Epoch[071/300], Step[0550/1252], Avg Loss: 3.6992, Avg Acc: 0.3845
2022-01-15 08:06:21,002 Epoch[071/300], Step[0600/1252], Avg Loss: 3.6971, Avg Acc: 0.3820
2022-01-15 08:07:51,895 Epoch[071/300], Step[0650/1252], Avg Loss: 3.6995, Avg Acc: 0.3821
2022-01-15 08:09:22,535 Epoch[071/300], Step[0700/1252], Avg Loss: 3.6979, Avg Acc: 0.3808
2022-01-15 08:10:52,058 Epoch[071/300], Step[0750/1252], Avg Loss: 3.7013, Avg Acc: 0.3789
2022-01-15 08:12:24,192 Epoch[071/300], Step[0800/1252], Avg Loss: 3.6922, Avg Acc: 0.3792
2022-01-15 08:13:55,667 Epoch[071/300], Step[0850/1252], Avg Loss: 3.6882, Avg Acc: 0.3779
2022-01-15 08:15:28,117 Epoch[071/300], Step[0900/1252], Avg Loss: 3.6910, Avg Acc: 0.3756
2022-01-15 08:16:59,764 Epoch[071/300], Step[0950/1252], Avg Loss: 3.6877, Avg Acc: 0.3761
2022-01-15 08:18:31,960 Epoch[071/300], Step[1000/1252], Avg Loss: 3.6871, Avg Acc: 0.3749
2022-01-15 08:20:03,053 Epoch[071/300], Step[1050/1252], Avg Loss: 3.6885, Avg Acc: 0.3757
2022-01-15 08:21:34,987 Epoch[071/300], Step[1100/1252], Avg Loss: 3.6932, Avg Acc: 0.3763
2022-01-15 08:23:06,743 Epoch[071/300], Step[1150/1252], Avg Loss: 3.6924, Avg Acc: 0.3759
2022-01-15 08:24:37,497 Epoch[071/300], Step[1200/1252], Avg Loss: 3.6972, Avg Acc: 0.3745
2022-01-15 08:26:08,989 Epoch[071/300], Step[1250/1252], Avg Loss: 3.6992, Avg Acc: 0.3739
2022-01-15 08:26:15,473 ----- Epoch[071/300], Train Loss: 3.6992, Train Acc: 0.3739, time: 2394.93
2022-01-15 08:26:15,474 Now training epoch 72. LR=0.000918
2022-01-15 08:28:08,427 Epoch[072/300], Step[0000/1252], Avg Loss: 4.4275, Avg Acc: 0.1758
2022-01-15 08:29:38,141 Epoch[072/300], Step[0050/1252], Avg Loss: 3.6640, Avg Acc: 0.4045
2022-01-15 08:31:09,470 Epoch[072/300], Step[0100/1252], Avg Loss: 3.7692, Avg Acc: 0.3732
2022-01-15 08:32:39,580 Epoch[072/300], Step[0150/1252], Avg Loss: 3.7333, Avg Acc: 0.3644
2022-01-15 08:34:11,011 Epoch[072/300], Step[0200/1252], Avg Loss: 3.7077, Avg Acc: 0.3840
2022-01-15 08:35:42,392 Epoch[072/300], Step[0250/1252], Avg Loss: 3.6830, Avg Acc: 0.3818
2022-01-15 08:37:12,551 Epoch[072/300], Step[0300/1252], Avg Loss: 3.6641, Avg Acc: 0.3813
2022-01-15 08:38:42,232 Epoch[072/300], Step[0350/1252], Avg Loss: 3.6807, Avg Acc: 0.3738
2022-01-15 08:40:13,306 Epoch[072/300], Step[0400/1252], Avg Loss: 3.6790, Avg Acc: 0.3695
2022-01-15 08:41:46,147 Epoch[072/300], Step[0450/1252], Avg Loss: 3.6865, Avg Acc: 0.3703
2022-01-15 08:43:18,873 Epoch[072/300], Step[0500/1252], Avg Loss: 3.6824, Avg Acc: 0.3686
2022-01-15 08:44:49,368 Epoch[072/300], Step[0550/1252], Avg Loss: 3.6811, Avg Acc: 0.3631
2022-01-15 08:46:21,157 Epoch[072/300], Step[0600/1252], Avg Loss: 3.6741, Avg Acc: 0.3672
2022-01-15 08:47:54,066 Epoch[072/300], Step[0650/1252], Avg Loss: 3.6697, Avg Acc: 0.3643
2022-01-15 08:49:24,924 Epoch[072/300], Step[0700/1252], Avg Loss: 3.6680, Avg Acc: 0.3611
2022-01-15 08:50:56,601 Epoch[072/300], Step[0750/1252], Avg Loss: 3.6694, Avg Acc: 0.3622
2022-01-15 08:52:27,302 Epoch[072/300], Step[0800/1252], Avg Loss: 3.6676, Avg Acc: 0.3623
2022-01-15 08:53:58,694 Epoch[072/300], Step[0850/1252], Avg Loss: 3.6622, Avg Acc: 0.3620
2022-01-15 08:55:28,970 Epoch[072/300], Step[0900/1252], Avg Loss: 3.6571, Avg Acc: 0.3614
2022-01-15 08:56:57,823 Epoch[072/300], Step[0950/1252], Avg Loss: 3.6639, Avg Acc: 0.3584
2022-01-15 08:58:28,482 Epoch[072/300], Step[1000/1252], Avg Loss: 3.6627, Avg Acc: 0.3598
2022-01-15 08:59:59,020 Epoch[072/300], Step[1050/1252], Avg Loss: 3.6640, Avg Acc: 0.3596
2022-01-15 09:01:28,989 Epoch[072/300], Step[1100/1252], Avg Loss: 3.6598, Avg Acc: 0.3608
2022-01-15 09:03:00,046 Epoch[072/300], Step[1150/1252], Avg Loss: 3.6595, Avg Acc: 0.3622
2022-01-15 09:04:31,686 Epoch[072/300], Step[1200/1252], Avg Loss: 3.6615, Avg Acc: 0.3606
2022-01-15 09:06:02,411 Epoch[072/300], Step[1250/1252], Avg Loss: 3.6628, Avg Acc: 0.3578
2022-01-15 09:06:09,168 ----- Epoch[072/300], Train Loss: 3.6629, Train Acc: 0.3578, time: 2393.69
2022-01-15 09:06:09,170 ----- Validation after Epoch: 72
2022-01-15 09:07:27,795 Val Step[0000/1563], Avg Loss: 0.8370, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 09:07:29,826 Val Step[0050/1563], Avg Loss: 1.2621, Avg Acc@1: 0.7206, Avg Acc@5: 0.9216
2022-01-15 09:07:31,790 Val Step[0100/1563], Avg Loss: 1.2907, Avg Acc@1: 0.6980, Avg Acc@5: 0.9146
2022-01-15 09:07:33,771 Val Step[0150/1563], Avg Loss: 1.3943, Avg Acc@1: 0.6772, Avg Acc@5: 0.8974
2022-01-15 09:07:35,731 Val Step[0200/1563], Avg Loss: 1.3787, Avg Acc@1: 0.6859, Avg Acc@5: 0.8937
2022-01-15 09:07:37,779 Val Step[0250/1563], Avg Loss: 1.3720, Avg Acc@1: 0.6907, Avg Acc@5: 0.8954
2022-01-15 09:07:39,741 Val Step[0300/1563], Avg Loss: 1.3770, Avg Acc@1: 0.6931, Avg Acc@5: 0.8929
2022-01-15 09:07:41,707 Val Step[0350/1563], Avg Loss: 1.4070, Avg Acc@1: 0.6895, Avg Acc@5: 0.8878
2022-01-15 09:07:43,645 Val Step[0400/1563], Avg Loss: 1.3974, Avg Acc@1: 0.6905, Avg Acc@5: 0.8906
2022-01-15 09:07:45,679 Val Step[0450/1563], Avg Loss: 1.4051, Avg Acc@1: 0.6896, Avg Acc@5: 0.8889
2022-01-15 09:07:47,690 Val Step[0500/1563], Avg Loss: 1.4106, Avg Acc@1: 0.6869, Avg Acc@5: 0.8872
2022-01-15 09:07:49,614 Val Step[0550/1563], Avg Loss: 1.4049, Avg Acc@1: 0.6890, Avg Acc@5: 0.8873
2022-01-15 09:07:51,610 Val Step[0600/1563], Avg Loss: 1.3997, Avg Acc@1: 0.6886, Avg Acc@5: 0.8885
2022-01-15 09:07:53,517 Val Step[0650/1563], Avg Loss: 1.3976, Avg Acc@1: 0.6886, Avg Acc@5: 0.8884
2022-01-15 09:07:55,525 Val Step[0700/1563], Avg Loss: 1.3960, Avg Acc@1: 0.6899, Avg Acc@5: 0.8889
2022-01-15 09:07:57,519 Val Step[0750/1563], Avg Loss: 1.4045, Avg Acc@1: 0.6879, Avg Acc@5: 0.8886
2022-01-15 09:07:59,558 Val Step[0800/1563], Avg Loss: 1.4075, Avg Acc@1: 0.6898, Avg Acc@5: 0.8876
2022-01-15 09:08:01,587 Val Step[0850/1563], Avg Loss: 1.4101, Avg Acc@1: 0.6886, Avg Acc@5: 0.8869
2022-01-15 09:08:03,579 Val Step[0900/1563], Avg Loss: 1.4037, Avg Acc@1: 0.6899, Avg Acc@5: 0.8875
2022-01-15 09:08:05,540 Val Step[0950/1563], Avg Loss: 1.3981, Avg Acc@1: 0.6910, Avg Acc@5: 0.8885
2022-01-15 09:08:07,643 Val Step[1000/1563], Avg Loss: 1.3953, Avg Acc@1: 0.6927, Avg Acc@5: 0.8896
2022-01-15 09:08:09,750 Val Step[1050/1563], Avg Loss: 1.3952, Avg Acc@1: 0.6924, Avg Acc@5: 0.8894
2022-01-15 09:08:11,717 Val Step[1100/1563], Avg Loss: 1.4032, Avg Acc@1: 0.6899, Avg Acc@5: 0.8882
2022-01-15 09:08:13,679 Val Step[1150/1563], Avg Loss: 1.4034, Avg Acc@1: 0.6905, Avg Acc@5: 0.8873
2022-01-15 09:08:15,667 Val Step[1200/1563], Avg Loss: 1.3977, Avg Acc@1: 0.6912, Avg Acc@5: 0.8878
2022-01-15 09:08:17,600 Val Step[1250/1563], Avg Loss: 1.3979, Avg Acc@1: 0.6911, Avg Acc@5: 0.8879
2022-01-15 09:08:19,529 Val Step[1300/1563], Avg Loss: 1.4033, Avg Acc@1: 0.6897, Avg Acc@5: 0.8874
2022-01-15 09:08:21,585 Val Step[1350/1563], Avg Loss: 1.4063, Avg Acc@1: 0.6886, Avg Acc@5: 0.8869
2022-01-15 09:08:23,525 Val Step[1400/1563], Avg Loss: 1.4060, Avg Acc@1: 0.6893, Avg Acc@5: 0.8869
2022-01-15 09:08:25,488 Val Step[1450/1563], Avg Loss: 1.4049, Avg Acc@1: 0.6898, Avg Acc@5: 0.8878
2022-01-15 09:08:27,474 Val Step[1500/1563], Avg Loss: 1.4047, Avg Acc@1: 0.6896, Avg Acc@5: 0.8873
2022-01-15 09:08:29,376 Val Step[1550/1563], Avg Loss: 1.4061, Avg Acc@1: 0.6892, Avg Acc@5: 0.8874
2022-01-15 09:08:31,249 ----- Epoch[072/300], Validation Loss: 1.4093, Validation Acc@1: 0.6883, Validation Acc@5: 0.8874, time: 142.08
2022-01-15 09:08:31,250 Now training epoch 73. LR=0.000915
2022-01-15 09:10:23,072 Epoch[073/300], Step[0000/1252], Avg Loss: 3.8726, Avg Acc: 0.4727
2022-01-15 09:11:52,736 Epoch[073/300], Step[0050/1252], Avg Loss: 3.6080, Avg Acc: 0.3476
2022-01-15 09:13:21,996 Epoch[073/300], Step[0100/1252], Avg Loss: 3.6762, Avg Acc: 0.3868
2022-01-15 09:14:50,992 Epoch[073/300], Step[0150/1252], Avg Loss: 3.6654, Avg Acc: 0.3931
2022-01-15 09:16:19,443 Epoch[073/300], Step[0200/1252], Avg Loss: 3.6947, Avg Acc: 0.3892
2022-01-15 09:17:49,124 Epoch[073/300], Step[0250/1252], Avg Loss: 3.6860, Avg Acc: 0.3920
2022-01-15 09:19:18,143 Epoch[073/300], Step[0300/1252], Avg Loss: 3.7124, Avg Acc: 0.3929
2022-01-15 09:20:46,331 Epoch[073/300], Step[0350/1252], Avg Loss: 3.6940, Avg Acc: 0.3928
2022-01-15 09:22:15,612 Epoch[073/300], Step[0400/1252], Avg Loss: 3.6910, Avg Acc: 0.3976
2022-01-15 09:23:46,250 Epoch[073/300], Step[0450/1252], Avg Loss: 3.6782, Avg Acc: 0.3975
2022-01-15 09:25:16,326 Epoch[073/300], Step[0500/1252], Avg Loss: 3.6832, Avg Acc: 0.3969
2022-01-15 09:26:46,696 Epoch[073/300], Step[0550/1252], Avg Loss: 3.6854, Avg Acc: 0.3944
2022-01-15 09:28:17,863 Epoch[073/300], Step[0600/1252], Avg Loss: 3.6793, Avg Acc: 0.3894
2022-01-15 09:29:49,169 Epoch[073/300], Step[0650/1252], Avg Loss: 3.6909, Avg Acc: 0.3860
2022-01-15 09:31:20,032 Epoch[073/300], Step[0700/1252], Avg Loss: 3.6890, Avg Acc: 0.3839
2022-01-15 09:32:51,101 Epoch[073/300], Step[0750/1252], Avg Loss: 3.6941, Avg Acc: 0.3851
2022-01-15 09:34:22,051 Epoch[073/300], Step[0800/1252], Avg Loss: 3.6902, Avg Acc: 0.3853
2022-01-15 09:35:52,816 Epoch[073/300], Step[0850/1252], Avg Loss: 3.6875, Avg Acc: 0.3852
2022-01-15 09:37:23,707 Epoch[073/300], Step[0900/1252], Avg Loss: 3.6935, Avg Acc: 0.3812
2022-01-15 09:38:52,062 Epoch[073/300], Step[0950/1252], Avg Loss: 3.6971, Avg Acc: 0.3804
2022-01-15 09:40:22,164 Epoch[073/300], Step[1000/1252], Avg Loss: 3.6917, Avg Acc: 0.3796
2022-01-15 09:41:52,236 Epoch[073/300], Step[1050/1252], Avg Loss: 3.6912, Avg Acc: 0.3790
2022-01-15 09:43:24,350 Epoch[073/300], Step[1100/1252], Avg Loss: 3.6926, Avg Acc: 0.3767
2022-01-15 09:44:55,611 Epoch[073/300], Step[1150/1252], Avg Loss: 3.6943, Avg Acc: 0.3761
2022-01-15 09:46:26,976 Epoch[073/300], Step[1200/1252], Avg Loss: 3.6887, Avg Acc: 0.3756
2022-01-15 09:47:57,660 Epoch[073/300], Step[1250/1252], Avg Loss: 3.6850, Avg Acc: 0.3758
2022-01-15 09:48:04,911 ----- Epoch[073/300], Train Loss: 3.6851, Train Acc: 0.3758, time: 2373.66
2022-01-15 09:48:04,913 Now training epoch 74. LR=0.000912
2022-01-15 09:49:55,806 Epoch[074/300], Step[0000/1252], Avg Loss: 4.1071, Avg Acc: 0.3633
2022-01-15 09:51:25,412 Epoch[074/300], Step[0050/1252], Avg Loss: 3.5445, Avg Acc: 0.3745
2022-01-15 09:52:56,293 Epoch[074/300], Step[0100/1252], Avg Loss: 3.6347, Avg Acc: 0.3929
2022-01-15 09:54:28,168 Epoch[074/300], Step[0150/1252], Avg Loss: 3.5989, Avg Acc: 0.3693
2022-01-15 09:55:59,860 Epoch[074/300], Step[0200/1252], Avg Loss: 3.6118, Avg Acc: 0.3734
2022-01-15 09:57:30,669 Epoch[074/300], Step[0250/1252], Avg Loss: 3.6140, Avg Acc: 0.3738
2022-01-15 09:58:59,895 Epoch[074/300], Step[0300/1252], Avg Loss: 3.6125, Avg Acc: 0.3754
2022-01-15 10:00:30,445 Epoch[074/300], Step[0350/1252], Avg Loss: 3.6170, Avg Acc: 0.3707
2022-01-15 10:02:01,041 Epoch[074/300], Step[0400/1252], Avg Loss: 3.6299, Avg Acc: 0.3719
2022-01-15 10:03:31,694 Epoch[074/300], Step[0450/1252], Avg Loss: 3.6257, Avg Acc: 0.3728
2022-01-15 10:05:03,034 Epoch[074/300], Step[0500/1252], Avg Loss: 3.6341, Avg Acc: 0.3701
2022-01-15 10:06:33,559 Epoch[074/300], Step[0550/1252], Avg Loss: 3.6556, Avg Acc: 0.3692
2022-01-15 10:08:02,183 Epoch[074/300], Step[0600/1252], Avg Loss: 3.6552, Avg Acc: 0.3667
2022-01-15 10:09:33,856 Epoch[074/300], Step[0650/1252], Avg Loss: 3.6583, Avg Acc: 0.3666
2022-01-15 10:11:05,489 Epoch[074/300], Step[0700/1252], Avg Loss: 3.6517, Avg Acc: 0.3682
2022-01-15 10:12:33,881 Epoch[074/300], Step[0750/1252], Avg Loss: 3.6480, Avg Acc: 0.3687
2022-01-15 10:14:04,529 Epoch[074/300], Step[0800/1252], Avg Loss: 3.6390, Avg Acc: 0.3723
2022-01-15 10:15:36,361 Epoch[074/300], Step[0850/1252], Avg Loss: 3.6484, Avg Acc: 0.3701
2022-01-15 10:17:07,064 Epoch[074/300], Step[0900/1252], Avg Loss: 3.6527, Avg Acc: 0.3686
2022-01-15 10:18:38,049 Epoch[074/300], Step[0950/1252], Avg Loss: 3.6531, Avg Acc: 0.3691
2022-01-15 10:20:08,646 Epoch[074/300], Step[1000/1252], Avg Loss: 3.6565, Avg Acc: 0.3675
2022-01-15 10:21:39,435 Epoch[074/300], Step[1050/1252], Avg Loss: 3.6621, Avg Acc: 0.3677
2022-01-15 10:23:11,142 Epoch[074/300], Step[1100/1252], Avg Loss: 3.6617, Avg Acc: 0.3700
2022-01-15 10:24:41,614 Epoch[074/300], Step[1150/1252], Avg Loss: 3.6625, Avg Acc: 0.3708
2022-01-15 10:26:12,488 Epoch[074/300], Step[1200/1252], Avg Loss: 3.6639, Avg Acc: 0.3721
2022-01-15 10:27:43,831 Epoch[074/300], Step[1250/1252], Avg Loss: 3.6654, Avg Acc: 0.3723
2022-01-15 10:27:50,836 ----- Epoch[074/300], Train Loss: 3.6654, Train Acc: 0.3723, time: 2385.92
2022-01-15 10:27:50,837 ----- Validation after Epoch: 74
2022-01-15 10:29:09,951 Val Step[0000/1563], Avg Loss: 0.8797, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 10:29:12,156 Val Step[0050/1563], Avg Loss: 1.3130, Avg Acc@1: 0.7304, Avg Acc@5: 0.9240
2022-01-15 10:29:14,559 Val Step[0100/1563], Avg Loss: 1.3287, Avg Acc@1: 0.7178, Avg Acc@5: 0.9146
2022-01-15 10:29:16,565 Val Step[0150/1563], Avg Loss: 1.4084, Avg Acc@1: 0.6995, Avg Acc@5: 0.8974
2022-01-15 10:29:18,575 Val Step[0200/1563], Avg Loss: 1.3959, Avg Acc@1: 0.7034, Avg Acc@5: 0.8924
2022-01-15 10:29:20,515 Val Step[0250/1563], Avg Loss: 1.3936, Avg Acc@1: 0.7072, Avg Acc@5: 0.8924
2022-01-15 10:29:22,672 Val Step[0300/1563], Avg Loss: 1.4086, Avg Acc@1: 0.7002, Avg Acc@5: 0.8895
2022-01-15 10:29:24,651 Val Step[0350/1563], Avg Loss: 1.4389, Avg Acc@1: 0.6916, Avg Acc@5: 0.8850
2022-01-15 10:29:26,847 Val Step[0400/1563], Avg Loss: 1.4307, Avg Acc@1: 0.6914, Avg Acc@5: 0.8856
2022-01-15 10:29:28,839 Val Step[0450/1563], Avg Loss: 1.4392, Avg Acc@1: 0.6876, Avg Acc@5: 0.8861
2022-01-15 10:29:30,847 Val Step[0500/1563], Avg Loss: 1.4465, Avg Acc@1: 0.6846, Avg Acc@5: 0.8850
2022-01-15 10:29:32,846 Val Step[0550/1563], Avg Loss: 1.4405, Avg Acc@1: 0.6872, Avg Acc@5: 0.8863
2022-01-15 10:29:34,809 Val Step[0600/1563], Avg Loss: 1.4348, Avg Acc@1: 0.6886, Avg Acc@5: 0.8869
2022-01-15 10:29:36,827 Val Step[0650/1563], Avg Loss: 1.4365, Avg Acc@1: 0.6889, Avg Acc@5: 0.8873
2022-01-15 10:29:38,746 Val Step[0700/1563], Avg Loss: 1.4341, Avg Acc@1: 0.6896, Avg Acc@5: 0.8875
2022-01-15 10:29:40,696 Val Step[0750/1563], Avg Loss: 1.4397, Avg Acc@1: 0.6876, Avg Acc@5: 0.8873
2022-01-15 10:29:42,665 Val Step[0800/1563], Avg Loss: 1.4422, Avg Acc@1: 0.6884, Avg Acc@5: 0.8865
2022-01-15 10:29:44,660 Val Step[0850/1563], Avg Loss: 1.4449, Avg Acc@1: 0.6867, Avg Acc@5: 0.8865
2022-01-15 10:29:46,681 Val Step[0900/1563], Avg Loss: 1.4370, Avg Acc@1: 0.6894, Avg Acc@5: 0.8875
2022-01-15 10:29:48,785 Val Step[0950/1563], Avg Loss: 1.4310, Avg Acc@1: 0.6890, Avg Acc@5: 0.8881
2022-01-15 10:29:50,828 Val Step[1000/1563], Avg Loss: 1.4324, Avg Acc@1: 0.6878, Avg Acc@5: 0.8884
2022-01-15 10:29:52,744 Val Step[1050/1563], Avg Loss: 1.4346, Avg Acc@1: 0.6870, Avg Acc@5: 0.8877
2022-01-15 10:29:54,668 Val Step[1100/1563], Avg Loss: 1.4393, Avg Acc@1: 0.6859, Avg Acc@5: 0.8869
2022-01-15 10:29:56,674 Val Step[1150/1563], Avg Loss: 1.4389, Avg Acc@1: 0.6857, Avg Acc@5: 0.8869
2022-01-15 10:29:58,840 Val Step[1200/1563], Avg Loss: 1.4331, Avg Acc@1: 0.6874, Avg Acc@5: 0.8878
2022-01-15 10:30:00,880 Val Step[1250/1563], Avg Loss: 1.4343, Avg Acc@1: 0.6871, Avg Acc@5: 0.8874
2022-01-15 10:30:02,969 Val Step[1300/1563], Avg Loss: 1.4356, Avg Acc@1: 0.6868, Avg Acc@5: 0.8871
2022-01-15 10:30:04,945 Val Step[1350/1563], Avg Loss: 1.4392, Avg Acc@1: 0.6860, Avg Acc@5: 0.8866
2022-01-15 10:30:07,121 Val Step[1400/1563], Avg Loss: 1.4395, Avg Acc@1: 0.6855, Avg Acc@5: 0.8864
2022-01-15 10:30:09,383 Val Step[1450/1563], Avg Loss: 1.4364, Avg Acc@1: 0.6857, Avg Acc@5: 0.8871
2022-01-15 10:30:11,662 Val Step[1500/1563], Avg Loss: 1.4348, Avg Acc@1: 0.6858, Avg Acc@5: 0.8871
2022-01-15 10:30:13,588 Val Step[1550/1563], Avg Loss: 1.4356, Avg Acc@1: 0.6857, Avg Acc@5: 0.8867
2022-01-15 10:30:15,393 ----- Epoch[074/300], Validation Loss: 1.4382, Validation Acc@1: 0.6845, Validation Acc@5: 0.8867, time: 144.55
2022-01-15 10:30:15,394 Now training epoch 75. LR=0.000909
2022-01-15 10:32:07,861 Epoch[075/300], Step[0000/1252], Avg Loss: 2.7531, Avg Acc: 0.6445
2022-01-15 10:33:37,865 Epoch[075/300], Step[0050/1252], Avg Loss: 3.5613, Avg Acc: 0.3425
2022-01-15 10:35:08,369 Epoch[075/300], Step[0100/1252], Avg Loss: 3.6532, Avg Acc: 0.3626
2022-01-15 10:36:39,667 Epoch[075/300], Step[0150/1252], Avg Loss: 3.6390, Avg Acc: 0.3711
2022-01-15 10:38:10,588 Epoch[075/300], Step[0200/1252], Avg Loss: 3.6454, Avg Acc: 0.3784
2022-01-15 10:39:40,733 Epoch[075/300], Step[0250/1252], Avg Loss: 3.6500, Avg Acc: 0.3742
2022-01-15 10:41:09,716 Epoch[075/300], Step[0300/1252], Avg Loss: 3.6644, Avg Acc: 0.3755
2022-01-15 10:42:41,988 Epoch[075/300], Step[0350/1252], Avg Loss: 3.6595, Avg Acc: 0.3768
2022-01-15 10:44:13,443 Epoch[075/300], Step[0400/1252], Avg Loss: 3.6680, Avg Acc: 0.3680
2022-01-15 10:45:45,205 Epoch[075/300], Step[0450/1252], Avg Loss: 3.6600, Avg Acc: 0.3678
2022-01-15 10:47:16,716 Epoch[075/300], Step[0500/1252], Avg Loss: 3.6754, Avg Acc: 0.3706
2022-01-15 10:48:47,013 Epoch[075/300], Step[0550/1252], Avg Loss: 3.6801, Avg Acc: 0.3724
2022-01-15 10:50:16,808 Epoch[075/300], Step[0600/1252], Avg Loss: 3.6811, Avg Acc: 0.3680
2022-01-15 10:51:46,848 Epoch[075/300], Step[0650/1252], Avg Loss: 3.6867, Avg Acc: 0.3674
2022-01-15 10:53:16,367 Epoch[075/300], Step[0700/1252], Avg Loss: 3.6747, Avg Acc: 0.3713
2022-01-15 10:54:44,293 Epoch[075/300], Step[0750/1252], Avg Loss: 3.6723, Avg Acc: 0.3742
2022-01-15 10:56:11,989 Epoch[075/300], Step[0800/1252], Avg Loss: 3.6703, Avg Acc: 0.3722
2022-01-15 10:57:38,815 Epoch[075/300], Step[0850/1252], Avg Loss: 3.6729, Avg Acc: 0.3720
2022-01-15 10:59:06,677 Epoch[075/300], Step[0900/1252], Avg Loss: 3.6734, Avg Acc: 0.3719
2022-01-15 11:00:38,029 Epoch[075/300], Step[0950/1252], Avg Loss: 3.6714, Avg Acc: 0.3717
2022-01-15 11:02:10,424 Epoch[075/300], Step[1000/1252], Avg Loss: 3.6687, Avg Acc: 0.3712
2022-01-15 11:03:42,072 Epoch[075/300], Step[1050/1252], Avg Loss: 3.6657, Avg Acc: 0.3701
2022-01-15 11:05:12,777 Epoch[075/300], Step[1100/1252], Avg Loss: 3.6717, Avg Acc: 0.3677
2022-01-15 11:06:43,674 Epoch[075/300], Step[1150/1252], Avg Loss: 3.6758, Avg Acc: 0.3662
2022-01-15 11:08:15,277 Epoch[075/300], Step[1200/1252], Avg Loss: 3.6792, Avg Acc: 0.3669
2022-01-15 11:09:46,784 Epoch[075/300], Step[1250/1252], Avg Loss: 3.6802, Avg Acc: 0.3677
2022-01-15 11:09:53,810 ----- Epoch[075/300], Train Loss: 3.6804, Train Acc: 0.3677, time: 2378.41
2022-01-15 11:09:53,812 Now training epoch 76. LR=0.000905
2022-01-15 11:11:47,551 Epoch[076/300], Step[0000/1252], Avg Loss: 2.8680, Avg Acc: 0.0039
2022-01-15 11:13:18,216 Epoch[076/300], Step[0050/1252], Avg Loss: 3.7548, Avg Acc: 0.4032
2022-01-15 11:14:48,892 Epoch[076/300], Step[0100/1252], Avg Loss: 3.6728, Avg Acc: 0.3977
2022-01-15 11:16:20,432 Epoch[076/300], Step[0150/1252], Avg Loss: 3.6685, Avg Acc: 0.4148
2022-01-15 11:17:51,216 Epoch[076/300], Step[0200/1252], Avg Loss: 3.6426, Avg Acc: 0.4080
2022-01-15 11:19:22,644 Epoch[076/300], Step[0250/1252], Avg Loss: 3.6123, Avg Acc: 0.3954
2022-01-15 11:20:54,479 Epoch[076/300], Step[0300/1252], Avg Loss: 3.6338, Avg Acc: 0.3915
2022-01-15 11:22:25,349 Epoch[076/300], Step[0350/1252], Avg Loss: 3.6337, Avg Acc: 0.3848
2022-01-15 11:23:58,086 Epoch[076/300], Step[0400/1252], Avg Loss: 3.6308, Avg Acc: 0.3852
2022-01-15 11:25:30,452 Epoch[076/300], Step[0450/1252], Avg Loss: 3.6358, Avg Acc: 0.3822
2022-01-15 11:27:01,309 Epoch[076/300], Step[0500/1252], Avg Loss: 3.6485, Avg Acc: 0.3785
2022-01-15 11:28:33,322 Epoch[076/300], Step[0550/1252], Avg Loss: 3.6560, Avg Acc: 0.3791
2022-01-15 11:30:04,735 Epoch[076/300], Step[0600/1252], Avg Loss: 3.6518, Avg Acc: 0.3828
2022-01-15 11:31:36,431 Epoch[076/300], Step[0650/1252], Avg Loss: 3.6438, Avg Acc: 0.3841
2022-01-15 11:33:08,122 Epoch[076/300], Step[0700/1252], Avg Loss: 3.6530, Avg Acc: 0.3819
2022-01-15 11:34:40,066 Epoch[076/300], Step[0750/1252], Avg Loss: 3.6478, Avg Acc: 0.3780
2022-01-15 11:36:10,556 Epoch[076/300], Step[0800/1252], Avg Loss: 3.6482, Avg Acc: 0.3731
2022-01-15 11:37:41,528 Epoch[076/300], Step[0850/1252], Avg Loss: 3.6474, Avg Acc: 0.3750
2022-01-15 11:39:12,389 Epoch[076/300], Step[0900/1252], Avg Loss: 3.6495, Avg Acc: 0.3729
2022-01-15 11:40:43,598 Epoch[076/300], Step[0950/1252], Avg Loss: 3.6513, Avg Acc: 0.3736
2022-01-15 11:42:15,544 Epoch[076/300], Step[1000/1252], Avg Loss: 3.6459, Avg Acc: 0.3776
2022-01-15 11:43:45,553 Epoch[076/300], Step[1050/1252], Avg Loss: 3.6518, Avg Acc: 0.3745
2022-01-15 11:45:17,602 Epoch[076/300], Step[1100/1252], Avg Loss: 3.6473, Avg Acc: 0.3771
2022-01-15 11:46:46,997 Epoch[076/300], Step[1150/1252], Avg Loss: 3.6510, Avg Acc: 0.3776
2022-01-15 11:48:17,976 Epoch[076/300], Step[1200/1252], Avg Loss: 3.6548, Avg Acc: 0.3766
2022-01-15 11:49:49,916 Epoch[076/300], Step[1250/1252], Avg Loss: 3.6522, Avg Acc: 0.3777
2022-01-15 11:49:56,569 ----- Epoch[076/300], Train Loss: 3.6523, Train Acc: 0.3777, time: 2402.75
2022-01-15 11:49:56,570 ----- Validation after Epoch: 76
2022-01-15 11:51:19,768 Val Step[0000/1563], Avg Loss: 1.3188, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 11:51:21,921 Val Step[0050/1563], Avg Loss: 1.3322, Avg Acc@1: 0.7132, Avg Acc@5: 0.9167
2022-01-15 11:51:24,116 Val Step[0100/1563], Avg Loss: 1.3951, Avg Acc@1: 0.6993, Avg Acc@5: 0.9109
2022-01-15 11:51:26,355 Val Step[0150/1563], Avg Loss: 1.4918, Avg Acc@1: 0.6796, Avg Acc@5: 0.8924
2022-01-15 11:51:28,675 Val Step[0200/1563], Avg Loss: 1.4648, Avg Acc@1: 0.6872, Avg Acc@5: 0.8937
2022-01-15 11:51:30,919 Val Step[0250/1563], Avg Loss: 1.4654, Avg Acc@1: 0.6907, Avg Acc@5: 0.8924
2022-01-15 11:51:33,081 Val Step[0300/1563], Avg Loss: 1.4647, Avg Acc@1: 0.6923, Avg Acc@5: 0.8941
2022-01-15 11:51:35,222 Val Step[0350/1563], Avg Loss: 1.4858, Avg Acc@1: 0.6895, Avg Acc@5: 0.8892
2022-01-15 11:51:37,363 Val Step[0400/1563], Avg Loss: 1.4699, Avg Acc@1: 0.6917, Avg Acc@5: 0.8915
2022-01-15 11:51:39,326 Val Step[0450/1563], Avg Loss: 1.4766, Avg Acc@1: 0.6885, Avg Acc@5: 0.8911
2022-01-15 11:51:41,216 Val Step[0500/1563], Avg Loss: 1.4792, Avg Acc@1: 0.6851, Avg Acc@5: 0.8907
2022-01-15 11:51:43,161 Val Step[0550/1563], Avg Loss: 1.4729, Avg Acc@1: 0.6869, Avg Acc@5: 0.8931
2022-01-15 11:51:45,130 Val Step[0600/1563], Avg Loss: 1.4697, Avg Acc@1: 0.6870, Avg Acc@5: 0.8929
2022-01-15 11:51:47,084 Val Step[0650/1563], Avg Loss: 1.4666, Avg Acc@1: 0.6876, Avg Acc@5: 0.8940
2022-01-15 11:51:49,047 Val Step[0700/1563], Avg Loss: 1.4613, Avg Acc@1: 0.6887, Avg Acc@5: 0.8943
2022-01-15 11:51:51,026 Val Step[0750/1563], Avg Loss: 1.4709, Avg Acc@1: 0.6869, Avg Acc@5: 0.8936
2022-01-15 11:51:53,070 Val Step[0800/1563], Avg Loss: 1.4739, Avg Acc@1: 0.6879, Avg Acc@5: 0.8926
2022-01-15 11:51:55,001 Val Step[0850/1563], Avg Loss: 1.4767, Avg Acc@1: 0.6865, Avg Acc@5: 0.8920
2022-01-15 11:51:56,920 Val Step[0900/1563], Avg Loss: 1.4699, Avg Acc@1: 0.6895, Avg Acc@5: 0.8925
2022-01-15 11:51:58,877 Val Step[0950/1563], Avg Loss: 1.4650, Avg Acc@1: 0.6903, Avg Acc@5: 0.8935
2022-01-15 11:52:00,888 Val Step[1000/1563], Avg Loss: 1.4660, Avg Acc@1: 0.6896, Avg Acc@5: 0.8942
2022-01-15 11:52:02,853 Val Step[1050/1563], Avg Loss: 1.4679, Avg Acc@1: 0.6889, Avg Acc@5: 0.8937
2022-01-15 11:52:04,842 Val Step[1100/1563], Avg Loss: 1.4737, Avg Acc@1: 0.6880, Avg Acc@5: 0.8934
2022-01-15 11:52:06,763 Val Step[1150/1563], Avg Loss: 1.4744, Avg Acc@1: 0.6882, Avg Acc@5: 0.8929
2022-01-15 11:52:08,717 Val Step[1200/1563], Avg Loss: 1.4682, Avg Acc@1: 0.6900, Avg Acc@5: 0.8940
2022-01-15 11:52:10,685 Val Step[1250/1563], Avg Loss: 1.4683, Avg Acc@1: 0.6902, Avg Acc@5: 0.8938
2022-01-15 11:52:12,606 Val Step[1300/1563], Avg Loss: 1.4718, Avg Acc@1: 0.6894, Avg Acc@5: 0.8928
2022-01-15 11:52:14,680 Val Step[1350/1563], Avg Loss: 1.4749, Avg Acc@1: 0.6894, Avg Acc@5: 0.8921
2022-01-15 11:52:16,816 Val Step[1400/1563], Avg Loss: 1.4745, Avg Acc@1: 0.6893, Avg Acc@5: 0.8921
2022-01-15 11:52:18,983 Val Step[1450/1563], Avg Loss: 1.4737, Avg Acc@1: 0.6890, Avg Acc@5: 0.8921
2022-01-15 11:52:21,178 Val Step[1500/1563], Avg Loss: 1.4734, Avg Acc@1: 0.6889, Avg Acc@5: 0.8925
2022-01-15 11:52:23,387 Val Step[1550/1563], Avg Loss: 1.4752, Avg Acc@1: 0.6889, Avg Acc@5: 0.8921
2022-01-15 11:52:25,323 ----- Epoch[076/300], Validation Loss: 1.4800, Validation Acc@1: 0.6874, Validation Acc@5: 0.8917, time: 148.75
2022-01-15 11:52:25,324 Now training epoch 77. LR=0.000902
2022-01-15 11:54:22,808 Epoch[077/300], Step[0000/1252], Avg Loss: 4.1907, Avg Acc: 0.3672
2022-01-15 11:55:52,848 Epoch[077/300], Step[0050/1252], Avg Loss: 3.6459, Avg Acc: 0.3560
2022-01-15 11:57:22,635 Epoch[077/300], Step[0100/1252], Avg Loss: 3.6967, Avg Acc: 0.3699
2022-01-15 11:58:54,764 Epoch[077/300], Step[0150/1252], Avg Loss: 3.6666, Avg Acc: 0.3588
2022-01-15 12:00:23,821 Epoch[077/300], Step[0200/1252], Avg Loss: 3.6701, Avg Acc: 0.3592
2022-01-15 12:01:55,096 Epoch[077/300], Step[0250/1252], Avg Loss: 3.6686, Avg Acc: 0.3584
2022-01-15 12:03:27,186 Epoch[077/300], Step[0300/1252], Avg Loss: 3.6690, Avg Acc: 0.3601
2022-01-15 12:04:57,714 Epoch[077/300], Step[0350/1252], Avg Loss: 3.6834, Avg Acc: 0.3610
2022-01-15 12:06:28,810 Epoch[077/300], Step[0400/1252], Avg Loss: 3.6833, Avg Acc: 0.3632
2022-01-15 12:07:59,736 Epoch[077/300], Step[0450/1252], Avg Loss: 3.6946, Avg Acc: 0.3684
2022-01-15 12:09:31,608 Epoch[077/300], Step[0500/1252], Avg Loss: 3.6942, Avg Acc: 0.3633
2022-01-15 12:11:02,908 Epoch[077/300], Step[0550/1252], Avg Loss: 3.6798, Avg Acc: 0.3668
2022-01-15 12:12:33,136 Epoch[077/300], Step[0600/1252], Avg Loss: 3.6678, Avg Acc: 0.3649
2022-01-15 12:14:03,790 Epoch[077/300], Step[0650/1252], Avg Loss: 3.6707, Avg Acc: 0.3660
2022-01-15 12:15:33,616 Epoch[077/300], Step[0700/1252], Avg Loss: 3.6741, Avg Acc: 0.3633
2022-01-15 12:17:04,372 Epoch[077/300], Step[0750/1252], Avg Loss: 3.6784, Avg Acc: 0.3621
2022-01-15 12:18:34,308 Epoch[077/300], Step[0800/1252], Avg Loss: 3.6812, Avg Acc: 0.3613
2022-01-15 12:20:04,139 Epoch[077/300], Step[0850/1252], Avg Loss: 3.6858, Avg Acc: 0.3610
2022-01-15 12:21:34,129 Epoch[077/300], Step[0900/1252], Avg Loss: 3.6802, Avg Acc: 0.3634
2022-01-15 12:23:05,846 Epoch[077/300], Step[0950/1252], Avg Loss: 3.6721, Avg Acc: 0.3643
2022-01-15 12:24:37,147 Epoch[077/300], Step[1000/1252], Avg Loss: 3.6646, Avg Acc: 0.3665
2022-01-15 12:26:06,721 Epoch[077/300], Step[1050/1252], Avg Loss: 3.6588, Avg Acc: 0.3673
2022-01-15 12:27:36,393 Epoch[077/300], Step[1100/1252], Avg Loss: 3.6628, Avg Acc: 0.3676
2022-01-15 12:29:05,225 Epoch[077/300], Step[1150/1252], Avg Loss: 3.6642, Avg Acc: 0.3685
2022-01-15 12:30:35,418 Epoch[077/300], Step[1200/1252], Avg Loss: 3.6627, Avg Acc: 0.3690
2022-01-15 12:32:06,013 Epoch[077/300], Step[1250/1252], Avg Loss: 3.6732, Avg Acc: 0.3678
2022-01-15 12:32:12,362 ----- Epoch[077/300], Train Loss: 3.6730, Train Acc: 0.3678, time: 2387.03
2022-01-15 12:32:12,363 Now training epoch 78. LR=0.000899
2022-01-15 12:34:02,402 Epoch[078/300], Step[0000/1252], Avg Loss: 4.2928, Avg Acc: 0.3359
2022-01-15 12:35:31,252 Epoch[078/300], Step[0050/1252], Avg Loss: 3.6848, Avg Acc: 0.3794
2022-01-15 12:37:00,058 Epoch[078/300], Step[0100/1252], Avg Loss: 3.6483, Avg Acc: 0.3777
2022-01-15 12:38:29,216 Epoch[078/300], Step[0150/1252], Avg Loss: 3.6459, Avg Acc: 0.3568
2022-01-15 12:39:59,951 Epoch[078/300], Step[0200/1252], Avg Loss: 3.6227, Avg Acc: 0.3611
2022-01-15 12:41:29,929 Epoch[078/300], Step[0250/1252], Avg Loss: 3.6093, Avg Acc: 0.3636
2022-01-15 12:43:01,713 Epoch[078/300], Step[0300/1252], Avg Loss: 3.6067, Avg Acc: 0.3690
2022-01-15 12:44:32,383 Epoch[078/300], Step[0350/1252], Avg Loss: 3.6196, Avg Acc: 0.3668
2022-01-15 12:46:03,417 Epoch[078/300], Step[0400/1252], Avg Loss: 3.6306, Avg Acc: 0.3622
2022-01-15 12:47:33,972 Epoch[078/300], Step[0450/1252], Avg Loss: 3.6276, Avg Acc: 0.3648
2022-01-15 12:49:05,888 Epoch[078/300], Step[0500/1252], Avg Loss: 3.6292, Avg Acc: 0.3616
2022-01-15 12:50:35,544 Epoch[078/300], Step[0550/1252], Avg Loss: 3.6338, Avg Acc: 0.3660
2022-01-15 12:52:06,803 Epoch[078/300], Step[0600/1252], Avg Loss: 3.6446, Avg Acc: 0.3640
2022-01-15 12:53:37,935 Epoch[078/300], Step[0650/1252], Avg Loss: 3.6398, Avg Acc: 0.3647
2022-01-15 12:55:08,780 Epoch[078/300], Step[0700/1252], Avg Loss: 3.6403, Avg Acc: 0.3659
2022-01-15 12:56:40,317 Epoch[078/300], Step[0750/1252], Avg Loss: 3.6395, Avg Acc: 0.3650
2022-01-15 12:58:10,808 Epoch[078/300], Step[0800/1252], Avg Loss: 3.6386, Avg Acc: 0.3680
2022-01-15 12:59:42,435 Epoch[078/300], Step[0850/1252], Avg Loss: 3.6415, Avg Acc: 0.3660
2022-01-15 13:01:14,020 Epoch[078/300], Step[0900/1252], Avg Loss: 3.6445, Avg Acc: 0.3671
2022-01-15 13:02:45,888 Epoch[078/300], Step[0950/1252], Avg Loss: 3.6434, Avg Acc: 0.3635
2022-01-15 13:04:17,050 Epoch[078/300], Step[1000/1252], Avg Loss: 3.6469, Avg Acc: 0.3626
2022-01-15 13:05:49,247 Epoch[078/300], Step[1050/1252], Avg Loss: 3.6454, Avg Acc: 0.3608
2022-01-15 13:07:21,230 Epoch[078/300], Step[1100/1252], Avg Loss: 3.6516, Avg Acc: 0.3575
2022-01-15 13:08:52,662 Epoch[078/300], Step[1150/1252], Avg Loss: 3.6509, Avg Acc: 0.3590
2022-01-15 13:10:23,053 Epoch[078/300], Step[1200/1252], Avg Loss: 3.6491, Avg Acc: 0.3591
2022-01-15 13:11:54,427 Epoch[078/300], Step[1250/1252], Avg Loss: 3.6522, Avg Acc: 0.3592
2022-01-15 13:12:01,410 ----- Epoch[078/300], Train Loss: 3.6521, Train Acc: 0.3592, time: 2389.04
2022-01-15 13:12:01,412 ----- Validation after Epoch: 78
2022-01-15 13:13:17,573 Val Step[0000/1563], Avg Loss: 1.0064, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 13:13:19,593 Val Step[0050/1563], Avg Loss: 1.2772, Avg Acc@1: 0.7230, Avg Acc@5: 0.9191
2022-01-15 13:13:21,919 Val Step[0100/1563], Avg Loss: 1.2866, Avg Acc@1: 0.7079, Avg Acc@5: 0.9220
2022-01-15 13:13:24,109 Val Step[0150/1563], Avg Loss: 1.3724, Avg Acc@1: 0.6929, Avg Acc@5: 0.9031
2022-01-15 13:13:26,262 Val Step[0200/1563], Avg Loss: 1.3598, Avg Acc@1: 0.6984, Avg Acc@5: 0.9030
2022-01-15 13:13:28,475 Val Step[0250/1563], Avg Loss: 1.3702, Avg Acc@1: 0.6912, Avg Acc@5: 0.8999
2022-01-15 13:13:30,573 Val Step[0300/1563], Avg Loss: 1.3766, Avg Acc@1: 0.6944, Avg Acc@5: 0.8978
2022-01-15 13:13:32,537 Val Step[0350/1563], Avg Loss: 1.4056, Avg Acc@1: 0.6873, Avg Acc@5: 0.8939
2022-01-15 13:13:34,556 Val Step[0400/1563], Avg Loss: 1.3952, Avg Acc@1: 0.6870, Avg Acc@5: 0.8950
2022-01-15 13:13:36,449 Val Step[0450/1563], Avg Loss: 1.4055, Avg Acc@1: 0.6851, Avg Acc@5: 0.8927
2022-01-15 13:13:38,492 Val Step[0500/1563], Avg Loss: 1.4072, Avg Acc@1: 0.6824, Avg Acc@5: 0.8915
2022-01-15 13:13:40,547 Val Step[0550/1563], Avg Loss: 1.3965, Avg Acc@1: 0.6853, Avg Acc@5: 0.8922
2022-01-15 13:13:42,548 Val Step[0600/1563], Avg Loss: 1.3916, Avg Acc@1: 0.6864, Avg Acc@5: 0.8931
2022-01-15 13:13:44,582 Val Step[0650/1563], Avg Loss: 1.3905, Avg Acc@1: 0.6870, Avg Acc@5: 0.8927
2022-01-15 13:13:46,531 Val Step[0700/1563], Avg Loss: 1.3885, Avg Acc@1: 0.6879, Avg Acc@5: 0.8925
2022-01-15 13:13:48,454 Val Step[0750/1563], Avg Loss: 1.3953, Avg Acc@1: 0.6869, Avg Acc@5: 0.8916
2022-01-15 13:13:50,482 Val Step[0800/1563], Avg Loss: 1.3985, Avg Acc@1: 0.6879, Avg Acc@5: 0.8904
2022-01-15 13:13:52,392 Val Step[0850/1563], Avg Loss: 1.4013, Avg Acc@1: 0.6865, Avg Acc@5: 0.8901
2022-01-15 13:13:54,370 Val Step[0900/1563], Avg Loss: 1.3950, Avg Acc@1: 0.6891, Avg Acc@5: 0.8905
2022-01-15 13:13:56,301 Val Step[0950/1563], Avg Loss: 1.3895, Avg Acc@1: 0.6899, Avg Acc@5: 0.8916
2022-01-15 13:13:58,384 Val Step[1000/1563], Avg Loss: 1.3885, Avg Acc@1: 0.6902, Avg Acc@5: 0.8922
2022-01-15 13:14:00,349 Val Step[1050/1563], Avg Loss: 1.3914, Avg Acc@1: 0.6896, Avg Acc@5: 0.8909
2022-01-15 13:14:02,346 Val Step[1100/1563], Avg Loss: 1.3993, Avg Acc@1: 0.6886, Avg Acc@5: 0.8895
2022-01-15 13:14:04,296 Val Step[1150/1563], Avg Loss: 1.4015, Avg Acc@1: 0.6885, Avg Acc@5: 0.8888
2022-01-15 13:14:06,265 Val Step[1200/1563], Avg Loss: 1.3959, Avg Acc@1: 0.6894, Avg Acc@5: 0.8901
2022-01-15 13:14:08,161 Val Step[1250/1563], Avg Loss: 1.3975, Avg Acc@1: 0.6891, Avg Acc@5: 0.8899
2022-01-15 13:14:10,182 Val Step[1300/1563], Avg Loss: 1.4001, Avg Acc@1: 0.6887, Avg Acc@5: 0.8897
2022-01-15 13:14:12,121 Val Step[1350/1563], Avg Loss: 1.4049, Avg Acc@1: 0.6879, Avg Acc@5: 0.8893
2022-01-15 13:14:14,137 Val Step[1400/1563], Avg Loss: 1.4040, Avg Acc@1: 0.6888, Avg Acc@5: 0.8899
2022-01-15 13:14:16,037 Val Step[1450/1563], Avg Loss: 1.4006, Avg Acc@1: 0.6890, Avg Acc@5: 0.8910
2022-01-15 13:14:18,085 Val Step[1500/1563], Avg Loss: 1.4008, Avg Acc@1: 0.6885, Avg Acc@5: 0.8910
2022-01-15 13:14:20,003 Val Step[1550/1563], Avg Loss: 1.4015, Avg Acc@1: 0.6882, Avg Acc@5: 0.8910
2022-01-15 13:14:22,043 ----- Epoch[078/300], Validation Loss: 1.4038, Validation Acc@1: 0.6874, Validation Acc@5: 0.8911, time: 140.63
2022-01-15 13:14:22,044 Now training epoch 79. LR=0.000895
2022-01-15 13:16:18,123 Epoch[079/300], Step[0000/1252], Avg Loss: 3.9347, Avg Acc: 0.5703
2022-01-15 13:17:49,477 Epoch[079/300], Step[0050/1252], Avg Loss: 3.5853, Avg Acc: 0.4088
2022-01-15 13:19:19,693 Epoch[079/300], Step[0100/1252], Avg Loss: 3.5839, Avg Acc: 0.4004
2022-01-15 13:20:50,660 Epoch[079/300], Step[0150/1252], Avg Loss: 3.6269, Avg Acc: 0.3752
2022-01-15 13:22:21,490 Epoch[079/300], Step[0200/1252], Avg Loss: 3.6107, Avg Acc: 0.3771
2022-01-15 13:23:52,856 Epoch[079/300], Step[0250/1252], Avg Loss: 3.6348, Avg Acc: 0.3641
2022-01-15 13:25:23,753 Epoch[079/300], Step[0300/1252], Avg Loss: 3.6366, Avg Acc: 0.3726
2022-01-15 13:26:55,302 Epoch[079/300], Step[0350/1252], Avg Loss: 3.6220, Avg Acc: 0.3712
2022-01-15 13:28:26,203 Epoch[079/300], Step[0400/1252], Avg Loss: 3.6355, Avg Acc: 0.3641
2022-01-15 13:29:58,343 Epoch[079/300], Step[0450/1252], Avg Loss: 3.6517, Avg Acc: 0.3645
2022-01-15 13:31:30,319 Epoch[079/300], Step[0500/1252], Avg Loss: 3.6556, Avg Acc: 0.3618
2022-01-15 13:33:02,006 Epoch[079/300], Step[0550/1252], Avg Loss: 3.6582, Avg Acc: 0.3635
2022-01-15 13:34:33,703 Epoch[079/300], Step[0600/1252], Avg Loss: 3.6628, Avg Acc: 0.3629
2022-01-15 13:36:05,173 Epoch[079/300], Step[0650/1252], Avg Loss: 3.6717, Avg Acc: 0.3615
2022-01-15 13:37:35,917 Epoch[079/300], Step[0700/1252], Avg Loss: 3.6782, Avg Acc: 0.3631
2022-01-15 13:39:06,323 Epoch[079/300], Step[0750/1252], Avg Loss: 3.6721, Avg Acc: 0.3598
2022-01-15 13:40:36,907 Epoch[079/300], Step[0800/1252], Avg Loss: 3.6715, Avg Acc: 0.3579
2022-01-15 13:42:07,134 Epoch[079/300], Step[0850/1252], Avg Loss: 3.6717, Avg Acc: 0.3615
2022-01-15 13:43:39,372 Epoch[079/300], Step[0900/1252], Avg Loss: 3.6649, Avg Acc: 0.3632
2022-01-15 13:45:10,266 Epoch[079/300], Step[0950/1252], Avg Loss: 3.6687, Avg Acc: 0.3629
2022-01-15 13:46:40,314 Epoch[079/300], Step[1000/1252], Avg Loss: 3.6707, Avg Acc: 0.3626
2022-01-15 13:48:12,055 Epoch[079/300], Step[1050/1252], Avg Loss: 3.6642, Avg Acc: 0.3632
2022-01-15 13:49:43,122 Epoch[079/300], Step[1100/1252], Avg Loss: 3.6630, Avg Acc: 0.3628
2022-01-15 13:51:14,152 Epoch[079/300], Step[1150/1252], Avg Loss: 3.6610, Avg Acc: 0.3625
2022-01-15 13:52:44,772 Epoch[079/300], Step[1200/1252], Avg Loss: 3.6627, Avg Acc: 0.3629
2022-01-15 13:54:17,172 Epoch[079/300], Step[1250/1252], Avg Loss: 3.6609, Avg Acc: 0.3629
2022-01-15 13:54:24,281 ----- Epoch[079/300], Train Loss: 3.6608, Train Acc: 0.3629, time: 2402.23
2022-01-15 13:54:24,282 Now training epoch 80. LR=0.000892
2022-01-15 13:56:15,265 Epoch[080/300], Step[0000/1252], Avg Loss: 4.0764, Avg Acc: 0.2656
2022-01-15 13:57:45,085 Epoch[080/300], Step[0050/1252], Avg Loss: 3.6589, Avg Acc: 0.3585
2022-01-15 13:59:13,928 Epoch[080/300], Step[0100/1252], Avg Loss: 3.6221, Avg Acc: 0.3639
2022-01-15 14:00:43,758 Epoch[080/300], Step[0150/1252], Avg Loss: 3.6742, Avg Acc: 0.3563
2022-01-15 14:02:13,858 Epoch[080/300], Step[0200/1252], Avg Loss: 3.6731, Avg Acc: 0.3592
2022-01-15 14:03:43,224 Epoch[080/300], Step[0250/1252], Avg Loss: 3.6729, Avg Acc: 0.3562
2022-01-15 14:05:13,826 Epoch[080/300], Step[0300/1252], Avg Loss: 3.6509, Avg Acc: 0.3478
2022-01-15 14:06:43,596 Epoch[080/300], Step[0350/1252], Avg Loss: 3.6448, Avg Acc: 0.3571
2022-01-15 14:08:12,941 Epoch[080/300], Step[0400/1252], Avg Loss: 3.6381, Avg Acc: 0.3505
2022-01-15 14:09:42,943 Epoch[080/300], Step[0450/1252], Avg Loss: 3.6626, Avg Acc: 0.3496
2022-01-15 14:11:13,432 Epoch[080/300], Step[0500/1252], Avg Loss: 3.6482, Avg Acc: 0.3546
2022-01-15 14:12:44,081 Epoch[080/300], Step[0550/1252], Avg Loss: 3.6595, Avg Acc: 0.3578
2022-01-15 14:14:14,346 Epoch[080/300], Step[0600/1252], Avg Loss: 3.6692, Avg Acc: 0.3610
2022-01-15 14:15:45,950 Epoch[080/300], Step[0650/1252], Avg Loss: 3.6702, Avg Acc: 0.3611
2022-01-15 14:17:17,337 Epoch[080/300], Step[0700/1252], Avg Loss: 3.6761, Avg Acc: 0.3583
2022-01-15 14:18:49,293 Epoch[080/300], Step[0750/1252], Avg Loss: 3.6800, Avg Acc: 0.3596
2022-01-15 14:20:18,581 Epoch[080/300], Step[0800/1252], Avg Loss: 3.6825, Avg Acc: 0.3588
2022-01-15 14:21:49,903 Epoch[080/300], Step[0850/1252], Avg Loss: 3.6833, Avg Acc: 0.3599
2022-01-15 14:23:21,290 Epoch[080/300], Step[0900/1252], Avg Loss: 3.6832, Avg Acc: 0.3604
2022-01-15 14:24:51,997 Epoch[080/300], Step[0950/1252], Avg Loss: 3.6833, Avg Acc: 0.3596
2022-01-15 14:26:24,339 Epoch[080/300], Step[1000/1252], Avg Loss: 3.6848, Avg Acc: 0.3609
2022-01-15 14:27:55,066 Epoch[080/300], Step[1050/1252], Avg Loss: 3.6819, Avg Acc: 0.3604
2022-01-15 14:29:25,979 Epoch[080/300], Step[1100/1252], Avg Loss: 3.6774, Avg Acc: 0.3599
2022-01-15 14:30:55,848 Epoch[080/300], Step[1150/1252], Avg Loss: 3.6745, Avg Acc: 0.3604
2022-01-15 14:32:27,963 Epoch[080/300], Step[1200/1252], Avg Loss: 3.6741, Avg Acc: 0.3624
2022-01-15 14:33:58,613 Epoch[080/300], Step[1250/1252], Avg Loss: 3.6730, Avg Acc: 0.3630
2022-01-15 14:34:05,751 ----- Epoch[080/300], Train Loss: 3.6729, Train Acc: 0.3629, time: 2381.47
2022-01-15 14:34:05,752 ----- Validation after Epoch: 80
2022-01-15 14:35:30,877 Val Step[0000/1563], Avg Loss: 1.1554, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-15 14:35:33,118 Val Step[0050/1563], Avg Loss: 1.3274, Avg Acc@1: 0.7059, Avg Acc@5: 0.9216
2022-01-15 14:35:35,496 Val Step[0100/1563], Avg Loss: 1.3556, Avg Acc@1: 0.6955, Avg Acc@5: 0.9109
2022-01-15 14:35:37,613 Val Step[0150/1563], Avg Loss: 1.4486, Avg Acc@1: 0.6829, Avg Acc@5: 0.8949
2022-01-15 14:35:39,720 Val Step[0200/1563], Avg Loss: 1.4225, Avg Acc@1: 0.6903, Avg Acc@5: 0.8968
2022-01-15 14:35:41,852 Val Step[0250/1563], Avg Loss: 1.4120, Avg Acc@1: 0.6942, Avg Acc@5: 0.8969
2022-01-15 14:35:44,005 Val Step[0300/1563], Avg Loss: 1.4217, Avg Acc@1: 0.6914, Avg Acc@5: 0.8949
2022-01-15 14:35:46,201 Val Step[0350/1563], Avg Loss: 1.4423, Avg Acc@1: 0.6895, Avg Acc@5: 0.8917
2022-01-15 14:35:48,394 Val Step[0400/1563], Avg Loss: 1.4335, Avg Acc@1: 0.6914, Avg Acc@5: 0.8925
2022-01-15 14:35:50,487 Val Step[0450/1563], Avg Loss: 1.4397, Avg Acc@1: 0.6879, Avg Acc@5: 0.8919
2022-01-15 14:35:52,660 Val Step[0500/1563], Avg Loss: 1.4454, Avg Acc@1: 0.6819, Avg Acc@5: 0.8895
2022-01-15 14:35:54,805 Val Step[0550/1563], Avg Loss: 1.4400, Avg Acc@1: 0.6828, Avg Acc@5: 0.8920
2022-01-15 14:35:56,910 Val Step[0600/1563], Avg Loss: 1.4390, Avg Acc@1: 0.6828, Avg Acc@5: 0.8902
2022-01-15 14:35:59,007 Val Step[0650/1563], Avg Loss: 1.4385, Avg Acc@1: 0.6834, Avg Acc@5: 0.8906
2022-01-15 14:36:01,185 Val Step[0700/1563], Avg Loss: 1.4373, Avg Acc@1: 0.6847, Avg Acc@5: 0.8900
2022-01-15 14:36:03,261 Val Step[0750/1563], Avg Loss: 1.4480, Avg Acc@1: 0.6819, Avg Acc@5: 0.8893
2022-01-15 14:36:05,284 Val Step[0800/1563], Avg Loss: 1.4475, Avg Acc@1: 0.6834, Avg Acc@5: 0.8894
2022-01-15 14:36:07,412 Val Step[0850/1563], Avg Loss: 1.4504, Avg Acc@1: 0.6826, Avg Acc@5: 0.8888
2022-01-15 14:36:09,414 Val Step[0900/1563], Avg Loss: 1.4435, Avg Acc@1: 0.6853, Avg Acc@5: 0.8898
2022-01-15 14:36:11,426 Val Step[0950/1563], Avg Loss: 1.4380, Avg Acc@1: 0.6865, Avg Acc@5: 0.8904
2022-01-15 14:36:13,466 Val Step[1000/1563], Avg Loss: 1.4365, Avg Acc@1: 0.6872, Avg Acc@5: 0.8901
2022-01-15 14:36:15,446 Val Step[1050/1563], Avg Loss: 1.4370, Avg Acc@1: 0.6871, Avg Acc@5: 0.8893
2022-01-15 14:36:17,437 Val Step[1100/1563], Avg Loss: 1.4475, Avg Acc@1: 0.6846, Avg Acc@5: 0.8882
2022-01-15 14:36:19,374 Val Step[1150/1563], Avg Loss: 1.4489, Avg Acc@1: 0.6841, Avg Acc@5: 0.8873
2022-01-15 14:36:21,541 Val Step[1200/1563], Avg Loss: 1.4439, Avg Acc@1: 0.6852, Avg Acc@5: 0.8883
2022-01-15 14:36:23,697 Val Step[1250/1563], Avg Loss: 1.4416, Avg Acc@1: 0.6858, Avg Acc@5: 0.8885
2022-01-15 14:36:25,906 Val Step[1300/1563], Avg Loss: 1.4462, Avg Acc@1: 0.6850, Avg Acc@5: 0.8876
2022-01-15 14:36:28,015 Val Step[1350/1563], Avg Loss: 1.4516, Avg Acc@1: 0.6842, Avg Acc@5: 0.8871
2022-01-15 14:36:30,041 Val Step[1400/1563], Avg Loss: 1.4519, Avg Acc@1: 0.6842, Avg Acc@5: 0.8871
2022-01-15 14:36:32,123 Val Step[1450/1563], Avg Loss: 1.4503, Avg Acc@1: 0.6845, Avg Acc@5: 0.8875
2022-01-15 14:36:34,169 Val Step[1500/1563], Avg Loss: 1.4498, Avg Acc@1: 0.6838, Avg Acc@5: 0.8880
2022-01-15 14:36:35,989 Val Step[1550/1563], Avg Loss: 1.4505, Avg Acc@1: 0.6838, Avg Acc@5: 0.8876
2022-01-15 14:36:37,847 ----- Epoch[080/300], Validation Loss: 1.4540, Validation Acc@1: 0.6830, Validation Acc@5: 0.8873, time: 152.09
2022-01-15 14:36:37,848 Now training epoch 81. LR=0.000889
2022-01-15 14:38:33,891 Epoch[081/300], Step[0000/1252], Avg Loss: 2.5446, Avg Acc: 0.0039
2022-01-15 14:40:02,415 Epoch[081/300], Step[0050/1252], Avg Loss: 3.6278, Avg Acc: 0.3663
2022-01-15 14:41:31,540 Epoch[081/300], Step[0100/1252], Avg Loss: 3.6621, Avg Acc: 0.3627
2022-01-15 14:43:01,139 Epoch[081/300], Step[0150/1252], Avg Loss: 3.6560, Avg Acc: 0.3603
2022-01-15 14:44:30,230 Epoch[081/300], Step[0200/1252], Avg Loss: 3.6438, Avg Acc: 0.3626
2022-01-15 14:46:00,780 Epoch[081/300], Step[0250/1252], Avg Loss: 3.6477, Avg Acc: 0.3635
2022-01-15 14:47:30,619 Epoch[081/300], Step[0300/1252], Avg Loss: 3.6502, Avg Acc: 0.3646
2022-01-15 14:49:01,181 Epoch[081/300], Step[0350/1252], Avg Loss: 3.6620, Avg Acc: 0.3675
2022-01-15 14:50:32,313 Epoch[081/300], Step[0400/1252], Avg Loss: 3.6465, Avg Acc: 0.3672
2022-01-15 14:52:03,262 Epoch[081/300], Step[0450/1252], Avg Loss: 3.6288, Avg Acc: 0.3679
2022-01-15 14:53:34,807 Epoch[081/300], Step[0500/1252], Avg Loss: 3.6307, Avg Acc: 0.3673
2022-01-15 14:55:04,912 Epoch[081/300], Step[0550/1252], Avg Loss: 3.6251, Avg Acc: 0.3676
2022-01-15 14:56:34,978 Epoch[081/300], Step[0600/1252], Avg Loss: 3.6226, Avg Acc: 0.3659
2022-01-15 14:58:05,093 Epoch[081/300], Step[0650/1252], Avg Loss: 3.6365, Avg Acc: 0.3677
2022-01-15 14:59:35,242 Epoch[081/300], Step[0700/1252], Avg Loss: 3.6377, Avg Acc: 0.3690
2022-01-15 15:01:05,102 Epoch[081/300], Step[0750/1252], Avg Loss: 3.6444, Avg Acc: 0.3676
2022-01-15 15:02:33,361 Epoch[081/300], Step[0800/1252], Avg Loss: 3.6539, Avg Acc: 0.3692
2022-01-15 15:04:01,958 Epoch[081/300], Step[0850/1252], Avg Loss: 3.6492, Avg Acc: 0.3697
2022-01-15 15:05:32,642 Epoch[081/300], Step[0900/1252], Avg Loss: 3.6448, Avg Acc: 0.3696
2022-01-15 15:07:03,892 Epoch[081/300], Step[0950/1252], Avg Loss: 3.6551, Avg Acc: 0.3678
2022-01-15 15:08:35,729 Epoch[081/300], Step[1000/1252], Avg Loss: 3.6491, Avg Acc: 0.3697
2022-01-15 15:10:06,484 Epoch[081/300], Step[1050/1252], Avg Loss: 3.6516, Avg Acc: 0.3704
2022-01-15 15:11:37,912 Epoch[081/300], Step[1100/1252], Avg Loss: 3.6541, Avg Acc: 0.3701
2022-01-15 15:13:08,195 Epoch[081/300], Step[1150/1252], Avg Loss: 3.6502, Avg Acc: 0.3698
2022-01-15 15:14:39,124 Epoch[081/300], Step[1200/1252], Avg Loss: 3.6457, Avg Acc: 0.3693
2022-01-15 15:16:10,146 Epoch[081/300], Step[1250/1252], Avg Loss: 3.6474, Avg Acc: 0.3690
2022-01-15 15:16:16,975 ----- Epoch[081/300], Train Loss: 3.6474, Train Acc: 0.3690, time: 2379.12
2022-01-15 15:16:16,977 Now training epoch 82. LR=0.000885
2022-01-15 15:18:10,501 Epoch[082/300], Step[0000/1252], Avg Loss: 3.1708, Avg Acc: 0.0039
2022-01-15 15:19:40,059 Epoch[082/300], Step[0050/1252], Avg Loss: 3.6779, Avg Acc: 0.3578
2022-01-15 15:21:11,130 Epoch[082/300], Step[0100/1252], Avg Loss: 3.7270, Avg Acc: 0.3702
2022-01-15 15:22:42,184 Epoch[082/300], Step[0150/1252], Avg Loss: 3.6890, Avg Acc: 0.3735
2022-01-15 15:24:13,515 Epoch[082/300], Step[0200/1252], Avg Loss: 3.6487, Avg Acc: 0.3762
2022-01-15 15:25:44,335 Epoch[082/300], Step[0250/1252], Avg Loss: 3.6506, Avg Acc: 0.3767
2022-01-15 15:27:14,696 Epoch[082/300], Step[0300/1252], Avg Loss: 3.6688, Avg Acc: 0.3815
2022-01-15 15:28:46,248 Epoch[082/300], Step[0350/1252], Avg Loss: 3.6651, Avg Acc: 0.3849
2022-01-15 15:30:18,110 Epoch[082/300], Step[0400/1252], Avg Loss: 3.6664, Avg Acc: 0.3771
2022-01-15 15:31:49,186 Epoch[082/300], Step[0450/1252], Avg Loss: 3.6737, Avg Acc: 0.3749
2022-01-15 15:33:21,244 Epoch[082/300], Step[0500/1252], Avg Loss: 3.6710, Avg Acc: 0.3723
2022-01-15 15:34:52,935 Epoch[082/300], Step[0550/1252], Avg Loss: 3.6608, Avg Acc: 0.3699
2022-01-15 15:36:24,939 Epoch[082/300], Step[0600/1252], Avg Loss: 3.6599, Avg Acc: 0.3703
2022-01-15 15:37:53,362 Epoch[082/300], Step[0650/1252], Avg Loss: 3.6506, Avg Acc: 0.3722
2022-01-15 15:39:24,135 Epoch[082/300], Step[0700/1252], Avg Loss: 3.6546, Avg Acc: 0.3702
2022-01-15 15:40:54,132 Epoch[082/300], Step[0750/1252], Avg Loss: 3.6596, Avg Acc: 0.3678
2022-01-15 15:42:24,647 Epoch[082/300], Step[0800/1252], Avg Loss: 3.6583, Avg Acc: 0.3685
2022-01-15 15:43:54,675 Epoch[082/300], Step[0850/1252], Avg Loss: 3.6614, Avg Acc: 0.3677
2022-01-15 15:45:23,585 Epoch[082/300], Step[0900/1252], Avg Loss: 3.6564, Avg Acc: 0.3708
2022-01-15 15:46:52,048 Epoch[082/300], Step[0950/1252], Avg Loss: 3.6579, Avg Acc: 0.3709
2022-01-15 15:48:23,791 Epoch[082/300], Step[1000/1252], Avg Loss: 3.6564, Avg Acc: 0.3700
2022-01-15 15:49:55,107 Epoch[082/300], Step[1050/1252], Avg Loss: 3.6514, Avg Acc: 0.3715
2022-01-15 15:51:27,072 Epoch[082/300], Step[1100/1252], Avg Loss: 3.6552, Avg Acc: 0.3707
2022-01-15 15:52:58,411 Epoch[082/300], Step[1150/1252], Avg Loss: 3.6592, Avg Acc: 0.3699
2022-01-15 15:54:28,411 Epoch[082/300], Step[1200/1252], Avg Loss: 3.6544, Avg Acc: 0.3727
2022-01-15 15:56:00,542 Epoch[082/300], Step[1250/1252], Avg Loss: 3.6537, Avg Acc: 0.3704
2022-01-15 15:56:07,617 ----- Epoch[082/300], Train Loss: 3.6538, Train Acc: 0.3704, time: 2390.64
2022-01-15 15:56:07,618 ----- Validation after Epoch: 82
2022-01-15 15:57:24,451 Val Step[0000/1563], Avg Loss: 1.1017, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 15:57:26,642 Val Step[0050/1563], Avg Loss: 1.3243, Avg Acc@1: 0.6961, Avg Acc@5: 0.9044
2022-01-15 15:57:28,616 Val Step[0100/1563], Avg Loss: 1.3166, Avg Acc@1: 0.6943, Avg Acc@5: 0.9097
2022-01-15 15:57:30,549 Val Step[0150/1563], Avg Loss: 1.3876, Avg Acc@1: 0.6896, Avg Acc@5: 0.8940
2022-01-15 15:57:32,554 Val Step[0200/1563], Avg Loss: 1.3739, Avg Acc@1: 0.6953, Avg Acc@5: 0.8943
2022-01-15 15:57:34,540 Val Step[0250/1563], Avg Loss: 1.3742, Avg Acc@1: 0.6957, Avg Acc@5: 0.8949
2022-01-15 15:57:36,530 Val Step[0300/1563], Avg Loss: 1.3837, Avg Acc@1: 0.6910, Avg Acc@5: 0.8933
2022-01-15 15:57:38,598 Val Step[0350/1563], Avg Loss: 1.4201, Avg Acc@1: 0.6838, Avg Acc@5: 0.8900
2022-01-15 15:57:40,516 Val Step[0400/1563], Avg Loss: 1.4059, Avg Acc@1: 0.6889, Avg Acc@5: 0.8909
2022-01-15 15:57:42,664 Val Step[0450/1563], Avg Loss: 1.4119, Avg Acc@1: 0.6868, Avg Acc@5: 0.8916
2022-01-15 15:57:44,753 Val Step[0500/1563], Avg Loss: 1.4158, Avg Acc@1: 0.6844, Avg Acc@5: 0.8920
2022-01-15 15:57:46,970 Val Step[0550/1563], Avg Loss: 1.4098, Avg Acc@1: 0.6876, Avg Acc@5: 0.8929
2022-01-15 15:57:49,030 Val Step[0600/1563], Avg Loss: 1.4063, Avg Acc@1: 0.6874, Avg Acc@5: 0.8935
2022-01-15 15:57:51,047 Val Step[0650/1563], Avg Loss: 1.4072, Avg Acc@1: 0.6872, Avg Acc@5: 0.8942
2022-01-15 15:57:52,981 Val Step[0700/1563], Avg Loss: 1.4040, Avg Acc@1: 0.6883, Avg Acc@5: 0.8939
2022-01-15 15:57:54,945 Val Step[0750/1563], Avg Loss: 1.4109, Avg Acc@1: 0.6864, Avg Acc@5: 0.8933
2022-01-15 15:57:56,956 Val Step[0800/1563], Avg Loss: 1.4136, Avg Acc@1: 0.6887, Avg Acc@5: 0.8914
2022-01-15 15:57:58,958 Val Step[0850/1563], Avg Loss: 1.4146, Avg Acc@1: 0.6886, Avg Acc@5: 0.8922
2022-01-15 15:58:01,026 Val Step[0900/1563], Avg Loss: 1.4064, Avg Acc@1: 0.6916, Avg Acc@5: 0.8925
2022-01-15 15:58:02,918 Val Step[0950/1563], Avg Loss: 1.4003, Avg Acc@1: 0.6930, Avg Acc@5: 0.8925
2022-01-15 15:58:04,912 Val Step[1000/1563], Avg Loss: 1.4012, Avg Acc@1: 0.6938, Avg Acc@5: 0.8922
2022-01-15 15:58:06,900 Val Step[1050/1563], Avg Loss: 1.4046, Avg Acc@1: 0.6933, Avg Acc@5: 0.8913
2022-01-15 15:58:08,806 Val Step[1100/1563], Avg Loss: 1.4127, Avg Acc@1: 0.6918, Avg Acc@5: 0.8902
2022-01-15 15:58:10,741 Val Step[1150/1563], Avg Loss: 1.4139, Avg Acc@1: 0.6914, Avg Acc@5: 0.8899
2022-01-15 15:58:12,654 Val Step[1200/1563], Avg Loss: 1.4092, Avg Acc@1: 0.6924, Avg Acc@5: 0.8906
2022-01-15 15:58:14,628 Val Step[1250/1563], Avg Loss: 1.4075, Avg Acc@1: 0.6924, Avg Acc@5: 0.8911
2022-01-15 15:58:16,565 Val Step[1300/1563], Avg Loss: 1.4092, Avg Acc@1: 0.6922, Avg Acc@5: 0.8909
2022-01-15 15:58:18,655 Val Step[1350/1563], Avg Loss: 1.4136, Avg Acc@1: 0.6914, Avg Acc@5: 0.8900
2022-01-15 15:58:20,769 Val Step[1400/1563], Avg Loss: 1.4139, Avg Acc@1: 0.6908, Avg Acc@5: 0.8903
2022-01-15 15:58:22,817 Val Step[1450/1563], Avg Loss: 1.4093, Avg Acc@1: 0.6912, Avg Acc@5: 0.8912
2022-01-15 15:58:24,875 Val Step[1500/1563], Avg Loss: 1.4107, Avg Acc@1: 0.6900, Avg Acc@5: 0.8906
2022-01-15 15:58:26,812 Val Step[1550/1563], Avg Loss: 1.4114, Avg Acc@1: 0.6895, Avg Acc@5: 0.8903
2022-01-15 15:58:28,912 ----- Epoch[082/300], Validation Loss: 1.4151, Validation Acc@1: 0.6880, Validation Acc@5: 0.8901, time: 141.29
2022-01-15 15:58:28,913 Now training epoch 83. LR=0.000881
2022-01-15 16:00:20,112 Epoch[083/300], Step[0000/1252], Avg Loss: 4.3600, Avg Acc: 0.3906
2022-01-15 16:01:51,660 Epoch[083/300], Step[0050/1252], Avg Loss: 3.6881, Avg Acc: 0.3722
2022-01-15 16:03:21,938 Epoch[083/300], Step[0100/1252], Avg Loss: 3.6742, Avg Acc: 0.3956
2022-01-15 16:04:51,791 Epoch[083/300], Step[0150/1252], Avg Loss: 3.6439, Avg Acc: 0.3970
2022-01-15 16:06:22,511 Epoch[083/300], Step[0200/1252], Avg Loss: 3.6335, Avg Acc: 0.3987
2022-01-15 16:07:54,236 Epoch[083/300], Step[0250/1252], Avg Loss: 3.6387, Avg Acc: 0.3933
2022-01-15 16:09:25,620 Epoch[083/300], Step[0300/1252], Avg Loss: 3.6405, Avg Acc: 0.3937
2022-01-15 16:10:55,855 Epoch[083/300], Step[0350/1252], Avg Loss: 3.6351, Avg Acc: 0.3896
2022-01-15 16:12:26,278 Epoch[083/300], Step[0400/1252], Avg Loss: 3.6267, Avg Acc: 0.3910
2022-01-15 16:13:57,168 Epoch[083/300], Step[0450/1252], Avg Loss: 3.6167, Avg Acc: 0.3915
2022-01-15 16:15:28,085 Epoch[083/300], Step[0500/1252], Avg Loss: 3.6227, Avg Acc: 0.3877
2022-01-15 16:16:58,734 Epoch[083/300], Step[0550/1252], Avg Loss: 3.6135, Avg Acc: 0.3883
2022-01-15 16:18:30,257 Epoch[083/300], Step[0600/1252], Avg Loss: 3.6211, Avg Acc: 0.3827
2022-01-15 16:20:01,078 Epoch[083/300], Step[0650/1252], Avg Loss: 3.6242, Avg Acc: 0.3844
2022-01-15 16:21:31,987 Epoch[083/300], Step[0700/1252], Avg Loss: 3.6371, Avg Acc: 0.3821
2022-01-15 16:23:03,170 Epoch[083/300], Step[0750/1252], Avg Loss: 3.6439, Avg Acc: 0.3784
2022-01-15 16:24:34,606 Epoch[083/300], Step[0800/1252], Avg Loss: 3.6479, Avg Acc: 0.3790
2022-01-15 16:26:06,019 Epoch[083/300], Step[0850/1252], Avg Loss: 3.6480, Avg Acc: 0.3765
2022-01-15 16:27:36,128 Epoch[083/300], Step[0900/1252], Avg Loss: 3.6469, Avg Acc: 0.3799
2022-01-15 16:29:06,323 Epoch[083/300], Step[0950/1252], Avg Loss: 3.6538, Avg Acc: 0.3801
2022-01-15 16:30:37,156 Epoch[083/300], Step[1000/1252], Avg Loss: 3.6565, Avg Acc: 0.3802
2022-01-15 16:32:08,309 Epoch[083/300], Step[1050/1252], Avg Loss: 3.6533, Avg Acc: 0.3799
2022-01-15 16:33:40,023 Epoch[083/300], Step[1100/1252], Avg Loss: 3.6512, Avg Acc: 0.3776
2022-01-15 16:35:11,184 Epoch[083/300], Step[1150/1252], Avg Loss: 3.6507, Avg Acc: 0.3782
2022-01-15 16:36:42,837 Epoch[083/300], Step[1200/1252], Avg Loss: 3.6545, Avg Acc: 0.3789
2022-01-15 16:38:15,282 Epoch[083/300], Step[1250/1252], Avg Loss: 3.6534, Avg Acc: 0.3778
2022-01-15 16:38:22,606 ----- Epoch[083/300], Train Loss: 3.6535, Train Acc: 0.3778, time: 2393.69
2022-01-15 16:38:22,607 Now training epoch 84. LR=0.000878
2022-01-15 16:40:28,185 Epoch[084/300], Step[0000/1252], Avg Loss: 2.8415, Avg Acc: 0.6328
2022-01-15 16:41:58,054 Epoch[084/300], Step[0050/1252], Avg Loss: 3.6700, Avg Acc: 0.4003
2022-01-15 16:43:27,813 Epoch[084/300], Step[0100/1252], Avg Loss: 3.6780, Avg Acc: 0.3966
2022-01-15 16:44:57,767 Epoch[084/300], Step[0150/1252], Avg Loss: 3.6179, Avg Acc: 0.3984
2022-01-15 16:46:27,746 Epoch[084/300], Step[0200/1252], Avg Loss: 3.6095, Avg Acc: 0.3900
2022-01-15 16:47:57,421 Epoch[084/300], Step[0250/1252], Avg Loss: 3.6029, Avg Acc: 0.3787
2022-01-15 16:49:28,711 Epoch[084/300], Step[0300/1252], Avg Loss: 3.6053, Avg Acc: 0.3898
2022-01-15 16:50:59,065 Epoch[084/300], Step[0350/1252], Avg Loss: 3.6143, Avg Acc: 0.3914
2022-01-15 16:52:31,019 Epoch[084/300], Step[0400/1252], Avg Loss: 3.6139, Avg Acc: 0.3920
2022-01-15 16:54:01,311 Epoch[084/300], Step[0450/1252], Avg Loss: 3.6243, Avg Acc: 0.3897
2022-01-15 16:55:31,468 Epoch[084/300], Step[0500/1252], Avg Loss: 3.6238, Avg Acc: 0.3942
2022-01-15 16:57:03,665 Epoch[084/300], Step[0550/1252], Avg Loss: 3.6265, Avg Acc: 0.3880
2022-01-15 16:58:35,964 Epoch[084/300], Step[0600/1252], Avg Loss: 3.6380, Avg Acc: 0.3833
2022-01-15 17:00:07,641 Epoch[084/300], Step[0650/1252], Avg Loss: 3.6386, Avg Acc: 0.3841
2022-01-15 17:01:39,919 Epoch[084/300], Step[0700/1252], Avg Loss: 3.6432, Avg Acc: 0.3812
2022-01-15 17:03:10,899 Epoch[084/300], Step[0750/1252], Avg Loss: 3.6458, Avg Acc: 0.3796
2022-01-15 17:04:40,855 Epoch[084/300], Step[0800/1252], Avg Loss: 3.6471, Avg Acc: 0.3784
2022-01-15 17:06:11,280 Epoch[084/300], Step[0850/1252], Avg Loss: 3.6517, Avg Acc: 0.3771
2022-01-15 17:07:41,297 Epoch[084/300], Step[0900/1252], Avg Loss: 3.6469, Avg Acc: 0.3820
2022-01-15 17:09:13,541 Epoch[084/300], Step[0950/1252], Avg Loss: 3.6508, Avg Acc: 0.3812
2022-01-15 17:10:44,103 Epoch[084/300], Step[1000/1252], Avg Loss: 3.6457, Avg Acc: 0.3819
2022-01-15 17:12:14,788 Epoch[084/300], Step[1050/1252], Avg Loss: 3.6335, Avg Acc: 0.3850
2022-01-15 17:13:45,206 Epoch[084/300], Step[1100/1252], Avg Loss: 3.6318, Avg Acc: 0.3852
2022-01-15 17:15:16,205 Epoch[084/300], Step[1150/1252], Avg Loss: 3.6348, Avg Acc: 0.3839
2022-01-15 17:16:46,781 Epoch[084/300], Step[1200/1252], Avg Loss: 3.6292, Avg Acc: 0.3852
2022-01-15 17:18:16,076 Epoch[084/300], Step[1250/1252], Avg Loss: 3.6274, Avg Acc: 0.3862
2022-01-15 17:18:22,834 ----- Epoch[084/300], Train Loss: 3.6274, Train Acc: 0.3862, time: 2400.22
2022-01-15 17:18:22,835 ----- Validation after Epoch: 84
2022-01-15 17:19:39,120 Val Step[0000/1563], Avg Loss: 1.2674, Avg Acc@1: 0.7500, Avg Acc@5: 0.8750
2022-01-15 17:19:41,054 Val Step[0050/1563], Avg Loss: 1.2792, Avg Acc@1: 0.7083, Avg Acc@5: 0.9118
2022-01-15 17:19:42,921 Val Step[0100/1563], Avg Loss: 1.2880, Avg Acc@1: 0.7054, Avg Acc@5: 0.9109
2022-01-15 17:19:44,879 Val Step[0150/1563], Avg Loss: 1.3660, Avg Acc@1: 0.6912, Avg Acc@5: 0.8949
2022-01-15 17:19:46,865 Val Step[0200/1563], Avg Loss: 1.3500, Avg Acc@1: 0.6965, Avg Acc@5: 0.8930
2022-01-15 17:19:48,721 Val Step[0250/1563], Avg Loss: 1.3529, Avg Acc@1: 0.6987, Avg Acc@5: 0.8919
2022-01-15 17:19:50,857 Val Step[0300/1563], Avg Loss: 1.3603, Avg Acc@1: 0.6973, Avg Acc@5: 0.8895
2022-01-15 17:19:53,052 Val Step[0350/1563], Avg Loss: 1.3908, Avg Acc@1: 0.6905, Avg Acc@5: 0.8875
2022-01-15 17:19:55,111 Val Step[0400/1563], Avg Loss: 1.3799, Avg Acc@1: 0.6939, Avg Acc@5: 0.8890
2022-01-15 17:19:57,177 Val Step[0450/1563], Avg Loss: 1.3862, Avg Acc@1: 0.6896, Avg Acc@5: 0.8891
2022-01-15 17:19:59,331 Val Step[0500/1563], Avg Loss: 1.3883, Avg Acc@1: 0.6861, Avg Acc@5: 0.8885
2022-01-15 17:20:01,582 Val Step[0550/1563], Avg Loss: 1.3856, Avg Acc@1: 0.6874, Avg Acc@5: 0.8879
2022-01-15 17:20:03,686 Val Step[0600/1563], Avg Loss: 1.3843, Avg Acc@1: 0.6859, Avg Acc@5: 0.8875
2022-01-15 17:20:05,740 Val Step[0650/1563], Avg Loss: 1.3849, Avg Acc@1: 0.6855, Avg Acc@5: 0.8879
2022-01-15 17:20:07,572 Val Step[0700/1563], Avg Loss: 1.3830, Avg Acc@1: 0.6854, Avg Acc@5: 0.8893
2022-01-15 17:20:09,458 Val Step[0750/1563], Avg Loss: 1.3896, Avg Acc@1: 0.6849, Avg Acc@5: 0.8886
2022-01-15 17:20:11,398 Val Step[0800/1563], Avg Loss: 1.3912, Avg Acc@1: 0.6857, Avg Acc@5: 0.8881
2022-01-15 17:20:13,332 Val Step[0850/1563], Avg Loss: 1.3908, Avg Acc@1: 0.6851, Avg Acc@5: 0.8891
2022-01-15 17:20:15,171 Val Step[0900/1563], Avg Loss: 1.3815, Avg Acc@1: 0.6877, Avg Acc@5: 0.8903
2022-01-15 17:20:16,984 Val Step[0950/1563], Avg Loss: 1.3755, Avg Acc@1: 0.6886, Avg Acc@5: 0.8908
2022-01-15 17:20:18,799 Val Step[1000/1563], Avg Loss: 1.3750, Avg Acc@1: 0.6891, Avg Acc@5: 0.8912
2022-01-15 17:20:20,654 Val Step[1050/1563], Avg Loss: 1.3761, Avg Acc@1: 0.6886, Avg Acc@5: 0.8909
2022-01-15 17:20:22,543 Val Step[1100/1563], Avg Loss: 1.3847, Avg Acc@1: 0.6870, Avg Acc@5: 0.8901
2022-01-15 17:20:24,474 Val Step[1150/1563], Avg Loss: 1.3844, Avg Acc@1: 0.6861, Avg Acc@5: 0.8894
2022-01-15 17:20:26,338 Val Step[1200/1563], Avg Loss: 1.3801, Avg Acc@1: 0.6862, Avg Acc@5: 0.8901
2022-01-15 17:20:28,146 Val Step[1250/1563], Avg Loss: 1.3805, Avg Acc@1: 0.6864, Avg Acc@5: 0.8906
2022-01-15 17:20:29,990 Val Step[1300/1563], Avg Loss: 1.3859, Avg Acc@1: 0.6846, Avg Acc@5: 0.8888
2022-01-15 17:20:31,822 Val Step[1350/1563], Avg Loss: 1.3911, Avg Acc@1: 0.6833, Avg Acc@5: 0.8888
2022-01-15 17:20:33,657 Val Step[1400/1563], Avg Loss: 1.3918, Avg Acc@1: 0.6827, Avg Acc@5: 0.8892
2022-01-15 17:20:35,521 Val Step[1450/1563], Avg Loss: 1.3898, Avg Acc@1: 0.6829, Avg Acc@5: 0.8895
2022-01-15 17:20:37,437 Val Step[1500/1563], Avg Loss: 1.3886, Avg Acc@1: 0.6817, Avg Acc@5: 0.8902
2022-01-15 17:20:39,245 Val Step[1550/1563], Avg Loss: 1.3874, Avg Acc@1: 0.6825, Avg Acc@5: 0.8899
2022-01-15 17:20:40,952 ----- Epoch[084/300], Validation Loss: 1.3894, Validation Acc@1: 0.6817, Validation Acc@5: 0.8901, time: 138.12
2022-01-15 17:20:40,953 Now training epoch 85. LR=0.000874
2022-01-15 17:22:31,549 Epoch[085/300], Step[0000/1252], Avg Loss: 3.4025, Avg Acc: 0.6250
2022-01-15 17:24:02,459 Epoch[085/300], Step[0050/1252], Avg Loss: 3.7329, Avg Acc: 0.3434
2022-01-15 17:25:32,753 Epoch[085/300], Step[0100/1252], Avg Loss: 3.6535, Avg Acc: 0.3651
2022-01-15 17:27:04,024 Epoch[085/300], Step[0150/1252], Avg Loss: 3.6515, Avg Acc: 0.3751
2022-01-15 17:28:34,651 Epoch[085/300], Step[0200/1252], Avg Loss: 3.5941, Avg Acc: 0.3644
2022-01-15 17:30:03,889 Epoch[085/300], Step[0250/1252], Avg Loss: 3.5843, Avg Acc: 0.3653
2022-01-15 17:31:34,056 Epoch[085/300], Step[0300/1252], Avg Loss: 3.5903, Avg Acc: 0.3799
2022-01-15 17:33:04,868 Epoch[085/300], Step[0350/1252], Avg Loss: 3.5888, Avg Acc: 0.3829
2022-01-15 17:34:36,525 Epoch[085/300], Step[0400/1252], Avg Loss: 3.5887, Avg Acc: 0.3722
2022-01-15 17:36:07,730 Epoch[085/300], Step[0450/1252], Avg Loss: 3.6043, Avg Acc: 0.3704
2022-01-15 17:37:39,155 Epoch[085/300], Step[0500/1252], Avg Loss: 3.6175, Avg Acc: 0.3667
2022-01-15 17:39:09,294 Epoch[085/300], Step[0550/1252], Avg Loss: 3.6135, Avg Acc: 0.3674
2022-01-15 17:40:39,186 Epoch[085/300], Step[0600/1252], Avg Loss: 3.6137, Avg Acc: 0.3700
2022-01-15 17:42:11,281 Epoch[085/300], Step[0650/1252], Avg Loss: 3.6109, Avg Acc: 0.3649
2022-01-15 17:43:43,492 Epoch[085/300], Step[0700/1252], Avg Loss: 3.6060, Avg Acc: 0.3681
2022-01-15 17:45:13,512 Epoch[085/300], Step[0750/1252], Avg Loss: 3.6130, Avg Acc: 0.3705
2022-01-15 17:46:45,035 Epoch[085/300], Step[0800/1252], Avg Loss: 3.6088, Avg Acc: 0.3701
2022-01-15 17:48:17,040 Epoch[085/300], Step[0850/1252], Avg Loss: 3.6132, Avg Acc: 0.3695
2022-01-15 17:49:48,899 Epoch[085/300], Step[0900/1252], Avg Loss: 3.6212, Avg Acc: 0.3672
2022-01-15 17:51:19,782 Epoch[085/300], Step[0950/1252], Avg Loss: 3.6231, Avg Acc: 0.3675
2022-01-15 17:52:50,533 Epoch[085/300], Step[1000/1252], Avg Loss: 3.6283, Avg Acc: 0.3693
2022-01-15 17:54:21,782 Epoch[085/300], Step[1050/1252], Avg Loss: 3.6291, Avg Acc: 0.3673
2022-01-15 17:55:54,241 Epoch[085/300], Step[1100/1252], Avg Loss: 3.6292, Avg Acc: 0.3690
2022-01-15 17:57:24,150 Epoch[085/300], Step[1150/1252], Avg Loss: 3.6270, Avg Acc: 0.3703
2022-01-15 17:58:55,103 Epoch[085/300], Step[1200/1252], Avg Loss: 3.6275, Avg Acc: 0.3726
2022-01-15 18:00:26,114 Epoch[085/300], Step[1250/1252], Avg Loss: 3.6323, Avg Acc: 0.3715
2022-01-15 18:00:32,977 ----- Epoch[085/300], Train Loss: 3.6323, Train Acc: 0.3715, time: 2392.02
2022-01-15 18:00:32,978 Now training epoch 86. LR=0.000870
2022-01-15 18:02:30,311 Epoch[086/300], Step[0000/1252], Avg Loss: 3.7615, Avg Acc: 0.5586
2022-01-15 18:03:59,621 Epoch[086/300], Step[0050/1252], Avg Loss: 3.5791, Avg Acc: 0.3472
2022-01-15 18:05:30,738 Epoch[086/300], Step[0100/1252], Avg Loss: 3.6628, Avg Acc: 0.3343
2022-01-15 18:07:00,563 Epoch[086/300], Step[0150/1252], Avg Loss: 3.6788, Avg Acc: 0.3541
2022-01-15 18:08:32,292 Epoch[086/300], Step[0200/1252], Avg Loss: 3.6511, Avg Acc: 0.3577
2022-01-15 18:10:00,558 Epoch[086/300], Step[0250/1252], Avg Loss: 3.6449, Avg Acc: 0.3738
2022-01-15 18:11:32,040 Epoch[086/300], Step[0300/1252], Avg Loss: 3.6099, Avg Acc: 0.3807
2022-01-15 18:13:02,609 Epoch[086/300], Step[0350/1252], Avg Loss: 3.5912, Avg Acc: 0.3819
2022-01-15 18:14:33,201 Epoch[086/300], Step[0400/1252], Avg Loss: 3.5884, Avg Acc: 0.3790
2022-01-15 18:16:03,660 Epoch[086/300], Step[0450/1252], Avg Loss: 3.5848, Avg Acc: 0.3786
2022-01-15 18:17:35,361 Epoch[086/300], Step[0500/1252], Avg Loss: 3.5813, Avg Acc: 0.3736
2022-01-15 18:19:06,158 Epoch[086/300], Step[0550/1252], Avg Loss: 3.5890, Avg Acc: 0.3746
2022-01-15 18:20:37,527 Epoch[086/300], Step[0600/1252], Avg Loss: 3.5932, Avg Acc: 0.3744
2022-01-15 18:22:07,894 Epoch[086/300], Step[0650/1252], Avg Loss: 3.5934, Avg Acc: 0.3721
2022-01-15 18:23:38,932 Epoch[086/300], Step[0700/1252], Avg Loss: 3.6064, Avg Acc: 0.3713
2022-01-15 18:25:10,127 Epoch[086/300], Step[0750/1252], Avg Loss: 3.6081, Avg Acc: 0.3722
2022-01-15 18:26:41,404 Epoch[086/300], Step[0800/1252], Avg Loss: 3.6014, Avg Acc: 0.3738
2022-01-15 18:28:10,010 Epoch[086/300], Step[0850/1252], Avg Loss: 3.6077, Avg Acc: 0.3730
2022-01-15 18:29:39,906 Epoch[086/300], Step[0900/1252], Avg Loss: 3.6075, Avg Acc: 0.3731
2022-01-15 18:31:08,657 Epoch[086/300], Step[0950/1252], Avg Loss: 3.6094, Avg Acc: 0.3717
2022-01-15 18:32:38,388 Epoch[086/300], Step[1000/1252], Avg Loss: 3.6096, Avg Acc: 0.3744
2022-01-15 18:34:08,467 Epoch[086/300], Step[1050/1252], Avg Loss: 3.6121, Avg Acc: 0.3731
2022-01-15 18:35:38,003 Epoch[086/300], Step[1100/1252], Avg Loss: 3.6139, Avg Acc: 0.3737
2022-01-15 18:37:09,659 Epoch[086/300], Step[1150/1252], Avg Loss: 3.6153, Avg Acc: 0.3729
2022-01-15 18:38:40,794 Epoch[086/300], Step[1200/1252], Avg Loss: 3.6179, Avg Acc: 0.3731
2022-01-15 18:40:11,390 Epoch[086/300], Step[1250/1252], Avg Loss: 3.6220, Avg Acc: 0.3743
2022-01-15 18:40:18,484 ----- Epoch[086/300], Train Loss: 3.6221, Train Acc: 0.3743, time: 2385.50
2022-01-15 18:40:18,485 ----- Validation after Epoch: 86
2022-01-15 18:41:40,597 Val Step[0000/1563], Avg Loss: 0.9457, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-15 18:41:42,885 Val Step[0050/1563], Avg Loss: 1.1998, Avg Acc@1: 0.7377, Avg Acc@5: 0.9338
2022-01-15 18:41:45,199 Val Step[0100/1563], Avg Loss: 1.2452, Avg Acc@1: 0.7203, Avg Acc@5: 0.9109
2022-01-15 18:41:47,219 Val Step[0150/1563], Avg Loss: 1.3565, Avg Acc@1: 0.7036, Avg Acc@5: 0.8907
2022-01-15 18:41:49,225 Val Step[0200/1563], Avg Loss: 1.3479, Avg Acc@1: 0.7015, Avg Acc@5: 0.8912
2022-01-15 18:41:51,161 Val Step[0250/1563], Avg Loss: 1.3518, Avg Acc@1: 0.6992, Avg Acc@5: 0.8934
2022-01-15 18:41:53,136 Val Step[0300/1563], Avg Loss: 1.3628, Avg Acc@1: 0.6948, Avg Acc@5: 0.8916
2022-01-15 18:41:55,156 Val Step[0350/1563], Avg Loss: 1.3861, Avg Acc@1: 0.6905, Avg Acc@5: 0.8900
2022-01-15 18:41:57,108 Val Step[0400/1563], Avg Loss: 1.3740, Avg Acc@1: 0.6908, Avg Acc@5: 0.8931
2022-01-15 18:41:59,137 Val Step[0450/1563], Avg Loss: 1.3815, Avg Acc@1: 0.6868, Avg Acc@5: 0.8908
2022-01-15 18:42:01,353 Val Step[0500/1563], Avg Loss: 1.3833, Avg Acc@1: 0.6856, Avg Acc@5: 0.8907
2022-01-15 18:42:03,547 Val Step[0550/1563], Avg Loss: 1.3804, Avg Acc@1: 0.6853, Avg Acc@5: 0.8913
2022-01-15 18:42:05,678 Val Step[0600/1563], Avg Loss: 1.3797, Avg Acc@1: 0.6864, Avg Acc@5: 0.8906
2022-01-15 18:42:07,811 Val Step[0650/1563], Avg Loss: 1.3765, Avg Acc@1: 0.6857, Avg Acc@5: 0.8923
2022-01-15 18:42:09,930 Val Step[0700/1563], Avg Loss: 1.3765, Avg Acc@1: 0.6853, Avg Acc@5: 0.8921
2022-01-15 18:42:12,097 Val Step[0750/1563], Avg Loss: 1.3841, Avg Acc@1: 0.6861, Avg Acc@5: 0.8916
2022-01-15 18:42:14,309 Val Step[0800/1563], Avg Loss: 1.3855, Avg Acc@1: 0.6888, Avg Acc@5: 0.8906
2022-01-15 18:42:16,473 Val Step[0850/1563], Avg Loss: 1.3875, Avg Acc@1: 0.6874, Avg Acc@5: 0.8912
2022-01-15 18:42:18,610 Val Step[0900/1563], Avg Loss: 1.3793, Avg Acc@1: 0.6915, Avg Acc@5: 0.8923
2022-01-15 18:42:20,729 Val Step[0950/1563], Avg Loss: 1.3745, Avg Acc@1: 0.6922, Avg Acc@5: 0.8938
2022-01-15 18:42:23,057 Val Step[1000/1563], Avg Loss: 1.3763, Avg Acc@1: 0.6922, Avg Acc@5: 0.8932
2022-01-15 18:42:25,376 Val Step[1050/1563], Avg Loss: 1.3770, Avg Acc@1: 0.6928, Avg Acc@5: 0.8921
2022-01-15 18:42:27,699 Val Step[1100/1563], Avg Loss: 1.3858, Avg Acc@1: 0.6907, Avg Acc@5: 0.8907
2022-01-15 18:42:29,796 Val Step[1150/1563], Avg Loss: 1.3881, Avg Acc@1: 0.6907, Avg Acc@5: 0.8899
2022-01-15 18:42:31,906 Val Step[1200/1563], Avg Loss: 1.3821, Avg Acc@1: 0.6923, Avg Acc@5: 0.8913
2022-01-15 18:42:34,039 Val Step[1250/1563], Avg Loss: 1.3805, Avg Acc@1: 0.6931, Avg Acc@5: 0.8906
2022-01-15 18:42:36,130 Val Step[1300/1563], Avg Loss: 1.3841, Avg Acc@1: 0.6919, Avg Acc@5: 0.8902
2022-01-15 18:42:38,299 Val Step[1350/1563], Avg Loss: 1.3892, Avg Acc@1: 0.6915, Avg Acc@5: 0.8893
2022-01-15 18:42:40,380 Val Step[1400/1563], Avg Loss: 1.3906, Avg Acc@1: 0.6912, Avg Acc@5: 0.8896
2022-01-15 18:42:42,529 Val Step[1450/1563], Avg Loss: 1.3894, Avg Acc@1: 0.6910, Avg Acc@5: 0.8905
2022-01-15 18:42:44,636 Val Step[1500/1563], Avg Loss: 1.3889, Avg Acc@1: 0.6900, Avg Acc@5: 0.8909
2022-01-15 18:42:46,693 Val Step[1550/1563], Avg Loss: 1.3892, Avg Acc@1: 0.6900, Avg Acc@5: 0.8909
2022-01-15 18:42:48,770 ----- Epoch[086/300], Validation Loss: 1.3912, Validation Acc@1: 0.6895, Validation Acc@5: 0.8910, time: 150.28
2022-01-15 18:42:48,771 Now training epoch 87. LR=0.000867
2022-01-15 18:44:44,187 Epoch[087/300], Step[0000/1252], Avg Loss: 4.4617, Avg Acc: 0.3359
2022-01-15 18:46:15,468 Epoch[087/300], Step[0050/1252], Avg Loss: 3.6575, Avg Acc: 0.3378
2022-01-15 18:47:45,815 Epoch[087/300], Step[0100/1252], Avg Loss: 3.6746, Avg Acc: 0.3605
2022-01-15 18:49:16,758 Epoch[087/300], Step[0150/1252], Avg Loss: 3.6465, Avg Acc: 0.3524
2022-01-15 18:50:45,405 Epoch[087/300], Step[0200/1252], Avg Loss: 3.6334, Avg Acc: 0.3463
2022-01-15 18:52:15,539 Epoch[087/300], Step[0250/1252], Avg Loss: 3.6163, Avg Acc: 0.3543
2022-01-15 18:53:45,158 Epoch[087/300], Step[0300/1252], Avg Loss: 3.6290, Avg Acc: 0.3563
2022-01-15 18:55:14,751 Epoch[087/300], Step[0350/1252], Avg Loss: 3.6254, Avg Acc: 0.3620
2022-01-15 18:56:44,704 Epoch[087/300], Step[0400/1252], Avg Loss: 3.6278, Avg Acc: 0.3646
2022-01-15 18:58:14,451 Epoch[087/300], Step[0450/1252], Avg Loss: 3.6358, Avg Acc: 0.3574
2022-01-15 18:59:45,344 Epoch[087/300], Step[0500/1252], Avg Loss: 3.6445, Avg Acc: 0.3530
2022-01-15 19:01:15,466 Epoch[087/300], Step[0550/1252], Avg Loss: 3.6388, Avg Acc: 0.3534
2022-01-15 19:02:44,529 Epoch[087/300], Step[0600/1252], Avg Loss: 3.6454, Avg Acc: 0.3547
2022-01-15 19:04:14,218 Epoch[087/300], Step[0650/1252], Avg Loss: 3.6418, Avg Acc: 0.3552
2022-01-15 19:05:44,708 Epoch[087/300], Step[0700/1252], Avg Loss: 3.6500, Avg Acc: 0.3580
2022-01-15 19:07:13,846 Epoch[087/300], Step[0750/1252], Avg Loss: 3.6480, Avg Acc: 0.3599
2022-01-15 19:08:43,036 Epoch[087/300], Step[0800/1252], Avg Loss: 3.6425, Avg Acc: 0.3661
2022-01-15 19:10:13,000 Epoch[087/300], Step[0850/1252], Avg Loss: 3.6437, Avg Acc: 0.3657
2022-01-15 19:11:42,836 Epoch[087/300], Step[0900/1252], Avg Loss: 3.6389, Avg Acc: 0.3683
2022-01-15 19:13:12,639 Epoch[087/300], Step[0950/1252], Avg Loss: 3.6331, Avg Acc: 0.3701
2022-01-15 19:14:40,665 Epoch[087/300], Step[1000/1252], Avg Loss: 3.6338, Avg Acc: 0.3688
2022-01-15 19:16:11,084 Epoch[087/300], Step[1050/1252], Avg Loss: 3.6317, Avg Acc: 0.3703
2022-01-15 19:17:41,512 Epoch[087/300], Step[1100/1252], Avg Loss: 3.6294, Avg Acc: 0.3696
2022-01-15 19:19:11,369 Epoch[087/300], Step[1150/1252], Avg Loss: 3.6278, Avg Acc: 0.3722
2022-01-15 19:20:40,332 Epoch[087/300], Step[1200/1252], Avg Loss: 3.6318, Avg Acc: 0.3718
2022-01-15 19:22:09,646 Epoch[087/300], Step[1250/1252], Avg Loss: 3.6331, Avg Acc: 0.3732
2022-01-15 19:22:17,394 ----- Epoch[087/300], Train Loss: 3.6331, Train Acc: 0.3732, time: 2368.62
2022-01-15 19:22:17,396 Now training epoch 88. LR=0.000863
2022-01-15 19:24:06,695 Epoch[088/300], Step[0000/1252], Avg Loss: 4.5323, Avg Acc: 0.3906
2022-01-15 19:25:35,020 Epoch[088/300], Step[0050/1252], Avg Loss: 3.7684, Avg Acc: 0.3803
2022-01-15 19:27:02,547 Epoch[088/300], Step[0100/1252], Avg Loss: 3.6635, Avg Acc: 0.3804
2022-01-15 19:28:29,864 Epoch[088/300], Step[0150/1252], Avg Loss: 3.6939, Avg Acc: 0.3826
2022-01-15 19:29:57,538 Epoch[088/300], Step[0200/1252], Avg Loss: 3.6833, Avg Acc: 0.3766
2022-01-15 19:31:24,699 Epoch[088/300], Step[0250/1252], Avg Loss: 3.7030, Avg Acc: 0.3698
2022-01-15 19:32:51,116 Epoch[088/300], Step[0300/1252], Avg Loss: 3.7052, Avg Acc: 0.3605
2022-01-15 19:34:18,875 Epoch[088/300], Step[0350/1252], Avg Loss: 3.6954, Avg Acc: 0.3656
2022-01-15 19:35:47,301 Epoch[088/300], Step[0400/1252], Avg Loss: 3.6851, Avg Acc: 0.3625
2022-01-15 19:37:14,909 Epoch[088/300], Step[0450/1252], Avg Loss: 3.6866, Avg Acc: 0.3669
2022-01-15 19:38:41,908 Epoch[088/300], Step[0500/1252], Avg Loss: 3.6796, Avg Acc: 0.3645
2022-01-15 19:40:09,701 Epoch[088/300], Step[0550/1252], Avg Loss: 3.6900, Avg Acc: 0.3645
2022-01-15 19:41:38,082 Epoch[088/300], Step[0600/1252], Avg Loss: 3.6821, Avg Acc: 0.3636
2022-01-15 19:43:04,847 Epoch[088/300], Step[0650/1252], Avg Loss: 3.6834, Avg Acc: 0.3599
2022-01-15 19:44:31,672 Epoch[088/300], Step[0700/1252], Avg Loss: 3.6818, Avg Acc: 0.3594
2022-01-15 19:46:00,038 Epoch[088/300], Step[0750/1252], Avg Loss: 3.6829, Avg Acc: 0.3575
2022-01-15 19:47:26,526 Epoch[088/300], Step[0800/1252], Avg Loss: 3.6830, Avg Acc: 0.3580
2022-01-15 19:48:54,802 Epoch[088/300], Step[0850/1252], Avg Loss: 3.6770, Avg Acc: 0.3573
2022-01-15 19:50:22,378 Epoch[088/300], Step[0900/1252], Avg Loss: 3.6665, Avg Acc: 0.3572
2022-01-15 19:51:47,967 Epoch[088/300], Step[0950/1252], Avg Loss: 3.6688, Avg Acc: 0.3595
2022-01-15 19:53:13,986 Epoch[088/300], Step[1000/1252], Avg Loss: 3.6664, Avg Acc: 0.3581
2022-01-15 19:54:41,050 Epoch[088/300], Step[1050/1252], Avg Loss: 3.6512, Avg Acc: 0.3616
2022-01-15 19:56:08,683 Epoch[088/300], Step[1100/1252], Avg Loss: 3.6481, Avg Acc: 0.3621
2022-01-15 19:57:35,224 Epoch[088/300], Step[1150/1252], Avg Loss: 3.6455, Avg Acc: 0.3639
2022-01-15 19:59:02,982 Epoch[088/300], Step[1200/1252], Avg Loss: 3.6423, Avg Acc: 0.3634
2022-01-15 20:00:30,594 Epoch[088/300], Step[1250/1252], Avg Loss: 3.6356, Avg Acc: 0.3647
2022-01-15 20:00:37,682 ----- Epoch[088/300], Train Loss: 3.6356, Train Acc: 0.3647, time: 2300.28
2022-01-15 20:00:37,684 ----- Validation after Epoch: 88
2022-01-15 20:02:12,922 Val Step[0000/1563], Avg Loss: 1.0104, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-15 20:02:14,847 Val Step[0050/1563], Avg Loss: 1.2477, Avg Acc@1: 0.7304, Avg Acc@5: 0.9240
2022-01-15 20:02:16,736 Val Step[0100/1563], Avg Loss: 1.2397, Avg Acc@1: 0.7290, Avg Acc@5: 0.9233
2022-01-15 20:02:18,782 Val Step[0150/1563], Avg Loss: 1.3196, Avg Acc@1: 0.7144, Avg Acc@5: 0.9023
2022-01-15 20:02:20,929 Val Step[0200/1563], Avg Loss: 1.2945, Avg Acc@1: 0.7220, Avg Acc@5: 0.9036
2022-01-15 20:02:22,883 Val Step[0250/1563], Avg Loss: 1.2961, Avg Acc@1: 0.7156, Avg Acc@5: 0.9019
2022-01-15 20:02:24,734 Val Step[0300/1563], Avg Loss: 1.3109, Avg Acc@1: 0.7105, Avg Acc@5: 0.8995
2022-01-15 20:02:26,633 Val Step[0350/1563], Avg Loss: 1.3388, Avg Acc@1: 0.7033, Avg Acc@5: 0.8981
2022-01-15 20:02:28,573 Val Step[0400/1563], Avg Loss: 1.3314, Avg Acc@1: 0.7036, Avg Acc@5: 0.8993
2022-01-15 20:02:30,476 Val Step[0450/1563], Avg Loss: 1.3405, Avg Acc@1: 0.7007, Avg Acc@5: 0.8983
2022-01-15 20:02:32,379 Val Step[0500/1563], Avg Loss: 1.3479, Avg Acc@1: 0.6984, Avg Acc@5: 0.8977
2022-01-15 20:02:34,370 Val Step[0550/1563], Avg Loss: 1.3501, Avg Acc@1: 0.6983, Avg Acc@5: 0.8975
2022-01-15 20:02:36,196 Val Step[0600/1563], Avg Loss: 1.3431, Avg Acc@1: 0.6984, Avg Acc@5: 0.8981
2022-01-15 20:02:38,049 Val Step[0650/1563], Avg Loss: 1.3400, Avg Acc@1: 0.6983, Avg Acc@5: 0.8990
2022-01-15 20:02:40,004 Val Step[0700/1563], Avg Loss: 1.3370, Avg Acc@1: 0.6990, Avg Acc@5: 0.8982
2022-01-15 20:02:41,849 Val Step[0750/1563], Avg Loss: 1.3472, Avg Acc@1: 0.6992, Avg Acc@5: 0.8975
2022-01-15 20:02:43,648 Val Step[0800/1563], Avg Loss: 1.3472, Avg Acc@1: 0.7013, Avg Acc@5: 0.8962
2022-01-15 20:02:45,482 Val Step[0850/1563], Avg Loss: 1.3525, Avg Acc@1: 0.6990, Avg Acc@5: 0.8960
2022-01-15 20:02:47,317 Val Step[0900/1563], Avg Loss: 1.3474, Avg Acc@1: 0.7009, Avg Acc@5: 0.8961
2022-01-15 20:02:49,226 Val Step[0950/1563], Avg Loss: 1.3419, Avg Acc@1: 0.7024, Avg Acc@5: 0.8972
2022-01-15 20:02:51,135 Val Step[1000/1563], Avg Loss: 1.3424, Avg Acc@1: 0.7030, Avg Acc@5: 0.8970
2022-01-15 20:02:53,073 Val Step[1050/1563], Avg Loss: 1.3465, Avg Acc@1: 0.7020, Avg Acc@5: 0.8965
2022-01-15 20:02:55,043 Val Step[1100/1563], Avg Loss: 1.3551, Avg Acc@1: 0.6997, Avg Acc@5: 0.8955
2022-01-15 20:02:56,839 Val Step[1150/1563], Avg Loss: 1.3580, Avg Acc@1: 0.6999, Avg Acc@5: 0.8942
2022-01-15 20:02:58,660 Val Step[1200/1563], Avg Loss: 1.3542, Avg Acc@1: 0.7007, Avg Acc@5: 0.8947
2022-01-15 20:03:00,476 Val Step[1250/1563], Avg Loss: 1.3551, Avg Acc@1: 0.7001, Avg Acc@5: 0.8944
2022-01-15 20:03:02,311 Val Step[1300/1563], Avg Loss: 1.3574, Avg Acc@1: 0.6994, Avg Acc@5: 0.8939
2022-01-15 20:03:04,219 Val Step[1350/1563], Avg Loss: 1.3620, Avg Acc@1: 0.6987, Avg Acc@5: 0.8929
2022-01-15 20:03:06,174 Val Step[1400/1563], Avg Loss: 1.3618, Avg Acc@1: 0.6986, Avg Acc@5: 0.8929
2022-01-15 20:03:08,141 Val Step[1450/1563], Avg Loss: 1.3605, Avg Acc@1: 0.6980, Avg Acc@5: 0.8933
2022-01-15 20:03:10,165 Val Step[1500/1563], Avg Loss: 1.3586, Avg Acc@1: 0.6980, Avg Acc@5: 0.8936
2022-01-15 20:03:12,178 Val Step[1550/1563], Avg Loss: 1.3616, Avg Acc@1: 0.6971, Avg Acc@5: 0.8939
2022-01-15 20:03:14,063 ----- Epoch[088/300], Validation Loss: 1.3645, Validation Acc@1: 0.6964, Validation Acc@5: 0.8938, time: 156.38
2022-01-15 20:03:14,063 Now training epoch 89. LR=0.000859
2022-01-15 20:05:11,685 Epoch[089/300], Step[0000/1252], Avg Loss: 3.2626, Avg Acc: 0.6289
2022-01-15 20:06:39,848 Epoch[089/300], Step[0050/1252], Avg Loss: 3.5135, Avg Acc: 0.3514
2022-01-15 20:08:05,515 Epoch[089/300], Step[0100/1252], Avg Loss: 3.4958, Avg Acc: 0.3811
2022-01-15 20:09:32,841 Epoch[089/300], Step[0150/1252], Avg Loss: 3.5207, Avg Acc: 0.3779
2022-01-15 20:11:00,149 Epoch[089/300], Step[0200/1252], Avg Loss: 3.5485, Avg Acc: 0.3762
2022-01-15 20:12:27,839 Epoch[089/300], Step[0250/1252], Avg Loss: 3.5672, Avg Acc: 0.3737
2022-01-15 20:13:54,019 Epoch[089/300], Step[0300/1252], Avg Loss: 3.5715, Avg Acc: 0.3643
2022-01-15 20:15:21,989 Epoch[089/300], Step[0350/1252], Avg Loss: 3.5902, Avg Acc: 0.3620
2022-01-15 20:16:50,365 Epoch[089/300], Step[0400/1252], Avg Loss: 3.5917, Avg Acc: 0.3709
2022-01-15 20:18:18,913 Epoch[089/300], Step[0450/1252], Avg Loss: 3.5797, Avg Acc: 0.3739
2022-01-15 20:19:47,294 Epoch[089/300], Step[0500/1252], Avg Loss: 3.5789, Avg Acc: 0.3787
2022-01-15 20:21:16,906 Epoch[089/300], Step[0550/1252], Avg Loss: 3.5838, Avg Acc: 0.3769
2022-01-15 20:22:45,571 Epoch[089/300], Step[0600/1252], Avg Loss: 3.5925, Avg Acc: 0.3776
2022-01-15 20:24:13,702 Epoch[089/300], Step[0650/1252], Avg Loss: 3.6058, Avg Acc: 0.3754
2022-01-15 20:25:41,662 Epoch[089/300], Step[0700/1252], Avg Loss: 3.6047, Avg Acc: 0.3735
2022-01-15 20:27:09,228 Epoch[089/300], Step[0750/1252], Avg Loss: 3.6174, Avg Acc: 0.3744
2022-01-15 20:28:36,715 Epoch[089/300], Step[0800/1252], Avg Loss: 3.6208, Avg Acc: 0.3737
2022-01-15 20:30:04,987 Epoch[089/300], Step[0850/1252], Avg Loss: 3.6254, Avg Acc: 0.3735
2022-01-15 20:31:33,667 Epoch[089/300], Step[0900/1252], Avg Loss: 3.6205, Avg Acc: 0.3711
2022-01-15 20:33:02,617 Epoch[089/300], Step[0950/1252], Avg Loss: 3.6237, Avg Acc: 0.3698
2022-01-15 20:34:31,056 Epoch[089/300], Step[1000/1252], Avg Loss: 3.6260, Avg Acc: 0.3684
2022-01-15 20:35:59,629 Epoch[089/300], Step[1050/1252], Avg Loss: 3.6208, Avg Acc: 0.3666
2022-01-15 20:37:28,853 Epoch[089/300], Step[1100/1252], Avg Loss: 3.6248, Avg Acc: 0.3671
2022-01-15 20:38:57,743 Epoch[089/300], Step[1150/1252], Avg Loss: 3.6247, Avg Acc: 0.3673
2022-01-15 20:40:25,378 Epoch[089/300], Step[1200/1252], Avg Loss: 3.6239, Avg Acc: 0.3696
2022-01-15 20:41:52,775 Epoch[089/300], Step[1250/1252], Avg Loss: 3.6215, Avg Acc: 0.3711
2022-01-15 20:41:59,792 ----- Epoch[089/300], Train Loss: 3.6216, Train Acc: 0.3711, time: 2325.73
2022-01-15 20:41:59,794 Now training epoch 90. LR=0.000855
2022-01-15 20:43:52,006 Epoch[090/300], Step[0000/1252], Avg Loss: 3.7385, Avg Acc: 0.5195
2022-01-15 20:45:20,774 Epoch[090/300], Step[0050/1252], Avg Loss: 3.6041, Avg Acc: 0.3944
2022-01-15 20:46:49,244 Epoch[090/300], Step[0100/1252], Avg Loss: 3.6951, Avg Acc: 0.3722
2022-01-15 20:48:16,487 Epoch[090/300], Step[0150/1252], Avg Loss: 3.6320, Avg Acc: 0.3725
2022-01-15 20:49:44,017 Epoch[090/300], Step[0200/1252], Avg Loss: 3.6416, Avg Acc: 0.3691
2022-01-15 20:51:11,769 Epoch[090/300], Step[0250/1252], Avg Loss: 3.6609, Avg Acc: 0.3669
2022-01-15 20:52:39,927 Epoch[090/300], Step[0300/1252], Avg Loss: 3.6434, Avg Acc: 0.3643
2022-01-15 20:54:08,617 Epoch[090/300], Step[0350/1252], Avg Loss: 3.6397, Avg Acc: 0.3639
2022-01-15 20:55:35,633 Epoch[090/300], Step[0400/1252], Avg Loss: 3.6406, Avg Acc: 0.3712
2022-01-15 20:57:03,713 Epoch[090/300], Step[0450/1252], Avg Loss: 3.6360, Avg Acc: 0.3646
2022-01-15 20:58:29,907 Epoch[090/300], Step[0500/1252], Avg Loss: 3.6334, Avg Acc: 0.3688
2022-01-15 20:59:57,080 Epoch[090/300], Step[0550/1252], Avg Loss: 3.6297, Avg Acc: 0.3714
2022-01-15 21:01:25,333 Epoch[090/300], Step[0600/1252], Avg Loss: 3.6111, Avg Acc: 0.3756
2022-01-15 21:02:53,257 Epoch[090/300], Step[0650/1252], Avg Loss: 3.6254, Avg Acc: 0.3755
2022-01-15 21:04:22,033 Epoch[090/300], Step[0700/1252], Avg Loss: 3.6267, Avg Acc: 0.3737
2022-01-15 21:05:50,255 Epoch[090/300], Step[0750/1252], Avg Loss: 3.6260, Avg Acc: 0.3742
2022-01-15 21:07:19,319 Epoch[090/300], Step[0800/1252], Avg Loss: 3.6326, Avg Acc: 0.3714
2022-01-15 21:08:47,780 Epoch[090/300], Step[0850/1252], Avg Loss: 3.6224, Avg Acc: 0.3739
2022-01-15 21:10:15,507 Epoch[090/300], Step[0900/1252], Avg Loss: 3.6285, Avg Acc: 0.3746
2022-01-15 21:11:43,720 Epoch[090/300], Step[0950/1252], Avg Loss: 3.6352, Avg Acc: 0.3758
2022-01-15 21:13:12,575 Epoch[090/300], Step[1000/1252], Avg Loss: 3.6330, Avg Acc: 0.3738
2022-01-15 21:14:41,077 Epoch[090/300], Step[1050/1252], Avg Loss: 3.6375, Avg Acc: 0.3727
2022-01-15 21:16:09,907 Epoch[090/300], Step[1100/1252], Avg Loss: 3.6392, Avg Acc: 0.3731
2022-01-15 21:17:38,229 Epoch[090/300], Step[1150/1252], Avg Loss: 3.6386, Avg Acc: 0.3745
2022-01-15 21:19:07,200 Epoch[090/300], Step[1200/1252], Avg Loss: 3.6428, Avg Acc: 0.3740
2022-01-15 21:20:34,617 Epoch[090/300], Step[1250/1252], Avg Loss: 3.6434, Avg Acc: 0.3746
2022-01-15 21:20:41,569 ----- Epoch[090/300], Train Loss: 3.6435, Train Acc: 0.3746, time: 2321.77
2022-01-15 21:20:41,570 ----- Validation after Epoch: 90
2022-01-15 21:22:11,236 Val Step[0000/1563], Avg Loss: 0.8257, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-15 21:22:13,215 Val Step[0050/1563], Avg Loss: 1.1969, Avg Acc@1: 0.7083, Avg Acc@5: 0.9387
2022-01-15 21:22:15,160 Val Step[0100/1563], Avg Loss: 1.2414, Avg Acc@1: 0.7054, Avg Acc@5: 0.9233
2022-01-15 21:22:17,133 Val Step[0150/1563], Avg Loss: 1.3358, Avg Acc@1: 0.6954, Avg Acc@5: 0.9106
2022-01-15 21:22:19,178 Val Step[0200/1563], Avg Loss: 1.3169, Avg Acc@1: 0.6990, Avg Acc@5: 0.9080
2022-01-15 21:22:21,318 Val Step[0250/1563], Avg Loss: 1.3225, Avg Acc@1: 0.7007, Avg Acc@5: 0.9049
2022-01-15 21:22:23,449 Val Step[0300/1563], Avg Loss: 1.3288, Avg Acc@1: 0.7010, Avg Acc@5: 0.9032
2022-01-15 21:22:25,546 Val Step[0350/1563], Avg Loss: 1.3575, Avg Acc@1: 0.6969, Avg Acc@5: 0.9028
2022-01-15 21:22:27,603 Val Step[0400/1563], Avg Loss: 1.3495, Avg Acc@1: 0.6970, Avg Acc@5: 0.9037
2022-01-15 21:22:29,744 Val Step[0450/1563], Avg Loss: 1.3576, Avg Acc@1: 0.6940, Avg Acc@5: 0.9027
2022-01-15 21:22:31,901 Val Step[0500/1563], Avg Loss: 1.3676, Avg Acc@1: 0.6924, Avg Acc@5: 0.9019
2022-01-15 21:22:34,006 Val Step[0550/1563], Avg Loss: 1.3687, Avg Acc@1: 0.6908, Avg Acc@5: 0.9027
2022-01-15 21:22:36,134 Val Step[0600/1563], Avg Loss: 1.3627, Avg Acc@1: 0.6936, Avg Acc@5: 0.9014
2022-01-15 21:22:38,235 Val Step[0650/1563], Avg Loss: 1.3637, Avg Acc@1: 0.6934, Avg Acc@5: 0.9011
2022-01-15 21:22:40,338 Val Step[0700/1563], Avg Loss: 1.3616, Avg Acc@1: 0.6929, Avg Acc@5: 0.9017
2022-01-15 21:22:42,393 Val Step[0750/1563], Avg Loss: 1.3643, Avg Acc@1: 0.6912, Avg Acc@5: 0.9015
2022-01-15 21:22:44,438 Val Step[0800/1563], Avg Loss: 1.3667, Avg Acc@1: 0.6921, Avg Acc@5: 0.9007
2022-01-15 21:22:46,470 Val Step[0850/1563], Avg Loss: 1.3713, Avg Acc@1: 0.6907, Avg Acc@5: 0.8994
2022-01-15 21:22:48,569 Val Step[0900/1563], Avg Loss: 1.3650, Avg Acc@1: 0.6930, Avg Acc@5: 0.8998
2022-01-15 21:22:50,716 Val Step[0950/1563], Avg Loss: 1.3605, Avg Acc@1: 0.6944, Avg Acc@5: 0.9009
2022-01-15 21:22:52,886 Val Step[1000/1563], Avg Loss: 1.3579, Avg Acc@1: 0.6954, Avg Acc@5: 0.9012
2022-01-15 21:22:55,086 Val Step[1050/1563], Avg Loss: 1.3601, Avg Acc@1: 0.6949, Avg Acc@5: 0.9005
2022-01-15 21:22:57,233 Val Step[1100/1563], Avg Loss: 1.3678, Avg Acc@1: 0.6936, Avg Acc@5: 0.8991
2022-01-15 21:22:59,274 Val Step[1150/1563], Avg Loss: 1.3696, Avg Acc@1: 0.6931, Avg Acc@5: 0.8979
2022-01-15 21:23:01,421 Val Step[1200/1563], Avg Loss: 1.3661, Avg Acc@1: 0.6942, Avg Acc@5: 0.8978
2022-01-15 21:23:03,471 Val Step[1250/1563], Avg Loss: 1.3669, Avg Acc@1: 0.6934, Avg Acc@5: 0.8969
2022-01-15 21:23:05,502 Val Step[1300/1563], Avg Loss: 1.3708, Avg Acc@1: 0.6928, Avg Acc@5: 0.8961
2022-01-15 21:23:07,545 Val Step[1350/1563], Avg Loss: 1.3757, Avg Acc@1: 0.6924, Avg Acc@5: 0.8950
2022-01-15 21:23:09,555 Val Step[1400/1563], Avg Loss: 1.3751, Avg Acc@1: 0.6924, Avg Acc@5: 0.8953
2022-01-15 21:23:11,675 Val Step[1450/1563], Avg Loss: 1.3731, Avg Acc@1: 0.6926, Avg Acc@5: 0.8957
2022-01-15 21:23:13,815 Val Step[1500/1563], Avg Loss: 1.3721, Avg Acc@1: 0.6919, Avg Acc@5: 0.8959
2022-01-15 21:23:15,883 Val Step[1550/1563], Avg Loss: 1.3734, Avg Acc@1: 0.6916, Avg Acc@5: 0.8960
2022-01-15 21:23:17,877 ----- Epoch[090/300], Validation Loss: 1.3753, Validation Acc@1: 0.6906, Validation Acc@5: 0.8961, time: 156.30
2022-01-15 21:23:17,878 Now training epoch 91. LR=0.000851
2022-01-15 21:25:11,833 Epoch[091/300], Step[0000/1252], Avg Loss: 3.4962, Avg Acc: 0.5000
2022-01-15 21:26:39,906 Epoch[091/300], Step[0050/1252], Avg Loss: 3.5378, Avg Acc: 0.4122
2022-01-15 21:28:07,169 Epoch[091/300], Step[0100/1252], Avg Loss: 3.5589, Avg Acc: 0.3837
2022-01-15 21:29:34,661 Epoch[091/300], Step[0150/1252], Avg Loss: 3.5636, Avg Acc: 0.3937
2022-01-15 21:31:01,274 Epoch[091/300], Step[0200/1252], Avg Loss: 3.5692, Avg Acc: 0.3851
2022-01-15 21:32:28,352 Epoch[091/300], Step[0250/1252], Avg Loss: 3.5683, Avg Acc: 0.3852
2022-01-15 21:33:55,534 Epoch[091/300], Step[0300/1252], Avg Loss: 3.5865, Avg Acc: 0.3852
2022-01-15 21:35:22,192 Epoch[091/300], Step[0350/1252], Avg Loss: 3.5846, Avg Acc: 0.3878
2022-01-15 21:36:49,986 Epoch[091/300], Step[0400/1252], Avg Loss: 3.5874, Avg Acc: 0.3852
2022-01-15 21:38:17,469 Epoch[091/300], Step[0450/1252], Avg Loss: 3.5846, Avg Acc: 0.3870
2022-01-15 21:39:46,206 Epoch[091/300], Step[0500/1252], Avg Loss: 3.5866, Avg Acc: 0.3885
2022-01-15 21:41:13,491 Epoch[091/300], Step[0550/1252], Avg Loss: 3.5918, Avg Acc: 0.3840
2022-01-15 21:42:39,958 Epoch[091/300], Step[0600/1252], Avg Loss: 3.6006, Avg Acc: 0.3860
2022-01-15 21:44:08,199 Epoch[091/300], Step[0650/1252], Avg Loss: 3.6126, Avg Acc: 0.3870
2022-01-15 21:45:35,249 Epoch[091/300], Step[0700/1252], Avg Loss: 3.6080, Avg Acc: 0.3878
2022-01-15 21:47:03,148 Epoch[091/300], Step[0750/1252], Avg Loss: 3.6129, Avg Acc: 0.3825
2022-01-15 21:48:31,600 Epoch[091/300], Step[0800/1252], Avg Loss: 3.6147, Avg Acc: 0.3805
2022-01-15 21:49:59,729 Epoch[091/300], Step[0850/1252], Avg Loss: 3.6100, Avg Acc: 0.3812
2022-01-15 21:51:28,040 Epoch[091/300], Step[0900/1252], Avg Loss: 3.6148, Avg Acc: 0.3810
2022-01-15 21:52:55,883 Epoch[091/300], Step[0950/1252], Avg Loss: 3.6144, Avg Acc: 0.3777
2022-01-15 21:54:23,779 Epoch[091/300], Step[1000/1252], Avg Loss: 3.6208, Avg Acc: 0.3760
2022-01-15 21:55:51,778 Epoch[091/300], Step[1050/1252], Avg Loss: 3.6173, Avg Acc: 0.3759
2022-01-15 21:57:19,790 Epoch[091/300], Step[1100/1252], Avg Loss: 3.6184, Avg Acc: 0.3737
2022-01-15 21:58:48,507 Epoch[091/300], Step[1150/1252], Avg Loss: 3.6174, Avg Acc: 0.3738
2022-01-15 22:00:15,592 Epoch[091/300], Step[1200/1252], Avg Loss: 3.6204, Avg Acc: 0.3734
2022-01-15 22:01:41,894 Epoch[091/300], Step[1250/1252], Avg Loss: 3.6193, Avg Acc: 0.3741
2022-01-15 22:01:48,969 ----- Epoch[091/300], Train Loss: 3.6193, Train Acc: 0.3741, time: 2311.09
2022-01-15 22:01:48,970 Now training epoch 92. LR=0.000847
2022-01-15 22:03:40,157 Epoch[092/300], Step[0000/1252], Avg Loss: 4.3441, Avg Acc: 0.1914
2022-01-15 22:05:07,750 Epoch[092/300], Step[0050/1252], Avg Loss: 3.6269, Avg Acc: 0.4164
2022-01-15 22:06:34,977 Epoch[092/300], Step[0100/1252], Avg Loss: 3.6526, Avg Acc: 0.3830
2022-01-15 22:08:03,409 Epoch[092/300], Step[0150/1252], Avg Loss: 3.6582, Avg Acc: 0.3812
2022-01-15 22:09:31,806 Epoch[092/300], Step[0200/1252], Avg Loss: 3.6276, Avg Acc: 0.3862
2022-01-15 22:11:00,361 Epoch[092/300], Step[0250/1252], Avg Loss: 3.6346, Avg Acc: 0.3880
2022-01-15 22:12:27,083 Epoch[092/300], Step[0300/1252], Avg Loss: 3.6524, Avg Acc: 0.3807
2022-01-15 22:13:54,748 Epoch[092/300], Step[0350/1252], Avg Loss: 3.6367, Avg Acc: 0.3816
2022-01-15 22:15:22,886 Epoch[092/300], Step[0400/1252], Avg Loss: 3.6323, Avg Acc: 0.3853
2022-01-15 22:16:51,393 Epoch[092/300], Step[0450/1252], Avg Loss: 3.6290, Avg Acc: 0.3813
2022-01-15 22:18:18,725 Epoch[092/300], Step[0500/1252], Avg Loss: 3.6270, Avg Acc: 0.3792
2022-01-15 22:19:46,874 Epoch[092/300], Step[0550/1252], Avg Loss: 3.6163, Avg Acc: 0.3812
2022-01-15 22:21:14,699 Epoch[092/300], Step[0600/1252], Avg Loss: 3.6076, Avg Acc: 0.3831
2022-01-15 22:22:42,481 Epoch[092/300], Step[0650/1252], Avg Loss: 3.6012, Avg Acc: 0.3829
2022-01-15 22:24:09,919 Epoch[092/300], Step[0700/1252], Avg Loss: 3.6048, Avg Acc: 0.3797
2022-01-15 22:25:37,011 Epoch[092/300], Step[0750/1252], Avg Loss: 3.6039, Avg Acc: 0.3805
2022-01-15 22:27:03,984 Epoch[092/300], Step[0800/1252], Avg Loss: 3.6028, Avg Acc: 0.3764
2022-01-15 22:28:32,145 Epoch[092/300], Step[0850/1252], Avg Loss: 3.6040, Avg Acc: 0.3766
2022-01-15 22:30:00,898 Epoch[092/300], Step[0900/1252], Avg Loss: 3.6054, Avg Acc: 0.3746
2022-01-15 22:31:29,441 Epoch[092/300], Step[0950/1252], Avg Loss: 3.6091, Avg Acc: 0.3697
2022-01-15 22:32:57,484 Epoch[092/300], Step[1000/1252], Avg Loss: 3.6035, Avg Acc: 0.3674
2022-01-15 22:34:24,832 Epoch[092/300], Step[1050/1252], Avg Loss: 3.6128, Avg Acc: 0.3661
2022-01-15 22:35:51,749 Epoch[092/300], Step[1100/1252], Avg Loss: 3.6144, Avg Acc: 0.3675
2022-01-15 22:37:18,019 Epoch[092/300], Step[1150/1252], Avg Loss: 3.6096, Avg Acc: 0.3675
2022-01-15 22:38:44,452 Epoch[092/300], Step[1200/1252], Avg Loss: 3.6105, Avg Acc: 0.3682
2022-01-15 22:40:08,818 Epoch[092/300], Step[1250/1252], Avg Loss: 3.6133, Avg Acc: 0.3675
2022-01-15 22:40:15,993 ----- Epoch[092/300], Train Loss: 3.6132, Train Acc: 0.3675, time: 2307.02
2022-01-15 22:40:15,994 ----- Validation after Epoch: 92
2022-01-15 22:41:39,811 Val Step[0000/1563], Avg Loss: 1.0498, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-15 22:41:41,977 Val Step[0050/1563], Avg Loss: 1.2831, Avg Acc@1: 0.7206, Avg Acc@5: 0.9240
2022-01-15 22:41:44,221 Val Step[0100/1563], Avg Loss: 1.2964, Avg Acc@1: 0.7191, Avg Acc@5: 0.9208
2022-01-15 22:41:46,098 Val Step[0150/1563], Avg Loss: 1.4149, Avg Acc@1: 0.6987, Avg Acc@5: 0.8949
2022-01-15 22:41:47,982 Val Step[0200/1563], Avg Loss: 1.3786, Avg Acc@1: 0.7052, Avg Acc@5: 0.9005
2022-01-15 22:41:49,791 Val Step[0250/1563], Avg Loss: 1.3742, Avg Acc@1: 0.7082, Avg Acc@5: 0.9004
2022-01-15 22:41:51,582 Val Step[0300/1563], Avg Loss: 1.3870, Avg Acc@1: 0.7051, Avg Acc@5: 0.8978
2022-01-15 22:41:53,384 Val Step[0350/1563], Avg Loss: 1.4143, Avg Acc@1: 0.6969, Avg Acc@5: 0.8942
2022-01-15 22:41:55,179 Val Step[0400/1563], Avg Loss: 1.4035, Avg Acc@1: 0.6979, Avg Acc@5: 0.8978
2022-01-15 22:41:56,963 Val Step[0450/1563], Avg Loss: 1.4079, Avg Acc@1: 0.6951, Avg Acc@5: 0.8969
2022-01-15 22:41:58,763 Val Step[0500/1563], Avg Loss: 1.4113, Avg Acc@1: 0.6929, Avg Acc@5: 0.8942
2022-01-15 22:42:00,632 Val Step[0550/1563], Avg Loss: 1.4066, Avg Acc@1: 0.6940, Avg Acc@5: 0.8961
2022-01-15 22:42:02,556 Val Step[0600/1563], Avg Loss: 1.4024, Avg Acc@1: 0.6947, Avg Acc@5: 0.8977
2022-01-15 22:42:04,570 Val Step[0650/1563], Avg Loss: 1.4012, Avg Acc@1: 0.6941, Avg Acc@5: 0.8988
2022-01-15 22:42:06,727 Val Step[0700/1563], Avg Loss: 1.3984, Avg Acc@1: 0.6944, Avg Acc@5: 0.8982
2022-01-15 22:42:08,814 Val Step[0750/1563], Avg Loss: 1.4033, Avg Acc@1: 0.6931, Avg Acc@5: 0.8973
2022-01-15 22:42:10,702 Val Step[0800/1563], Avg Loss: 1.4035, Avg Acc@1: 0.6955, Avg Acc@5: 0.8964
2022-01-15 22:42:12,589 Val Step[0850/1563], Avg Loss: 1.4044, Avg Acc@1: 0.6942, Avg Acc@5: 0.8964
2022-01-15 22:42:14,478 Val Step[0900/1563], Avg Loss: 1.3943, Avg Acc@1: 0.6963, Avg Acc@5: 0.8971
2022-01-15 22:42:16,439 Val Step[0950/1563], Avg Loss: 1.3883, Avg Acc@1: 0.6979, Avg Acc@5: 0.8981
2022-01-15 22:42:18,419 Val Step[1000/1563], Avg Loss: 1.3878, Avg Acc@1: 0.6986, Avg Acc@5: 0.8982
2022-01-15 22:42:20,260 Val Step[1050/1563], Avg Loss: 1.3875, Avg Acc@1: 0.6985, Avg Acc@5: 0.8980
2022-01-15 22:42:22,244 Val Step[1100/1563], Avg Loss: 1.3942, Avg Acc@1: 0.6972, Avg Acc@5: 0.8966
2022-01-15 22:42:24,120 Val Step[1150/1563], Avg Loss: 1.3946, Avg Acc@1: 0.6973, Avg Acc@5: 0.8957
2022-01-15 22:42:25,946 Val Step[1200/1563], Avg Loss: 1.3900, Avg Acc@1: 0.6979, Avg Acc@5: 0.8962
2022-01-15 22:42:27,752 Val Step[1250/1563], Avg Loss: 1.3917, Avg Acc@1: 0.6977, Avg Acc@5: 0.8957
2022-01-15 22:42:29,515 Val Step[1300/1563], Avg Loss: 1.3953, Avg Acc@1: 0.6962, Avg Acc@5: 0.8958
2022-01-15 22:42:31,345 Val Step[1350/1563], Avg Loss: 1.4007, Avg Acc@1: 0.6952, Avg Acc@5: 0.8950
2022-01-15 22:42:33,160 Val Step[1400/1563], Avg Loss: 1.4010, Avg Acc@1: 0.6945, Avg Acc@5: 0.8950
2022-01-15 22:42:34,990 Val Step[1450/1563], Avg Loss: 1.3991, Avg Acc@1: 0.6943, Avg Acc@5: 0.8958
2022-01-15 22:42:36,797 Val Step[1500/1563], Avg Loss: 1.3970, Avg Acc@1: 0.6944, Avg Acc@5: 0.8966
2022-01-15 22:42:38,522 Val Step[1550/1563], Avg Loss: 1.3988, Avg Acc@1: 0.6940, Avg Acc@5: 0.8964
2022-01-15 22:42:40,401 ----- Epoch[092/300], Validation Loss: 1.4015, Validation Acc@1: 0.6929, Validation Acc@5: 0.8966, time: 144.40
2022-01-15 22:42:40,402 Now training epoch 93. LR=0.000843
2022-01-15 22:44:33,323 Epoch[093/300], Step[0000/1252], Avg Loss: 3.7762, Avg Acc: 0.5000
2022-01-15 22:46:00,952 Epoch[093/300], Step[0050/1252], Avg Loss: 3.5085, Avg Acc: 0.3652
2022-01-15 22:47:28,076 Epoch[093/300], Step[0100/1252], Avg Loss: 3.5764, Avg Acc: 0.3284
2022-01-15 22:48:55,193 Epoch[093/300], Step[0150/1252], Avg Loss: 3.5787, Avg Acc: 0.3431
2022-01-15 22:50:22,016 Epoch[093/300], Step[0200/1252], Avg Loss: 3.5596, Avg Acc: 0.3551
2022-01-15 22:51:49,770 Epoch[093/300], Step[0250/1252], Avg Loss: 3.5958, Avg Acc: 0.3608
2022-01-15 22:53:18,162 Epoch[093/300], Step[0300/1252], Avg Loss: 3.6119, Avg Acc: 0.3603
2022-01-15 22:54:44,760 Epoch[093/300], Step[0350/1252], Avg Loss: 3.5975, Avg Acc: 0.3667
2022-01-15 22:56:11,596 Epoch[093/300], Step[0400/1252], Avg Loss: 3.6006, Avg Acc: 0.3681
2022-01-15 22:57:38,551 Epoch[093/300], Step[0450/1252], Avg Loss: 3.6045, Avg Acc: 0.3701
2022-01-15 22:59:06,440 Epoch[093/300], Step[0500/1252], Avg Loss: 3.6135, Avg Acc: 0.3670
2022-01-15 23:00:33,314 Epoch[093/300], Step[0550/1252], Avg Loss: 3.6133, Avg Acc: 0.3643
2022-01-15 23:01:59,521 Epoch[093/300], Step[0600/1252], Avg Loss: 3.6048, Avg Acc: 0.3643
2022-01-15 23:03:27,329 Epoch[093/300], Step[0650/1252], Avg Loss: 3.5985, Avg Acc: 0.3680
2022-01-15 23:04:53,229 Epoch[093/300], Step[0700/1252], Avg Loss: 3.5987, Avg Acc: 0.3700
2022-01-15 23:06:19,002 Epoch[093/300], Step[0750/1252], Avg Loss: 3.5961, Avg Acc: 0.3726
2022-01-15 23:07:44,663 Epoch[093/300], Step[0800/1252], Avg Loss: 3.5891, Avg Acc: 0.3720
2022-01-15 23:09:11,556 Epoch[093/300], Step[0850/1252], Avg Loss: 3.5916, Avg Acc: 0.3711
2022-01-15 23:10:38,387 Epoch[093/300], Step[0900/1252], Avg Loss: 3.5927, Avg Acc: 0.3738
2022-01-15 23:12:05,163 Epoch[093/300], Step[0950/1252], Avg Loss: 3.5865, Avg Acc: 0.3750
2022-01-15 23:13:31,229 Epoch[093/300], Step[1000/1252], Avg Loss: 3.5845, Avg Acc: 0.3740
2022-01-15 23:14:57,583 Epoch[093/300], Step[1050/1252], Avg Loss: 3.5885, Avg Acc: 0.3735
2022-01-15 23:16:22,998 Epoch[093/300], Step[1100/1252], Avg Loss: 3.5932, Avg Acc: 0.3721
2022-01-15 23:17:49,145 Epoch[093/300], Step[1150/1252], Avg Loss: 3.5926, Avg Acc: 0.3722
2022-01-15 23:19:16,776 Epoch[093/300], Step[1200/1252], Avg Loss: 3.5895, Avg Acc: 0.3699
2022-01-15 23:20:43,681 Epoch[093/300], Step[1250/1252], Avg Loss: 3.5913, Avg Acc: 0.3698
2022-01-15 23:20:50,747 ----- Epoch[093/300], Train Loss: 3.5913, Train Acc: 0.3697, time: 2290.34
2022-01-15 23:20:50,748 Now training epoch 94. LR=0.000839
2022-01-15 23:22:36,825 Epoch[094/300], Step[0000/1252], Avg Loss: 4.2116, Avg Acc: 0.3867
2022-01-15 23:24:03,905 Epoch[094/300], Step[0050/1252], Avg Loss: 3.6523, Avg Acc: 0.3771
2022-01-15 23:25:32,107 Epoch[094/300], Step[0100/1252], Avg Loss: 3.6549, Avg Acc: 0.3711
2022-01-15 23:27:00,266 Epoch[094/300], Step[0150/1252], Avg Loss: 3.6136, Avg Acc: 0.3662
2022-01-15 23:28:28,787 Epoch[094/300], Step[0200/1252], Avg Loss: 3.5920, Avg Acc: 0.3815
2022-01-15 23:29:56,893 Epoch[094/300], Step[0250/1252], Avg Loss: 3.5890, Avg Acc: 0.3863
2022-01-15 23:31:25,265 Epoch[094/300], Step[0300/1252], Avg Loss: 3.5836, Avg Acc: 0.3893
2022-01-15 23:32:53,624 Epoch[094/300], Step[0350/1252], Avg Loss: 3.5928, Avg Acc: 0.3901
2022-01-15 23:34:22,205 Epoch[094/300], Step[0400/1252], Avg Loss: 3.6099, Avg Acc: 0.3862
2022-01-15 23:35:51,035 Epoch[094/300], Step[0450/1252], Avg Loss: 3.6131, Avg Acc: 0.3883
2022-01-15 23:37:19,435 Epoch[094/300], Step[0500/1252], Avg Loss: 3.6214, Avg Acc: 0.3804
2022-01-15 23:38:47,456 Epoch[094/300], Step[0550/1252], Avg Loss: 3.6175, Avg Acc: 0.3811
2022-01-15 23:40:15,159 Epoch[094/300], Step[0600/1252], Avg Loss: 3.6284, Avg Acc: 0.3803
2022-01-15 23:41:42,204 Epoch[094/300], Step[0650/1252], Avg Loss: 3.6320, Avg Acc: 0.3829
2022-01-15 23:43:09,226 Epoch[094/300], Step[0700/1252], Avg Loss: 3.6248, Avg Acc: 0.3837
2022-01-15 23:44:36,969 Epoch[094/300], Step[0750/1252], Avg Loss: 3.6192, Avg Acc: 0.3865
2022-01-15 23:46:04,906 Epoch[094/300], Step[0800/1252], Avg Loss: 3.6196, Avg Acc: 0.3870
2022-01-15 23:47:32,560 Epoch[094/300], Step[0850/1252], Avg Loss: 3.6245, Avg Acc: 0.3887
2022-01-15 23:48:59,322 Epoch[094/300], Step[0900/1252], Avg Loss: 3.6243, Avg Acc: 0.3879
2022-01-15 23:50:27,814 Epoch[094/300], Step[0950/1252], Avg Loss: 3.6261, Avg Acc: 0.3847
2022-01-15 23:51:56,263 Epoch[094/300], Step[1000/1252], Avg Loss: 3.6251, Avg Acc: 0.3833
2022-01-15 23:53:23,997 Epoch[094/300], Step[1050/1252], Avg Loss: 3.6331, Avg Acc: 0.3815
2022-01-15 23:54:50,887 Epoch[094/300], Step[1100/1252], Avg Loss: 3.6262, Avg Acc: 0.3797
2022-01-15 23:56:18,075 Epoch[094/300], Step[1150/1252], Avg Loss: 3.6244, Avg Acc: 0.3790
2022-01-15 23:57:44,869 Epoch[094/300], Step[1200/1252], Avg Loss: 3.6204, Avg Acc: 0.3789
2022-01-15 23:59:12,629 Epoch[094/300], Step[1250/1252], Avg Loss: 3.6250, Avg Acc: 0.3759
2022-01-15 23:59:19,866 ----- Epoch[094/300], Train Loss: 3.6249, Train Acc: 0.3760, time: 2309.11
2022-01-15 23:59:19,867 ----- Validation after Epoch: 94
2022-01-16 00:00:41,316 Val Step[0000/1563], Avg Loss: 1.0109, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-16 00:00:43,156 Val Step[0050/1563], Avg Loss: 1.2002, Avg Acc@1: 0.7206, Avg Acc@5: 0.9314
2022-01-16 00:00:45,009 Val Step[0100/1563], Avg Loss: 1.2512, Avg Acc@1: 0.7017, Avg Acc@5: 0.9245
2022-01-16 00:00:46,896 Val Step[0150/1563], Avg Loss: 1.3285, Avg Acc@1: 0.6995, Avg Acc@5: 0.9040
2022-01-16 00:00:48,787 Val Step[0200/1563], Avg Loss: 1.3010, Avg Acc@1: 0.7121, Avg Acc@5: 0.8999
2022-01-16 00:00:50,615 Val Step[0250/1563], Avg Loss: 1.3164, Avg Acc@1: 0.7082, Avg Acc@5: 0.9004
2022-01-16 00:00:52,433 Val Step[0300/1563], Avg Loss: 1.3177, Avg Acc@1: 0.7076, Avg Acc@5: 0.9007
2022-01-16 00:00:54,267 Val Step[0350/1563], Avg Loss: 1.3423, Avg Acc@1: 0.7012, Avg Acc@5: 0.8985
2022-01-16 00:00:56,122 Val Step[0400/1563], Avg Loss: 1.3372, Avg Acc@1: 0.7023, Avg Acc@5: 0.8990
2022-01-16 00:00:58,033 Val Step[0450/1563], Avg Loss: 1.3472, Avg Acc@1: 0.6957, Avg Acc@5: 0.8983
2022-01-16 00:00:59,860 Val Step[0500/1563], Avg Loss: 1.3572, Avg Acc@1: 0.6929, Avg Acc@5: 0.8970
2022-01-16 00:01:01,746 Val Step[0550/1563], Avg Loss: 1.3514, Avg Acc@1: 0.6933, Avg Acc@5: 0.8975
2022-01-16 00:01:03,601 Val Step[0600/1563], Avg Loss: 1.3512, Avg Acc@1: 0.6924, Avg Acc@5: 0.8975
2022-01-16 00:01:05,456 Val Step[0650/1563], Avg Loss: 1.3511, Avg Acc@1: 0.6930, Avg Acc@5: 0.8971
2022-01-16 00:01:07,321 Val Step[0700/1563], Avg Loss: 1.3473, Avg Acc@1: 0.6944, Avg Acc@5: 0.8968
2022-01-16 00:01:09,230 Val Step[0750/1563], Avg Loss: 1.3491, Avg Acc@1: 0.6946, Avg Acc@5: 0.8968
2022-01-16 00:01:11,035 Val Step[0800/1563], Avg Loss: 1.3482, Avg Acc@1: 0.6979, Avg Acc@5: 0.8953
2022-01-16 00:01:12,877 Val Step[0850/1563], Avg Loss: 1.3502, Avg Acc@1: 0.6958, Avg Acc@5: 0.8956
2022-01-16 00:01:14,711 Val Step[0900/1563], Avg Loss: 1.3438, Avg Acc@1: 0.6983, Avg Acc@5: 0.8962
2022-01-16 00:01:16,514 Val Step[0950/1563], Avg Loss: 1.3382, Avg Acc@1: 0.6991, Avg Acc@5: 0.8976
2022-01-16 00:01:18,373 Val Step[1000/1563], Avg Loss: 1.3386, Avg Acc@1: 0.6997, Avg Acc@5: 0.8969
2022-01-16 00:01:20,249 Val Step[1050/1563], Avg Loss: 1.3397, Avg Acc@1: 0.6992, Avg Acc@5: 0.8957
2022-01-16 00:01:22,197 Val Step[1100/1563], Avg Loss: 1.3489, Avg Acc@1: 0.6971, Avg Acc@5: 0.8949
2022-01-16 00:01:24,065 Val Step[1150/1563], Avg Loss: 1.3499, Avg Acc@1: 0.6971, Avg Acc@5: 0.8945
2022-01-16 00:01:25,895 Val Step[1200/1563], Avg Loss: 1.3452, Avg Acc@1: 0.6975, Avg Acc@5: 0.8951
2022-01-16 00:01:27,704 Val Step[1250/1563], Avg Loss: 1.3440, Avg Acc@1: 0.6973, Avg Acc@5: 0.8952
2022-01-16 00:01:29,493 Val Step[1300/1563], Avg Loss: 1.3474, Avg Acc@1: 0.6963, Avg Acc@5: 0.8949
2022-01-16 00:01:31,358 Val Step[1350/1563], Avg Loss: 1.3519, Avg Acc@1: 0.6953, Avg Acc@5: 0.8937
2022-01-16 00:01:33,286 Val Step[1400/1563], Avg Loss: 1.3525, Avg Acc@1: 0.6956, Avg Acc@5: 0.8936
2022-01-16 00:01:35,159 Val Step[1450/1563], Avg Loss: 1.3520, Avg Acc@1: 0.6954, Avg Acc@5: 0.8935
2022-01-16 00:01:37,016 Val Step[1500/1563], Avg Loss: 1.3510, Avg Acc@1: 0.6954, Avg Acc@5: 0.8939
2022-01-16 00:01:38,858 Val Step[1550/1563], Avg Loss: 1.3510, Avg Acc@1: 0.6953, Avg Acc@5: 0.8937
2022-01-16 00:01:40,798 ----- Epoch[094/300], Validation Loss: 1.3540, Validation Acc@1: 0.6946, Validation Acc@5: 0.8935, time: 140.93
2022-01-16 00:01:40,803 Now training epoch 95. LR=0.000835
2022-01-16 00:03:38,359 Epoch[095/300], Step[0000/1252], Avg Loss: 3.1777, Avg Acc: 0.0039
2022-01-16 00:05:07,310 Epoch[095/300], Step[0050/1252], Avg Loss: 3.5690, Avg Acc: 0.4489
2022-01-16 00:06:35,081 Epoch[095/300], Step[0100/1252], Avg Loss: 3.5612, Avg Acc: 0.4259
2022-01-16 00:08:02,660 Epoch[095/300], Step[0150/1252], Avg Loss: 3.5303, Avg Acc: 0.4173
2022-01-16 00:09:32,118 Epoch[095/300], Step[0200/1252], Avg Loss: 3.5428, Avg Acc: 0.4246
2022-01-16 00:11:00,153 Epoch[095/300], Step[0250/1252], Avg Loss: 3.5529, Avg Acc: 0.4051
2022-01-16 00:12:27,926 Epoch[095/300], Step[0300/1252], Avg Loss: 3.5633, Avg Acc: 0.4111
2022-01-16 00:13:55,327 Epoch[095/300], Step[0350/1252], Avg Loss: 3.5590, Avg Acc: 0.4082
2022-01-16 00:15:22,592 Epoch[095/300], Step[0400/1252], Avg Loss: 3.5474, Avg Acc: 0.4045
2022-01-16 00:16:49,952 Epoch[095/300], Step[0450/1252], Avg Loss: 3.5570, Avg Acc: 0.3989
2022-01-16 00:18:18,293 Epoch[095/300], Step[0500/1252], Avg Loss: 3.5662, Avg Acc: 0.3997
2022-01-16 00:19:45,476 Epoch[095/300], Step[0550/1252], Avg Loss: 3.5666, Avg Acc: 0.4034
2022-01-16 00:21:14,175 Epoch[095/300], Step[0600/1252], Avg Loss: 3.5640, Avg Acc: 0.4007
2022-01-16 00:22:43,251 Epoch[095/300], Step[0650/1252], Avg Loss: 3.5687, Avg Acc: 0.3990
2022-01-16 00:24:11,474 Epoch[095/300], Step[0700/1252], Avg Loss: 3.5710, Avg Acc: 0.3988
2022-01-16 00:25:39,083 Epoch[095/300], Step[0750/1252], Avg Loss: 3.5910, Avg Acc: 0.3981
2022-01-16 00:27:06,624 Epoch[095/300], Step[0800/1252], Avg Loss: 3.5992, Avg Acc: 0.3958
2022-01-16 00:28:35,892 Epoch[095/300], Step[0850/1252], Avg Loss: 3.6083, Avg Acc: 0.3938
2022-01-16 00:30:04,195 Epoch[095/300], Step[0900/1252], Avg Loss: 3.6039, Avg Acc: 0.3934
2022-01-16 00:31:32,715 Epoch[095/300], Step[0950/1252], Avg Loss: 3.6082, Avg Acc: 0.3930
2022-01-16 00:33:02,103 Epoch[095/300], Step[1000/1252], Avg Loss: 3.6069, Avg Acc: 0.3904
2022-01-16 00:34:31,365 Epoch[095/300], Step[1050/1252], Avg Loss: 3.6150, Avg Acc: 0.3899
2022-01-16 00:35:59,699 Epoch[095/300], Step[1100/1252], Avg Loss: 3.6165, Avg Acc: 0.3890
2022-01-16 00:37:28,199 Epoch[095/300], Step[1150/1252], Avg Loss: 3.6207, Avg Acc: 0.3897
2022-01-16 00:38:57,487 Epoch[095/300], Step[1200/1252], Avg Loss: 3.6205, Avg Acc: 0.3894
2022-01-16 00:40:26,385 Epoch[095/300], Step[1250/1252], Avg Loss: 3.6199, Avg Acc: 0.3883
2022-01-16 00:40:33,433 ----- Epoch[095/300], Train Loss: 3.6199, Train Acc: 0.3883, time: 2332.63
2022-01-16 00:40:33,434 Now training epoch 96. LR=0.000831
2022-01-16 00:42:21,892 Epoch[096/300], Step[0000/1252], Avg Loss: 4.5136, Avg Acc: 0.1797
2022-01-16 00:43:48,287 Epoch[096/300], Step[0050/1252], Avg Loss: 3.6903, Avg Acc: 0.3735
2022-01-16 00:45:14,774 Epoch[096/300], Step[0100/1252], Avg Loss: 3.5756, Avg Acc: 0.3894
2022-01-16 00:46:42,156 Epoch[096/300], Step[0150/1252], Avg Loss: 3.5493, Avg Acc: 0.3875
2022-01-16 00:48:08,137 Epoch[096/300], Step[0200/1252], Avg Loss: 3.5226, Avg Acc: 0.3952
2022-01-16 00:49:35,530 Epoch[096/300], Step[0250/1252], Avg Loss: 3.5576, Avg Acc: 0.3816
2022-01-16 00:51:03,094 Epoch[096/300], Step[0300/1252], Avg Loss: 3.5618, Avg Acc: 0.3713
2022-01-16 00:52:29,691 Epoch[096/300], Step[0350/1252], Avg Loss: 3.5608, Avg Acc: 0.3780
2022-01-16 00:53:55,720 Epoch[096/300], Step[0400/1252], Avg Loss: 3.5767, Avg Acc: 0.3772
2022-01-16 00:55:22,235 Epoch[096/300], Step[0450/1252], Avg Loss: 3.5735, Avg Acc: 0.3824
2022-01-16 00:56:49,819 Epoch[096/300], Step[0500/1252], Avg Loss: 3.5815, Avg Acc: 0.3827
2022-01-16 00:58:17,537 Epoch[096/300], Step[0550/1252], Avg Loss: 3.5783, Avg Acc: 0.3824
2022-01-16 00:59:45,790 Epoch[096/300], Step[0600/1252], Avg Loss: 3.5808, Avg Acc: 0.3865
2022-01-16 01:01:14,050 Epoch[096/300], Step[0650/1252], Avg Loss: 3.5892, Avg Acc: 0.3857
2022-01-16 01:02:42,250 Epoch[096/300], Step[0700/1252], Avg Loss: 3.5880, Avg Acc: 0.3838
2022-01-16 01:04:11,375 Epoch[096/300], Step[0750/1252], Avg Loss: 3.5816, Avg Acc: 0.3836
2022-01-16 01:05:40,666 Epoch[096/300], Step[0800/1252], Avg Loss: 3.5778, Avg Acc: 0.3846
2022-01-16 01:07:08,688 Epoch[096/300], Step[0850/1252], Avg Loss: 3.5839, Avg Acc: 0.3846
2022-01-16 01:08:37,104 Epoch[096/300], Step[0900/1252], Avg Loss: 3.5814, Avg Acc: 0.3871
2022-01-16 01:10:06,158 Epoch[096/300], Step[0950/1252], Avg Loss: 3.5781, Avg Acc: 0.3848
2022-01-16 01:11:34,483 Epoch[096/300], Step[1000/1252], Avg Loss: 3.5858, Avg Acc: 0.3829
2022-01-16 01:13:03,443 Epoch[096/300], Step[1050/1252], Avg Loss: 3.5925, Avg Acc: 0.3805
2022-01-16 01:14:32,313 Epoch[096/300], Step[1100/1252], Avg Loss: 3.5916, Avg Acc: 0.3812
2022-01-16 01:16:00,185 Epoch[096/300], Step[1150/1252], Avg Loss: 3.5878, Avg Acc: 0.3823
2022-01-16 01:17:28,441 Epoch[096/300], Step[1200/1252], Avg Loss: 3.5947, Avg Acc: 0.3821
2022-01-16 01:18:56,507 Epoch[096/300], Step[1250/1252], Avg Loss: 3.5859, Avg Acc: 0.3819
2022-01-16 01:19:03,655 ----- Epoch[096/300], Train Loss: 3.5859, Train Acc: 0.3819, time: 2310.22
2022-01-16 01:19:03,656 ----- Validation after Epoch: 96
2022-01-16 01:20:17,742 Val Step[0000/1563], Avg Loss: 1.1261, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-16 01:20:19,605 Val Step[0050/1563], Avg Loss: 1.2436, Avg Acc@1: 0.7181, Avg Acc@5: 0.9265
2022-01-16 01:20:21,505 Val Step[0100/1563], Avg Loss: 1.2558, Avg Acc@1: 0.7104, Avg Acc@5: 0.9245
2022-01-16 01:20:23,348 Val Step[0150/1563], Avg Loss: 1.3415, Avg Acc@1: 0.7028, Avg Acc@5: 0.9073
2022-01-16 01:20:25,141 Val Step[0200/1563], Avg Loss: 1.3198, Avg Acc@1: 0.7046, Avg Acc@5: 0.9098
2022-01-16 01:20:26,934 Val Step[0250/1563], Avg Loss: 1.3350, Avg Acc@1: 0.6982, Avg Acc@5: 0.9074
2022-01-16 01:20:28,746 Val Step[0300/1563], Avg Loss: 1.3444, Avg Acc@1: 0.6968, Avg Acc@5: 0.9041
2022-01-16 01:20:30,544 Val Step[0350/1563], Avg Loss: 1.3664, Avg Acc@1: 0.6930, Avg Acc@5: 0.9006
2022-01-16 01:20:32,373 Val Step[0400/1563], Avg Loss: 1.3554, Avg Acc@1: 0.6920, Avg Acc@5: 0.9024
2022-01-16 01:20:34,311 Val Step[0450/1563], Avg Loss: 1.3591, Avg Acc@1: 0.6918, Avg Acc@5: 0.8999
2022-01-16 01:20:36,117 Val Step[0500/1563], Avg Loss: 1.3604, Avg Acc@1: 0.6904, Avg Acc@5: 0.9007
2022-01-16 01:20:37,920 Val Step[0550/1563], Avg Loss: 1.3537, Avg Acc@1: 0.6924, Avg Acc@5: 0.9004
2022-01-16 01:20:39,807 Val Step[0600/1563], Avg Loss: 1.3515, Avg Acc@1: 0.6922, Avg Acc@5: 0.9004
2022-01-16 01:20:41,728 Val Step[0650/1563], Avg Loss: 1.3481, Avg Acc@1: 0.6912, Avg Acc@5: 0.9011
2022-01-16 01:20:43,614 Val Step[0700/1563], Avg Loss: 1.3422, Avg Acc@1: 0.6929, Avg Acc@5: 0.9014
2022-01-16 01:20:45,574 Val Step[0750/1563], Avg Loss: 1.3462, Avg Acc@1: 0.6914, Avg Acc@5: 0.9001
2022-01-16 01:20:47,531 Val Step[0800/1563], Avg Loss: 1.3488, Avg Acc@1: 0.6930, Avg Acc@5: 0.8986
2022-01-16 01:20:49,410 Val Step[0850/1563], Avg Loss: 1.3526, Avg Acc@1: 0.6907, Avg Acc@5: 0.8998
2022-01-16 01:20:51,215 Val Step[0900/1563], Avg Loss: 1.3423, Avg Acc@1: 0.6946, Avg Acc@5: 0.9008
2022-01-16 01:20:53,285 Val Step[0950/1563], Avg Loss: 1.3381, Avg Acc@1: 0.6960, Avg Acc@5: 0.9013
2022-01-16 01:20:55,344 Val Step[1000/1563], Avg Loss: 1.3380, Avg Acc@1: 0.6961, Avg Acc@5: 0.9023
2022-01-16 01:20:57,389 Val Step[1050/1563], Avg Loss: 1.3415, Avg Acc@1: 0.6954, Avg Acc@5: 0.9015
2022-01-16 01:20:59,154 Val Step[1100/1563], Avg Loss: 1.3500, Avg Acc@1: 0.6932, Avg Acc@5: 0.9003
2022-01-16 01:21:00,965 Val Step[1150/1563], Avg Loss: 1.3513, Avg Acc@1: 0.6931, Avg Acc@5: 0.9004
2022-01-16 01:21:02,789 Val Step[1200/1563], Avg Loss: 1.3465, Avg Acc@1: 0.6950, Avg Acc@5: 0.9011
2022-01-16 01:21:04,727 Val Step[1250/1563], Avg Loss: 1.3467, Avg Acc@1: 0.6951, Avg Acc@5: 0.9007
2022-01-16 01:21:06,654 Val Step[1300/1563], Avg Loss: 1.3513, Avg Acc@1: 0.6935, Avg Acc@5: 0.9003
2022-01-16 01:21:08,435 Val Step[1350/1563], Avg Loss: 1.3578, Avg Acc@1: 0.6925, Avg Acc@5: 0.8992
2022-01-16 01:21:10,309 Val Step[1400/1563], Avg Loss: 1.3565, Avg Acc@1: 0.6928, Avg Acc@5: 0.8992
2022-01-16 01:21:12,273 Val Step[1450/1563], Avg Loss: 1.3535, Avg Acc@1: 0.6934, Avg Acc@5: 0.8995
2022-01-16 01:21:14,233 Val Step[1500/1563], Avg Loss: 1.3518, Avg Acc@1: 0.6935, Avg Acc@5: 0.8998
2022-01-16 01:21:16,004 Val Step[1550/1563], Avg Loss: 1.3528, Avg Acc@1: 0.6932, Avg Acc@5: 0.8993
2022-01-16 01:21:17,900 ----- Epoch[096/300], Validation Loss: 1.3556, Validation Acc@1: 0.6921, Validation Acc@5: 0.8993, time: 134.24
2022-01-16 01:21:17,901 Now training epoch 97. LR=0.000826
2022-01-16 01:23:07,144 Epoch[097/300], Step[0000/1252], Avg Loss: 4.0562, Avg Acc: 0.4961
2022-01-16 01:24:34,916 Epoch[097/300], Step[0050/1252], Avg Loss: 3.6503, Avg Acc: 0.4027
2022-01-16 01:26:01,838 Epoch[097/300], Step[0100/1252], Avg Loss: 3.5509, Avg Acc: 0.4106
2022-01-16 01:27:30,555 Epoch[097/300], Step[0150/1252], Avg Loss: 3.5217, Avg Acc: 0.4029
2022-01-16 01:28:58,240 Epoch[097/300], Step[0200/1252], Avg Loss: 3.5409, Avg Acc: 0.3887
2022-01-16 01:30:25,678 Epoch[097/300], Step[0250/1252], Avg Loss: 3.5368, Avg Acc: 0.3877
2022-01-16 01:31:54,152 Epoch[097/300], Step[0300/1252], Avg Loss: 3.5451, Avg Acc: 0.3854
2022-01-16 01:33:22,315 Epoch[097/300], Step[0350/1252], Avg Loss: 3.5389, Avg Acc: 0.3864
2022-01-16 01:34:50,652 Epoch[097/300], Step[0400/1252], Avg Loss: 3.5577, Avg Acc: 0.3817
2022-01-16 01:36:20,155 Epoch[097/300], Step[0450/1252], Avg Loss: 3.5550, Avg Acc: 0.3790
2022-01-16 01:37:47,798 Epoch[097/300], Step[0500/1252], Avg Loss: 3.5717, Avg Acc: 0.3784
2022-01-16 01:39:16,029 Epoch[097/300], Step[0550/1252], Avg Loss: 3.5837, Avg Acc: 0.3778
2022-01-16 01:40:45,027 Epoch[097/300], Step[0600/1252], Avg Loss: 3.5806, Avg Acc: 0.3815
2022-01-16 01:42:13,556 Epoch[097/300], Step[0650/1252], Avg Loss: 3.5823, Avg Acc: 0.3817
2022-01-16 01:43:40,879 Epoch[097/300], Step[0700/1252], Avg Loss: 3.5800, Avg Acc: 0.3789
2022-01-16 01:45:08,627 Epoch[097/300], Step[0750/1252], Avg Loss: 3.5822, Avg Acc: 0.3799
2022-01-16 01:46:37,112 Epoch[097/300], Step[0800/1252], Avg Loss: 3.5783, Avg Acc: 0.3810
2022-01-16 01:48:04,027 Epoch[097/300], Step[0850/1252], Avg Loss: 3.5783, Avg Acc: 0.3770
2022-01-16 01:49:32,696 Epoch[097/300], Step[0900/1252], Avg Loss: 3.5804, Avg Acc: 0.3785
2022-01-16 01:51:00,867 Epoch[097/300], Step[0950/1252], Avg Loss: 3.5849, Avg Acc: 0.3782
2022-01-16 01:52:28,711 Epoch[097/300], Step[1000/1252], Avg Loss: 3.5941, Avg Acc: 0.3809
2022-01-16 01:53:56,901 Epoch[097/300], Step[1050/1252], Avg Loss: 3.5942, Avg Acc: 0.3812
2022-01-16 01:55:24,944 Epoch[097/300], Step[1100/1252], Avg Loss: 3.5930, Avg Acc: 0.3781
2022-01-16 01:56:53,241 Epoch[097/300], Step[1150/1252], Avg Loss: 3.5891, Avg Acc: 0.3781
2022-01-16 01:58:21,410 Epoch[097/300], Step[1200/1252], Avg Loss: 3.5830, Avg Acc: 0.3796
2022-01-16 01:59:47,702 Epoch[097/300], Step[1250/1252], Avg Loss: 3.5804, Avg Acc: 0.3798
2022-01-16 01:59:55,021 ----- Epoch[097/300], Train Loss: 3.5804, Train Acc: 0.3797, time: 2317.12
2022-01-16 01:59:55,022 Now training epoch 98. LR=0.000822
2022-01-16 02:01:41,129 Epoch[098/300], Step[0000/1252], Avg Loss: 4.3396, Avg Acc: 0.1445
2022-01-16 02:03:08,510 Epoch[098/300], Step[0050/1252], Avg Loss: 3.5644, Avg Acc: 0.3450
2022-01-16 02:04:33,373 Epoch[098/300], Step[0100/1252], Avg Loss: 3.4969, Avg Acc: 0.4000
2022-01-16 02:06:00,797 Epoch[098/300], Step[0150/1252], Avg Loss: 3.5657, Avg Acc: 0.3901
2022-01-16 02:07:28,569 Epoch[098/300], Step[0200/1252], Avg Loss: 3.5478, Avg Acc: 0.4033
2022-01-16 02:08:55,298 Epoch[098/300], Step[0250/1252], Avg Loss: 3.5847, Avg Acc: 0.3896
2022-01-16 02:10:22,642 Epoch[098/300], Step[0300/1252], Avg Loss: 3.5884, Avg Acc: 0.3929
2022-01-16 02:11:50,092 Epoch[098/300], Step[0350/1252], Avg Loss: 3.5759, Avg Acc: 0.3902
2022-01-16 02:13:17,266 Epoch[098/300], Step[0400/1252], Avg Loss: 3.5936, Avg Acc: 0.3886
2022-01-16 02:14:43,177 Epoch[098/300], Step[0450/1252], Avg Loss: 3.5971, Avg Acc: 0.3935
2022-01-16 02:16:10,985 Epoch[098/300], Step[0500/1252], Avg Loss: 3.5996, Avg Acc: 0.3935
2022-01-16 02:17:37,506 Epoch[098/300], Step[0550/1252], Avg Loss: 3.5951, Avg Acc: 0.3929
2022-01-16 02:19:05,201 Epoch[098/300], Step[0600/1252], Avg Loss: 3.5831, Avg Acc: 0.3921
2022-01-16 02:20:32,701 Epoch[098/300], Step[0650/1252], Avg Loss: 3.5888, Avg Acc: 0.3917
2022-01-16 02:22:01,173 Epoch[098/300], Step[0700/1252], Avg Loss: 3.5913, Avg Acc: 0.3895
2022-01-16 02:23:28,597 Epoch[098/300], Step[0750/1252], Avg Loss: 3.5966, Avg Acc: 0.3883
2022-01-16 02:24:56,331 Epoch[098/300], Step[0800/1252], Avg Loss: 3.5998, Avg Acc: 0.3877
2022-01-16 02:26:24,284 Epoch[098/300], Step[0850/1252], Avg Loss: 3.6084, Avg Acc: 0.3877
2022-01-16 02:27:52,117 Epoch[098/300], Step[0900/1252], Avg Loss: 3.6021, Avg Acc: 0.3898
2022-01-16 02:29:20,420 Epoch[098/300], Step[0950/1252], Avg Loss: 3.5870, Avg Acc: 0.3883
2022-01-16 02:30:48,834 Epoch[098/300], Step[1000/1252], Avg Loss: 3.5897, Avg Acc: 0.3868
2022-01-16 02:32:17,778 Epoch[098/300], Step[1050/1252], Avg Loss: 3.5909, Avg Acc: 0.3846
2022-01-16 02:33:45,890 Epoch[098/300], Step[1100/1252], Avg Loss: 3.5914, Avg Acc: 0.3839
2022-01-16 02:35:14,967 Epoch[098/300], Step[1150/1252], Avg Loss: 3.5940, Avg Acc: 0.3822
2022-01-16 02:36:42,590 Epoch[098/300], Step[1200/1252], Avg Loss: 3.5955, Avg Acc: 0.3831
2022-01-16 02:38:11,952 Epoch[098/300], Step[1250/1252], Avg Loss: 3.6015, Avg Acc: 0.3823
2022-01-16 02:38:19,177 ----- Epoch[098/300], Train Loss: 3.6016, Train Acc: 0.3823, time: 2304.15
2022-01-16 02:38:19,178 ----- Validation after Epoch: 98
2022-01-16 02:39:30,464 Val Step[0000/1563], Avg Loss: 1.1563, Avg Acc@1: 0.8750, Avg Acc@5: 1.0000
2022-01-16 02:39:32,669 Val Step[0050/1563], Avg Loss: 1.3003, Avg Acc@1: 0.6985, Avg Acc@5: 0.9265
2022-01-16 02:39:34,603 Val Step[0100/1563], Avg Loss: 1.2635, Avg Acc@1: 0.7129, Avg Acc@5: 0.9220
2022-01-16 02:39:36,385 Val Step[0150/1563], Avg Loss: 1.3491, Avg Acc@1: 0.7003, Avg Acc@5: 0.8982
2022-01-16 02:39:38,189 Val Step[0200/1563], Avg Loss: 1.3139, Avg Acc@1: 0.7108, Avg Acc@5: 0.9005
2022-01-16 02:39:40,065 Val Step[0250/1563], Avg Loss: 1.3164, Avg Acc@1: 0.7166, Avg Acc@5: 0.9014
2022-01-16 02:39:41,895 Val Step[0300/1563], Avg Loss: 1.3240, Avg Acc@1: 0.7155, Avg Acc@5: 0.8995
2022-01-16 02:39:43,684 Val Step[0350/1563], Avg Loss: 1.3467, Avg Acc@1: 0.7126, Avg Acc@5: 0.8974
2022-01-16 02:39:45,572 Val Step[0400/1563], Avg Loss: 1.3401, Avg Acc@1: 0.7135, Avg Acc@5: 0.8974
2022-01-16 02:39:47,383 Val Step[0450/1563], Avg Loss: 1.3497, Avg Acc@1: 0.7101, Avg Acc@5: 0.8952
2022-01-16 02:39:49,442 Val Step[0500/1563], Avg Loss: 1.3586, Avg Acc@1: 0.7058, Avg Acc@5: 0.8950
2022-01-16 02:39:51,504 Val Step[0550/1563], Avg Loss: 1.3592, Avg Acc@1: 0.7042, Avg Acc@5: 0.8966
2022-01-16 02:39:53,573 Val Step[0600/1563], Avg Loss: 1.3589, Avg Acc@1: 0.7040, Avg Acc@5: 0.8970
2022-01-16 02:39:55,621 Val Step[0650/1563], Avg Loss: 1.3563, Avg Acc@1: 0.7035, Avg Acc@5: 0.8978
2022-01-16 02:39:57,649 Val Step[0700/1563], Avg Loss: 1.3520, Avg Acc@1: 0.7033, Avg Acc@5: 0.8976
2022-01-16 02:39:59,676 Val Step[0750/1563], Avg Loss: 1.3584, Avg Acc@1: 0.7019, Avg Acc@5: 0.8971
2022-01-16 02:40:01,736 Val Step[0800/1563], Avg Loss: 1.3618, Avg Acc@1: 0.7032, Avg Acc@5: 0.8948
2022-01-16 02:40:03,801 Val Step[0850/1563], Avg Loss: 1.3628, Avg Acc@1: 0.7015, Avg Acc@5: 0.8956
2022-01-16 02:40:05,856 Val Step[0900/1563], Avg Loss: 1.3554, Avg Acc@1: 0.7030, Avg Acc@5: 0.8962
2022-01-16 02:40:07,983 Val Step[0950/1563], Avg Loss: 1.3513, Avg Acc@1: 0.7035, Avg Acc@5: 0.8972
2022-01-16 02:40:09,867 Val Step[1000/1563], Avg Loss: 1.3514, Avg Acc@1: 0.7033, Avg Acc@5: 0.8976
2022-01-16 02:40:11,819 Val Step[1050/1563], Avg Loss: 1.3548, Avg Acc@1: 0.7029, Avg Acc@5: 0.8974
2022-01-16 02:40:13,714 Val Step[1100/1563], Avg Loss: 1.3596, Avg Acc@1: 0.7019, Avg Acc@5: 0.8969
2022-01-16 02:40:15,487 Val Step[1150/1563], Avg Loss: 1.3618, Avg Acc@1: 0.7009, Avg Acc@5: 0.8966
2022-01-16 02:40:17,280 Val Step[1200/1563], Avg Loss: 1.3562, Avg Acc@1: 0.7015, Avg Acc@5: 0.8971
2022-01-16 02:40:19,067 Val Step[1250/1563], Avg Loss: 1.3586, Avg Acc@1: 0.7011, Avg Acc@5: 0.8965
2022-01-16 02:40:20,893 Val Step[1300/1563], Avg Loss: 1.3605, Avg Acc@1: 0.7005, Avg Acc@5: 0.8968
2022-01-16 02:40:22,773 Val Step[1350/1563], Avg Loss: 1.3655, Avg Acc@1: 0.6996, Avg Acc@5: 0.8959
2022-01-16 02:40:24,665 Val Step[1400/1563], Avg Loss: 1.3643, Avg Acc@1: 0.6996, Avg Acc@5: 0.8961
2022-01-16 02:40:26,489 Val Step[1450/1563], Avg Loss: 1.3617, Avg Acc@1: 0.6998, Avg Acc@5: 0.8965
2022-01-16 02:40:28,312 Val Step[1500/1563], Avg Loss: 1.3609, Avg Acc@1: 0.6996, Avg Acc@5: 0.8963
2022-01-16 02:40:30,079 Val Step[1550/1563], Avg Loss: 1.3628, Avg Acc@1: 0.6988, Avg Acc@5: 0.8961
2022-01-16 02:40:32,012 ----- Epoch[098/300], Validation Loss: 1.3659, Validation Acc@1: 0.6978, Validation Acc@5: 0.8958, time: 132.83
2022-01-16 02:40:32,013 Now training epoch 99. LR=0.000818
2022-01-16 02:42:17,225 Epoch[099/300], Step[0000/1252], Avg Loss: 3.8505, Avg Acc: 0.5742
2022-01-16 02:43:44,893 Epoch[099/300], Step[0050/1252], Avg Loss: 3.4502, Avg Acc: 0.3856
2022-01-16 02:45:13,337 Epoch[099/300], Step[0100/1252], Avg Loss: 3.4559, Avg Acc: 0.3870
2022-01-16 02:46:39,602 Epoch[099/300], Step[0150/1252], Avg Loss: 3.5552, Avg Acc: 0.3734
2022-01-16 02:48:07,984 Epoch[099/300], Step[0200/1252], Avg Loss: 3.5686, Avg Acc: 0.3717
2022-01-16 02:49:36,036 Epoch[099/300], Step[0250/1252], Avg Loss: 3.5644, Avg Acc: 0.3835
2022-01-16 02:51:03,629 Epoch[099/300], Step[0300/1252], Avg Loss: 3.5409, Avg Acc: 0.3881
2022-01-16 02:52:31,388 Epoch[099/300], Step[0350/1252], Avg Loss: 3.5470, Avg Acc: 0.3816
2022-01-16 02:53:59,168 Epoch[099/300], Step[0400/1252], Avg Loss: 3.5603, Avg Acc: 0.3838
2022-01-16 02:55:24,788 Epoch[099/300], Step[0450/1252], Avg Loss: 3.5590, Avg Acc: 0.3791
2022-01-16 02:56:52,143 Epoch[099/300], Step[0500/1252], Avg Loss: 3.5661, Avg Acc: 0.3781
2022-01-16 02:58:18,920 Epoch[099/300], Step[0550/1252], Avg Loss: 3.5696, Avg Acc: 0.3759
2022-01-16 02:59:45,678 Epoch[099/300], Step[0600/1252], Avg Loss: 3.5646, Avg Acc: 0.3792
2022-01-16 03:01:13,853 Epoch[099/300], Step[0650/1252], Avg Loss: 3.5724, Avg Acc: 0.3788
2022-01-16 03:02:42,628 Epoch[099/300], Step[0700/1252], Avg Loss: 3.5682, Avg Acc: 0.3797
2022-01-16 03:04:10,860 Epoch[099/300], Step[0750/1252], Avg Loss: 3.5576, Avg Acc: 0.3829
2022-01-16 03:05:38,553 Epoch[099/300], Step[0800/1252], Avg Loss: 3.5560, Avg Acc: 0.3810
2022-01-16 03:07:07,052 Epoch[099/300], Step[0850/1252], Avg Loss: 3.5679, Avg Acc: 0.3805
2022-01-16 03:08:35,445 Epoch[099/300], Step[0900/1252], Avg Loss: 3.5683, Avg Acc: 0.3767
2022-01-16 03:10:02,233 Epoch[099/300], Step[0950/1252], Avg Loss: 3.5692, Avg Acc: 0.3786
2022-01-16 03:11:28,948 Epoch[099/300], Step[1000/1252], Avg Loss: 3.5742, Avg Acc: 0.3809
2022-01-16 03:12:57,097 Epoch[099/300], Step[1050/1252], Avg Loss: 3.5741, Avg Acc: 0.3805
2022-01-16 03:14:25,408 Epoch[099/300], Step[1100/1252], Avg Loss: 3.5779, Avg Acc: 0.3820
2022-01-16 03:15:52,676 Epoch[099/300], Step[1150/1252], Avg Loss: 3.5826, Avg Acc: 0.3785
2022-01-16 03:17:21,057 Epoch[099/300], Step[1200/1252], Avg Loss: 3.5849, Avg Acc: 0.3778
2022-01-16 03:18:50,141 Epoch[099/300], Step[1250/1252], Avg Loss: 3.5859, Avg Acc: 0.3784
2022-01-16 03:18:57,211 ----- Epoch[099/300], Train Loss: 3.5859, Train Acc: 0.3784, time: 2305.19
2022-01-16 03:18:57,212 Now training epoch 100. LR=0.000814
2022-01-16 03:20:43,316 Epoch[100/300], Step[0000/1252], Avg Loss: 2.4824, Avg Acc: 0.0078
2022-01-16 03:22:11,453 Epoch[100/300], Step[0050/1252], Avg Loss: 3.4928, Avg Acc: 0.4078
2022-01-16 03:23:39,569 Epoch[100/300], Step[0100/1252], Avg Loss: 3.5154, Avg Acc: 0.3875
2022-01-16 03:25:07,640 Epoch[100/300], Step[0150/1252], Avg Loss: 3.5529, Avg Acc: 0.3942
2022-01-16 03:26:35,099 Epoch[100/300], Step[0200/1252], Avg Loss: 3.5538, Avg Acc: 0.3968
2022-01-16 03:28:03,234 Epoch[100/300], Step[0250/1252], Avg Loss: 3.5438, Avg Acc: 0.3905
2022-01-16 03:29:31,365 Epoch[100/300], Step[0300/1252], Avg Loss: 3.5437, Avg Acc: 0.4037
2022-01-16 03:31:00,181 Epoch[100/300], Step[0350/1252], Avg Loss: 3.5465, Avg Acc: 0.3969
2022-01-16 03:32:29,259 Epoch[100/300], Step[0400/1252], Avg Loss: 3.5716, Avg Acc: 0.3970
2022-01-16 03:33:57,983 Epoch[100/300], Step[0450/1252], Avg Loss: 3.5811, Avg Acc: 0.3971
2022-01-16 03:35:25,603 Epoch[100/300], Step[0500/1252], Avg Loss: 3.5880, Avg Acc: 0.3999
2022-01-16 03:36:52,035 Epoch[100/300], Step[0550/1252], Avg Loss: 3.5838, Avg Acc: 0.4034
2022-01-16 03:38:19,672 Epoch[100/300], Step[0600/1252], Avg Loss: 3.5984, Avg Acc: 0.3984
2022-01-16 03:39:45,878 Epoch[100/300], Step[0650/1252], Avg Loss: 3.5946, Avg Acc: 0.3976
2022-01-16 03:41:14,412 Epoch[100/300], Step[0700/1252], Avg Loss: 3.5924, Avg Acc: 0.4011
2022-01-16 03:42:42,169 Epoch[100/300], Step[0750/1252], Avg Loss: 3.5900, Avg Acc: 0.3977
2022-01-16 03:44:12,067 Epoch[100/300], Step[0800/1252], Avg Loss: 3.5932, Avg Acc: 0.3985
2022-01-16 03:45:41,623 Epoch[100/300], Step[0850/1252], Avg Loss: 3.5934, Avg Acc: 0.3964
2022-01-16 03:47:10,080 Epoch[100/300], Step[0900/1252], Avg Loss: 3.6019, Avg Acc: 0.3951
2022-01-16 03:48:39,351 Epoch[100/300], Step[0950/1252], Avg Loss: 3.5995, Avg Acc: 0.3917
2022-01-16 03:50:08,553 Epoch[100/300], Step[1000/1252], Avg Loss: 3.6027, Avg Acc: 0.3917
2022-01-16 03:51:38,384 Epoch[100/300], Step[1050/1252], Avg Loss: 3.6055, Avg Acc: 0.3889
2022-01-16 03:53:07,948 Epoch[100/300], Step[1100/1252], Avg Loss: 3.6000, Avg Acc: 0.3875
2022-01-16 03:54:36,557 Epoch[100/300], Step[1150/1252], Avg Loss: 3.6027, Avg Acc: 0.3885
2022-01-16 03:56:04,856 Epoch[100/300], Step[1200/1252], Avg Loss: 3.6047, Avg Acc: 0.3892
2022-01-16 03:57:34,502 Epoch[100/300], Step[1250/1252], Avg Loss: 3.6066, Avg Acc: 0.3887
2022-01-16 03:57:41,543 ----- Epoch[100/300], Train Loss: 3.6066, Train Acc: 0.3886, time: 2324.33
2022-01-16 03:57:41,544 ----- Validation after Epoch: 100
2022-01-16 03:58:56,083 Val Step[0000/1563], Avg Loss: 0.8997, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-16 03:58:57,951 Val Step[0050/1563], Avg Loss: 1.1680, Avg Acc@1: 0.7181, Avg Acc@5: 0.9412
2022-01-16 03:58:59,782 Val Step[0100/1563], Avg Loss: 1.1847, Avg Acc@1: 0.7277, Avg Acc@5: 0.9257
2022-01-16 03:59:01,800 Val Step[0150/1563], Avg Loss: 1.2852, Avg Acc@1: 0.7136, Avg Acc@5: 0.9081
2022-01-16 03:59:03,848 Val Step[0200/1563], Avg Loss: 1.2709, Avg Acc@1: 0.7183, Avg Acc@5: 0.9073
2022-01-16 03:59:05,927 Val Step[0250/1563], Avg Loss: 1.2836, Avg Acc@1: 0.7176, Avg Acc@5: 0.9069
2022-01-16 03:59:08,030 Val Step[0300/1563], Avg Loss: 1.2940, Avg Acc@1: 0.7110, Avg Acc@5: 0.9061
2022-01-16 03:59:10,061 Val Step[0350/1563], Avg Loss: 1.3231, Avg Acc@1: 0.7033, Avg Acc@5: 0.9031
2022-01-16 03:59:12,099 Val Step[0400/1563], Avg Loss: 1.3127, Avg Acc@1: 0.7054, Avg Acc@5: 0.9052
2022-01-16 03:59:14,147 Val Step[0450/1563], Avg Loss: 1.3213, Avg Acc@1: 0.7018, Avg Acc@5: 0.9027
2022-01-16 03:59:16,195 Val Step[0500/1563], Avg Loss: 1.3313, Avg Acc@1: 0.6996, Avg Acc@5: 0.9002
2022-01-16 03:59:18,260 Val Step[0550/1563], Avg Loss: 1.3233, Avg Acc@1: 0.7012, Avg Acc@5: 0.9011
2022-01-16 03:59:20,077 Val Step[0600/1563], Avg Loss: 1.3224, Avg Acc@1: 0.7007, Avg Acc@5: 0.9006
2022-01-16 03:59:21,898 Val Step[0650/1563], Avg Loss: 1.3208, Avg Acc@1: 0.6997, Avg Acc@5: 0.9017
2022-01-16 03:59:23,686 Val Step[0700/1563], Avg Loss: 1.3165, Avg Acc@1: 0.7015, Avg Acc@5: 0.9023
2022-01-16 03:59:25,469 Val Step[0750/1563], Avg Loss: 1.3221, Avg Acc@1: 0.7006, Avg Acc@5: 0.9025
2022-01-16 03:59:27,355 Val Step[0800/1563], Avg Loss: 1.3265, Avg Acc@1: 0.7021, Avg Acc@5: 0.9001
2022-01-16 03:59:29,233 Val Step[0850/1563], Avg Loss: 1.3305, Avg Acc@1: 0.7008, Avg Acc@5: 0.8997
2022-01-16 03:59:31,023 Val Step[0900/1563], Avg Loss: 1.3224, Avg Acc@1: 0.7038, Avg Acc@5: 0.8996
2022-01-16 03:59:32,818 Val Step[0950/1563], Avg Loss: 1.3193, Avg Acc@1: 0.7039, Avg Acc@5: 0.8992
2022-01-16 03:59:34,807 Val Step[1000/1563], Avg Loss: 1.3177, Avg Acc@1: 0.7038, Avg Acc@5: 0.9000
2022-01-16 03:59:36,728 Val Step[1050/1563], Avg Loss: 1.3194, Avg Acc@1: 0.7025, Avg Acc@5: 0.8987
2022-01-16 03:59:38,589 Val Step[1100/1563], Avg Loss: 1.3281, Avg Acc@1: 0.7010, Avg Acc@5: 0.8978
2022-01-16 03:59:40,384 Val Step[1150/1563], Avg Loss: 1.3294, Avg Acc@1: 0.7015, Avg Acc@5: 0.8977
2022-01-16 03:59:42,290 Val Step[1200/1563], Avg Loss: 1.3234, Avg Acc@1: 0.7030, Avg Acc@5: 0.8985
2022-01-16 03:59:44,103 Val Step[1250/1563], Avg Loss: 1.3257, Avg Acc@1: 0.7024, Avg Acc@5: 0.8983
2022-01-16 03:59:45,888 Val Step[1300/1563], Avg Loss: 1.3301, Avg Acc@1: 0.7021, Avg Acc@5: 0.8981
2022-01-16 03:59:47,706 Val Step[1350/1563], Avg Loss: 1.3327, Avg Acc@1: 0.7015, Avg Acc@5: 0.8974
2022-01-16 03:59:49,492 Val Step[1400/1563], Avg Loss: 1.3312, Avg Acc@1: 0.7017, Avg Acc@5: 0.8977
2022-01-16 03:59:51,270 Val Step[1450/1563], Avg Loss: 1.3283, Avg Acc@1: 0.7019, Avg Acc@5: 0.8981
2022-01-16 03:59:53,054 Val Step[1500/1563], Avg Loss: 1.3264, Avg Acc@1: 0.7024, Avg Acc@5: 0.8987
2022-01-16 03:59:54,789 Val Step[1550/1563], Avg Loss: 1.3270, Avg Acc@1: 0.7022, Avg Acc@5: 0.8985
2022-01-16 03:59:56,753 ----- Epoch[100/300], Validation Loss: 1.3293, Validation Acc@1: 0.7016, Validation Acc@5: 0.8984, time: 135.21
2022-01-16 03:59:56,754 Now training epoch 101. LR=0.000809
2022-01-16 04:01:49,510 Epoch[101/300], Step[0000/1252], Avg Loss: 3.7535, Avg Acc: 0.5742
2022-01-16 04:03:17,184 Epoch[101/300], Step[0050/1252], Avg Loss: 3.5038, Avg Acc: 0.4189
2022-01-16 04:04:43,958 Epoch[101/300], Step[0100/1252], Avg Loss: 3.4996, Avg Acc: 0.4024
2022-01-16 04:06:12,265 Epoch[101/300], Step[0150/1252], Avg Loss: 3.5649, Avg Acc: 0.3920
2022-01-16 04:07:39,257 Epoch[101/300], Step[0200/1252], Avg Loss: 3.5774, Avg Acc: 0.3854
2022-01-16 04:09:06,580 Epoch[101/300], Step[0250/1252], Avg Loss: 3.5674, Avg Acc: 0.3830
2022-01-16 04:10:34,686 Epoch[101/300], Step[0300/1252], Avg Loss: 3.5795, Avg Acc: 0.3895
2022-01-16 04:12:03,190 Epoch[101/300], Step[0350/1252], Avg Loss: 3.5806, Avg Acc: 0.3773
2022-01-16 04:13:31,610 Epoch[101/300], Step[0400/1252], Avg Loss: 3.5620, Avg Acc: 0.3776
2022-01-16 04:14:59,779 Epoch[101/300], Step[0450/1252], Avg Loss: 3.5506, Avg Acc: 0.3819
2022-01-16 04:16:27,218 Epoch[101/300], Step[0500/1252], Avg Loss: 3.5485, Avg Acc: 0.3844
2022-01-16 04:17:54,857 Epoch[101/300], Step[0550/1252], Avg Loss: 3.5532, Avg Acc: 0.3814
2022-01-16 04:19:21,891 Epoch[101/300], Step[0600/1252], Avg Loss: 3.5478, Avg Acc: 0.3842
2022-01-16 04:20:49,979 Epoch[101/300], Step[0650/1252], Avg Loss: 3.5569, Avg Acc: 0.3814
2022-01-16 04:22:18,356 Epoch[101/300], Step[0700/1252], Avg Loss: 3.5607, Avg Acc: 0.3824
2022-01-16 04:23:46,270 Epoch[101/300], Step[0750/1252], Avg Loss: 3.5624, Avg Acc: 0.3807
2022-01-16 04:25:14,432 Epoch[101/300], Step[0800/1252], Avg Loss: 3.5534, Avg Acc: 0.3776
2022-01-16 04:26:42,750 Epoch[101/300], Step[0850/1252], Avg Loss: 3.5502, Avg Acc: 0.3748
2022-01-16 04:28:10,748 Epoch[101/300], Step[0900/1252], Avg Loss: 3.5574, Avg Acc: 0.3760
2022-01-16 04:29:38,104 Epoch[101/300], Step[0950/1252], Avg Loss: 3.5625, Avg Acc: 0.3778
2022-01-16 04:31:06,556 Epoch[101/300], Step[1000/1252], Avg Loss: 3.5626, Avg Acc: 0.3751
2022-01-16 04:32:33,478 Epoch[101/300], Step[1050/1252], Avg Loss: 3.5647, Avg Acc: 0.3753
2022-01-16 04:34:01,767 Epoch[101/300], Step[1100/1252], Avg Loss: 3.5660, Avg Acc: 0.3767
2022-01-16 04:35:29,985 Epoch[101/300], Step[1150/1252], Avg Loss: 3.5691, Avg Acc: 0.3765
2022-01-16 04:36:58,129 Epoch[101/300], Step[1200/1252], Avg Loss: 3.5708, Avg Acc: 0.3767
2022-01-16 04:38:26,926 Epoch[101/300], Step[1250/1252], Avg Loss: 3.5707, Avg Acc: 0.3751
2022-01-16 04:38:34,053 ----- Epoch[101/300], Train Loss: 3.5707, Train Acc: 0.3751, time: 2317.30
2022-01-16 04:38:34,054 Now training epoch 102. LR=0.000805
2022-01-16 04:40:18,857 Epoch[102/300], Step[0000/1252], Avg Loss: 2.7377, Avg Acc: 0.6562
2022-01-16 04:41:46,318 Epoch[102/300], Step[0050/1252], Avg Loss: 3.5092, Avg Acc: 0.3890
2022-01-16 04:43:13,306 Epoch[102/300], Step[0100/1252], Avg Loss: 3.5647, Avg Acc: 0.3822
2022-01-16 04:44:41,626 Epoch[102/300], Step[0150/1252], Avg Loss: 3.5554, Avg Acc: 0.3700
2022-01-16 04:46:08,713 Epoch[102/300], Step[0200/1252], Avg Loss: 3.5588, Avg Acc: 0.3819
2022-01-16 04:47:37,296 Epoch[102/300], Step[0250/1252], Avg Loss: 3.5749, Avg Acc: 0.3738
2022-01-16 04:49:05,505 Epoch[102/300], Step[0300/1252], Avg Loss: 3.5573, Avg Acc: 0.3768
2022-01-16 04:50:33,021 Epoch[102/300], Step[0350/1252], Avg Loss: 3.5682, Avg Acc: 0.3795
2022-01-16 04:52:00,231 Epoch[102/300], Step[0400/1252], Avg Loss: 3.5542, Avg Acc: 0.3870
2022-01-16 04:53:28,625 Epoch[102/300], Step[0450/1252], Avg Loss: 3.5529, Avg Acc: 0.3789
2022-01-16 04:54:56,137 Epoch[102/300], Step[0500/1252], Avg Loss: 3.5639, Avg Acc: 0.3789
2022-01-16 04:56:24,080 Epoch[102/300], Step[0550/1252], Avg Loss: 3.5666, Avg Acc: 0.3775
2022-01-16 04:57:52,339 Epoch[102/300], Step[0600/1252], Avg Loss: 3.5645, Avg Acc: 0.3782
2022-01-16 04:59:18,666 Epoch[102/300], Step[0650/1252], Avg Loss: 3.5578, Avg Acc: 0.3784
2022-01-16 05:00:46,408 Epoch[102/300], Step[0700/1252], Avg Loss: 3.5662, Avg Acc: 0.3751
2022-01-16 05:02:14,697 Epoch[102/300], Step[0750/1252], Avg Loss: 3.5638, Avg Acc: 0.3758
2022-01-16 05:03:41,051 Epoch[102/300], Step[0800/1252], Avg Loss: 3.5695, Avg Acc: 0.3756
2022-01-16 05:05:07,401 Epoch[102/300], Step[0850/1252], Avg Loss: 3.5801, Avg Acc: 0.3727
2022-01-16 05:06:35,283 Epoch[102/300], Step[0900/1252], Avg Loss: 3.5794, Avg Acc: 0.3729
2022-01-16 05:08:02,791 Epoch[102/300], Step[0950/1252], Avg Loss: 3.5765, Avg Acc: 0.3748
2022-01-16 05:09:31,176 Epoch[102/300], Step[1000/1252], Avg Loss: 3.5738, Avg Acc: 0.3746
2022-01-16 05:11:00,258 Epoch[102/300], Step[1050/1252], Avg Loss: 3.5754, Avg Acc: 0.3749
2022-01-16 05:12:27,498 Epoch[102/300], Step[1100/1252], Avg Loss: 3.5773, Avg Acc: 0.3775
2022-01-16 05:13:54,630 Epoch[102/300], Step[1150/1252], Avg Loss: 3.5783, Avg Acc: 0.3779
2022-01-16 05:15:23,427 Epoch[102/300], Step[1200/1252], Avg Loss: 3.5805, Avg Acc: 0.3781
2022-01-16 05:16:52,168 Epoch[102/300], Step[1250/1252], Avg Loss: 3.5820, Avg Acc: 0.3780
2022-01-16 05:16:59,298 ----- Epoch[102/300], Train Loss: 3.5819, Train Acc: 0.3780, time: 2305.24
2022-01-16 05:16:59,299 ----- Validation after Epoch: 102
2022-01-16 05:18:11,373 Val Step[0000/1563], Avg Loss: 1.0292, Avg Acc@1: 0.7500, Avg Acc@5: 1.0000
2022-01-16 05:18:13,308 Val Step[0050/1563], Avg Loss: 1.2260, Avg Acc@1: 0.7377, Avg Acc@5: 0.9289
2022-01-16 05:18:15,143 Val Step[0100/1563], Avg Loss: 1.2323, Avg Acc@1: 0.7228, Avg Acc@5: 0.9245
2022-01-16 05:18:16,985 Val Step[0150/1563], Avg Loss: 1.3243, Avg Acc@1: 0.7028, Avg Acc@5: 0.9056
2022-01-16 05:18:18,867 Val Step[0200/1563], Avg Loss: 1.3047, Avg Acc@1: 0.7083, Avg Acc@5: 0.9067
2022-01-16 05:18:20,733 Val Step[0250/1563], Avg Loss: 1.3010, Avg Acc@1: 0.7107, Avg Acc@5: 0.9059
2022-01-16 05:18:22,645 Val Step[0300/1563], Avg Loss: 1.3066, Avg Acc@1: 0.7110, Avg Acc@5: 0.9037
2022-01-16 05:18:24,497 Val Step[0350/1563], Avg Loss: 1.3299, Avg Acc@1: 0.7058, Avg Acc@5: 0.9035
2022-01-16 05:18:26,338 Val Step[0400/1563], Avg Loss: 1.3192, Avg Acc@1: 0.7076, Avg Acc@5: 0.9043
2022-01-16 05:18:28,203 Val Step[0450/1563], Avg Loss: 1.3292, Avg Acc@1: 0.7037, Avg Acc@5: 0.9033
2022-01-16 05:18:30,027 Val Step[0500/1563], Avg Loss: 1.3361, Avg Acc@1: 0.6999, Avg Acc@5: 0.9019
2022-01-16 05:18:31,829 Val Step[0550/1563], Avg Loss: 1.3291, Avg Acc@1: 0.7026, Avg Acc@5: 0.9022
2022-01-16 05:18:33,641 Val Step[0600/1563], Avg Loss: 1.3266, Avg Acc@1: 0.7015, Avg Acc@5: 0.9022
2022-01-16 05:18:35,521 Val Step[0650/1563], Avg Loss: 1.3223, Avg Acc@1: 0.7005, Avg Acc@5: 0.9028
2022-01-16 05:18:37,612 Val Step[0700/1563], Avg Loss: 1.3174, Avg Acc@1: 0.7020, Avg Acc@5: 0.9025
2022-01-16 05:18:39,648 Val Step[0750/1563], Avg Loss: 1.3222, Avg Acc@1: 0.7007, Avg Acc@5: 0.9016
2022-01-16 05:18:41,691 Val Step[0800/1563], Avg Loss: 1.3267, Avg Acc@1: 0.7019, Avg Acc@5: 0.9003
2022-01-16 05:18:43,745 Val Step[0850/1563], Avg Loss: 1.3307, Avg Acc@1: 0.6993, Avg Acc@5: 0.8992
2022-01-16 05:18:45,659 Val Step[0900/1563], Avg Loss: 1.3249, Avg Acc@1: 0.7010, Avg Acc@5: 0.8998
2022-01-16 05:18:47,516 Val Step[0950/1563], Avg Loss: 1.3202, Avg Acc@1: 0.7035, Avg Acc@5: 0.9002
2022-01-16 05:18:49,391 Val Step[1000/1563], Avg Loss: 1.3186, Avg Acc@1: 0.7042, Avg Acc@5: 0.9008
2022-01-16 05:18:51,197 Val Step[1050/1563], Avg Loss: 1.3204, Avg Acc@1: 0.7030, Avg Acc@5: 0.9006
2022-01-16 05:18:52,992 Val Step[1100/1563], Avg Loss: 1.3286, Avg Acc@1: 0.7007, Avg Acc@5: 0.8994
2022-01-16 05:18:54,783 Val Step[1150/1563], Avg Loss: 1.3318, Avg Acc@1: 0.6997, Avg Acc@5: 0.8992
2022-01-16 05:18:56,609 Val Step[1200/1563], Avg Loss: 1.3273, Avg Acc@1: 0.7009, Avg Acc@5: 0.9001
2022-01-16 05:18:58,514 Val Step[1250/1563], Avg Loss: 1.3297, Avg Acc@1: 0.7003, Avg Acc@5: 0.8993
2022-01-16 05:19:00,571 Val Step[1300/1563], Avg Loss: 1.3344, Avg Acc@1: 0.6992, Avg Acc@5: 0.8986
2022-01-16 05:19:02,635 Val Step[1350/1563], Avg Loss: 1.3391, Avg Acc@1: 0.6986, Avg Acc@5: 0.8976
2022-01-16 05:19:04,710 Val Step[1400/1563], Avg Loss: 1.3378, Avg Acc@1: 0.6988, Avg Acc@5: 0.8974
2022-01-16 05:19:06,804 Val Step[1450/1563], Avg Loss: 1.3340, Avg Acc@1: 0.6991, Avg Acc@5: 0.8981
2022-01-16 05:19:08,910 Val Step[1500/1563], Avg Loss: 1.3325, Avg Acc@1: 0.6990, Avg Acc@5: 0.8985
2022-01-16 05:19:10,968 Val Step[1550/1563], Avg Loss: 1.3327, Avg Acc@1: 0.6985, Avg Acc@5: 0.8984
2022-01-16 05:19:12,884 ----- Epoch[102/300], Validation Loss: 1.3350, Validation Acc@1: 0.6978, Validation Acc@5: 0.8985, time: 133.58
2022-01-16 05:19:12,885 Now training epoch 103. LR=0.000800
2022-01-16 05:20:57,882 Epoch[103/300], Step[0000/1252], Avg Loss: 4.1459, Avg Acc: 0.1367
2022-01-16 05:22:26,229 Epoch[103/300], Step[0050/1252], Avg Loss: 3.7450, Avg Acc: 0.2999
2022-01-16 05:23:53,568 Epoch[103/300], Step[0100/1252], Avg Loss: 3.6237, Avg Acc: 0.3540
2022-01-16 05:25:19,997 Epoch[103/300], Step[0150/1252], Avg Loss: 3.6169, Avg Acc: 0.3675
2022-01-16 05:26:48,273 Epoch[103/300], Step[0200/1252], Avg Loss: 3.5754, Avg Acc: 0.3807
2022-01-16 05:28:15,247 Epoch[103/300], Step[0250/1252], Avg Loss: 3.5634, Avg Acc: 0.3841
2022-01-16 05:29:43,747 Epoch[103/300], Step[0300/1252], Avg Loss: 3.5743, Avg Acc: 0.3705
2022-01-16 05:31:10,725 Epoch[103/300], Step[0350/1252], Avg Loss: 3.5467, Avg Acc: 0.3752
2022-01-16 05:32:38,307 Epoch[103/300], Step[0400/1252], Avg Loss: 3.5535, Avg Acc: 0.3794
2022-01-16 05:34:05,942 Epoch[103/300], Step[0450/1252], Avg Loss: 3.5508, Avg Acc: 0.3756
2022-01-16 05:35:33,941 Epoch[103/300], Step[0500/1252], Avg Loss: 3.5577, Avg Acc: 0.3744
2022-01-16 05:37:02,524 Epoch[103/300], Step[0550/1252], Avg Loss: 3.5600, Avg Acc: 0.3752
2022-01-16 05:38:30,988 Epoch[103/300], Step[0600/1252], Avg Loss: 3.5555, Avg Acc: 0.3736
2022-01-16 05:40:00,300 Epoch[103/300], Step[0650/1252], Avg Loss: 3.5616, Avg Acc: 0.3742
2022-01-16 05:41:29,217 Epoch[103/300], Step[0700/1252], Avg Loss: 3.5575, Avg Acc: 0.3761
2022-01-16 05:42:58,456 Epoch[103/300], Step[0750/1252], Avg Loss: 3.5613, Avg Acc: 0.3745
2022-01-16 05:44:26,375 Epoch[103/300], Step[0800/1252], Avg Loss: 3.5562, Avg Acc: 0.3779
2022-01-16 05:45:54,914 Epoch[103/300], Step[0850/1252], Avg Loss: 3.5562, Avg Acc: 0.3774
2022-01-16 05:47:22,949 Epoch[103/300], Step[0900/1252], Avg Loss: 3.5571, Avg Acc: 0.3787
2022-01-16 05:48:51,085 Epoch[103/300], Step[0950/1252], Avg Loss: 3.5653, Avg Acc: 0.3763
2022-01-16 05:50:19,399 Epoch[103/300], Step[1000/1252], Avg Loss: 3.5588, Avg Acc: 0.3757
2022-01-16 05:51:45,201 Epoch[103/300], Step[1050/1252], Avg Loss: 3.5662, Avg Acc: 0.3733
2022-01-16 05:53:12,054 Epoch[103/300], Step[1100/1252], Avg Loss: 3.5653, Avg Acc: 0.3731
2022-01-16 05:54:38,796 Epoch[103/300], Step[1150/1252], Avg Loss: 3.5656, Avg Acc: 0.3752
2022-01-16 05:56:06,914 Epoch[103/300], Step[1200/1252], Avg Loss: 3.5698, Avg Acc: 0.3749
2022-01-16 05:57:35,581 Epoch[103/300], Step[1250/1252], Avg Loss: 3.5658, Avg Acc: 0.3770
2022-01-16 05:57:42,828 ----- Epoch[103/300], Train Loss: 3.5658, Train Acc: 0.3770, time: 2309.94
2022-01-16 05:57:42,829 Now training epoch 104. LR=0.000796
2022-01-16 05:59:29,811 Epoch[104/300], Step[0000/1252], Avg Loss: 4.2143, Avg Acc: 0.1094
2022-01-16 06:00:57,591 Epoch[104/300], Step[0050/1252], Avg Loss: 3.4645, Avg Acc: 0.3614
2022-01-16 06:02:24,074 Epoch[104/300], Step[0100/1252], Avg Loss: 3.4936, Avg Acc: 0.3721
2022-01-16 06:03:53,130 Epoch[104/300], Step[0150/1252], Avg Loss: 3.5202, Avg Acc: 0.3607
2022-01-16 06:05:22,059 Epoch[104/300], Step[0200/1252], Avg Loss: 3.5180, Avg Acc: 0.3618
2022-01-16 06:06:50,491 Epoch[104/300], Step[0250/1252], Avg Loss: 3.5136, Avg Acc: 0.3640
2022-01-16 06:08:17,610 Epoch[104/300], Step[0300/1252], Avg Loss: 3.5431, Avg Acc: 0.3674
2022-01-16 06:09:45,641 Epoch[104/300], Step[0350/1252], Avg Loss: 3.5261, Avg Acc: 0.3793
2022-01-16 06:11:14,014 Epoch[104/300], Step[0400/1252], Avg Loss: 3.5497, Avg Acc: 0.3817
2022-01-16 06:12:42,050 Epoch[104/300], Step[0450/1252], Avg Loss: 3.5377, Avg Acc: 0.3800
2022-01-16 06:14:10,666 Epoch[104/300], Step[0500/1252], Avg Loss: 3.5408, Avg Acc: 0.3796
2022-01-16 06:15:39,733 Epoch[104/300], Step[0550/1252], Avg Loss: 3.5430, Avg Acc: 0.3777
2022-01-16 06:17:09,415 Epoch[104/300], Step[0600/1252], Avg Loss: 3.5520, Avg Acc: 0.3771
2022-01-16 06:18:38,849 Epoch[104/300], Step[0650/1252], Avg Loss: 3.5498, Avg Acc: 0.3753
2022-01-16 06:20:07,133 Epoch[104/300], Step[0700/1252], Avg Loss: 3.5539, Avg Acc: 0.3762
2022-01-16 06:21:35,461 Epoch[104/300], Step[0750/1252], Avg Loss: 3.5545, Avg Acc: 0.3777
2022-01-16 06:23:04,453 Epoch[104/300], Step[0800/1252], Avg Loss: 3.5514, Avg Acc: 0.3736
2022-01-16 06:24:32,582 Epoch[104/300], Step[0850/1252], Avg Loss: 3.5580, Avg Acc: 0.3697
2022-01-16 06:26:01,388 Epoch[104/300], Step[0900/1252], Avg Loss: 3.5587, Avg Acc: 0.3735
2022-01-16 06:27:29,287 Epoch[104/300], Step[0950/1252], Avg Loss: 3.5557, Avg Acc: 0.3765
2022-01-16 06:28:57,284 Epoch[104/300], Step[1000/1252], Avg Loss: 3.5554, Avg Acc: 0.3791
2022-01-16 06:30:24,372 Epoch[104/300], Step[1050/1252], Avg Loss: 3.5595, Avg Acc: 0.3777
2022-01-16 06:31:52,095 Epoch[104/300], Step[1100/1252], Avg Loss: 3.5621, Avg Acc: 0.3749
2022-01-16 06:33:20,014 Epoch[104/300], Step[1150/1252], Avg Loss: 3.5596, Avg Acc: 0.3771
2022-01-16 06:34:47,525 Epoch[104/300], Step[1200/1252], Avg Loss: 3.5613, Avg Acc: 0.3767
2022-01-16 06:36:15,235 Epoch[104/300], Step[1250/1252], Avg Loss: 3.5629, Avg Acc: 0.3749
2022-01-16 06:36:22,466 ----- Epoch[104/300], Train Loss: 3.5630, Train Acc: 0.3749, time: 2319.63
2022-01-16 06:36:22,467 ----- Validation after Epoch: 104
2022-01-16 06:37:32,196 Val Step[0000/1563], Avg Loss: 0.9166, Avg Acc@1: 0.8750, Avg Acc@5: 0.8750
2022-01-16 06:37:34,512 Val Step[0050/1563], Avg Loss: 1.2477, Avg Acc@1: 0.7157, Avg Acc@5: 0.9363
2022-01-16 06:37:36,282 Val Step[0100/1563], Avg Loss: 1.2557, Avg Acc@1: 0.7116, Avg Acc@5: 0.9295
2022-01-16 06:37:38,058 Val Step[0150/1563], Avg Loss: 1.3452, Avg Acc@1: 0.7061, Avg Acc@5: 0.9106
2022-01-16 06:37:39,851 Val Step[0200/1563], Avg Loss: 1.3287, Avg Acc@1: 0.7102, Avg Acc@5: 0.9117
2022-01-16 06:37:41,638 Val Step[0250/1563], Avg Loss: 1.3401, Avg Acc@1: 0.7117, Avg Acc@5: 0.9109
2022-01-16 06:37:43,422 Val Step[0300/1563], Avg Loss: 1.3436, Avg Acc@1: 0.7089, Avg Acc@5: 0.9086
2022-01-16 06:37:45,324 Val Step[0350/1563], Avg Loss: 1.3622, Avg Acc@1: 0.7051, Avg Acc@5: 0.9063
2022-01-16 06:37:47,110 Val Step[0400/1563], Avg Loss: 1.3492, Avg Acc@1: 0.7082, Avg Acc@5: 0.9077
2022-01-16 06:37:48,887 Val Step[0450/1563], Avg Loss: 1.3619, Avg Acc@1: 0.7043, Avg Acc@5: 0.9049
2022-01-16 06:37:50,660 Val Step[0500/1563], Avg Loss: 1.3681, Avg Acc@1: 0.7011, Avg Acc@5: 0.9057
2022-01-16 06:37:52,565 Val Step[0550/1563], Avg Loss: 1.3623, Avg Acc@1: 0.7015, Avg Acc@5: 0.9063
2022-01-16 06:37:54,498 Val Step[0600/1563], Avg Loss: 1.3626, Avg Acc@1: 0.7013, Avg Acc@5: 0.9062
2022-01-16 06:37:56,383 Val Step[0650/1563], Avg Loss: 1.3585, Avg Acc@1: 0.7008, Avg Acc@5: 0.9075
2022-01-16 06:37:58,195 Val Step[0700/1563], Avg Loss: 1.3569, Avg Acc@1: 0.7010, Avg Acc@5: 0.9071
2022-01-16 06:38:00,098 Val Step[0750/1563], Avg Loss: 1.3607, Avg Acc@1: 0.7014, Avg Acc@5: 0.9060
2022-01-16 06:38:02,020 Val Step[0800/1563], Avg Loss: 1.3618, Avg Acc@1: 0.7032, Avg Acc@5: 0.9045
2022-01-16 06:38:03,912 Val Step[0850/1563], Avg Loss: 1.3645, Avg Acc@1: 0.7014, Avg Acc@5: 0.9042
2022-01-16 06:38:05,754 Val Step[0900/1563], Avg Loss: 1.3576, Avg Acc@1: 0.7031, Avg Acc@5: 0.9043
2022-01-16 06:38:07,606 Val Step[0950/1563], Avg Loss: 1.3547, Avg Acc@1: 0.7040, Avg Acc@5: 0.9048
2022-01-16 06:38:09,541 Val Step[1000/1563], Avg Loss: 1.3541, Avg Acc@1: 0.7044, Avg Acc@5: 0.9053
2022-01-16 06:38:11,472 Val Step[1050/1563], Avg Loss: 1.3561, Avg Acc@1: 0.7036, Avg Acc@5: 0.9045
2022-01-16 06:38:13,282 Val Step[1100/1563], Avg Loss: 1.3640, Avg Acc@1: 0.7024, Avg Acc@5: 0.9035
2022-01-16 06:38:15,115 Val Step[1150/1563], Avg Loss: 1.3667, Avg Acc@1: 0.7012, Avg Acc@5: 0.9025
2022-01-16 06:38:16,928 Val Step[1200/1563], Avg Loss: 1.3635, Avg Acc@1: 0.7023, Avg Acc@5: 0.9026
2022-01-16 06:38:18,723 Val Step[1250/1563], Avg Loss: 1.3637, Avg Acc@1: 0.7025, Avg Acc@5: 0.9022
2022-01-16 06:38:20,511 Val Step[1300/1563], Avg Loss: 1.3671, Avg Acc@1: 0.7018, Avg Acc@5: 0.9016
2022-01-16 06:38:22,360 Val Step[1350/1563], Avg Loss: 1.3717, Avg Acc@1: 0.7016, Avg Acc@5: 0.9005
2022-01-16 06:38:24,130 Val Step[1400/1563], Avg Loss: 1.3701, Avg Acc@1: 0.7022, Avg Acc@5: 0.9006
2022-01-16 06:38:25,905 Val Step[1450/1563], Avg Loss: 1.3697, Avg Acc@1: 0.7016, Avg Acc@5: 0.9009
2022-01-16 06:38:27,791 Val Step[1500/1563], Avg Loss: 1.3675, Avg Acc@1: 0.7022, Avg Acc@5: 0.9009
2022-01-16 06:38:29,584 Val Step[1550/1563], Avg Loss: 1.3681, Avg Acc@1: 0.7017, Avg Acc@5: 0.9010
2022-01-16 06:38:31,563 ----- Epoch[104/300], Validation Loss: 1.3705, Validation Acc@1: 0.7010, Validation Acc@5: 0.9010, time: 129.08
2022-01-16 06:38:31,564 Now training epoch 105. LR=0.000791
2022-01-16 06:40:16,038 Epoch[105/300], Step[0000/1252], Avg Loss: 3.8893, Avg Acc: 0.5195
2022-01-16 06:41:43,159 Epoch[105/300], Step[0050/1252], Avg Loss: 3.6064, Avg Acc: 0.3944
2022-01-16 06:43:09,809 Epoch[105/300], Step[0100/1252], Avg Loss: 3.5501, Avg Acc: 0.3657
2022-01-16 06:44:37,424 Epoch[105/300], Step[0150/1252], Avg Loss: 3.5668, Avg Acc: 0.3658
2022-01-16 06:46:04,684 Epoch[105/300], Step[0200/1252], Avg Loss: 3.5765, Avg Acc: 0.3748
2022-01-16 06:47:31,482 Epoch[105/300], Step[0250/1252], Avg Loss: 3.5791, Avg Acc: 0.3761
2022-01-16 06:48:59,507 Epoch[105/300], Step[0300/1252], Avg Loss: 3.5716, Avg Acc: 0.3728
2022-01-16 06:50:25,580 Epoch[105/300], Step[0350/1252], Avg Loss: 3.5867, Avg Acc: 0.3751
2022-01-16 06:51:51,734 Epoch[105/300], Step[0400/1252], Avg Loss: 3.5974, Avg Acc: 0.3772
2022-01-16 06:53:18,569 Epoch[105/300], Step[0450/1252], Avg Loss: 3.5990, Avg Acc: 0.3765
2022-01-16 06:54:44,595 Epoch[105/300], Step[0500/1252], Avg Loss: 3.5710, Avg Acc: 0.3859
2022-01-16 06:56:11,408 Epoch[105/300], Step[0550/1252], Avg Loss: 3.5640, Avg Acc: 0.3873
2022-01-16 06:57:36,377 Epoch[105/300], Step[0600/1252], Avg Loss: 3.5606, Avg Acc: 0.3887
2022-01-16 06:59:03,574 Epoch[105/300], Step[0650/1252], Avg Loss: 3.5585, Avg Acc: 0.3912
2022-01-16 07:00:31,317 Epoch[105/300], Step[0700/1252], Avg Loss: 3.5518, Avg Acc: 0.3925
2022-01-16 07:01:58,702 Epoch[105/300], Step[0750/1252], Avg Loss: 3.5448, Avg Acc: 0.3925
2022-01-16 07:03:27,387 Epoch[105/300], Step[0800/1252], Avg Loss: 3.5415, Avg Acc: 0.3901
2022-01-16 07:04:55,514 Epoch[105/300], Step[0850/1252], Avg Loss: 3.5457, Avg Acc: 0.3869
2022-01-16 07:06:23,583 Epoch[105/300], Step[0900/1252], Avg Loss: 3.5443, Avg Acc: 0.3860
2022-01-16 07:07:50,815 Epoch[105/300], Step[0950/1252], Avg Loss: 3.5476, Avg Acc: 0.3864
2022-01-16 07:09:18,525 Epoch[105/300], Step[1000/1252], Avg Loss: 3.5439, Avg Acc: 0.3847
2022-01-16 07:10:46,818 Epoch[105/300], Step[1050/1252], Avg Loss: 3.5505, Avg Acc: 0.3841
2022-01-16 07:12:15,596 Epoch[105/300], Step[1100/1252], Avg Loss: 3.5449, Avg Acc: 0.3825
2022-01-16 07:13:44,446 Epoch[105/300], Step[1150/1252], Avg Loss: 3.5416, Avg Acc: 0.3819
2022-01-16 07:15:13,186 Epoch[105/300], Step[1200/1252], Avg Loss: 3.5393, Avg Acc: 0.3820
2022-01-16 07:16:41,335 Epoch[105/300], Step[1250/1252], Avg Loss: 3.5399, Avg Acc: 0.3809
2022-01-16 07:16:48,571 ----- Epoch[105/300], Train Loss: 3.5398, Train Acc: 0.3810, time: 2297.00
2022-01-16 07:16:48,572 Now training epoch 106. LR=0.000787
